{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Darren_blog\n\n\n\u5f20\u5927\u9e4f\u4e2a\u4eba\u535a\u5ba2\n\n\nProject layout\n\n\ndocs/\n    index.md  \n    data_analysis/lagou_job_analysis/\u62c9\u52fe\u62db\u8058\u804c\u4f4d\u4fe1\u606f\u6570\u636e\u5206\u6790\n    data_analysis/p2p_runaway_analysis/p2p\u7f51\u7ad9\u8dd1\u8def\u5224\u522b\n    data_analysis/stocks_analysis/\u80a1\u7968\u7ebf\u6027\u56de\u5f52\u5206\u6790\n    machine_learning/logistic_regression/Logistic_regression\u7684Python\u4ee3\u7801\u5b9e\u73b0\n    machine_learning/perceptron_classifier/\u611f\u77e5\u5668python\u4ee3\u7801\u5b9e\u73b0\n    machine_learning/stock_index_classification/\u6caa\u6df1300\u80a1\u6307\u6da8\u8dcc\u9884\u6d4b\n    machine_learning/hs300_classification/\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6caa\u6df1300\u80a1\u7968\u6da8\u8dcc", 
            "title": "Darren_blog"
        }, 
        {
            "location": "/#welcome-to-darren_blog", 
            "text": "\u5f20\u5927\u9e4f\u4e2a\u4eba\u535a\u5ba2", 
            "title": "Welcome to Darren_blog"
        }, 
        {
            "location": "/#project-layout", 
            "text": "docs/\n    index.md  \n    data_analysis/lagou_job_analysis/\u62c9\u52fe\u62db\u8058\u804c\u4f4d\u4fe1\u606f\u6570\u636e\u5206\u6790\n    data_analysis/p2p_runaway_analysis/p2p\u7f51\u7ad9\u8dd1\u8def\u5224\u522b\n    data_analysis/stocks_analysis/\u80a1\u7968\u7ebf\u6027\u56de\u5f52\u5206\u6790\n    machine_learning/logistic_regression/Logistic_regression\u7684Python\u4ee3\u7801\u5b9e\u73b0\n    machine_learning/perceptron_classifier/\u611f\u77e5\u5668python\u4ee3\u7801\u5b9e\u73b0\n    machine_learning/stock_index_classification/\u6caa\u6df1300\u80a1\u6307\u6da8\u8dcc\u9884\u6d4b\n    machine_learning/hs300_classification/\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6caa\u6df1300\u80a1\u7968\u6da8\u8dcc", 
            "title": "Project layout"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/", 
            "text": "\u62c9\u52fe\u62db\u8058\u804c\u4f4d\u4fe1\u606f\u6570\u636e\u5206\u6790\n\n\n\u80cc\u666f\u4ecb\u7ecd\n\n\n\u91c7\u7528scrapy\u6846\u67b6\u91c7\u96c6\u4e86\u62c9\u52fe\u7f51\u67d0\u5929\u7684\u6240\u6709\u62db\u8058\u804c\u4f4d\u4fe1\u606f\uff0c\u8fdb\u884c\u7b80\u5355\u7684\u6570\u636e\u5206\u6790\uff0c\u4e3b\u8981\u76ee\u7684\u662f\u5206\u6790IT\u884c\u4e1a\u76ee\u524d\u62db\u8058\u7684\u6574\u4f53\u72b6\u51b5\uff0c\u5206\u6790\u6280\u672f\u7c7b\u4e2d\u540e\u7aef\u5f00\u53d1\u7684\u62db\u8058\u5f62\u52bf\u4ee5\u53caPython\u7f16\u7a0b\u8bed\u8a00\u7684\u62db\u8058\u9700\u6c42\u3002\n\n\n# \u5bfc\u5165\u76f8\u5173\u6a21\u5757\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport time\nimport datetime\nimport re\nimport seaborn as sns\nsns.set(style=\nticks\n, palette=\nmuted\n, font_scale=1.3, color_codes=True, context=\ntalk\n)\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\n%matplotlib inline\nfrom matplotlib.font_manager import FontProperties \nfont = FontProperties(fname=r\n/usr/share/fonts/truetype/arphic/ukai.ttc\n)\nfrom os import path\n\n\n\n\n\u6570\u636e\u91c7\u96c6\n\n\n\u9996\u5148\u662f\u83b7\u53d6\u6570\u636e\uff0c\u4f7f\u7528Python\u7684Scrapy\u6846\u67b6\u91c7\u96c6\u6570\u636e\uff0c\u6570\u636e\u91c7\u96c6\u8fc7\u7a0b\u5728\u6b64\u7565\u8fc7...\n\n\n\u91c7\u96c6\u7684\u6570\u636e\u5b58\u50a8\u5728csv\u6587\u4ef6\u4e2d\uff0c\u8be5\u6570\u636e\u96c6\u662f\u91c7\u96c6\u62c9\u52fe\u7f51\u4e00\u5929\u5185\u53d1\u5e03\u7684\u804c\u4f4d\u62db\u8058\u4fe1\u606f\uff0c\u603b\u51718\u4e07\u591a\u6761\u62db\u8058\u4fe1\u606f\u3002\n\n\n\u6570\u636e\u5206\u6790\n\n\n\u6570\u636e\u6e05\u6d17\n\n\n\u62c9\u52fe\u7f51\u7684\u62db\u8058\u4fe1\u606f\u4ee5Json\u683c\u5f0f\u53d1\u9001\u5230\u524d\u7aef\uff0c\u6574\u4f53\u6570\u636e\u6bd4\u8f83\u89c4\u6574\uff0c\u7f3a\u5931\u6570\u636e\u8f83\u5c11\uff0c\u5728\u672c\u5206\u6790\u6d41\u7a0b\u524d\u4e8b\u5148\u5bf9\u539f\u59cb\u6570\u636e\u96c6\u7684\u91cd\u8981\u5b57\u6bb5\u8fdb\u884c\u4e86\u7f3a\u5931\u503c\u586b\u8865\u5904\u7406\u3001\u5bf9\u4e00\u4e9b\u5206\u7c7b\u53d8\u91cf\u8fdb\u884c\u4e86\u91cd\u65b0\u5f52\u7c7b\u5408\u5e76\u7b49\u6570\u636e\u6e05\u6d17\u52a8\u4f5c\uff0c\u56e0\u6b64\uff0c\u67e5\u770b\u73b0\u5728\u6570\u636e\u7684\u7f3a\u5931\u60c5\u51b5\uff0c\u53ea\u6709dist\u3001position_advantagei\u4e24\u4e2a\u7279\u5f81\u6709\u7f3a\u5931\u6570\u636e\n\n\ndata = pd.read_csv(\n/home/darren/Desktop/lagou_position/scrapy/lagou_job_all_dropduplicated.csv\n, encoding=\nutf-8\n)    \n\n\n\n\n# \u67e5\u770bcompany_size\u7f3a\u5931\u7684\u6837\u672c\u6570\u91cf\ndata[data.company_size.isnull()].shape\n# \u7528\n\u5c11\u4e8e15\u4eba\n\u586b\u8865\u7f3a\u5931\u7684\u6570\u636e\ndata.company_size.fillna(u\n\u5c11\u4e8e15\u4eba\n, inplace=True)\n\n\n\n\n\u67e5\u770b\u6570\u636e\u96c6\u4e2d\u975e\u7a7a\u6570\u636e\u767e\u5206\u6bd4\n\n\n#\u5404\u4e2a\u7279\u5f81\u975e\u7a7a\u7684\u6837\u672c\u6570\u91cf\nnot_null = data.count()\nall = data.shape[0]\n# \u67e5\u770b\u6570\u636e\u96c6\u4e2d\u975e\u7a7a\u6570\u636e\u767e\u5206\u6bd4\nnot_null / all * 100\n\n\n\n\nfinance_stage         100.000000\ncity                  100.000000\ndist                   98.252158\nsalary                100.000000\njob_nature            100.000000\nindustry_field        100.000000\ncompany               100.000000\nthird_tag             100.000000\npublished_time        100.000000\nsecond_tag            100.000000\nposition_advantage     99.990527\nfirst_tag             100.000000\nlast_login            100.000000\nwork_experience       100.000000\nposition_type         100.000000\nposition              100.000000\neducation             100.000000\ncrawl                 100.000000\ncompany_size          100.000000\nday                   100.000000\ndtype: float64\n\n\n\nIT\u884c\u4e1a\u6574\u4f53\u7684\u63cf\u8ff0\u6027\u5206\u6790\n\n\n# position_advantage\u548cdist\u7684\u7f3a\u5931\u503c\u6682\u4e0d\u5904\u7406\n# \u83b7\u53d6\u6570\u636e\u96c6\u7684\u67d0\u4e9b\u6837\u672c\u7279\u5f81\u7528\u4e8e\u53ef\u89c6\u5316\u8f93\u51fa\nfeatures = data.columns.values.tolist()\n\n\n\n\n# \u63d0\u53d6\u4e0esalary\u76f8\u5173\u5ea6\u8f83\u5927\u7684\u7279\u5f81\uff0c\u7528\u4e8e\u63cf\u8ff0\u6027\u63a2\u7d22\u4e0e\u53ef\u89c6\u5316\u8f93\u51fa\nfor x in [u\ncompany_size\n, u\nposition_type\n, u\nday\n, u\nthird_tag\n, u\nsalary\n, u\ndist\n, u\ncompany\n, u\npublished_time\n, u\nposition_advantage\n, u\nlast_login\n, u\nposition\n, u\ncrawl\n]:  # \n    features.remove(x) \n\n\n\n\n# \u5b9a\u4e49\u4e00\u4e9b\u7279\u5f81\u548c\u8bc4\u4f30\u7684\u6620\u5c04\nfeature_name = [u\n\u4f01\u4e1a\u91d1\u878d\u72b6\u51b5\n, u\n\u57ce\u5e02\n, u\n\u5de5\u4f5c\u7c7b\u578b\n, u\n\u884c\u4e1a\u9886\u57df\n, u\n\u804c\u4f4d\u5c0f\u7c7b\n, u\n\u804c\u4f4d\u5927\u7c7b\n, u\n\u5de5\u4f5c\u7ecf\u9a8c\n, u\n\u5b66\u5386\n]  # u\n\u804c\u4f4d\u7c7b\u578b\n, ,u\n\u516c\u53f8\u89c4\u6a21\n\nfeature_dict = dict(zip(features,feature_name))\nfeature_dict\nmethod_dict = {\nmean\n: u\n\u5e73\u5747\u85aa\u8d44\n, \nmedian\n: u\n\u85aa\u8d44\u4e2d\u4f4d\u6570\n, \nsize\n: u\n\u62db\u8058\u804c\u4f4d\u6570\u91cf\n}\n\n\n\n\ndef feature_target_bar(evalute_method_str):\n    \n\n    \u4ee5bar_plot\u7684\u65b9\u5f0f\u5c06IT\u884c\u4e1a\u6574\u4f53\u7684\u4e00\u4e9b\u7279\u5f81\u4e0e\u85aa\u8d44\u5173\u7cfb\u8fdb\u884c\u53ef\u89c6\u5316\u8f93\u51fa\n    \n\n    fig, axes = plt.subplots(4,2, figsize=(18,40), sharex=False, sharey=False)\n    axes_subject_list = [j for i in axes.tolist() for j in i]\n    evalute_method = \nnp.\n + evalute_method_str\n    for index, feature in enumerate(features):\n        df_salary= data.groupby(feature)[\nsalary\n].aggregate([eval(evalute_method)]).sort_values(evalute_method_str, ascending=False)\n        g = sns.barplot(y=df_salary.index, x=df_salary[evalute_method_str], ax=axes_subject_list[index], palette=\nhusl\n)\n        axes_subject_list[index].set_yticklabels(g.get_yticklabels(), fontproperties=font, fontsize=18)\n        axes_subject_list[index].set_xlabel(\n)\n        axes_subject_list[index].set_title(u\n\u4e0d\u540c\n + feature_dict[feature] + method_dict[evalute_method_str], fontsize=25, fontproperties=font)    \n        axes_subject_list[index].set_ylabel(\n) \n        axes_subject_list[index].xaxis.grid(True, linestyle = \n-.\n,)    \n    text = method_dict[evalute_method_str] + 'k(\uffe5)' if evalute_method_str in [\nmean\n, \nmedian\n] else method_dict[evalute_method_str]\n    # \u5c06x\u8f74\u4ee5\u6587\u672cplt.text\u7684\u5f62\u5f0f\u5199\u5165axis\u5bf9\u8c61\u4e2d\n    plt.text(-3.8, 5.0, s=text, ha='center', va='center', fontsize=25, fontproperties=font)\n    fig.tight_layout()\n    # fig.savefig(\n/home/darren/Desktop/salary_mean \n features.png\n)\n\n\n\n\nIT\u884c\u4e1a\u6574\u4f53\u62db\u8058\u9700\u6c42\n\n\n\u4e3b\u8981\u63a2\u8ba8\u804c\u4f4d\u62db\u8058\u9700\u6c42\u3001\u804c\u4f4d\u5e73\u5747/\u4e2d\u4f4d\u6570\u85aa\u8d44\u4e0e\u62db\u8058\u4f01\u4e1a\u7684\u91d1\u878d\u72b6\u51b5\u3001\u4f01\u4e1a\u89c4\u6a21\uff0c\u6240\u5c5e\u884c\u4e1a\u7684\u7ec6\u5206\u9886\u57df\uff0c\u6c42\u804c\u8005\u5b66\u5386\u3001\u5de5\u4f5c\u7ecf\u9a8c\u7684\u5173\u7cfb\u3002\u4e4b\u6240\u4ee5\u8981\u8bc4\u4f30\u85aa\u8d44\u7684\u4e2d\u4f4d\u6570\uff0c\u4e3b\u8981\u662f\u5c3d\u91cf\u51cf\u5c0f\u4e00\u4e9b\u9ad8\u85aa\u5c97\u4f4d\u7684\u85aa\u8d44\u53ef\u80fd\u4f1a\u5f15\u8d77\u7684\u5de6\u504f\u73b0\u8c61\u3002\n\n\nfor i in method_dict.keys():\n    feature_target_bar(i)\n\n\n\n\n\n\n\n\n\n\n\u4e0d\u540c\u89c4\u6a21\u7684\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u56fe\u662f\u53ccy\u8f74\u5750\u6807\u56fe\uff0c\u53f3\u4fa7y\u8f74\u5750\u6807\u8868\u793a\u7684\u662f\u4e0d\u540c\u89c4\u6a21\u7684\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u5360\u603b\u62db\u8058\u9700\u6c42\u7684\u767e\u5206\u6bd4\uff08\u6ce8\u610f\u548c\u4e0b\u9762\u7684\u53ccy\u5750\u6807\u8f74\u7684\u767e\u5206\u6bd4\u7684\u533a\u522b\uff09\n\n\n# \u804c\u4f4d\u62db\u8058\u9700\u6c42\u3001\u5e73\u5747\u85aa\u8d44\u4e0e\u516c\u53f8\u89c4\u6a21\u7684\u5173\u7cfb\nd_company_salary = data.groupby('company_size')[\nsalary\n].aggregate([np.size, np.mean, np.median]).sort_values(\nsize\n, ascending=True)\nd_company_salary[\nproperty\n] = d_company_salary[\nsize\n] / d_company_salary[\nsize\n].sum() * 100\nfig, ax1 = plt.subplots(figsize=(8,6))  # \u4f7f\u7528subplots()\u521b\u5efa\u7a97\u53e3\nax2 = ax1.twinx() # \u521b\u5efa\u7b2c\u4e8c\u4e2a\u5750\u6807\u8f74\nx_list = range(len(d_company_salary))\nax1.plot(x_list, d_company_salary[\nmean\n], linewidth = 2, ls=\n-.\n, marker=\n^\n, label=u\n\u5e73\u5747\u85aa\u8d44\n) \nax1.plot(x_list, d_company_salary[\nmedian\n], linewidth = 2, ls='--', marker=\nv\n, label=u\n\u85aa\u8d44\u4e2d\u4f4d\u6570\n) \nax2.plot(x_list, d_company_salary[\nproperty\n], linewidth = 3, color=\nc\n, marker=\no\n, label=u\n\u804c\u4f4d\u9700\u6c42\u91cf %\n) \nax1.set_xlabel(u'\u516c\u53f8\u89c4\u6a21', fontproperties=font, fontsize = 16) \nax1.set_ylabel(u'\u85aa\u8d44 k(\uffe5)', fontproperties=font, fontsize = 16)\nax2.set_ylabel(u'\u62db\u8058\u804c\u4f4d\u767e\u5206\u6bd4 %', fontproperties=font, fontsize = 16)\nax1.set_xlim(0, 5.4)  # \u6b64\u5904\u5fc5\u987b\u8bbe\u7f6e set_xlim(0,...),\u8d77\u59cb\u4f4d\u7f6e\u5fc5\u987b\u662f0\uff0c\u5426\u521915\u4eba\u4ee5\u4e0b\u5c31\u4e0d\u663e\u793a\uff1f\nax1.set_xticklabels(d_company_salary.index, fontproperties=font, fontsize=16, rotation=30)\nax1.xaxis.grid(True, linestyle = \n-.\n,)\nax1.yaxis.grid(True, linestyle = \n-.\n,)\nax1.legend(loc=2, prop=font)\nax2.legend(loc=4, prop=font)\nax1.set_title(u'\u4e0d\u540c\u89c4\u6a21\u7684\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44',fontproperties=font,fontsize=25)\n\n\n\n\nmatplotlib.text.Text at 0x7f21a4798610\n\n\n\n\n\n\n\u7531\u4e8e\u62c9\u52fe\u7f51\u662f\u4e13\u4e1a\u7684\u4e92\u8054\u7f51\u62db\u8058\u5e73\u53f0\uff0c\u62db\u8058\u4fe1\u606f\u4ee5IT\u884c\u4e1a\u4e3a\u4e3b\uff0c\u6574\u4f53\u85aa\u8d44\u6c34\u5e73\u662f\u504f\u9ad8\u7684\u3002\u4ece\u4e0a\u9762\u7684\u67f1\u72b6\u56fe\u53ef\u770b\u51fa\uff0c\u62db\u8058\u85aa\u8d44\u4e0e\u62db\u8058\u4f01\u4e1a\u7684\u91d1\u878d\u72b6\u51b5\u3001\u62db\u8058\u4f01\u4e1a\u6240\u5c5e\u7684\u884c\u4e1a\u9886\u57df\u3001\u6c42\u804c\u8005\u7684\u5b66\u5386\u4e0e\u5de5\u4f5c\u7ecf\u9a8c\u7b49\u7279\u5f81\u5747\u6709\u5173\u8054\u6027\u3002\n\n\n\u6839\u636e\u62db\u8058\u4f01\u4e1a\u7684\u91d1\u878d\u72b6\u51b5\u53ef\u5206\u6210\u4e0a\u5e02\u516c\u53f8\u3001\u6210\u719f\u3001\u6210\u957f\u3001\u521d\u521b\u6027\u516c\u53f8\uff0c\u6839\u636e\u4e0a\u9762\u7684\u67f1\u72b6\u56fe\u660e\u663e\u770b\u51fa\u521d\u521b\u6027\u516c\u53f8\u7684\u85aa\u8d44\u504f\u4f4e\uff0c\u800c\u6210\u719f\u6027\u4e14\u878d\u8d44\u89c4\u6a21\u8f83\u5927\u7684\u4f01\u4e1a\u7684\u85aa\u8d44\u8f83\u9ad8\u3002\n\n\n\u5206\u6790\u4e00\u7ebf\u548c\u70ed\u95e8\u4e8c\u7ebf\u57ce\u5e02\u7684\u85aa\u8d44\u67f1\u72b6\u56fe\uff0c\u660e\u663e\u770b\u51fa\u4e00\u7ebf\u57ce\u5e02\u7684\u5e73\u5747\u85aa\u8d44\u660e\u663e\u9ad8\u4e8e\u5176\u4ed6\u57ce\u5e02\uff08\u5929\u6d25\u9664\u5916\uff09\uff0c\u5c24\u5176\u4ee5\u5317\u4eac\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u800c\u4e8c\u7ebf\u7684\u676d\u5dde\u85aa\u8d44\u4e5f\u8f83\u9ad8\uff0c\u53ef\u80fd\u4e0e\u963f\u91cc\u5df4\u5df4\u7b49\u4e92\u8054\u7f51\u516c\u53f8\u5750\u843d\u676d\u5dde\u6709\u5173\u3002\n\n\n\u4e92\u8054\u7f51\u76f8\u5173\u7684\u804c\u4f4d\u85aa\u8d44\uff08\u804c\u4e1a\u5c0f\u7c7b\uff09\u4e2d\u660e\u663e\u770b\u51fa\uff0c\u4eba\u5de5\u667a\u80fd\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u8fd9\u4e5f\u53cd\u6620\u51fa\u5f53\u524d\u7684\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u5927\u70ed\u3002\n\n\n\u6b64\u5916\uff0c\u5bf9\u6bd4\u5e73\u5747\u85aa\u8d44\u548c\u85aa\u8d44\u7684\u4e2d\u4f4d\u6570\u53ef\u4ee5\u53d1\u73b0\u4e00\u4e9b\u4e0d\u540c\u4e4b\u5904\uff0c\u8fd9\u662f\u7531\u4e8e\u4e00\u4e9b\u79bb\u7fa4\u7684\u6837\u672c\u70b9\u5c06\u6837\u672c\u5747\u503c\u62c9\u4f4e\u6216\u62c9\u9ad8\uff0c\u7528\u4e2d\u4f4d\u6570\u80fd\u8f83\u597d\u7684\u53cd\u6620\u96c6\u4e2d\u8d8b\u52bf\u3002\n\n\n\u4ece\u516c\u53f8\u89c4\u6a21\u4e0e\u85aa\u8d44\u548c\u62db\u8058\u9700\u6c42\u66f2\u7ebf\u770b\uff0cIT\u884c\u4e1a\u62db\u8058\u804c\u4f4d\u9700\u6c42\u6700\u591a\u7684\u4e0d\u662f\u5927\u578b\u516c\u53f8\u800c\u662f50-500\u4eba\u89c4\u6a21\u7684\u516c\u53f8\uff0c\u85aa\u8d44\u4e0a\uff0c\u5927\u578b\u516c\u53f8\u7684\u85aa\u8d44\u6700\u9ad8\uff0c50-500\u89c4\u6a21\u7684\u6b21\u4e4b\uff0c50\u4eba\u4ee5\u4e0b\u7684\u516c\u53f8\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u90fd\u8f83\u4f4e\u3002\n\n\n\u7b80\u800c\u6982\u4e4b\uff0c\u4ece\u5404\u4e2a\u57ce\u5e02\u7684\u62db\u8058\u804c\u4f4d\u9700\u6c42\u770b\uff0c\u5317\u4eac\u7684\u62db\u8058\u804c\u4f4d\u6700\u591a\uff0c\u4e0a\u6d77\u6b21\u4e4b\uff0c\u4ece\u516c\u53f8\u89c4\u6a21\u770b\u4e2d\u578b\u516c\u53f8\u7684\u62db\u8058\u5bfb\u6c42\u6700\u5927\uff0c\u5927\u578b\u516c\u53f8\u6b21\u4e4b\uff0c\u5c0f\u578b\u516c\u53f8\u7684\u9700\u6c42\u91cf\u8f83\u5c0f\uff1b\u4ece\u85aa\u8d44\u4e0a\u770b\uff0c\u5927\u578b\u516c\u53f8\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u5176\u6b21\u662f\u4e2d\u578b\u516c\u53f8\uff0c\u5c0f\u516c\u53f8\u6700\u4f4e\uff0c\u56e0\u6b64\uff0cIT\u884c\u4e1a\u7684\u6700\u4f73\u6c42\u804c\u5730\u4e3a\u5317\u4eac\u6216\u4e0a\u6d77\uff0c\u516c\u53f8\u53ef\u9009\u62e9\u4e2d\u578b\u7684\u4e0a\u5e02\u6216\u6210\u719f\u578b\u516c\u53f8\u3002\n\n\nIT\u884c\u4e1a\u5404\u9886\u57df\u63cf\u8ff0\u6027\u5206\u6790\n\n\n\u4ee5\u4e0a\u662f\u4ece\u6574\u4f53\u4e0a\u5bf9\u62c9\u52fe\u7f51\u7684IT\u62db\u8058\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u63a5\u4e0b\u6765\u5bf9IT\u884c\u4e1a\u4e03\u5927\u9886\u57df\uff0c\u6280\u672f\u3001\u4ea7\u54c1\u3001\u8fd0\u8425\u3001\u804c\u80fd\u3001\u91d1\u878d\u3001\u5e02\u573a\u4e0e\u9500\u552e\u3001\u8bbe\u8ba1\u8fdb\u884c\u7b80\u5355\u7684\u63cf\u8ff0\u6027\u5206\u6790\n\n\n# \u4e0d\u540c\u804c\u4e1a\u7684\u804c\u4f4d\u6570\u91cf\u3001\u5e73\u5747\u85aa\u8d44\u3001\u85aa\u8d44\u4e2d\u4f4d\u6570\nIT_domains = data.groupby([\nfirst_tag\n, \nthird_tag\n])[\nsalary\n].aggregate([np.size, np.mean, np.median])\nIT_domains = IT_domains.reset_index()\n\n\n\n\n# IT\u884c\u4e1a\u5404\u9886\u57df\u7684\u804c\u4f4d\u6bd4\u4f8b\nposition_num  = IT_domains.groupby([\nfirst_tag\n])[\nsize\n].sum() / IT_domains[\nsize\n].sum() * 100\n# IT\u884c\u4e1a\u5404\u9886\u57df\u7684\u5e73\u5747\u85aa\u8d44\nposition_mean = IT_domains.groupby([\nfirst_tag\n])[\nmean\n].mean().sort_values(ascending=False) \n\n\n\n\nplt.figure(figsize=(8,6))\ng = sns.barplot(y=position_mean.index, x=position_mean.values, palette=\nBuPu_d\n)\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.xlabel(u\n\u5e73\u5747\u85aa\u8d44 k (\uffe5)\n, fontsize=16, fontproperties=font)\nplt.ylabel(\n)\nplt.title(u\nIT\u884c\u4e1a\u4e0d\u540c\u9886\u57df\u85aa\u8d44\n, fontproperties=font, fontsize=25)\nplt.gca().xaxis.grid(True, linestyle = \n-.\n,)\n\n\n\n\n\n\n\nplt.pie\u53c2\u6570\nx       (\u6bcf\u4e00\u5757)\u7684\u6bd4\u4f8b\uff0c\u5982\u679csum(x) \n 1\u4f1a\u4f7f\u7528sum(x)\u5f52\u4e00\u5316\nlabels  (\u6bcf\u4e00\u5757)\u997c\u56fe\u5916\u4fa7\u663e\u793a\u7684\u8bf4\u660e\u6587\u5b57\nexplode (\u6bcf\u4e00\u5757)\u79bb\u5f00\u4e2d\u5fc3\u8ddd\u79bb\nstartangle  \u8d77\u59cb\u7ed8\u5236\u89d2\u5ea6,\u9ed8\u8ba4\u56fe\u662f\u4ecex\u8f74\u6b63\u65b9\u5411\u9006\u65f6\u9488\u753b\u8d77,\u5982\u8bbe\u5b9a=90\u5219\u4ecey\u8f74\u6b63\u65b9\u5411\u753b\u8d77\nshadow  \u662f\u5426\u9634\u5f71\nlabeldistance label\u7ed8\u5236\u4f4d\u7f6e,\u76f8\u5bf9\u4e8e\u534a\u5f84\u7684\u6bd4\u4f8b, \u5982\n1\u5219\u7ed8\u5236\u5728\u997c\u56fe\u5185\u4fa7\nautopct \u63a7\u5236\u997c\u56fe\u5185\u767e\u5206\u6bd4\u8bbe\u7f6e,\u53ef\u4ee5\u4f7f\u7528format\u5b57\u7b26\u4e32\u6216\u8005format function\n        '%1.1f'\u6307\u5c0f\u6570\u70b9\u524d\u540e\u4f4d\u6570(\u6ca1\u6709\u7528\u7a7a\u683c\u8865\u9f50)\npctdistance \u7c7b\u4f3c\u4e8elabeldistance,\u6307\u5b9aautopct\u7684\u4f4d\u7f6e\u523b\u5ea6\nradius  \u63a7\u5236\u997c\u56fe\u534a\u5f84\n\n\nvals = range(len(position_num)) #\u521b\u5efa\u6570\u636e\u7cfb\u5217\nlabels = position_num.index.values.tolist()\nplt.figure(1, figsize=(7,7))\nplt.pie(position_num.values, labels=labels, autopct='%1.2f%%', \n        pctdistance=.8, shadow=False, startangle=60,radius=1.2, \n        labeldistance=1.06, colors=('b', 'g', 'r', 'c', 'y', 'orange', 'm'),\n        textprops={\nfontproperties\n: font, \nfontsize\n:12})\nplt.title(u'IT\u884c\u4e1a\u5404\u9886\u57df\u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4',fontsize=25, fontproperties=font)\nplt.axis('equal') \n\n\n\n\n(-1.3429042534959512,\n 1.329370895558277,\n -1.3334685921667122,\n 1.3271730638043182)\n\n\n\n\n\nIT\u884c\u4e1a\u4e03\u5927\u9886\u57df\u4e2d\u804c\u4f4d\u9700\u6c42\u6700\u591a\u7684\u662f\u6280\u672f\u7c7b\uff0c\u5176\u6b21\u662f\u4ea7\u54c1\u7c7b\uff0c\u53d1\u5e03\u804c\u4f4d\u6700\u5c11\u7684\u662f\u91d1\u878d\u7c7b\uff0c\u800c\u85aa\u8d44\u65b9\u9762\uff0c\u5e73\u5747\u85aa\u8d44\u6700\u9ad8\u7684\u662f\u91d1\u878d\u7c7b\uff0c\u5176\u6b21\u662f\u6280\u672f\u7c7b\u3002\n\n\nIT\u884c\u4e1a\u85aa\u8d44\u4e0e\u57ce\u5e02\n\n\n# \u5bf9\u4e0d\u540c\u57ce\u5e02\u548cIT\u884c\u4e1a\u4e03\u5927\u9886\u57df\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u5bf9\u7279\u5f81salary\u8fdb\u884c\u6570\u91cf\u7edf\u8ba1\u3001\u5e73\u5747\u3001\u4e2d\u4f4d\u6570\u8ba1\u7b97\nd_city = data.groupby([\ncity\n, \nfirst_tag\n])[\nsalary\n].aggregate([np.size, np.mean, np.median])\nd_city = d_city.reset_index() \n# \u5efa\u7acb\u57ce\u5e02\u540d\u5b57\u5217\u8868\u7528\u4e8e\u540e\u7eed\u56fe\u7684tickslabels\ncity_list = data.groupby([\ncity\n])[\nsalary\n].mean().sort_values(ascending=False).index.values.tolist()\n\n\n\n\nplt.figure(figsize=(12,20))\n# with sns.color_palette(sns.palplot(sns.xkcd_palette(colors)),  n_colors=9):\ng = sns.barplot(y=\nfirst_tag\n, x=\nmean\n, data=d_city, hue=\ncity\n, hue_order=city_list, palette=\nSet1\n)\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.xlabel(u\n\u5e73\u5747\u85aa\u8d44 k (\uffe5)\n, fontsize=16, fontproperties=font)\nplt.ylabel(\n)\nplt.title(u\nIT\u884c\u4e1a\u5404\u9886\u57df\u5404\u57ce\u5e02\u85aa\u8d44\n, fontproperties=font, fontsize=25)\nplt.gca().xaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=7,prop=font, fontsize=17)\n\n\n\n\nmatplotlib.legend.Legend at 0x7f219c64f950\n\n\n\n\n\n\nplt.figure(figsize=(12,20))\ng = sns.barplot(y=\nfirst_tag\n, x=\nsize\n, data=d_city, hue=\ncity\n, hue_order=city_list, palette=\nSet1\n)\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.xlabel(u\n\u62db\u8058\u804c\u4f4d\u6570\u91cf\n, fontsize=16, fontproperties=font)\nplt.ylabel(\n)\nplt.title(u\nIT\u884c\u4e1a\u5404\u9886\u57df\u5404\u57ce\u5e02\u62db\u8058\u804c\u4f4d\u6570\u91cf\n, fontproperties=font, fontsize=25)\nplt.gca().xaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=7,prop=font, fontsize=17)\n\n\n\n\nmatplotlib.legend.Legend at 0x7f219c0e4250\n\n\n\n\n\n\n\u4eceIT\u884c\u4e1a\u5404\u4e2a\u9886\u57df\u7684\u5e73\u5747\u85aa\u8d44\u548c\u62db\u8058\u804c\u4f4d\u6570\u91cf\u53ef\u77e5\uff0c\u65e0\u8bba\u4ece\u62db\u8058\u6570\u91cf\u8fd8\u662f\u5e73\u5747\u85aa\u8d44\u5317\u4eac\u7684\u8001\u5927\u5730\u4f4d\u5f88\u7262\u56fa\uff08\u9664\u4e86\u91d1\u878d\u9886\u57df\uff09\uff0c\u5176\u6b21\u662f\u4e0a\u6d77\uff0c\u518d\u4e4b\u662f\u6df1\u5733\uff0c\u7136\u540e\u662f\u676d\u5dde\u3001\u5e7f\u5dde\u3002\u5f88\u6709\u610f\u601d\u7684\u4e00\u4e2a\u73b0\u8c61\u662fIT\u884c\u4e1a\u7684\u91d1\u878d\u9886\u57df\uff0c\u867d\u7136\u5317\u4eac\u7684\u62db\u8058\u9700\u6c42\u4ecd\u65e7\u662f\u6700\u5927\u7684\uff0c\u4f46\u5e73\u5747\u85aa\u8d44\u4f4e\u4e8e\u4e0a\u6d77\u548c\u6df1\u5733\uff0c\u8fd9\u4e0e\u4e2d\u56fd\u5357\u65b9\u7684\u4e00\u7ebf\u57ce\u5e02\u7684\u91d1\u878d\u884c\u4e1a\u53d1\u5c55\u76f8\u543b\u5408\uff0c\u53e6\u4e00\u4e2a\u73b0\u8c61\u662f\u53a6\u95e8\u7684\u91d1\u878d\u9886\u57df\u85aa\u8d44\u6700\u9ad8\uff0c\u8d85\u8fc7\u4e86\u4e0a\u6d77\uff0c\u4f46\u62db\u8058\u804c\u4f4d\u6570\u91cf\u592a\u5c11\uff0c\u53ea\u67093\u4e2a\u804c\u4f4d\u9700\u6c42\u3002\n\n\n\u53a6\u95e8\u7684IT\u884c\u4e1a\u4e03\u5927\u7ec6\u5206\u9886\u57df\u7684\u62db\u8058\u6574\u4f53\u72b6\u51b5\n\n\n\u5176\u4e2d\uff0csize\u8868\u793a\u7684\u662f\u62db\u8058\u804c\u4f4d\u7684\u6570\u91cf\uff0cmean\u8868\u793a\u7684\u662f\u804c\u4f4d\u7684\u5e73\u5747\u85aa\u8d44\uff0cmidian\u8868\u793a\u7684\u662f\u85aa\u8d44\u4e2d\u4f4d\u6570\n\n\nd_city[d_city[\ncity\n] == u\n\u53a6\u95e8\n]\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \ncity\n\n      \nfirst_tag\n\n      \nsize\n\n      \nmean\n\n      \nmedian\n\n    \n\n  \n\n  \n\n    \n\n      \n21\n\n      \n\u53a6\u95e8\n\n      \n\u4ea7\u54c1\n\n      \n378.0\n\n      \n10.279101\n\n      \n10.00\n\n    \n\n    \n\n      \n22\n\n      \n\u53a6\u95e8\n\n      \n\u5e02\u573a\u4e0e\u9500\u552e\n\n      \n184.0\n\n      \n8.388587\n\n      \n7.25\n\n    \n\n    \n\n      \n23\n\n      \n\u53a6\u95e8\n\n      \n\u6280\u672f\n\n      \n403.0\n\n      \n12.493797\n\n      \n11.50\n\n    \n\n    \n\n      \n24\n\n      \n\u53a6\u95e8\n\n      \n\u804c\u80fd\n\n      \n59.0\n\n      \n6.745763\n\n      \n5.00\n\n    \n\n    \n\n      \n25\n\n      \n\u53a6\u95e8\n\n      \n\u8bbe\u8ba1\n\n      \n188.0\n\n      \n9.425532\n\n      \n9.00\n\n    \n\n    \n\n      \n26\n\n      \n\u53a6\u95e8\n\n      \n\u8fd0\u8425\n\n      \n393.0\n\n      \n7.541985\n\n      \n6.00\n\n    \n\n    \n\n      \n27\n\n      \n\u53a6\u95e8\n\n      \n\u91d1\u878d\n\n      \n3.0\n\n      \n29.666667\n\n      \n30.00\n\n    \n\n  \n\n\n\n\n\n\n\nIT\u884c\u4e1a\u4e0d\u540c\u9886\u57df\u7684\u85aa\u8d44\u4e0e\u6c42\u804c\u8005\u5173\u7cfb\u5206\u6790\n\n\n# \u4e3b\u8981\u4ece\u6c42\u804c\u8005\u7684\u5b66\u5386\u548c\u5de5\u4f5c\u7ecf\u9a8c\u63a2\u8ba8IT\u4e03\u5927\u5206\u652f\u9886\u57df\u7684\u85aa\u8d44\u548c\u62db\u8058\u9700\u6c42\njobseeker_education = data.groupby([\neducation\n, \nfirst_tag\n])[\nsalary\n].aggregate([np.size, np.mean])\njobseeker_education = jobseeker_education.reset_index()\neducation_list = data.groupby(\neducation\n)[\nsalary\n].count().sort_values(ascending=False).index.values.tolist()\nparam_dist = {\neducation\n: u\n\u5b66\u5386\n, \ncity\n: u\n\u57ce\u5e02\n, \nwork_experience\n: u\n\u5de5\u4f5c\u7ecf\u9a8c\n, \nsize\n: u\n\u6570\u91cf\n, \nmean\n: u\n\u5e73\u5747\u85aa\u8d44\n}\njobseeker_experience = data.groupby([\nwork_experience\n, \nfirst_tag\n])[\nsalary\n].aggregate([np.size, np.mean])\njobseeker_experience = jobseeker_experience.reset_index()\nexperience_list = data.groupby(\nwork_experience\n)[\nsalary\n].count().sort_values(ascending=False).index.values.tolist()\n\n\n\n\ndef domains_relation(dataframe, evalute_method, hue_param, hue_order=None):    \n    plt.figure(figsize=(8,6))\n    g = sns.barplot(x=\nfirst_tag\n, y=evalute_method, data=dataframe, hue=hue_param, hue_order=hue_order, palette=\nSet1\n)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n    plt.ylabel(u\n\u62db\u8058\u804c\u4f4d{}\n.format(param_dist.get(evalute_method)), fontsize=16, fontproperties=font)\n    plt.xlabel(\n)\n    plt.title(u\nIT\u884c\u4e1a\u5404\u9886\u57df\u62db\u8058\u804c\u4f4d{0}\u4e0e{1}\n.format(param_dist.get(evalute_method), param_dist.get(hue_param)), fontproperties=font, fontsize=20)\n    plt.gca().yaxis.grid(True, linestyle = \n-.\n,)\n    plt.legend(loc=\nbest\n,prop=font, fontsize=17)\n\n\n\n\nfor method in [\nsize\n, \nmean\n]:\n    domains_relation(jobseeker_education, method, \neducation\n, education_list)\n\n\n\n\n\n\n\n\nfor method in [\nsize\n, \nmean\n]:\n    domains_relation(jobseeker_experience, method, \nwork_experience\n, experience_list)\n\n\n\n\n\n\n\n\n\u62db\u8058\u9700\u6c42\u8981\u6c42\u6700\u591a\u7684\u5b66\u5386\u662f\u672c\u79d1\uff0c\u5176\u6b21\u662f\u5927\u4e13\uff0c\u53ea\u6709\u5728\u5e02\u573a\u4e0e\u9500\u552e\u9886\u57df\uff0c\u672c\u79d1\u9700\u6c42\u7565\u4f4e\u4e8e\u5927\u4e13\uff1b\u5de5\u4f5c\u7ecf\u9a8c\u4e0a\uff0c\u6280\u672f\u76f8\u5173\u7684\u9886\u57df\u9700\u6c42\u6700\u5927\u7684\u662f3-5\u5e74\u5de5\u4f5c\u7ecf\u9a8c\uff0c\u5176\u6b21\u662f1-3\u5e74\uff0c\u800c\u5176\u4ed6\u975e\u6280\u672f\u7684\u9700\u6c42\u6700\u591a\u7684\u662f1-3\u5e74\uff0c\u5176\u6b21\u662f3-5\u5e74\uff1b\n\n\n\u85aa\u8d44\u65b9\u9762\uff0c\u57fa\u672c\u5448\u73b0\u51fa\u5b66\u5386\u8d8a\u9ad8\u3001\u5de5\u4f5c\u7ecf\u9a8c\u8d8a\u4e30\u5bcc\u85aa\u8d44\u8d8a\u9ad8\u7684\u8d8b\u52bf\uff0c\u5076\u5c14\u6709\u7279\u6b8a\u60c5\u51b5\u3002\n\n\n\u4e00\u822c\u800c\u8a00\uff0c\u6c42\u804c\u8005\u7684\u5b66\u5386\u8f83\u9ad8\u6216\u5de5\u4f5c\u7ecf\u9a8c\u4e30\u5bcc\uff0c\u5176\u85aa\u8d44\u8f83\u9ad8\uff0c\u8fd9\u4e0e\u4e0a\u9762\u7684\u67f1\u72b6\u56fe\u7684\u6574\u4f53\u8d8b\u52bf\u662f\u543b\u5408\u7684\uff1b\u62db\u8058\u9700\u6c42\u6700\u591a\u7684\u5b66\u5386\u662f\u672c\u79d1\uff0c\u5176\u6b21\u662f\u5927\u4e13\uff0c\u5de5\u4f5c\u7ecf\u9a8c\u8981\u6c423-5\u5e74\u62161-3\u5e74\u5c45\u591a\u3002\n\n\nIT\u884c\u4e1a\u4e0d\u540c\u9886\u57df\u7684\u85aa\u8d44\u4e0e\u62db\u8058\u4f01\u4e1a\u5173\u7cfb\u5206\u6790\n\n\n# \u4ece\u62db\u8058\u4f01\u4e1a\u7684\u89c4\u6a21\u548c\u91d1\u878d\u72b6\u51b5\u63a2\u8ba8\u5176\u4e0e\u62db\u8058\u804c\u4f4d\u85aa\u8d44\u3001\u62db\u8058\u9700\u6c42\u7684\u5173\u7cfb\nemployee_finance = data.groupby([\nfinance_stage\n, \nfirst_tag\n])[\nsalary\n].aggregate([np.size, np.mean])\nemployee_finance = employee_finance.reset_index()\nemployee_field = data.groupby([\nindustry_field\n, \nfirst_tag\n])[\nsalary\n].aggregate([np.size, np.mean])\nemployee_field = employee_field.reset_index()\n# education_list = data.groupby(\neducation\n)[\nsalary\n].count().sort_values(ascending=False).index.values.tolist()\nparam_dist = {\nindustry_field\n: u\n\u884c\u4e1a\u9886\u57df\n, \ncity\n: u\n\u57ce\u5e02\n, \nfinance_stage\n: u\n\u91d1\u878d\u72b6\u51b5\n, \nsize\n: u\n\u6570\u91cf\n, \nmean\n: u\n\u5e73\u5747\u85aa\u8d44\n}\n\n\n\n\ndef domains_employee(dataframe, evalute_method, hue_param, hue_order=None):    \n    plt.figure(figsize=(12,8))\n    hue_order = data.groupby(hue_param)[\nsalary\n].aggregate(eval('np.'+evalute_method)).sort_values(ascending=False).index\n    g = sns.barplot(x=\nfirst_tag\n, y=evalute_method, data=dataframe, hue=hue_param, hue_order=hue_order, palette=\nSet1\n)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n    plt.ylabel(u\n\u62db\u8058\u804c\u4f4d{}\n.format(param_dist.get(evalute_method)), fontsize=16, fontproperties=font)\n    plt.xlabel(\n)\n    plt.title(u\nIT\u884c\u4e1a\u5404\u9886\u57df\u62db\u8058\u804c\u4f4d{0}\u4e0e\u4f01\u4e1a{1}\n.format(param_dist.get(evalute_method), param_dist.get(hue_param)), fontproperties=font, fontsize=20)\n    plt.gca().yaxis.grid(True, linestyle = \n-.\n,)\n    plt.legend(loc=\nbest\n,prop=font, fontsize=17)\n\n\n\n\nfor method in [\nsize\n, \nmean\n]:\n    domains_employee(employee_finance, method, \nfinance_stage\n)\n\n\n\n\n\n\n\n\nfor method in [\nsize\n, \nmean\n]:\n    domains_employee(employee_field, method, \nindustry_field\n)\n\n\n\n\n\n\n\n\n\u62db\u8058\u9700\u6c42\u4e2d\u6700\u591a\u7684\u662f\u6280\u672f\u9886\u57df\uff0c\u4e0a\u5e02\u516c\u53f8\u548c\u6210\u957f\u6027\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u65fa\u76db\uff0c\u4f46\u5e73\u5747\u85aa\u8d44\u6700\u591a\u7684\u5374\u662f\u6210\u719f\u578b\u516c\u53f8\u5176\u6b21\u624d\u662f\u4e0a\u5e02\u548c\u6210\u957f\u578b\u516c\u53f8\u3002\u4ece\u516c\u53f8\u6240\u5c5e\u7c7b\u578b\u4e0a\u770b\uff0c\u79fb\u52a8\u4e92\u8054\u7f51\u7684\u62db\u8058\u9700\u6c42\u6700\u591a\uff08\u90e8\u5206\u539f\u56e0\u662f\u5206\u7c7b\u7684\u65f6\u5019\u5c06\u6240\u6709\u8ddf\u79fb\u52a8\u4e92\u8054\u7f51\u6cbe\u8fb9\u7684\u516c\u53f8\u5747\u5212\u5206\u5230\u79fb\u52a8\u4e92\u8054\u7f51\u9886\u57df\u4e86\uff09\uff0c\u85aa\u8d44\u4e0a\uff0c\u91d1\u878d\u9886\u57df\u6700\u9ad8\uff0c\u63a5\u7740\u662fO2O\u3001\u793e\u4ea4\u7f51\u7edc\u3001\u6570\u636e\u670d\u52a1\u7b49\u4e00\u4e9b\u65b0\u578b\u7684\u7f51\u7edc\u79d1\u6280\u516c\u53f8\uff0c\u8d85\u8fc7\u4e86\u4f20\u7edf\u7684\u4e92\u8054\u7f51\u516c\u53f8\u7684\u85aa\u8d44\u6c34\u5e73\u3002\n\n\nIT\u4e03\u5927\u9886\u57df\u7684\u6280\u672f\u7c7b\u4e2d\u7684\u540e\u7aef\u5f00\u53d1\u5c97\u4f4d\u63cf\u8ff0\u6027\u5206\u6790\n\n\ndef IT_occupies(dataframe, content, evaluate_method):\n    \n\u8ba1\u7b97\u62c9\u52fe\u7f51\u6280\u672f\u5927\u7c7b\u4e2d\u540e\u7aef\u5f00\u53d1\u7684\u804c\u4f4d\u6570\u91cf\u3001\u85aa\u8d44\u60c5\u51b5\n \n    # \u83b7\u53d6IT\u6280\u672f\u7c7b\u4e2d\u7684\u540e\u7aef\u5f00\u53d1\u5c97\u4f4d\u4fe1\u606f  \n    technology_backend = dataframe.loc[dataframe[\nsecond_tag\n]==u\n\u540e\u7aef\u5f00\u53d1\n,:]\n     # \u7edf\u8ba1\u6240\u6709\u540e\u7aef\u5f00\u53d1\u7f16\u7a0b\u8bed\u8a00\u7684\u804c\u4f4d\u9700\u6c42\u91cf\u3001\u5e73\u5747\u85aa\u8d44\u3001\u85aa\u8d44\u4e2d\u4f4d\u6570\n    tech_backend = technology_backend.groupby([\nthird_tag\n])[\nsalary\n].aggregate([eval(\nnp.\n+evaluate_method)]).sort_values(evaluate_method, ascending=False).reset_index()\n     # \u83b7\u53d6Python\u7684\u804c\u4f4d\u4fe1\u606f\u7528\u4e8e\u540e\u7eed\u753b\u56fe\u7684annotate\u7684text\u5750\u6807\u4f4d\u7f6e\u548c\u663e\u793a\u7684\u6570\u5b57\n    python_index = tech_backend.loc[tech_backend[\nthird_tag\n] == u\nPython\n, :].index.values[0]\n    python_value = tech_backend.loc[tech_backend[\nthird_tag\n] == u\nPython\n, :][evaluate_method].values[0]\n    # \u901a\u8fc7plt.subplots()\u5efa\u7acb\u4e00\u4e2aaxis\u5b50\u56fe\u7528\u4e8e\u540e\u7eed\u7ed8\u56fe\n    fig, ax = plt.subplots(figsize=(10,8))\n    # \u8c03\u7528seaborn\u7684barplot\u8fdb\u884c\u7ed8\u56fe\n    g = sns.barplot(y=\nthird_tag\n, x=evaluate_method, data=tech_backend, palette=\nPuBu_d\n, ax=ax)\n    ax.set_yticklabels(g.get_yticklabels(), fontproperties=font, fontsize=18)\n    # \u786e\u5b9aannotate\u7684text\u6587\u672c\u4f4d\u7f6e\u7684x\u5750\u6807\u4f4d\u7f6e\n    annotate_x_delta = tech_backend[evaluate_method][0] / 10    \n    ax.set_xlabel(content, fontsize=16, fontproperties=font)\n    ax.set_ylabel(\n)\n    ax.set_title(u\n\u540e\u7aef\u5f00\u53d1\n+content, fontproperties=font, fontsize=20)\n    # sns.despine() \n    ax.annotate(str(int(python_value)), xy = (python_value, python_index), xytext = (python_value+annotate_x_delta, python_index+3), fontproperties=font, fontsize=20, arrowprops = dict(facecolor = 'k'))\n    ax.xaxis.grid(True, linestyle = \n-.\n,)\n    # \u7ed8\u5236\u540e\u7aef\u5f00\u53d1\u7f16\u7a0b\u8bed\u8a00\u767e\u5206\u6bd4\u997c\u56fe\n    if evaluate_method == \nsize\n:\n        # \u8ba1\u7b97\u540e\u7aef\u5f00\u53d1\u5404\u7f16\u7a0b\u8bed\u8a00\u7684\u804c\u4f4d\u6bd4\u4f8b        \n        tech_backend[\nposition_property\n] = tech_backend[\nsize\n] / tech_backend[\nsize\n].sum() * 100\n        pie_data = tech_backend.loc[tech_backend[\nposition_property\n] \n 1, [\nthird_tag\n, \nposition_property\n]]\n        less_than_one = 100 - pie_data[\nposition_property\n].sum()\n        pie_data.loc[pie_data[\nthird_tag\n] == u\n\u540e\u7aef\u5f00\u53d1\u5176\u5b83\n, \nposition_property\n] += less_than_one\n        pie_data.sort_values(\nposition_property\n, ascending=False, inplace=True)\n        num = len(pie_data)\n        vals = range(num) #\u521b\u5efa\u6570\u636e\u7cfb\u5217\n        labels = pie_data[\nthird_tag\n]\n        explode = np.zeros(num)\n        index_py = pie_data[pie_data[\nthird_tag\n] == u\nPython\n].index.values[0]\n        explode[index_py] += 0.15\n        fig1,ax1 = plt.subplots(figsize=(6,6))\n        ax1.pie(pie_data[\nposition_property\n], labels=labels, autopct='%1.2f%%', \n                pctdistance=.8, shadow=False, startangle=20,radius=1.2, \n                labeldistance=1.06, colors=('b', 'g', 'r', 'c', 'y', 'orange', 'm', 'yellowgreen', 'gold', 'lightskyblue', 'lightcoral'),\n                textprops={\nfontproperties\n: font, \nfontsize\n:12}, explode=explode)\n        ax1.set_title(u'\u540e\u7aef\u5f00\u53d1\u804c\u4f4d\u5206\u5e03',fontsize=20, fontproperties=font)\n        ax1.axis(\nequal\n)\n#     fig.savefig(\n/home/darren/Desktop/backend_techww.png\n)\n\n\n\n\nIT_occupies(data, u\n\u62db\u8058\u804c\u4f4d\u6570\u91cf\n, \nsize\n)\n\n\n\n\n\n\n\n\nIT_occupies(data, u\n\u5e73\u5747\u85aa\u8d44 k(\uffe5)\n, \nmean\n)\n\n\n\n\n\n\nIT_occupies(data, u\n\u85aa\u8d44\u4e2d\u4f4d\u6570 k(\uffe5)\n, \nmedian\n)\n\n\n\n\n\n\nJava\u7684\u62db\u8058\u804c\u4f4d\u4fe1\u606f\u6700\u591a,\u67092700\u591a\u62db\u8058\u804c\u4f4d\uff0c\u5360\u6bd429.37%\uff0c\u7f16\u7a0b\u8bed\u8a00\u7684\u8001\u5927\u5730\u4f4d\u4e0d\u53ef\u64bc\u52a8\uff01PHP\u804c\u4f4d\u9700\u6c42\u6b21\u4e4b\uff0c\u5360\u6bd414.08%\uff0c\u540e\u7eed\u5206\u522b\u662fC\u3001C++\u3001.NET\u3001Python\uff0c\u5176\u4e2dPython\u65e5\u9700\u6c42\u804c\u4f4d\u4e0d\u5230400\u4e2a\uff0c\u5360\u6bd45.24%\u3002\uff08\u6ce8\uff1a\u867d\u7136.NET\u4e0d\u7b97\u771f\u6b63\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u4f46\u62c9\u52fe\u7f51\u7684\u6570\u636e\u662f\u5982\u6b64\u5206\u7c7b\uff0c\u5728\u8fd9\u4e5f\u4e00\u5e76\u5f53\u6210\u4e00\u95e8\u7f16\u7a0b\u8bed\u8a00\u770b\u5f85\uff0c\u6570\u636e\u6316\u6398\u3001\u7cbe\u51c6\u63a8\u8350\u7b49\u7c7b\u540c\uff09\n\n\n\u85aa\u8d44\u65b9\u9762\uff0c\u6700\u9ad8\u7684\u662f\u6570\u636e\u6316\u6398\u548c\u63a8\u8350\u7b97\u6cd5\u7c7b\u3001\u5176\u6b21\u662f\u4e00\u4e9b\u65b0\u5174\u7f16\u7a0b\u8bed\u8a00\u5982Go\uff0cPython\u7684\u5e73\u5747\u85aa\u8d44\u8f83\u9ad8\uff0c\u8fbe\u523019K\uff0c\u9ad8\u4e8eJava\u3001PHP\u3001C\u3001C++\u7b49\u3002\n\n\n\u6ce8\u610f\uff1a\u62c9\u52fe\u7f51\u53d1\u5e03\u85aa\u8d44\u662f\u4e00\u4e2a\u533a\u95f4\u8303\u56f4\uff0c\u56e0\u6b64\u672c\u6587\u91c7\u53d6\u7684\u662f\u8be5\u533a\u95f4\u7684\u5e73\u5747\u503c\uff0c\u4f46\u4ece\u73b0\u5b9e\u751f\u6d3b\u7684\u89c4\u5f8b\u770b\uff0c\u4f7f\u7528\u85aa\u8d44\u533a\u95f4\u7684\u6700\u4f4e\u503c\u6bd4\u8f83\u7b26\u5408\u903b\u8f91\u3002\n\n\n\u5404\u5927\u57ce\u5e02\u7684\u540e\u7aef\u5f00\u53d1\u8bed\u8a00\u7684\u804c\u4f4d\u9700\u6c42\u548c\u85aa\u8d44\u6c34\u5e73\n\n\n# seaborn\u7684pointplot\u6216matplotlib\u7684plot\u7684\u70b9\u7684\u7c7b\u578b\nmarkers = [\n            'd', '\n', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', '\n', '|'\n        ] # '_',\nparam_dist = {\ncity\n: u\n\u57ce\u5e02\n, \nsize\n: u\n\u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4 %\n, \nmean\n: u\n\u5e73\u5747\u85aa\u8d44 k(\uffe5)\n,\n              \nmedian\n: u\n\u85aa\u8d44\u4e2d\u4f4d\u6570 k(\uffe5)\n, \ncompany_size\n: u\n\u4f01\u4e1a\u89c4\u6a21\n, \n              \nfinance_stage\n: u\n\u4f01\u4e1a\u91d1\u878d\u72b6\u51b5\n, \nwork_experience\n: u\n\u5de5\u4f5c\u7ecf\u9a8c\n, \neducation\n: u\n\u5b66\u5386\n}\n\n\n\n\ndef tech_backend_plot(second_feature, evaluate_method, lang_part=True, big_feature=u\n\u540e\u7aef\u5f00\u53d1\n):\n    \n\u8ba1\u7b97\u5404\u5927\u57ce\u5e02\u7684\u540e\u7aef\u5f00\u53d1\u7684\u7f16\u7a0b\u8bed\u8a00\u7684\u804c\u4f4d\u9700\u6c42\u548c\u85aa\u8d44\u72b6\u51b5\uff0c\u53ea\u53d6\u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4\n5\u7684\u5e38\u89c1\u7f16\u7a0b\u8bed\u8a00\n    big_feature: IT\u4e03\u5927\u5206\u652f\u9886\u57df\u7684\u4e00\u4e2a\uff0c\u9ed8\u8ba4\u662f\u6280\u672f\n    second_feature: \u662f\u6570\u636e\u96c6\u4e2d\u9664\u4e86\u6280\u672f\u7684\u5176\u4ed6\u7279\u5f81\uff0c\u5305\u62eccity,company_size, education etc\u7aef\n    evaluate_method: \u8868\u793a\u7684\u662f\u5bf9data\u6570\u636e\u5206\u7ec4\u540e\u5bf9\u5404\u4e2a\u5206\u7ec4\u5b9e\u65bd\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u4e3b\u8981\u6709np.mean,np.median,np.size\n    lang_part: \u610f\u601d\u662f\u8981\u4e0d\u8981\u53d6\u540e\u7aef\u7f16\u7a0b\u8bed\u8a00\u7684\u4e00\u90e8\u5206\uff0c\u9ed8\u8ba4\u662fTrue,\u5426\u5219\u5c06\u7ed8\u5236\u6240\u6709\u7684\u540e\u7aef\u5f00\u53d1\u8bed\u8a00\n    \n\n    technology_backend = data.loc[data[\nsecond_tag\n] == big_feature,:]    \n    # \u53ea\u62bd\u53d6\u540e\u7aef\u7f16\u7a0b\u8bed\u8a00\u4e2d\u62db\u8058\u9700\u6c42\u5927\u7684\u524d7\u4e2a\u7f16\u7a0b\u8bed\u8a00\u7684\u540d\u79f0\n    targeted_lang = technology_backend['third_tag'].value_counts().index.values.tolist()[:7]\n    # \u5220\u9664\n\u540e\u7aef\u5f00\u53d1\u5176\u4ed6\u8bed\u8a00\n\uff0c\u5148\u7528\n|\n.join(targeted_lang)\u518d\u6267\u884c\u4ee5\u4e0b\u8bed\u53e5\n    if u'\\u540e\\u7aef\\u5f00\\u53d1\\u5176\\u5b83' in targeted_lang:\n        targeted_lang.remove(u'\\u540e\\u7aef\\u5f00\\u53d1\\u5176\\u5b83') \n\n    tech_backend = technology_backend.groupby([second_feature, \nthird_tag\n])[\nsalary\n].aggregate([eval(\nnp.\n + evaluate_method)]).reset_index()    \n    # \u53ea\u8bc4\u4f30Java\u3001C\u3001C++\u3001Python\u7b496\u4e2a\u540e\u7aef\u7f16\u7a0b\u8bed\u8a00\n    if lang_part:\n        tech_backend = tech_backend[tech_backend['third_tag'].str.contains(u'Java|PHP|C|C\\+\\+|\\.NET|Python')]\n    # \u540e\u7aef\u7f16\u7a0b\u8bed\u8a00\u7684\u540d\u79f0\u5217\u8868\uff0c\u7528\u4e8e\u7ed8\u56fe\u7684tickslabels\u8bbe\u7f6e\n    second_feature_list = tech_backend[second_feature].unique().tolist()\n    # \u5bf9\u8bc4\u4f30\u804c\u4f4d\u9700\u6c42\u7684\uff0c\u91c7\u7528\u767e\u5206\u6bd4\n    if evaluate_method == \nsize\n:\n        for i in second_feature_list:\n            one_data = tech_backend.loc[tech_backend[second_feature] == i, :]\n            index_ = one_data.index\n            total_ = one_data[evaluate_method].sum()\n            # \u5728tech_backend\u7684DataFrame\u65b0\u5efa\u4e00\u4e2a\u7279\u5f81property\uff0c\u5b58\u653e\u8ba1\u7b97\u5404\u4e2a\u7f16\u7a0b\u8bed\u8a00\u5728second_feature\u4e2d\u7684\u767e\u5206\u6bd4\uff0c\u5982second_feature\u662fcity\n            tech_backend.ix[index_, \nproperty\n] = one_data[evaluate_method] / total_ * 100\n    # \u7528\u4e8eseaborn barplot\u7684hue_order\u987a\u5e8f\u5217\u8868\n    backend_lang = tech_backend.groupby(\nthird_tag\n)[evaluate_method].sum().sort_values(ascending=False).index.values.tolist()\n    # \u7528\u4e8eseaborn barplot\u7684order\u987a\u5e8f\u5217\u8868    \n    backend_second_feature = tech_backend.groupby(second_feature)[evaluate_method].sum().sort_values(ascending=False).index.values.tolist()\n\n    plt.figure(figsize=(12,10))\n    with sns.color_palette(\nPuBuGn_d\n):\n        if evaluate_method == \nsize\n:\n            y_str = \nproperty\n\n        else:\n            y_str = evaluate_method\n        g = sns.pointplot(y=y_str, x=second_feature, hue=\nthird_tag\n, hue_order=backend_lang, order=backend_second_feature,\n                       data=tech_backend, size=10, markers=markers, index=True,\n                       aspect=1.2, legend=False, dodge=True)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=45)\n    plt.ylabel(u\n{0}\n.format(param_dist.get(evaluate_method)), fontsize=16, fontproperties=font)\n    plt.xlabel(\n)\n    plt.title(u\n\u540e\u7aef\u5f00\u53d1\u7f16\u7a0b\u8bed\u8a00\u4e0e\u4e0d\u540c{0}\u7684{1}\n.format(param_dist.get(second_feature),param_dist.get(evaluate_method)), fontproperties=font, fontsize=23)\n    plt.gca().yaxis.grid(True, linestyle = \n-.\n,)\n    plt.legend(loc=\nbest\n,prop=font, fontsize=8)\n\n\n\n\ntech_backend_plot(\ncity\n, \nsize\n)\n\n\n\n\n\n\ntech_backend_plot(\ncity\n, \nmean\n)\n\n\n\n\n\n\ntech_backend_plot(\ncity\n, \nmedian\n)\n\n\n\n\n\n\n\u5317\u4eac\u3001\u4e0a\u6d77\u3001\u6df1\u5733\u3001\u5e7f\u5dde\u3001\u676d\u5dde\u7684IT\u884c\u4e1a\u9700\u6c42\u91cf\u6700\u591a\uff0c\u85aa\u8d44\u4e5f\u8f83\u9ad8\uff08\u5e7f\u5dde\u85aa\u8d44\u504f\u4f4e\uff09\uff0c\u5c5e\u4e8e\u7b2c\u4e00\u68af\u961f\uff1b\u4ece\u5404\u7f16\u7a0b\u8bed\u8a00\u770b\uff0cJava\u7edd\u5bf9\u7684\u9738\u4e3b\u5730\u4f4d\uff0c\u4f46\u5728\u4e00\u7ebf\u53d1\u8fbe\u57ce\u5e02\uff0cJava\u8bed\u8a00\u6240\u5360\u7684\u6bd4\u4f8b\u8fdc\u4f4e\u4e8e\u5176\u4ed6\u57ce\u5e02\u7684\u6bd4\u4f8b\uff0c\u5373\u4e00\u7ebf\u53d1\u8fbe\u57ce\u5e02\u5404\u79cd\u7f16\u7a0b\u8bed\u8a00\u90fd\u6709\u53d1\u5c55\u673a\u4f1a\uff0c\u800c\u4e8c\u7ebf\u57ce\u5e02\u8fd8\u5c40\u9650\u5728\u51e0\u95e8\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0c\u5982\u6d4e\u5357\uff0cJava\u5360\u6d4e\u5357\u804c\u4f4d\u9700\u6c42\u768480%\u5de6\u53f3\uff0cPHP\u5360\u6bd415%\u5de6\u53f3\uff0c.NET\u5360\u6bd45%\u5de6\u53f3\uff1bPython\u9700\u6c42\u5360\u6bd4\u6700\u5927\u7684\u662f\u5317\u4eac\uff0c\u5176\u6b21\u662f\u4e0a\u6d77\u548c\u676d\u5dde\uff0c\u76f8\u6bd4\u5176\u4ed6\u8bed\u8a00\uff0cPython\u62db\u8058\u9700\u6c42\u8f83\u5c0f\uff0c\u4f46\u85aa\u8d44\u8f83\u9ad8\u3002\n\n\ntech_backend_plot(\nfinance_stage\n, \nsize\n)\n\n\n\n\n\n\n\u4ece\u62db\u8058\u9700\u6c42\u4e0a\u770b\uff0cJava\u7684\u62db\u8058\u9700\u6c42\u6700\u591a\uff0c\u5176\u6b21\u662fPHP\uff0cPython\u62db\u8058\u804c\u4f4d\u8f83\u4f4e\uff0c\u4f46Python\u7684\u85aa\u8d44\u8f83\u9ad8\u3002\n\n\ntech_backend_plot(\nfinance_stage\n, \nmean\n)\n\n\n\n\n\n\ntech_backend_plot(\nfinance_stage\n, \nmedian\n)\n\n\n\n\n\n\ntech_backend_plot(\ncompany_size\n, \nsize\n)\n\n\n\n\n\n\ntech_backend_plot(\ncompany_size\n, \nmean\n)\n\n\n\n\n\n\ntech_backend_plot(\ncompany_size\n, \nmedian\n)\n\n\n\n\n\n\n\u516c\u53f8\u89c4\u6a21\u4e0e\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u6298\u7ebf\u56fe\u770b\u51fa\uff0c\u5927\u578b\u516c\u53f8\u5bf9Java\u7684\u9700\u6c42\u6700\u591a\uff0c\u5c0f\u578b\u516c\u53f8\u5bf9PHP\u548cPython\u7684\u9700\u6c42\u8f83\u5927\uff08\u6ce8\u610f\uff0c\u56fe\u4e2d\u4e00\u79cd\u7c7b\u578b\u7684\u516c\u53f8\u4e2d\u5404\u4e2a\u7f16\u7a0b\u8bed\u8a00\u5360\u6bd4\u4e4b\u548c\u662f100%\uff0c\u5176\u4ed6\u6298\u7ebf\u56fe\u4e5f\u7c7b\u4f3c\uff09\u3002\u85aa\u8d44\u65b9\u9762\uff0c\u5927\u578b\u516c\u53f8\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u5176\u6b21\u662f\u4e2d\u578b\u516c\u53f8\uff0c\u6700\u4f4e\u662f\u5c0f\u578b\u516c\u53f8\u3002\n\n\ntech_backend_plot(\nwork_experience\n, \nsize\n)\n\n\n\n\n\n\ntech_backend_plot(\nwork_experience\n, \nmean\n)\n\n\n\n\n\n\n\u85aa\u8d44\u57fa\u672c\u4e0e\u5de5\u4f5c\u7ecf\u9a8c\u6210\u6b63\u6bd4\u3002\n\n\ntech_backend_plot(\neducation\n, \nmedian\n)\n\n\n\n\n\n\ntech_backend_plot(\neducation\n, \nmean\n)\n\n\n\n\n\n\ntech_backend_plot(\neducation\n, \nsize\n)\n\n\n\n\n\n\n\u4e0a\u56fe\u8868\u793a\u7684\u662f\u4e0d\u540c\u5b66\u5386\u7684\u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4\uff0c\u5373\u672c\u79d1\u5b66\u5386\u4e2d\uff0c\u5404\u4e2a\u540e\u7aef\u5f00\u53d1\u8bed\u8a00\u62db\u8058\u9700\u6c42\u7684\u767e\u5206\u6bd4\uff08\u672c\u79d1\u5b66\u5386\u4e2d\u8fd96\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u767e\u5206\u6bd4\u4e4b\u548c\u4e3a100%\uff09\uff0c\u7531\u4e8eC#\u548c.NET\u5728\u7855\u58eb\u5b66\u5386\u4e0a\u6ca1\u6709\u62db\u8058\u9700\u6c42\uff0c\u6240\u4ee5\uff0c\u867d\u7136C++\u3001C\u3001Python\u7684\u7855\u58eb\u5b66\u5386\u9700\u6c42\u767e\u5206\u6bd4\u660e\u663e\u589e\u591a\uff0c\u5e76\u4e0d\u4e00\u5b9a\u4ee3\u8868\u4e86\u8fd93\u95e8\u7f16\u7a0b\u8bed\u8a00\u5bf9\u9ad8\u5b66\u5386\u7684\u7edd\u5bf9\u9700\u6c42\u8d85\u8fc7\u4e86\u5176\u4ed6\u76f8\u5bf9\u4f4e\u5b66\u5386\uff0c\u53ea\u662f\u76f8\u5bf9\u800c\u8a00\uff0cC\u548cC++\u66f4\u9752\u7750\u4e8e\u9ad8\u5b66\u5386\u6c42\u804c\u8005\u3002\u4ece\u524d\u9762\u7684\u5206\u6790\u53ef\u77e5\uff0c\u672c\u79d1\u548c\u5927\u4e13\u662f\u62db\u8058\u4f01\u4e1a\u7684\u9996\u5148\u5b66\u5386\u3002\n\n\n\u85aa\u8d44\u4e0e\u5b66\u5386\u57fa\u672c\u6210\u6b63\u6bd4\n\n\n\u62c9\u52fe\u7f51Python\u804c\u4f4d\u63cf\u8ff0\u6027\u5206\u6790\n\n\nparam_dist = {\nsize\n: u\n\u62db\u8058\u804c\u4f4d\u6570\u91cf\u4e0e\u767e\u5206\u6bd4\n, \nmean\n: u\n\u5e73\u5747\u85aa\u8d44\n, \n              \nmedian\n: u\n\u85aa\u8d44\u4e2d\u4f4d\u6570\n,             \n             }\n\n\n\n\ndef series_bar_plot(lang, feature, evaluate_method):\n    \n\n    \u7ed8\u5236\u4e00\u95e8\u7f16\u7a0b\u8bed\u8a00\u7684\u804c\u4f4d\u9700\u6c42\u3001\u85aa\u8d44\u7684\u67f1\u72b6\u56fe\n    lang: \u7f16\u7a0b\u8bed\u8a00\u540d\u79f0\n    feature: \u6570\u636e\u5206\u7ec4\u7684\u4f9d\u636e\u7279\u5f81\n    evaluate_method: \u5b9e\u65bd\u5230\u5206\u7ec4\u540e\u7684\u6570\u636e\u7684\u7edf\u8ba1\u65b9\u6cd5\n    \n\n    # \u83b7\u53d6\u4e00\u95e8\u7f16\u7a0b\u8bed\u8a00\u7684\u6240\u6709\u62db\u8058\u4fe1\u606f\u6570\u636e\n    data_lang = data[data[\nthird_tag\n] == lang]\n    # \u6839\u636efeature\u5c06\u6570\u636e\u96c6\u5206\u7ec4\uff0c\u5e76\u4f9d\u636eevaluate_method\u5bf9\u5206\u7ec4\u540e\u7684\u6570\u636e\u8fdb\u884c\u7edf\u8ba1\n    one_series = data_lang.groupby([feature])['salary'].aggregate([eval('np.'+evaluate_method)]).sort_values(evaluate_method, ascending=False)\n\n    fig, ax1 = plt.subplots(figsize=(8,6))  # \u4f7f\u7528subplots()\u521b\u5efa\u7a97\u53e3    \n    g = sns.barplot(y=one_series[evaluate_method], x=one_series.index, palette=\nBuGn_d\n, ax=ax1)\n    # \u7edf\u8ba1\u65b9\u6cd5\u662fcout/size\u5c31\u7ed8\u5236\u53ccy\u8f74\u56fe\n    if evaluate_method == \nsize\n:\n        ax2 = ax1.twinx() # \u521b\u5efa\u7b2c\u4e8c\u4e2a\u5750\u6807\u8f74\n        x_list = range(len(one_series))\n        y_point_list = one_series[evaluate_method] / one_series[evaluate_method].sum() * 100\n        ax2.plot(x_list, y_point_list, linewidth = 3, color=\ng\n, marker=\no\n, label=u\n\u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4\n) \n        ax2.legend(loc=\nbest\n, prop=font)\n        ax2.set_ylabel(u'\u62db\u8058\u804c\u4f4d\u6570\u91cf\u767e\u5206\u6bd4%', fontproperties=font, fontsize = 16)\n    ax1.set_xlabel(\n) \n    ax1.set_ylabel(param_dist.get(evaluate_method), fontsize=16, fontproperties=font)\n    x_ticks_l = [i for i in one_series.index]\n    ax1.set_xticklabels(x_ticks_l, fontproperties=font, fontsize=16, rotation= 90 if feature == \nfinance_stage\n else 30)\n    ax1.yaxis.grid(True, linestyle = \n-.\n,)\n    ax1.set_title(lang+param_dist.get(evaluate_method),fontproperties=font,fontsize=25)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n\n\n\n\nseries_bar_plot(\nPython\n, \ncity\n, \nsize\n)\n\n\n\n\n\n\nseries_bar_plot(\nPython\n, \ncity\n, \nmean\n)\n\n\n\n\n\n\nseries_bar_plot(\nPython\n, \ncity\n, \nmedian\n)\n\n\n\n\n\n\nseries_bar_plot(\nPython\n, \nfinance_stage\n, \nsize\n)\n\n\n\n\n\n\nseries_bar_plot(\nPython\n, \nfinance_stage\n, \nmean\n)\n\n\n\n\n\n\nseries_bar_plot(\nPython\n, \nfinance_stage\n, \nmedian\n)\n\n\n\n\n\n\nfor i in [\nsize\n, \nmean\n, \nmedian\n]:\n    series_bar_plot(\nPython\n, \ncompany_size\n, i)\n\n\n\n\n\n\n\n\n\n\nfor i in [\nsize\n, \nmean\n, \nmedian\n]:\n    series_bar_plot(\nPython\n, \nwork_experience\n, i)\n\n\n\n\n\n\n\n\n\n\nfor i in [\nsize\n, \nmean\n, \nmedian\n]:\n    series_bar_plot(\nPython\n, \neducation\n, i)\n\n\n\n\n\n\n\n\n\n\nPython\u7684\u62db\u8058\u9700\u6c42\u603b\u91cf\u4e0d\u591a\uff0c\u4f46\u5e73\u5747\u85aa\u8d44\u8f83\u9ad8\uff0c\u8fd9\u4e5f\u7b26\u5408\u65b0\u5174\u8bed\u8a00\u7684\u7279\u70b9\u3002\n\n\nPython\u62db\u8058\u9700\u6c42\u6700\u591a\u7684\u4f9d\u65e7\u662f\u5317\u4eac\uff0c\u5176\u6b21\u4e0a\u6d77\uff0c\u5e73\u5747\u85aa\u8d44\u6700\u9ad8\u7684\u8fd8\u662f\u5317\u4eac\uff0c\u5176\u6b21\u662f\u6df1\u5733\u548c\u4e0a\u6d77\u3002\u4ece\u62db\u8058\u516c\u53f8\u7684\u89d2\u5ea6\u5206\u6790\uff0c\u4e2d\u578b\u7684\u6210\u719f\u548c\u6210\u957f\u6027\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u6c34\u5e73\u90fd\u8f83\u9ad8\uff0c\u5927\u578b\u4e0a\u5e02\u516c\u53f8\u7684\u85aa\u8d44\u9ad8\u4f46\u62db\u8058\u9700\u6c42\u6ca1\u6709\u4e2d\u578b\u516c\u53f8\u591a\uff0c50\u4eba\u4ee5\u4e0b\u7684\u521d\u521b\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u90fd\u662f\u6700\u4f4e\u3002\n\n\n\u5de5\u4f5c\u7ecf\u9a8c\u65b9\u9762\uff0c\u9700\u6c42\u6700\u5927\u7684\u662f3-5\u5e74\uff0c\u5176\u6b21\u662f1-3\u5e74\uff0c\u85aa\u8d44\u8ddf\u5de5\u4f5c\u7ecf\u9a8c\u57fa\u672c\u6210\u6b63\u6bd4\uff0c\u6709\u4e00\u4e2a\u7279\u4f8b\u662f\u5e94\u5c4a\u6bd5\u4e1a\u751f\uff0c\u5176\u5e73\u5747\u85aa\u8d44\u7adf\u7136\u9ad8\u4e8e\u67093\u5e74\u5de5\u4f5c\u7ecf\u9a8c\u7684\u6c42\u804c\u8005\uff01\u4ed4\u7ec6\u5206\u6790\u53d1\u73b0\uff0c\u5e94\u5c4a\u6bd5\u4e1a\u751f\u7684\u62db\u8058\u9700\u6c42\u975e\u5e38\u4e4b\u4f4e\uff0c\u6240\u4ee5\uff0c\u5e94\u5c4a\u6bd5\u4e1a\u751f\u7684\u9ad8\u85aa\u5176\u5b9e\u662f\u7531\u4e8e\u6837\u672c\u91cf\u592a\u5c11\u53c8\u53c8\u53d7\u5230\u7ec4\u5185\u79bb\u7fa4\u503c\u7684\u5e72\u6270\uff0c\u9020\u6210\u5e73\u5747\u85aa\u8d44\u5f88\u9ad8\u3002\n\n\n\u67e5\u8be2\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u53ea\u6709\u5317\u4eac\u9ad8\u7ef4\u6570\u91d1\u79d1\u6280\u6709\u9650\u516c\u53f8\u660e\u786e\u6807\u660e\u62db\u8058\u5e94\u5c4a\u6bd5\u4e1a\u751f\uff0c\u5e73\u5747\u85aa\u8d44\u662f22k\uff0c\u56e0\u6b64\u672c\u6587\u4e2d\u5e94\u5c4a\u6bd5\u4e1a\u751f\u7684\u4fe1\u606f\u6ca1\u6709\u592a\u5927\u53c2\u8003\u610f\u4e49\u3002\n\n\n\u5e73\u5747\u85aa\u8d44\u4e0e\u5b66\u5386\u4e5f\u6210\u6b63\u6bd4\uff0c\u4f46\u672c\u79d1\u5b66\u5386\u7684\u62db\u8058\u9700\u6c42\u8fdc\u8fdc\u8d85\u8fc7\u5176\u4ed6\u5b66\u5386\u3002\n\n\n# data_lang = data[data[\nthird_tag\n] == \nPython\n]\n# one_series = data_lang.groupby([\ncompany_size\n])['salary'].aggregate([np.size]).sort_values(\nsize\n, ascending=False)\ndata_py = data[data[\nthird_tag\n] == \nPython\n]\n\n\n\n\ndata_py.loc[data_py[\nwork_experience\n] == u\n\u5e94\u5c4a\u6bd5\u4e1a\u751f\n, :]\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nfinance_stage\n\n      \ncity\n\n      \ndist\n\n      \nsalary\n\n      \njob_nature\n\n      \nindustry_field\n\n      \ncompany\n\n      \nthird_tag\n\n      \npublished_time\n\n      \nsecond_tag\n\n      \nposition_advantage\n\n      \nfirst_tag\n\n      \nlast_login\n\n      \nwork_experience\n\n      \nposition_type\n\n      \nposition\n\n      \neducation\n\n      \ncrawl\n\n      \ncompany_size\n\n      \nday\n\n    \n\n  \n\n  \n\n    \n\n      \n79248\n\n      \n\u6210\u957f\u578b(\u4e0d\u9700\u8981\u878d\u8d44)\n\n      \n\u5317\u4eac\n\n      \n\u671d\u9633\u533a\n\n      \n22.5\n\n      \n\u5168\u804c\n\n      \n\u79fb\u52a8\u4e92\u8054\u7f51\n\n      \n\u5317\u4eac\u9ad8\u7ef4\u6570\u91d1\u79d1\u6280\u6709\u9650\u516c\u53f8\n\n      \nPython\n\n      \n2017/8/4 10:11\n\n      \n\u540e\u7aef\u5f00\u53d1\n\n      \n\u5e74\u5e95\u53cc\u85aa,\u5f39\u6027\u5236\u529e\u516c,15\u5929\u5e74\u5047\n\n      \n\u6280\u672f\n\n      \n1.500000e+12\n\n      \n\u5e94\u5c4a\u6bd5\u4e1a\u751f\n\n      \n\u540e\u7aef\u5f00\u53d1\n\n      \npython\u5f00\u53d1\u9ad8\u7ea7\u5de5\u7a0b\u5e08\n\n      \n\u672c\u79d1\n\n      \n2017/8/4\n\n      \n50-150\u4eba\n\n      \n2017/8/4\n\n    \n\n  \n\n\n\n\n\n\n\n# \u66ff\u6362position\u63cf\u8ff0\n# data_py[\nposition\n] = data_py[\nposition\n].str.replace(u\n(.*?)\u9ad8\u7ea7(.*)\n, \n\\\\1\\\\2\n)\n# data_py[\nposition\n].replace(u\n.*?\u7814\u53d1.*\n, u\n\u5f00\u53d1\n, regex=True, inplace=True)\n# data_py[\nposition\n].replace(u\n.*?\u722c\u866b.*\n, u\n\u722c\u866b\n, regex=True, inplace=True)\n# data_py[\nposition\n].replace(u\n.*?\u6570\u636e.*\n, u\n\u6570\u636e\n, regex=True, inplace=True)\n# data_py[\nposition\n].replace(u\n.*?\u5168\u6808.*\n, u\n\u5168\u6808\n, regex=True, inplace=True)\n# data_py[\nposition\n].replace(u\n.*?\u8fd0\u7ef4.*\n, u\n\u8fd0\u7ef4\n, regex=True, inplace=True)\n# data_py[\nposition\n].replace(u\n.*?\u7b97\u6cd5.*\n, u\n\u7b97\u6cd5\n, regex=True, inplace=True)\n# data_py[\nposition\n].replace(u\n.*?\u540e\u7aef.*\n,u\n\u540e\u7aef\n, regex=True, inplace=True)\n# data_py[\nposition\n].replace(u\n.*?\u540e\u53f0.*\n,u\n\u540e\u7aef\n, regex=True, inplace=True)\n# data_py[\nposition\n].replace(u\n.*?\u5b89\u5168.*\n,u\n\u5b89\u5168\n, regex=True, inplace=True)\n# data_py[\nposition\n] = data_py[\nposition\n].str.replace(r\n.*?web.*\n,u\n\u540e\u7aef\n, flags=re.IGNORECASE)\n# data_py[\nposition\n].replace(u\n.*?\u670d\u52a1[\u5668|\u7aef].*\n,u\n\u540e\u7aef\n, regex=True, inplace=True)\n# data_py[\nposition\n] = data_py[\nposition\n].str.replace(r\n.*?python.*\n,u\npython\u5de5\u7a0b\u5e08\n, flags=re.IGNORECASE)\n# data_py[\nposition\n].replace(u\n.*?[\u540e\u7aef|\u5f00\u53d1].*\n,u\nweb\u5f00\u53d1\u5de5\u7a0b\u5e08\n, regex=True, inplace=True)\n# data_py[\nposition\n].replace(u\nweb\u5f00\u53d1\u5de5\u7a0b\u5e08\n,u\npython\u5f00\u53d1\u5de5\u7a0b\u5e08\n, regex=True, inplace=True)\n# data_py.loc[data_py[\nposition\n].str.contains(u\n\u5168\u6808\n), :].shape\n\n\n\n\nPython\u5177\u4f53\u804c\u4f4d\u5206\u5e03\n\n\npy_count = data_py[\nposition\n].value_counts()\npy_count.values.sum()\n\n\n\n\nnumpy.int64\n\n\n\nfig, ax1 = plt.subplots(figsize=(8,6))  # \u4f7f\u7528subplots()\u521b\u5efa\u7a97\u53e3    \ng = sns.barplot(y=py_count.values, x=py_count.index, palette=\nPuBu_d\n, ax=ax1)\n# \u7ed8\u5236\u53ccy\u8f74\u56fe\nax2 = ax1.twinx() # \u521b\u5efa\u7b2c\u4e8c\u4e2a\u5750\u6807\u8f74\nx_list = range(len(py_count))\ny_point_list = py_count.values / np.float(py_count.values.sum()) * 100\nax2.plot(x_list, y_point_list, linewidth = 3, color=\nb\n, marker=\no\n, label=u\n\u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4\n) \nax2.legend(loc=\nbest\n, prop=font)\nax2.set_ylabel(u'\u62db\u8058\u804c\u4f4d\u6570\u91cf\u767e\u5206\u6bd4%', fontproperties=font, fontsize = 16)\nax1.set_xlabel(\n) \nax1.set_ylabel(u\n\u62db\u8058\u804c\u4f4d\u6570\u91cf\n, fontsize=16, fontproperties=font)\nx_ticks_l = [i for i in py_count.index]\nax1.set_xticklabels(x_ticks_l, fontproperties=font, fontsize=16, rotation= 45)\nax1.yaxis.grid(True, linestyle = \n-.\n,)\nax1.set_title(u\nPython\u62db\u8058\u804c\u4f4d\u5206\u5e03\u8be6\u60c5\n,fontproperties=font,fontsize=25)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n\n\n\n\n([\nmatplotlib.axis.XTick at 0x7f8a0f50a250\n,\n  \nmatplotlib.axis.XTick at 0x7f8a0f5d9950\n,\n  \nmatplotlib.axis.XTick at 0x7f8a0f5e2690\n,\n  \nmatplotlib.axis.XTick at 0x7f8a0f49b150\n,\n  \nmatplotlib.axis.XTick at 0x7f8a0f49b850\n,\n  \nmatplotlib.axis.XTick at 0x7f8a0f49bf50\n,\n  \nmatplotlib.axis.XTick at 0x7f8a0f4910d0\n,\n  \nmatplotlib.axis.XTick at 0x7f8a0f4a7b90\n,\n  \nmatplotlib.axis.XTick at 0x7f8a0f4b22d0\n],\n \na list of 9 Text xticklabel objects\n)\n\n\n\n\n\npython\u5f00\u53d1\u5de5\u7a0b\u5e08\u4e3b\u8981\u6307\u7684\u662fweb\u5f00\u53d1\uff0c\u800cpython\u5de5\u7a0b\u5e08\u662f\u62db\u8058\u5c97\u4f4d\u540d\u79f0\u6ca1\u6709\u660e\u786e\u6807\u660e\uff0c\u8981\u4ece\u5c97\u4f4d\u8be6\u60c5\u9875\u9a8c\u8bc1\u5177\u4f53\u5c97\u4f4d\u60c5\u51b5\uff0c\u5176\u4ed6\u7684\u5206\u7c7b\u6807\u7b7e\u662f\u660e\u786e\u7684\u5177\u4f53\u5c97\u4f4d\uff0c\u5982\u6570\u636e\u7c7b\uff0c\u5305\u62ec\u4e86\u6570\u636e\u5206\u6790\u3001\u6316\u6398\u7b49\u3002\n\n\n\u7531\u4e8e\u6ca1\u6709\u91c7\u96c6\u804c\u4f4d\u8be6\u60c5\u9875\u4fe1\u606f\uff0c\u65e0\u6cd5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u62db\u8058\u6570\u91cf\u4ec5\u6b21\u4e8e\u5f00\u53d1\u7c7b\u7684\u6240\u8c13\u7684python\u5de5\u7a0b\u5e08\u5177\u4f53\u5c97\u4f4d\u4fe1\u606f\u3002\n\n\n\u62db\u8058\u804c\u4f4d\u63cf\u8ff0\u8bcd\u4e91\u56fe\n\n\n# \u7531\u4e8eposition_advantage\u4e2d\u6709float\u7c7b\u578b\uff0c\u6545\u8981\u5148\u8f6c\u6210str\nword_ = data[\nposition_advantage\n].apply(lambda x: str(x))\n# \u5c06\u6240\u6709str\u8fde\u63a5\u8d77\u6765\nwords = \n \n.join(word_)\n\n\n\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator   #\u8bcd\u4e91\u5e93\nimport jieba.analyse\nfrom scipy.misc import imread\ntags = jieba.analyse.extract_tags(words, topK=80, withWeight=False)\ntext =\n \n.join(tags)\ntext = unicode(text)\nd = path.dirname(__name__)\ntrump_coloring = imread(path.join(d, \nheroes.png\n))\n\nwc = WordCloud(font_path=\nukai.ttc\n,\n        background_color=\nwhite\n, max_words=300, mask=trump_coloring,\n        max_font_size=80, random_state=42)  # gray balck\n# generate word cloud \nwc.generate(text)\n# generate color from image\nimage_colors = ImageColorGenerator(trump_coloring)\nplt.figure(1,figsize=(8,10))\nplt.imshow(wc)\nplt.axis(\noff\n)\nplt.show()\n\n\n\n\n\n\n\u5c97\u4f4d\u63cf\u8ff0\u7528\u7684\u8bcd\u6c47\u6700\u591a\u7684\u662f\u57f9\u8bad\u3001\u6241\u5e73\u3001\u5e73\u53f0\uff0c\u4f53\u73b0\u51fa\u5f53\u4ecaIT\u884c\u4e1a\u6bd4\u8f83\u6ce8\u91cd\u5458\u5de5\u7684\u57f9\u8bad\u53ca\u5b9e\u65bd\u6241\u5e73\u5316\u7ba1\u7406\n\n\n\u62db\u8058\u804c\u4f4d\u53d1\u5e03\u65f6\u95f4\u89c4\u5f8b\n\n\n# \u5c06\u65f6\u95f4str\u8f6c\u6210datetime\ndata['time_published'] = pd.to_datetime(data['published_time'])\n# \u5c06\u8f6c\u6362\u597d\u7684\u65f6\u95f4series\u8bbe\u7f6e\u6210\u884c\u7d22\u5f15\ndata.set_index(\ntime_published\n, inplace=True)\n\n\n\n\n# \u63d0\u53d6\u65f6\u95f4\u7d22\u5f15\u7684\u5c0f\u65f6\ndata[\nhour\n] = data.index.hour\nhour_info = pd.DataFrame(data.hour.value_counts())\nhour_info[\nproperty\n] = np.round(hour_info.hour / hour_info.hour.sum() * 100, 2)\n\n\n\n\nhour_cs = data.groupby([\nhour\n, \ncompany_size\n])[\nsalary\n].aggregate(np.size).reset_index().sort(\nsalary\n, ascending=False)\n\n\n\n\nplt.figure(figsize=(8,6))\nmarkers = [\n            'd', '\n', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', '\n', '|', \n_\n\n        ]\ng = sns.pointplot(x=\nhour\n, y=\nsalary\n, hue=\ncompany_size\n,\n                  data=hour_cs, dodage=True, markers=markers, size=7)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u\n\u5c0f\u65f6\n, fontsize=16, fontproperties=font)\nplt.ylabel(u\n\u62db\u8058\u804c\u4f4d\u6570\u91cf\n, fontsize=16, fontproperties=font)\nplt.title(u\nIT\u884c\u4e1a\u804c\u4f4d\u62db\u8058\u9700\u6c42\n, fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=\nbest\n,prop=font, fontsize=15)\n\n\n\n\nmatplotlib.legend.Legend at 0x7fc966e6bf50\n\n\n\n\n\n\nhour_fs = data.groupby([\nhour\n, \nfinance_stage\n])[\nsalary\n].aggregate(np.size).reset_index().sort(\nsalary\n, ascending=False)\nplt.figure(figsize=(8,6))\nmarkers = [\n            'd', '\n', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', '\n', '|', \n_\n\n        ]\ng = sns.pointplot(x=\nhour\n, y=\nsalary\n, hue=\nfinance_stage\n,\n                  data=hour_fs, dodage=True, markers=markers, size=7)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u\n\u5c0f\u65f6\n, fontsize=16, fontproperties=font)\nplt.ylabel(u\n\u62db\u8058\u804c\u4f4d\u6570\u91cf\n, fontsize=16, fontproperties=font)\nplt.title(u\nIT\u884c\u4e1a\u804c\u4f4d\u62db\u8058\u9700\u6c42\n, fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=\nbest\n,prop=font, fontsize=15)\n\n\n\n\nmatplotlib.legend.Legend at 0x7fc973c6ba10\n\n\n\n\n\n\ndata_py = data[data[\nthird_tag\n] == u\nPython\n]\nhour_cs = data_py.groupby([\nhour\n, \ncompany_size\n])[\nsalary\n].aggregate(np.size).reset_index().sort(\nsalary\n, ascending=False)\nplt.figure(figsize=(8,6))\nmarkers = [\n            'd', '\n', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', '\n', '|', \n_\n\n        ]\ng = sns.pointplot(x=\nhour\n, y=\nsalary\n, hue=\ncompany_size\n,\n                  data=hour_cs, dodage=True, markers=markers, size=7)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u\n\u5c0f\u65f6\n, fontsize=16, fontproperties=font)\nplt.ylabel(u\n\u62db\u8058\u804c\u4f4d\u6570\u91cf\n, fontsize=16, fontproperties=font)\nplt.title(u\nPython\u804c\u4f4d\u62db\u8058\u9700\u6c42\n, fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=\nbest\n,prop=font, fontsize=15)\n\n\n\n\nmatplotlib.legend.Legend at 0x7fc965e59c10\n\n\n\n\n\n\ndata_py = data[data[\nthird_tag\n] == u\nPython\n]\nhour_fs = data_py.groupby([\nhour\n, \nfinance_stage\n])[\nsalary\n].aggregate(np.size).reset_index().sort(\nsalary\n, ascending=False)\nplt.figure(figsize=(8,6))\nmarkers = [\n            'd', '\n', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', '\n', '|', \n_\n\n        ]\ng = sns.pointplot(x=\nhour\n, y=\nsalary\n, hue=\nfinance_stage\n,\n                  data=hour_fs, dodage=True, markers=markers, size=7)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u\n\u5c0f\u65f6\n, fontsize=16, fontproperties=font)\nplt.ylabel(u\n\u62db\u8058\u804c\u4f4d\u6570\u91cf\n, fontsize=16, fontproperties=font)\nplt.title(u\nPython\u804c\u4f4d\u62db\u8058\u9700\u6c42\n, fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=\nbest\n,prop=font, fontsize=15)\n\n\n\n\nmatplotlib.legend.Legend at 0x7fc9639932d0\n\n\n\n\n\n\nplt.figure(figsize=(8,6))\ng = sns.pointplot(x=hour_info.index, y=hour_info[\nproperty\n], color=\nindianred\n, markers=\n.\n)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u\n\u5c0f\u65f6\n, fontsize=16, fontproperties=font)\nplt.ylabel(u\n\u62db\u8058\u804c\u4f4d\u767e\u5206\u6bd4 %\n, fontsize=16, fontproperties=font)\nplt.title(u\nIT\u804c\u4f4d\u62db\u8058\u53d1\u5e03\u65f6\u95f4\u89c4\u5f8b\n, fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=\nbest\n,prop=font, fontsize=15)\n\n\n\n\n\n\n\u4ece24\u5c0f\u65f6\u65f6\u6bb5\u7684\u62db\u8058\u4fe1\u606f\u53d1\u5e03\u91cf\u53ef\u77e5\uff0c\u4e0a\u53489-10\u70b9\u662f\u804c\u4f4d\u53d1\u5e03\u7684\u9ad8\u5cf0\u671f\uff0c\u5176\u6b21\u662f\u4e0b\u534814\u70b9\u3002\u56e0\u6b64\uff0c\u6709\u6c42\u804c\u9700\u6c42\u7684\u4e2a\u4eba\u53ef\u4ee5\u5728\u4e0a\u534811\u70b9\u4e4b\u540e\u67e5\u770b\u62c9\u52fe\u7f51\u7684\u62db\u8058\u4fe1\u606f\u3002\n\n\nHr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u89c4\u5f8b\n\n\ndf_login = pd.read_csv(\n/home/darren/Desktop/lagou_position/scrapy/job_info_201784.csv\n, encoding=\nutf-8\n)\n\n\n\n\n# \u53bb\u9664\u91cd\u590d\u7684\u62db\u8058\u804c\u4f4d\u4fe1\u606f\ndf_login.drop_duplicates(inplace=True)\n\n\n\n\nd_time = df_login.published_time.str.split(\n \n).str.get(0)\ndf_login[\nday\n] = d_time\n# \u9009\u62e9\u62db\u8058\u53d1\u5e03\u65f6\u95f4\u6700\u65b0\u4e00\u5929\u7684\u6570\u636e\uff0c2017-8-4\uff0c\u62162017-8-5\uff0c\u56e0\u4e3a\u91c7\u96c6\u6570\u636e\u6700\u540e\u65f6\u95f4\u662f8\u67085\u65e5\nda = df_login[(df_login.day == \n2017/8/4\n) | (df_login.day == \n2017/8/5\n)]\n\n\n\n\n# \u8fdb\u4e00\u6b65\u53bb\u91cd\u6570\u636e\nda_col = da.columns.values.tolist()\nda_col.remove(u\npublished_time\n)\nrow_duplicated = da[da.duplicated(da_col)].index.values\nda.drop(row_duplicated, inplace=True)\n# last_login\u683c\u5f0f\u6b63\u786e\n# da.to_csv(\n/home/darren/Desktop/lagou_drop_duplicated1.csv\n, index=False)\n\n\n\n\n# \u4ee5\u4e0b\u505a\u6cd5\u62a5\u9519 \n# ValueError: timestamp out of range for platform localtime()/gmtime() function\n# last_login_.head(1).map(lambda x: datetime.datetime.utcfromtimestamp(x).strftime(\n%Y-%m-%d %H:%M:%S\n))\n# \u91c7\u7528\u904d\u5386\u4f9d\u65e7\u4e0d\u884c\n# last_login_date = []\n# for i in xrange(len(last_login_)):       \n#     last_login_date.append(datetime.datetime.utcfromtimestamp(last_login_[i]).strftime(\n%Y-%m-%d %H:%M:%S\n) )\n\n\n\n\n# \u6beb\u79d2\u8f6c\u6362\u6210\u79d2\nlast_login_ = da[\nlast_login\n] / 1000\n# \u5317\u4eac\u65f6\u95f42017/8/4 5\u65e5 0:0:0 \u7684\u65f6\u95f4\u6233\u5206\u522b\u4e3a 1501776000 1501862400\n# \u5148\u5224\u65ad\u6700\u540e\u767b\u5f55\u65f6\u95f4\u662f\u5426\u662f8\u67084\u65e5\nlogin_time_l = last_login_[last_login_.values \n= 1501776000]\nlogin_time_ = login_time_l[login_time_l \n= 1501862400]\n# \u5c06\u4e00\u5929\u767b\u5f55\u65f6\u95f4\u4ece\u79d2\u53d8\u6210\u5c0f\u65f6\nlast_login_s = ((login_time_ - 1501776000) / 3600).map(lambda x: np.int(x))\n\n\n\n\n# \u7edf\u8ba1Hr\u572824\u5c0f\u65f6\u5185\u6700\u540e\u767b\u5f55\u65f6\u95f4\u5206\u5e03\u60c5\u51b5\nlast_login_time = last_login_s.value_counts()\n\n\n\n\nlogin_property = last_login_time.values / np.float(last_login_time.values.sum()) *100\nplt.figure(figsize=(8,6))\ng = sns.pointplot(x=last_login_time.index, y=login_property, color=\npurple\n, markers=\n*\n)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u\n\u5c0f\u65f6\n, fontsize=16, fontproperties=font)\nplt.ylabel(u\n\u767e\u5206\u6bd4 %\n, fontsize=16, fontproperties=font)\nplt.title(u\nHr\u767b\u5f55\u65f6\u95f4\u5206\u5e03\n, fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=\nbest\n,prop=font, fontsize=15)\n\n\n\n\n\n\nHr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u5206\u5e03\u56fe\u5982\u4e0a\uff0cHr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u96c6\u4e2d\u5728\u4e0b\u5348\uff0c\u5c24\u5176\u662f15-17\u70b9\u4e4b\u95f4\uff0c\u7ed3\u5408\u540c\u4e00\u5929\u7684\u62db\u8058\u4fe1\u606f\u53d1\u5e03\u72b6\u51b5\uff0c\u6295\u9012\u7b80\u5386\u7684\u8f83\u4f73\u65f6\u95f4\u6bb5\u4e3a\u4e0a\u534811\u70b9-\u4e0b\u534813\u70b9\u4e4b\u95f4\u3002\n\n\n\u603b\u7ed3\n\n\n\u5f53\u524d\uff0cIT\u884c\u4e1a\u53d1\u5c55\u5982\u706b\u5982\u837c\uff0c\u4eceIT\u884c\u4e1a\u7684\u5e73\u5747\u85aa\u8d44\u4fbf\u53ef\u7aa5\u4e00\u6591\u3002\u4ece\u5168\u56fd\u8303\u56f4\u770b\uff0cIT\u884c\u4e1a\u53d1\u5c55\u5e76\u4e0d\u5747\u8861\uff0c\u800c\u662f\u96c6\u4e2d\u5728\u4e00\u7ebf\u548c\u4e00\u4e9b\u70ed\u95e8\u7684\u4e8c\u7ebf\u57ce\u5e02\uff0c\u5c24\u5176\u662f\u5317\u4e0a\u6df1\u5e7f\u4ee5\u53ca\u676d\u5dde\uff0c\u5176\u4e2d\u53c8\u4ee5\u5317\u4eac\u6700\u4e3a\u53d1\u8fbe\uff01\n\n\n\u4ece\u5404\u4e2a\u57ce\u5e02\u7684\u62db\u8058\u804c\u4f4d\u9700\u6c42\u770b\uff0c\u5317\u4eac\u7684\u62db\u8058\u804c\u4f4d\u6700\u591a\uff0c\u4e0a\u6d77\u6b21\u4e4b\uff0c\u4ece\u516c\u53f8\u89c4\u6a21\u770b\u4e2d\u578b\u516c\u53f8\u7684\u62db\u8058\u5bfb\u6c42\u6700\u5927\uff0c\u5927\u578b\u516c\u53f8\u6b21\u4e4b\uff0c\u5c0f\u578b\u516c\u53f8\u7684\u9700\u6c42\u91cf\u8f83\u5c0f\uff1b\u4ece\u85aa\u8d44\u4e0a\u770b\uff0c\u5927\u578b\u516c\u53f8\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u5176\u6b21\u662f\u4e2d\u578b\u516c\u53f8\uff0c\u5c0f\u516c\u53f8\u6700\u4f4e\uff0c\u56e0\u6b64\uff0cIT\u884c\u4e1a\u7684\u6700\u4f73\u6c42\u804c\u5730\u4e3a\u5317\u4eac\uff0c\u516c\u53f8\u53ef\u9009\u62e9\u4e2d\u578b\u7684\u4e0a\u5e02\u6216\u6210\u719f\u578b\u516c\u53f8\u3002\n\n\n\u5f53\u7136\uff0c\u8fd9\u4ec5\u4ec5\u662f\u4ece\u804c\u4f4d\u9700\u6c42\u72b6\u51b5\u4e0a\u5206\u6790\uff0c\u5e76\u6ca1\u6709\u7ed3\u5408\u6c42\u804c\u8005\u6570\u91cf\u7b49\u5176\u4ed6\u4fe1\u606f\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8fd9\u90e8\u5206\u6570\u636e\u96be\u91c7\u96c6\uff01\n\n\nIT\u884c\u4e1a\u804c\u4f4d\u9700\u6c42\u6700\u5927\u7684\u662f\u6280\u672f\u7c7b\uff0c\u85aa\u8d44\u6700\u9ad8\u7684\u662f\u91d1\u878d\u7c7b\uff0c\u5176\u6b21\u662f\u6280\u672f\u7c7b\u3002\n\n\n\u4ece\u540e\u7aef\u5f00\u53d1\u7684\u5404\u4e2a\u7f16\u7a0b\u8bed\u8a00\u5206\u6790\uff0cJava\u7684\u62db\u8058\u9700\u6c42\u662f\u5904\u4e8e\u9738\u4e3b\u5730\u4f4d\uff0c\u53ea\u662f\u85aa\u8d44\u7565\u4f4e\u3002\u85aa\u8d44\u6700\u9ad8\u7684\u662f\u5404\u79cd\u7b97\u6cd5\u7c7b\uff0c\u5305\u62ec\u6570\u636e\u6316\u6398\u3001\u7cbe\u51c6\u63a8\u8350\u7b49\uff0c\u5176\u6b21\u662f\u4e00\u4e9b\u65b0\u5174\u8bed\u8a00\uff0c\u5982Go\u3001Python\u7b49\u3002\n\n\nPython\u7684\u62db\u8058\u89c4\u5f8b\u548c\u540e\u7aef\u5f00\u53d1\u662f\u4e00\u81f4\u7684\uff0c\u6574\u4f53\u800c\u8a00\uff0cPython\u7684\u62db\u8058\u9700\u6c42\u603b\u91cf\u4e0d\u591a\uff0c\u4f46\u5e73\u5747\u85aa\u8d44\u8f83\u9ad8\u3002\u62db\u8058\u9700\u6c42\u8f83\u591a\u7684\u662f\u4e00\u7ebf\u57ce\u5e02\u7684\u4e2d\u578b\u516c\u53f8\uff0c\u85aa\u8d44\u4e5f\u6bd4\u8f83\u9ad8\uff0c\u4ec5\u7565\u4f4e\u4e8e\u5927\u578b\u4e0a\u5e02\u516c\u53f8\uff0c\u5b66\u5386\u8981\u6c42\u672c\u79d1\u5c45\u591a\uff0c\u5de5\u4f5c\u7ecf\u9a8c3-5\u548c1-3\u5e74\u8f83\u591a\u3002\n\n\npython\u62db\u8058\u7684\u5177\u4f53\u5c97\u4f4d\u5206\u5e03\uff0c\u4ee5web\u5f00\u53d1\u5c45\u591a\uff0c\u722c\u866b\u6b21\u4e4b\uff0c\u7531\u4e8e\u6709\u5927\u91cf\u7684\u804c\u4f4d\u6807\u9898\u5e76\u6ca1\u6709\u660e\u786e\u6807\u660e\u5c97\u4f4d\u7684\u5177\u4f53\u540d\u79f0\uff0c\u56e0\u6b64\uff0c\u5177\u4f53\u5c97\u4f4d\u5206\u5e03\u5e76\u4e0d\u51c6\u786e\uff0c\u8fd9\u8fd8\u8981\u7ed3\u5408\u804c\u4f4d\u8be6\u60c5\u9875\u9762\u8fdb\u884c\u5206\u6790\u3002\n\n\n\u6b64\u5916\uff0c\u6839\u636e\u62db\u8058\u5c97\u4f4d\u63cf\u8ff0\u8bcd\u6c47\u751f\u6210\u7684\u8bcd\u4e91\u56fe\u53ef\u770b\u5230\u51fa\u73b0\u9891\u7387\u6700\u9ad8\u7684\u8bcd\u6c47\u662f\u201c\u57f9\u8bad\u201d\u3001\u201c\u6241\u5e73\u201d\u3001\u201c\u5e73\u53f0\u201d\uff0c\u4f53\u73b0\u51fa\u5f53\u4ecaIT\u884c\u4e1a\u6bd4\u8f83\u6ce8\u91cd\u5458\u5de5\u7684\u57f9\u8bad\u53ca\u6ce8\u91cd\u6241\u5e73\u5316\u7ba1\u7406\u3002\n\n\n\u5206\u6790\u62db\u8058\u804c\u4f4d\u7684\u53d1\u5e03\u65f6\u95f4\u548cHr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u7684\u6298\u7ebf\u56fe\u53ef\u77e5\uff0c\u804c\u4f4d\u53d1\u5e03\u4e3b\u8981\u96c6\u4e2d\u5728\u4e0a\u53489\u70b9\u5de6\u53f3\uff0c\u800cHr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u96c6\u4e2d\u5728\u4e0b\u534815-17\u70b9\u4e4b\u95f4\uff0c\u56e0\u6b64\uff0c\u4e2a\u4eba\u8ba4\u4e3a\u62c9\u52fe\u7f51\u6295\u9012\u62db\u8058\u7b80\u5386\u7684\u8f83\u4f73\u65f6\u95f4\u4e3a\u4e0a\u534811\u70b9-\u4e0b\u534813\u70b9\u4e4b\u95f4\u3002", 
            "title": "\u62c9\u52fe\u62db\u8058\u804c\u4f4d\u4fe1\u606f\u6570\u636e\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#_1", 
            "text": "", 
            "title": "\u62c9\u52fe\u62db\u8058\u804c\u4f4d\u4fe1\u606f\u6570\u636e\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#_2", 
            "text": "\u91c7\u7528scrapy\u6846\u67b6\u91c7\u96c6\u4e86\u62c9\u52fe\u7f51\u67d0\u5929\u7684\u6240\u6709\u62db\u8058\u804c\u4f4d\u4fe1\u606f\uff0c\u8fdb\u884c\u7b80\u5355\u7684\u6570\u636e\u5206\u6790\uff0c\u4e3b\u8981\u76ee\u7684\u662f\u5206\u6790IT\u884c\u4e1a\u76ee\u524d\u62db\u8058\u7684\u6574\u4f53\u72b6\u51b5\uff0c\u5206\u6790\u6280\u672f\u7c7b\u4e2d\u540e\u7aef\u5f00\u53d1\u7684\u62db\u8058\u5f62\u52bf\u4ee5\u53caPython\u7f16\u7a0b\u8bed\u8a00\u7684\u62db\u8058\u9700\u6c42\u3002  # \u5bfc\u5165\u76f8\u5173\u6a21\u5757\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport time\nimport datetime\nimport re\nimport seaborn as sns\nsns.set(style= ticks , palette= muted , font_scale=1.3, color_codes=True, context= talk )\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\n%matplotlib inline\nfrom matplotlib.font_manager import FontProperties \nfont = FontProperties(fname=r /usr/share/fonts/truetype/arphic/ukai.ttc )\nfrom os import path", 
            "title": "\u80cc\u666f\u4ecb\u7ecd"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#_3", 
            "text": "\u9996\u5148\u662f\u83b7\u53d6\u6570\u636e\uff0c\u4f7f\u7528Python\u7684Scrapy\u6846\u67b6\u91c7\u96c6\u6570\u636e\uff0c\u6570\u636e\u91c7\u96c6\u8fc7\u7a0b\u5728\u6b64\u7565\u8fc7...  \u91c7\u96c6\u7684\u6570\u636e\u5b58\u50a8\u5728csv\u6587\u4ef6\u4e2d\uff0c\u8be5\u6570\u636e\u96c6\u662f\u91c7\u96c6\u62c9\u52fe\u7f51\u4e00\u5929\u5185\u53d1\u5e03\u7684\u804c\u4f4d\u62db\u8058\u4fe1\u606f\uff0c\u603b\u51718\u4e07\u591a\u6761\u62db\u8058\u4fe1\u606f\u3002", 
            "title": "\u6570\u636e\u91c7\u96c6"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#_4", 
            "text": "", 
            "title": "\u6570\u636e\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#_5", 
            "text": "\u62c9\u52fe\u7f51\u7684\u62db\u8058\u4fe1\u606f\u4ee5Json\u683c\u5f0f\u53d1\u9001\u5230\u524d\u7aef\uff0c\u6574\u4f53\u6570\u636e\u6bd4\u8f83\u89c4\u6574\uff0c\u7f3a\u5931\u6570\u636e\u8f83\u5c11\uff0c\u5728\u672c\u5206\u6790\u6d41\u7a0b\u524d\u4e8b\u5148\u5bf9\u539f\u59cb\u6570\u636e\u96c6\u7684\u91cd\u8981\u5b57\u6bb5\u8fdb\u884c\u4e86\u7f3a\u5931\u503c\u586b\u8865\u5904\u7406\u3001\u5bf9\u4e00\u4e9b\u5206\u7c7b\u53d8\u91cf\u8fdb\u884c\u4e86\u91cd\u65b0\u5f52\u7c7b\u5408\u5e76\u7b49\u6570\u636e\u6e05\u6d17\u52a8\u4f5c\uff0c\u56e0\u6b64\uff0c\u67e5\u770b\u73b0\u5728\u6570\u636e\u7684\u7f3a\u5931\u60c5\u51b5\uff0c\u53ea\u6709dist\u3001position_advantagei\u4e24\u4e2a\u7279\u5f81\u6709\u7f3a\u5931\u6570\u636e  data = pd.read_csv( /home/darren/Desktop/lagou_position/scrapy/lagou_job_all_dropduplicated.csv , encoding= utf-8 )      # \u67e5\u770bcompany_size\u7f3a\u5931\u7684\u6837\u672c\u6570\u91cf\ndata[data.company_size.isnull()].shape\n# \u7528 \u5c11\u4e8e15\u4eba \u586b\u8865\u7f3a\u5931\u7684\u6570\u636e\ndata.company_size.fillna(u \u5c11\u4e8e15\u4eba , inplace=True)  \u67e5\u770b\u6570\u636e\u96c6\u4e2d\u975e\u7a7a\u6570\u636e\u767e\u5206\u6bd4  #\u5404\u4e2a\u7279\u5f81\u975e\u7a7a\u7684\u6837\u672c\u6570\u91cf\nnot_null = data.count()\nall = data.shape[0]\n# \u67e5\u770b\u6570\u636e\u96c6\u4e2d\u975e\u7a7a\u6570\u636e\u767e\u5206\u6bd4\nnot_null / all * 100  finance_stage         100.000000\ncity                  100.000000\ndist                   98.252158\nsalary                100.000000\njob_nature            100.000000\nindustry_field        100.000000\ncompany               100.000000\nthird_tag             100.000000\npublished_time        100.000000\nsecond_tag            100.000000\nposition_advantage     99.990527\nfirst_tag             100.000000\nlast_login            100.000000\nwork_experience       100.000000\nposition_type         100.000000\nposition              100.000000\neducation             100.000000\ncrawl                 100.000000\ncompany_size          100.000000\nday                   100.000000\ndtype: float64", 
            "title": "\u6570\u636e\u6e05\u6d17"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#it", 
            "text": "# position_advantage\u548cdist\u7684\u7f3a\u5931\u503c\u6682\u4e0d\u5904\u7406\n# \u83b7\u53d6\u6570\u636e\u96c6\u7684\u67d0\u4e9b\u6837\u672c\u7279\u5f81\u7528\u4e8e\u53ef\u89c6\u5316\u8f93\u51fa\nfeatures = data.columns.values.tolist()  # \u63d0\u53d6\u4e0esalary\u76f8\u5173\u5ea6\u8f83\u5927\u7684\u7279\u5f81\uff0c\u7528\u4e8e\u63cf\u8ff0\u6027\u63a2\u7d22\u4e0e\u53ef\u89c6\u5316\u8f93\u51fa\nfor x in [u company_size , u position_type , u day , u third_tag , u salary , u dist , u company , u published_time , u position_advantage , u last_login , u position , u crawl ]:  # \n    features.remove(x)   # \u5b9a\u4e49\u4e00\u4e9b\u7279\u5f81\u548c\u8bc4\u4f30\u7684\u6620\u5c04\nfeature_name = [u \u4f01\u4e1a\u91d1\u878d\u72b6\u51b5 , u \u57ce\u5e02 , u \u5de5\u4f5c\u7c7b\u578b , u \u884c\u4e1a\u9886\u57df , u \u804c\u4f4d\u5c0f\u7c7b , u \u804c\u4f4d\u5927\u7c7b , u \u5de5\u4f5c\u7ecf\u9a8c , u \u5b66\u5386 ]  # u \u804c\u4f4d\u7c7b\u578b , ,u \u516c\u53f8\u89c4\u6a21 \nfeature_dict = dict(zip(features,feature_name))\nfeature_dict\nmethod_dict = { mean : u \u5e73\u5747\u85aa\u8d44 ,  median : u \u85aa\u8d44\u4e2d\u4f4d\u6570 ,  size : u \u62db\u8058\u804c\u4f4d\u6570\u91cf }  def feature_target_bar(evalute_method_str):\n     \n    \u4ee5bar_plot\u7684\u65b9\u5f0f\u5c06IT\u884c\u4e1a\u6574\u4f53\u7684\u4e00\u4e9b\u7279\u5f81\u4e0e\u85aa\u8d44\u5173\u7cfb\u8fdb\u884c\u53ef\u89c6\u5316\u8f93\u51fa\n     \n    fig, axes = plt.subplots(4,2, figsize=(18,40), sharex=False, sharey=False)\n    axes_subject_list = [j for i in axes.tolist() for j in i]\n    evalute_method =  np.  + evalute_method_str\n    for index, feature in enumerate(features):\n        df_salary= data.groupby(feature)[ salary ].aggregate([eval(evalute_method)]).sort_values(evalute_method_str, ascending=False)\n        g = sns.barplot(y=df_salary.index, x=df_salary[evalute_method_str], ax=axes_subject_list[index], palette= husl )\n        axes_subject_list[index].set_yticklabels(g.get_yticklabels(), fontproperties=font, fontsize=18)\n        axes_subject_list[index].set_xlabel( )\n        axes_subject_list[index].set_title(u \u4e0d\u540c  + feature_dict[feature] + method_dict[evalute_method_str], fontsize=25, fontproperties=font)    \n        axes_subject_list[index].set_ylabel( ) \n        axes_subject_list[index].xaxis.grid(True, linestyle =  -. ,)    \n    text = method_dict[evalute_method_str] + 'k(\uffe5)' if evalute_method_str in [ mean ,  median ] else method_dict[evalute_method_str]\n    # \u5c06x\u8f74\u4ee5\u6587\u672cplt.text\u7684\u5f62\u5f0f\u5199\u5165axis\u5bf9\u8c61\u4e2d\n    plt.text(-3.8, 5.0, s=text, ha='center', va='center', fontsize=25, fontproperties=font)\n    fig.tight_layout()\n    # fig.savefig( /home/darren/Desktop/salary_mean   features.png )", 
            "title": "IT\u884c\u4e1a\u6574\u4f53\u7684\u63cf\u8ff0\u6027\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#it_1", 
            "text": "\u4e3b\u8981\u63a2\u8ba8\u804c\u4f4d\u62db\u8058\u9700\u6c42\u3001\u804c\u4f4d\u5e73\u5747/\u4e2d\u4f4d\u6570\u85aa\u8d44\u4e0e\u62db\u8058\u4f01\u4e1a\u7684\u91d1\u878d\u72b6\u51b5\u3001\u4f01\u4e1a\u89c4\u6a21\uff0c\u6240\u5c5e\u884c\u4e1a\u7684\u7ec6\u5206\u9886\u57df\uff0c\u6c42\u804c\u8005\u5b66\u5386\u3001\u5de5\u4f5c\u7ecf\u9a8c\u7684\u5173\u7cfb\u3002\u4e4b\u6240\u4ee5\u8981\u8bc4\u4f30\u85aa\u8d44\u7684\u4e2d\u4f4d\u6570\uff0c\u4e3b\u8981\u662f\u5c3d\u91cf\u51cf\u5c0f\u4e00\u4e9b\u9ad8\u85aa\u5c97\u4f4d\u7684\u85aa\u8d44\u53ef\u80fd\u4f1a\u5f15\u8d77\u7684\u5de6\u504f\u73b0\u8c61\u3002  for i in method_dict.keys():\n    feature_target_bar(i)     \u4e0d\u540c\u89c4\u6a21\u7684\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u56fe\u662f\u53ccy\u8f74\u5750\u6807\u56fe\uff0c\u53f3\u4fa7y\u8f74\u5750\u6807\u8868\u793a\u7684\u662f\u4e0d\u540c\u89c4\u6a21\u7684\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u5360\u603b\u62db\u8058\u9700\u6c42\u7684\u767e\u5206\u6bd4\uff08\u6ce8\u610f\u548c\u4e0b\u9762\u7684\u53ccy\u5750\u6807\u8f74\u7684\u767e\u5206\u6bd4\u7684\u533a\u522b\uff09  # \u804c\u4f4d\u62db\u8058\u9700\u6c42\u3001\u5e73\u5747\u85aa\u8d44\u4e0e\u516c\u53f8\u89c4\u6a21\u7684\u5173\u7cfb\nd_company_salary = data.groupby('company_size')[ salary ].aggregate([np.size, np.mean, np.median]).sort_values( size , ascending=True)\nd_company_salary[ property ] = d_company_salary[ size ] / d_company_salary[ size ].sum() * 100\nfig, ax1 = plt.subplots(figsize=(8,6))  # \u4f7f\u7528subplots()\u521b\u5efa\u7a97\u53e3\nax2 = ax1.twinx() # \u521b\u5efa\u7b2c\u4e8c\u4e2a\u5750\u6807\u8f74\nx_list = range(len(d_company_salary))\nax1.plot(x_list, d_company_salary[ mean ], linewidth = 2, ls= -. , marker= ^ , label=u \u5e73\u5747\u85aa\u8d44 ) \nax1.plot(x_list, d_company_salary[ median ], linewidth = 2, ls='--', marker= v , label=u \u85aa\u8d44\u4e2d\u4f4d\u6570 ) \nax2.plot(x_list, d_company_salary[ property ], linewidth = 3, color= c , marker= o , label=u \u804c\u4f4d\u9700\u6c42\u91cf % ) \nax1.set_xlabel(u'\u516c\u53f8\u89c4\u6a21', fontproperties=font, fontsize = 16) \nax1.set_ylabel(u'\u85aa\u8d44 k(\uffe5)', fontproperties=font, fontsize = 16)\nax2.set_ylabel(u'\u62db\u8058\u804c\u4f4d\u767e\u5206\u6bd4 %', fontproperties=font, fontsize = 16)\nax1.set_xlim(0, 5.4)  # \u6b64\u5904\u5fc5\u987b\u8bbe\u7f6e set_xlim(0,...),\u8d77\u59cb\u4f4d\u7f6e\u5fc5\u987b\u662f0\uff0c\u5426\u521915\u4eba\u4ee5\u4e0b\u5c31\u4e0d\u663e\u793a\uff1f\nax1.set_xticklabels(d_company_salary.index, fontproperties=font, fontsize=16, rotation=30)\nax1.xaxis.grid(True, linestyle =  -. ,)\nax1.yaxis.grid(True, linestyle =  -. ,)\nax1.legend(loc=2, prop=font)\nax2.legend(loc=4, prop=font)\nax1.set_title(u'\u4e0d\u540c\u89c4\u6a21\u7684\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44',fontproperties=font,fontsize=25)  matplotlib.text.Text at 0x7f21a4798610    \u7531\u4e8e\u62c9\u52fe\u7f51\u662f\u4e13\u4e1a\u7684\u4e92\u8054\u7f51\u62db\u8058\u5e73\u53f0\uff0c\u62db\u8058\u4fe1\u606f\u4ee5IT\u884c\u4e1a\u4e3a\u4e3b\uff0c\u6574\u4f53\u85aa\u8d44\u6c34\u5e73\u662f\u504f\u9ad8\u7684\u3002\u4ece\u4e0a\u9762\u7684\u67f1\u72b6\u56fe\u53ef\u770b\u51fa\uff0c\u62db\u8058\u85aa\u8d44\u4e0e\u62db\u8058\u4f01\u4e1a\u7684\u91d1\u878d\u72b6\u51b5\u3001\u62db\u8058\u4f01\u4e1a\u6240\u5c5e\u7684\u884c\u4e1a\u9886\u57df\u3001\u6c42\u804c\u8005\u7684\u5b66\u5386\u4e0e\u5de5\u4f5c\u7ecf\u9a8c\u7b49\u7279\u5f81\u5747\u6709\u5173\u8054\u6027\u3002  \u6839\u636e\u62db\u8058\u4f01\u4e1a\u7684\u91d1\u878d\u72b6\u51b5\u53ef\u5206\u6210\u4e0a\u5e02\u516c\u53f8\u3001\u6210\u719f\u3001\u6210\u957f\u3001\u521d\u521b\u6027\u516c\u53f8\uff0c\u6839\u636e\u4e0a\u9762\u7684\u67f1\u72b6\u56fe\u660e\u663e\u770b\u51fa\u521d\u521b\u6027\u516c\u53f8\u7684\u85aa\u8d44\u504f\u4f4e\uff0c\u800c\u6210\u719f\u6027\u4e14\u878d\u8d44\u89c4\u6a21\u8f83\u5927\u7684\u4f01\u4e1a\u7684\u85aa\u8d44\u8f83\u9ad8\u3002  \u5206\u6790\u4e00\u7ebf\u548c\u70ed\u95e8\u4e8c\u7ebf\u57ce\u5e02\u7684\u85aa\u8d44\u67f1\u72b6\u56fe\uff0c\u660e\u663e\u770b\u51fa\u4e00\u7ebf\u57ce\u5e02\u7684\u5e73\u5747\u85aa\u8d44\u660e\u663e\u9ad8\u4e8e\u5176\u4ed6\u57ce\u5e02\uff08\u5929\u6d25\u9664\u5916\uff09\uff0c\u5c24\u5176\u4ee5\u5317\u4eac\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u800c\u4e8c\u7ebf\u7684\u676d\u5dde\u85aa\u8d44\u4e5f\u8f83\u9ad8\uff0c\u53ef\u80fd\u4e0e\u963f\u91cc\u5df4\u5df4\u7b49\u4e92\u8054\u7f51\u516c\u53f8\u5750\u843d\u676d\u5dde\u6709\u5173\u3002  \u4e92\u8054\u7f51\u76f8\u5173\u7684\u804c\u4f4d\u85aa\u8d44\uff08\u804c\u4e1a\u5c0f\u7c7b\uff09\u4e2d\u660e\u663e\u770b\u51fa\uff0c\u4eba\u5de5\u667a\u80fd\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u8fd9\u4e5f\u53cd\u6620\u51fa\u5f53\u524d\u7684\u4eba\u5de5\u667a\u80fd\u9886\u57df\u7684\u5927\u70ed\u3002  \u6b64\u5916\uff0c\u5bf9\u6bd4\u5e73\u5747\u85aa\u8d44\u548c\u85aa\u8d44\u7684\u4e2d\u4f4d\u6570\u53ef\u4ee5\u53d1\u73b0\u4e00\u4e9b\u4e0d\u540c\u4e4b\u5904\uff0c\u8fd9\u662f\u7531\u4e8e\u4e00\u4e9b\u79bb\u7fa4\u7684\u6837\u672c\u70b9\u5c06\u6837\u672c\u5747\u503c\u62c9\u4f4e\u6216\u62c9\u9ad8\uff0c\u7528\u4e2d\u4f4d\u6570\u80fd\u8f83\u597d\u7684\u53cd\u6620\u96c6\u4e2d\u8d8b\u52bf\u3002  \u4ece\u516c\u53f8\u89c4\u6a21\u4e0e\u85aa\u8d44\u548c\u62db\u8058\u9700\u6c42\u66f2\u7ebf\u770b\uff0cIT\u884c\u4e1a\u62db\u8058\u804c\u4f4d\u9700\u6c42\u6700\u591a\u7684\u4e0d\u662f\u5927\u578b\u516c\u53f8\u800c\u662f50-500\u4eba\u89c4\u6a21\u7684\u516c\u53f8\uff0c\u85aa\u8d44\u4e0a\uff0c\u5927\u578b\u516c\u53f8\u7684\u85aa\u8d44\u6700\u9ad8\uff0c50-500\u89c4\u6a21\u7684\u6b21\u4e4b\uff0c50\u4eba\u4ee5\u4e0b\u7684\u516c\u53f8\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u90fd\u8f83\u4f4e\u3002  \u7b80\u800c\u6982\u4e4b\uff0c\u4ece\u5404\u4e2a\u57ce\u5e02\u7684\u62db\u8058\u804c\u4f4d\u9700\u6c42\u770b\uff0c\u5317\u4eac\u7684\u62db\u8058\u804c\u4f4d\u6700\u591a\uff0c\u4e0a\u6d77\u6b21\u4e4b\uff0c\u4ece\u516c\u53f8\u89c4\u6a21\u770b\u4e2d\u578b\u516c\u53f8\u7684\u62db\u8058\u5bfb\u6c42\u6700\u5927\uff0c\u5927\u578b\u516c\u53f8\u6b21\u4e4b\uff0c\u5c0f\u578b\u516c\u53f8\u7684\u9700\u6c42\u91cf\u8f83\u5c0f\uff1b\u4ece\u85aa\u8d44\u4e0a\u770b\uff0c\u5927\u578b\u516c\u53f8\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u5176\u6b21\u662f\u4e2d\u578b\u516c\u53f8\uff0c\u5c0f\u516c\u53f8\u6700\u4f4e\uff0c\u56e0\u6b64\uff0cIT\u884c\u4e1a\u7684\u6700\u4f73\u6c42\u804c\u5730\u4e3a\u5317\u4eac\u6216\u4e0a\u6d77\uff0c\u516c\u53f8\u53ef\u9009\u62e9\u4e2d\u578b\u7684\u4e0a\u5e02\u6216\u6210\u719f\u578b\u516c\u53f8\u3002", 
            "title": "IT\u884c\u4e1a\u6574\u4f53\u62db\u8058\u9700\u6c42"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#it_2", 
            "text": "\u4ee5\u4e0a\u662f\u4ece\u6574\u4f53\u4e0a\u5bf9\u62c9\u52fe\u7f51\u7684IT\u62db\u8058\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u63a5\u4e0b\u6765\u5bf9IT\u884c\u4e1a\u4e03\u5927\u9886\u57df\uff0c\u6280\u672f\u3001\u4ea7\u54c1\u3001\u8fd0\u8425\u3001\u804c\u80fd\u3001\u91d1\u878d\u3001\u5e02\u573a\u4e0e\u9500\u552e\u3001\u8bbe\u8ba1\u8fdb\u884c\u7b80\u5355\u7684\u63cf\u8ff0\u6027\u5206\u6790  # \u4e0d\u540c\u804c\u4e1a\u7684\u804c\u4f4d\u6570\u91cf\u3001\u5e73\u5747\u85aa\u8d44\u3001\u85aa\u8d44\u4e2d\u4f4d\u6570\nIT_domains = data.groupby([ first_tag ,  third_tag ])[ salary ].aggregate([np.size, np.mean, np.median])\nIT_domains = IT_domains.reset_index()  # IT\u884c\u4e1a\u5404\u9886\u57df\u7684\u804c\u4f4d\u6bd4\u4f8b\nposition_num  = IT_domains.groupby([ first_tag ])[ size ].sum() / IT_domains[ size ].sum() * 100\n# IT\u884c\u4e1a\u5404\u9886\u57df\u7684\u5e73\u5747\u85aa\u8d44\nposition_mean = IT_domains.groupby([ first_tag ])[ mean ].mean().sort_values(ascending=False)   plt.figure(figsize=(8,6))\ng = sns.barplot(y=position_mean.index, x=position_mean.values, palette= BuPu_d )\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.xlabel(u \u5e73\u5747\u85aa\u8d44 k (\uffe5) , fontsize=16, fontproperties=font)\nplt.ylabel( )\nplt.title(u IT\u884c\u4e1a\u4e0d\u540c\u9886\u57df\u85aa\u8d44 , fontproperties=font, fontsize=25)\nplt.gca().xaxis.grid(True, linestyle =  -. ,)   \nplt.pie\u53c2\u6570\nx       (\u6bcf\u4e00\u5757)\u7684\u6bd4\u4f8b\uff0c\u5982\u679csum(x)   1\u4f1a\u4f7f\u7528sum(x)\u5f52\u4e00\u5316\nlabels  (\u6bcf\u4e00\u5757)\u997c\u56fe\u5916\u4fa7\u663e\u793a\u7684\u8bf4\u660e\u6587\u5b57\nexplode (\u6bcf\u4e00\u5757)\u79bb\u5f00\u4e2d\u5fc3\u8ddd\u79bb\nstartangle  \u8d77\u59cb\u7ed8\u5236\u89d2\u5ea6,\u9ed8\u8ba4\u56fe\u662f\u4ecex\u8f74\u6b63\u65b9\u5411\u9006\u65f6\u9488\u753b\u8d77,\u5982\u8bbe\u5b9a=90\u5219\u4ecey\u8f74\u6b63\u65b9\u5411\u753b\u8d77\nshadow  \u662f\u5426\u9634\u5f71\nlabeldistance label\u7ed8\u5236\u4f4d\u7f6e,\u76f8\u5bf9\u4e8e\u534a\u5f84\u7684\u6bd4\u4f8b, \u5982 1\u5219\u7ed8\u5236\u5728\u997c\u56fe\u5185\u4fa7\nautopct \u63a7\u5236\u997c\u56fe\u5185\u767e\u5206\u6bd4\u8bbe\u7f6e,\u53ef\u4ee5\u4f7f\u7528format\u5b57\u7b26\u4e32\u6216\u8005format function\n        '%1.1f'\u6307\u5c0f\u6570\u70b9\u524d\u540e\u4f4d\u6570(\u6ca1\u6709\u7528\u7a7a\u683c\u8865\u9f50)\npctdistance \u7c7b\u4f3c\u4e8elabeldistance,\u6307\u5b9aautopct\u7684\u4f4d\u7f6e\u523b\u5ea6\nradius  \u63a7\u5236\u997c\u56fe\u534a\u5f84 \nvals = range(len(position_num)) #\u521b\u5efa\u6570\u636e\u7cfb\u5217\nlabels = position_num.index.values.tolist()\nplt.figure(1, figsize=(7,7))\nplt.pie(position_num.values, labels=labels, autopct='%1.2f%%', \n        pctdistance=.8, shadow=False, startangle=60,radius=1.2, \n        labeldistance=1.06, colors=('b', 'g', 'r', 'c', 'y', 'orange', 'm'),\n        textprops={ fontproperties : font,  fontsize :12})\nplt.title(u'IT\u884c\u4e1a\u5404\u9886\u57df\u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4',fontsize=25, fontproperties=font)\nplt.axis('equal')   (-1.3429042534959512,\n 1.329370895558277,\n -1.3334685921667122,\n 1.3271730638043182)   IT\u884c\u4e1a\u4e03\u5927\u9886\u57df\u4e2d\u804c\u4f4d\u9700\u6c42\u6700\u591a\u7684\u662f\u6280\u672f\u7c7b\uff0c\u5176\u6b21\u662f\u4ea7\u54c1\u7c7b\uff0c\u53d1\u5e03\u804c\u4f4d\u6700\u5c11\u7684\u662f\u91d1\u878d\u7c7b\uff0c\u800c\u85aa\u8d44\u65b9\u9762\uff0c\u5e73\u5747\u85aa\u8d44\u6700\u9ad8\u7684\u662f\u91d1\u878d\u7c7b\uff0c\u5176\u6b21\u662f\u6280\u672f\u7c7b\u3002", 
            "title": "IT\u884c\u4e1a\u5404\u9886\u57df\u63cf\u8ff0\u6027\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#it_3", 
            "text": "# \u5bf9\u4e0d\u540c\u57ce\u5e02\u548cIT\u884c\u4e1a\u4e03\u5927\u9886\u57df\u8fdb\u884c\u5206\u7ec4\uff0c\u5e76\u5bf9\u7279\u5f81salary\u8fdb\u884c\u6570\u91cf\u7edf\u8ba1\u3001\u5e73\u5747\u3001\u4e2d\u4f4d\u6570\u8ba1\u7b97\nd_city = data.groupby([ city ,  first_tag ])[ salary ].aggregate([np.size, np.mean, np.median])\nd_city = d_city.reset_index() \n# \u5efa\u7acb\u57ce\u5e02\u540d\u5b57\u5217\u8868\u7528\u4e8e\u540e\u7eed\u56fe\u7684tickslabels\ncity_list = data.groupby([ city ])[ salary ].mean().sort_values(ascending=False).index.values.tolist()  plt.figure(figsize=(12,20))\n# with sns.color_palette(sns.palplot(sns.xkcd_palette(colors)),  n_colors=9):\ng = sns.barplot(y= first_tag , x= mean , data=d_city, hue= city , hue_order=city_list, palette= Set1 )\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.xlabel(u \u5e73\u5747\u85aa\u8d44 k (\uffe5) , fontsize=16, fontproperties=font)\nplt.ylabel( )\nplt.title(u IT\u884c\u4e1a\u5404\u9886\u57df\u5404\u57ce\u5e02\u85aa\u8d44 , fontproperties=font, fontsize=25)\nplt.gca().xaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc=7,prop=font, fontsize=17)  matplotlib.legend.Legend at 0x7f219c64f950    plt.figure(figsize=(12,20))\ng = sns.barplot(y= first_tag , x= size , data=d_city, hue= city , hue_order=city_list, palette= Set1 )\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.xlabel(u \u62db\u8058\u804c\u4f4d\u6570\u91cf , fontsize=16, fontproperties=font)\nplt.ylabel( )\nplt.title(u IT\u884c\u4e1a\u5404\u9886\u57df\u5404\u57ce\u5e02\u62db\u8058\u804c\u4f4d\u6570\u91cf , fontproperties=font, fontsize=25)\nplt.gca().xaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc=7,prop=font, fontsize=17)  matplotlib.legend.Legend at 0x7f219c0e4250    \u4eceIT\u884c\u4e1a\u5404\u4e2a\u9886\u57df\u7684\u5e73\u5747\u85aa\u8d44\u548c\u62db\u8058\u804c\u4f4d\u6570\u91cf\u53ef\u77e5\uff0c\u65e0\u8bba\u4ece\u62db\u8058\u6570\u91cf\u8fd8\u662f\u5e73\u5747\u85aa\u8d44\u5317\u4eac\u7684\u8001\u5927\u5730\u4f4d\u5f88\u7262\u56fa\uff08\u9664\u4e86\u91d1\u878d\u9886\u57df\uff09\uff0c\u5176\u6b21\u662f\u4e0a\u6d77\uff0c\u518d\u4e4b\u662f\u6df1\u5733\uff0c\u7136\u540e\u662f\u676d\u5dde\u3001\u5e7f\u5dde\u3002\u5f88\u6709\u610f\u601d\u7684\u4e00\u4e2a\u73b0\u8c61\u662fIT\u884c\u4e1a\u7684\u91d1\u878d\u9886\u57df\uff0c\u867d\u7136\u5317\u4eac\u7684\u62db\u8058\u9700\u6c42\u4ecd\u65e7\u662f\u6700\u5927\u7684\uff0c\u4f46\u5e73\u5747\u85aa\u8d44\u4f4e\u4e8e\u4e0a\u6d77\u548c\u6df1\u5733\uff0c\u8fd9\u4e0e\u4e2d\u56fd\u5357\u65b9\u7684\u4e00\u7ebf\u57ce\u5e02\u7684\u91d1\u878d\u884c\u4e1a\u53d1\u5c55\u76f8\u543b\u5408\uff0c\u53e6\u4e00\u4e2a\u73b0\u8c61\u662f\u53a6\u95e8\u7684\u91d1\u878d\u9886\u57df\u85aa\u8d44\u6700\u9ad8\uff0c\u8d85\u8fc7\u4e86\u4e0a\u6d77\uff0c\u4f46\u62db\u8058\u804c\u4f4d\u6570\u91cf\u592a\u5c11\uff0c\u53ea\u67093\u4e2a\u804c\u4f4d\u9700\u6c42\u3002", 
            "title": "IT\u884c\u4e1a\u85aa\u8d44\u4e0e\u57ce\u5e02"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#it_4", 
            "text": "\u5176\u4e2d\uff0csize\u8868\u793a\u7684\u662f\u62db\u8058\u804c\u4f4d\u7684\u6570\u91cf\uff0cmean\u8868\u793a\u7684\u662f\u804c\u4f4d\u7684\u5e73\u5747\u85aa\u8d44\uff0cmidian\u8868\u793a\u7684\u662f\u85aa\u8d44\u4e2d\u4f4d\u6570  d_city[d_city[ city ] == u \u53a6\u95e8 ]   \n   \n     \n       \n       city \n       first_tag \n       size \n       mean \n       median \n     \n   \n   \n     \n       21 \n       \u53a6\u95e8 \n       \u4ea7\u54c1 \n       378.0 \n       10.279101 \n       10.00 \n     \n     \n       22 \n       \u53a6\u95e8 \n       \u5e02\u573a\u4e0e\u9500\u552e \n       184.0 \n       8.388587 \n       7.25 \n     \n     \n       23 \n       \u53a6\u95e8 \n       \u6280\u672f \n       403.0 \n       12.493797 \n       11.50 \n     \n     \n       24 \n       \u53a6\u95e8 \n       \u804c\u80fd \n       59.0 \n       6.745763 \n       5.00 \n     \n     \n       25 \n       \u53a6\u95e8 \n       \u8bbe\u8ba1 \n       188.0 \n       9.425532 \n       9.00 \n     \n     \n       26 \n       \u53a6\u95e8 \n       \u8fd0\u8425 \n       393.0 \n       7.541985 \n       6.00 \n     \n     \n       27 \n       \u53a6\u95e8 \n       \u91d1\u878d \n       3.0 \n       29.666667 \n       30.00", 
            "title": "\u53a6\u95e8\u7684IT\u884c\u4e1a\u4e03\u5927\u7ec6\u5206\u9886\u57df\u7684\u62db\u8058\u6574\u4f53\u72b6\u51b5"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#it_5", 
            "text": "# \u4e3b\u8981\u4ece\u6c42\u804c\u8005\u7684\u5b66\u5386\u548c\u5de5\u4f5c\u7ecf\u9a8c\u63a2\u8ba8IT\u4e03\u5927\u5206\u652f\u9886\u57df\u7684\u85aa\u8d44\u548c\u62db\u8058\u9700\u6c42\njobseeker_education = data.groupby([ education ,  first_tag ])[ salary ].aggregate([np.size, np.mean])\njobseeker_education = jobseeker_education.reset_index()\neducation_list = data.groupby( education )[ salary ].count().sort_values(ascending=False).index.values.tolist()\nparam_dist = { education : u \u5b66\u5386 ,  city : u \u57ce\u5e02 ,  work_experience : u \u5de5\u4f5c\u7ecf\u9a8c ,  size : u \u6570\u91cf ,  mean : u \u5e73\u5747\u85aa\u8d44 }\njobseeker_experience = data.groupby([ work_experience ,  first_tag ])[ salary ].aggregate([np.size, np.mean])\njobseeker_experience = jobseeker_experience.reset_index()\nexperience_list = data.groupby( work_experience )[ salary ].count().sort_values(ascending=False).index.values.tolist()  def domains_relation(dataframe, evalute_method, hue_param, hue_order=None):    \n    plt.figure(figsize=(8,6))\n    g = sns.barplot(x= first_tag , y=evalute_method, data=dataframe, hue=hue_param, hue_order=hue_order, palette= Set1 )\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n    plt.ylabel(u \u62db\u8058\u804c\u4f4d{} .format(param_dist.get(evalute_method)), fontsize=16, fontproperties=font)\n    plt.xlabel( )\n    plt.title(u IT\u884c\u4e1a\u5404\u9886\u57df\u62db\u8058\u804c\u4f4d{0}\u4e0e{1} .format(param_dist.get(evalute_method), param_dist.get(hue_param)), fontproperties=font, fontsize=20)\n    plt.gca().yaxis.grid(True, linestyle =  -. ,)\n    plt.legend(loc= best ,prop=font, fontsize=17)  for method in [ size ,  mean ]:\n    domains_relation(jobseeker_education, method,  education , education_list)    for method in [ size ,  mean ]:\n    domains_relation(jobseeker_experience, method,  work_experience , experience_list)    \u62db\u8058\u9700\u6c42\u8981\u6c42\u6700\u591a\u7684\u5b66\u5386\u662f\u672c\u79d1\uff0c\u5176\u6b21\u662f\u5927\u4e13\uff0c\u53ea\u6709\u5728\u5e02\u573a\u4e0e\u9500\u552e\u9886\u57df\uff0c\u672c\u79d1\u9700\u6c42\u7565\u4f4e\u4e8e\u5927\u4e13\uff1b\u5de5\u4f5c\u7ecf\u9a8c\u4e0a\uff0c\u6280\u672f\u76f8\u5173\u7684\u9886\u57df\u9700\u6c42\u6700\u5927\u7684\u662f3-5\u5e74\u5de5\u4f5c\u7ecf\u9a8c\uff0c\u5176\u6b21\u662f1-3\u5e74\uff0c\u800c\u5176\u4ed6\u975e\u6280\u672f\u7684\u9700\u6c42\u6700\u591a\u7684\u662f1-3\u5e74\uff0c\u5176\u6b21\u662f3-5\u5e74\uff1b  \u85aa\u8d44\u65b9\u9762\uff0c\u57fa\u672c\u5448\u73b0\u51fa\u5b66\u5386\u8d8a\u9ad8\u3001\u5de5\u4f5c\u7ecf\u9a8c\u8d8a\u4e30\u5bcc\u85aa\u8d44\u8d8a\u9ad8\u7684\u8d8b\u52bf\uff0c\u5076\u5c14\u6709\u7279\u6b8a\u60c5\u51b5\u3002  \u4e00\u822c\u800c\u8a00\uff0c\u6c42\u804c\u8005\u7684\u5b66\u5386\u8f83\u9ad8\u6216\u5de5\u4f5c\u7ecf\u9a8c\u4e30\u5bcc\uff0c\u5176\u85aa\u8d44\u8f83\u9ad8\uff0c\u8fd9\u4e0e\u4e0a\u9762\u7684\u67f1\u72b6\u56fe\u7684\u6574\u4f53\u8d8b\u52bf\u662f\u543b\u5408\u7684\uff1b\u62db\u8058\u9700\u6c42\u6700\u591a\u7684\u5b66\u5386\u662f\u672c\u79d1\uff0c\u5176\u6b21\u662f\u5927\u4e13\uff0c\u5de5\u4f5c\u7ecf\u9a8c\u8981\u6c423-5\u5e74\u62161-3\u5e74\u5c45\u591a\u3002", 
            "title": "IT\u884c\u4e1a\u4e0d\u540c\u9886\u57df\u7684\u85aa\u8d44\u4e0e\u6c42\u804c\u8005\u5173\u7cfb\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#it_6", 
            "text": "# \u4ece\u62db\u8058\u4f01\u4e1a\u7684\u89c4\u6a21\u548c\u91d1\u878d\u72b6\u51b5\u63a2\u8ba8\u5176\u4e0e\u62db\u8058\u804c\u4f4d\u85aa\u8d44\u3001\u62db\u8058\u9700\u6c42\u7684\u5173\u7cfb\nemployee_finance = data.groupby([ finance_stage ,  first_tag ])[ salary ].aggregate([np.size, np.mean])\nemployee_finance = employee_finance.reset_index()\nemployee_field = data.groupby([ industry_field ,  first_tag ])[ salary ].aggregate([np.size, np.mean])\nemployee_field = employee_field.reset_index()\n# education_list = data.groupby( education )[ salary ].count().sort_values(ascending=False).index.values.tolist()\nparam_dist = { industry_field : u \u884c\u4e1a\u9886\u57df ,  city : u \u57ce\u5e02 ,  finance_stage : u \u91d1\u878d\u72b6\u51b5 ,  size : u \u6570\u91cf ,  mean : u \u5e73\u5747\u85aa\u8d44 }  def domains_employee(dataframe, evalute_method, hue_param, hue_order=None):    \n    plt.figure(figsize=(12,8))\n    hue_order = data.groupby(hue_param)[ salary ].aggregate(eval('np.'+evalute_method)).sort_values(ascending=False).index\n    g = sns.barplot(x= first_tag , y=evalute_method, data=dataframe, hue=hue_param, hue_order=hue_order, palette= Set1 )\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n    plt.ylabel(u \u62db\u8058\u804c\u4f4d{} .format(param_dist.get(evalute_method)), fontsize=16, fontproperties=font)\n    plt.xlabel( )\n    plt.title(u IT\u884c\u4e1a\u5404\u9886\u57df\u62db\u8058\u804c\u4f4d{0}\u4e0e\u4f01\u4e1a{1} .format(param_dist.get(evalute_method), param_dist.get(hue_param)), fontproperties=font, fontsize=20)\n    plt.gca().yaxis.grid(True, linestyle =  -. ,)\n    plt.legend(loc= best ,prop=font, fontsize=17)  for method in [ size ,  mean ]:\n    domains_employee(employee_finance, method,  finance_stage )    for method in [ size ,  mean ]:\n    domains_employee(employee_field, method,  industry_field )    \u62db\u8058\u9700\u6c42\u4e2d\u6700\u591a\u7684\u662f\u6280\u672f\u9886\u57df\uff0c\u4e0a\u5e02\u516c\u53f8\u548c\u6210\u957f\u6027\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u65fa\u76db\uff0c\u4f46\u5e73\u5747\u85aa\u8d44\u6700\u591a\u7684\u5374\u662f\u6210\u719f\u578b\u516c\u53f8\u5176\u6b21\u624d\u662f\u4e0a\u5e02\u548c\u6210\u957f\u578b\u516c\u53f8\u3002\u4ece\u516c\u53f8\u6240\u5c5e\u7c7b\u578b\u4e0a\u770b\uff0c\u79fb\u52a8\u4e92\u8054\u7f51\u7684\u62db\u8058\u9700\u6c42\u6700\u591a\uff08\u90e8\u5206\u539f\u56e0\u662f\u5206\u7c7b\u7684\u65f6\u5019\u5c06\u6240\u6709\u8ddf\u79fb\u52a8\u4e92\u8054\u7f51\u6cbe\u8fb9\u7684\u516c\u53f8\u5747\u5212\u5206\u5230\u79fb\u52a8\u4e92\u8054\u7f51\u9886\u57df\u4e86\uff09\uff0c\u85aa\u8d44\u4e0a\uff0c\u91d1\u878d\u9886\u57df\u6700\u9ad8\uff0c\u63a5\u7740\u662fO2O\u3001\u793e\u4ea4\u7f51\u7edc\u3001\u6570\u636e\u670d\u52a1\u7b49\u4e00\u4e9b\u65b0\u578b\u7684\u7f51\u7edc\u79d1\u6280\u516c\u53f8\uff0c\u8d85\u8fc7\u4e86\u4f20\u7edf\u7684\u4e92\u8054\u7f51\u516c\u53f8\u7684\u85aa\u8d44\u6c34\u5e73\u3002", 
            "title": "IT\u884c\u4e1a\u4e0d\u540c\u9886\u57df\u7684\u85aa\u8d44\u4e0e\u62db\u8058\u4f01\u4e1a\u5173\u7cfb\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#it_7", 
            "text": "def IT_occupies(dataframe, content, evaluate_method):\n     \u8ba1\u7b97\u62c9\u52fe\u7f51\u6280\u672f\u5927\u7c7b\u4e2d\u540e\u7aef\u5f00\u53d1\u7684\u804c\u4f4d\u6570\u91cf\u3001\u85aa\u8d44\u60c5\u51b5  \n    # \u83b7\u53d6IT\u6280\u672f\u7c7b\u4e2d\u7684\u540e\u7aef\u5f00\u53d1\u5c97\u4f4d\u4fe1\u606f  \n    technology_backend = dataframe.loc[dataframe[ second_tag ]==u \u540e\u7aef\u5f00\u53d1 ,:]\n     # \u7edf\u8ba1\u6240\u6709\u540e\u7aef\u5f00\u53d1\u7f16\u7a0b\u8bed\u8a00\u7684\u804c\u4f4d\u9700\u6c42\u91cf\u3001\u5e73\u5747\u85aa\u8d44\u3001\u85aa\u8d44\u4e2d\u4f4d\u6570\n    tech_backend = technology_backend.groupby([ third_tag ])[ salary ].aggregate([eval( np. +evaluate_method)]).sort_values(evaluate_method, ascending=False).reset_index()\n     # \u83b7\u53d6Python\u7684\u804c\u4f4d\u4fe1\u606f\u7528\u4e8e\u540e\u7eed\u753b\u56fe\u7684annotate\u7684text\u5750\u6807\u4f4d\u7f6e\u548c\u663e\u793a\u7684\u6570\u5b57\n    python_index = tech_backend.loc[tech_backend[ third_tag ] == u Python , :].index.values[0]\n    python_value = tech_backend.loc[tech_backend[ third_tag ] == u Python , :][evaluate_method].values[0]\n    # \u901a\u8fc7plt.subplots()\u5efa\u7acb\u4e00\u4e2aaxis\u5b50\u56fe\u7528\u4e8e\u540e\u7eed\u7ed8\u56fe\n    fig, ax = plt.subplots(figsize=(10,8))\n    # \u8c03\u7528seaborn\u7684barplot\u8fdb\u884c\u7ed8\u56fe\n    g = sns.barplot(y= third_tag , x=evaluate_method, data=tech_backend, palette= PuBu_d , ax=ax)\n    ax.set_yticklabels(g.get_yticklabels(), fontproperties=font, fontsize=18)\n    # \u786e\u5b9aannotate\u7684text\u6587\u672c\u4f4d\u7f6e\u7684x\u5750\u6807\u4f4d\u7f6e\n    annotate_x_delta = tech_backend[evaluate_method][0] / 10    \n    ax.set_xlabel(content, fontsize=16, fontproperties=font)\n    ax.set_ylabel( )\n    ax.set_title(u \u540e\u7aef\u5f00\u53d1 +content, fontproperties=font, fontsize=20)\n    # sns.despine() \n    ax.annotate(str(int(python_value)), xy = (python_value, python_index), xytext = (python_value+annotate_x_delta, python_index+3), fontproperties=font, fontsize=20, arrowprops = dict(facecolor = 'k'))\n    ax.xaxis.grid(True, linestyle =  -. ,)\n    # \u7ed8\u5236\u540e\u7aef\u5f00\u53d1\u7f16\u7a0b\u8bed\u8a00\u767e\u5206\u6bd4\u997c\u56fe\n    if evaluate_method ==  size :\n        # \u8ba1\u7b97\u540e\u7aef\u5f00\u53d1\u5404\u7f16\u7a0b\u8bed\u8a00\u7684\u804c\u4f4d\u6bd4\u4f8b        \n        tech_backend[ position_property ] = tech_backend[ size ] / tech_backend[ size ].sum() * 100\n        pie_data = tech_backend.loc[tech_backend[ position_property ]   1, [ third_tag ,  position_property ]]\n        less_than_one = 100 - pie_data[ position_property ].sum()\n        pie_data.loc[pie_data[ third_tag ] == u \u540e\u7aef\u5f00\u53d1\u5176\u5b83 ,  position_property ] += less_than_one\n        pie_data.sort_values( position_property , ascending=False, inplace=True)\n        num = len(pie_data)\n        vals = range(num) #\u521b\u5efa\u6570\u636e\u7cfb\u5217\n        labels = pie_data[ third_tag ]\n        explode = np.zeros(num)\n        index_py = pie_data[pie_data[ third_tag ] == u Python ].index.values[0]\n        explode[index_py] += 0.15\n        fig1,ax1 = plt.subplots(figsize=(6,6))\n        ax1.pie(pie_data[ position_property ], labels=labels, autopct='%1.2f%%', \n                pctdistance=.8, shadow=False, startangle=20,radius=1.2, \n                labeldistance=1.06, colors=('b', 'g', 'r', 'c', 'y', 'orange', 'm', 'yellowgreen', 'gold', 'lightskyblue', 'lightcoral'),\n                textprops={ fontproperties : font,  fontsize :12}, explode=explode)\n        ax1.set_title(u'\u540e\u7aef\u5f00\u53d1\u804c\u4f4d\u5206\u5e03',fontsize=20, fontproperties=font)\n        ax1.axis( equal )\n#     fig.savefig( /home/darren/Desktop/backend_techww.png )  IT_occupies(data, u \u62db\u8058\u804c\u4f4d\u6570\u91cf ,  size )    IT_occupies(data, u \u5e73\u5747\u85aa\u8d44 k(\uffe5) ,  mean )   IT_occupies(data, u \u85aa\u8d44\u4e2d\u4f4d\u6570 k(\uffe5) ,  median )   Java\u7684\u62db\u8058\u804c\u4f4d\u4fe1\u606f\u6700\u591a,\u67092700\u591a\u62db\u8058\u804c\u4f4d\uff0c\u5360\u6bd429.37%\uff0c\u7f16\u7a0b\u8bed\u8a00\u7684\u8001\u5927\u5730\u4f4d\u4e0d\u53ef\u64bc\u52a8\uff01PHP\u804c\u4f4d\u9700\u6c42\u6b21\u4e4b\uff0c\u5360\u6bd414.08%\uff0c\u540e\u7eed\u5206\u522b\u662fC\u3001C++\u3001.NET\u3001Python\uff0c\u5176\u4e2dPython\u65e5\u9700\u6c42\u804c\u4f4d\u4e0d\u5230400\u4e2a\uff0c\u5360\u6bd45.24%\u3002\uff08\u6ce8\uff1a\u867d\u7136.NET\u4e0d\u7b97\u771f\u6b63\u7684\u7f16\u7a0b\u8bed\u8a00\uff0c\u4f46\u62c9\u52fe\u7f51\u7684\u6570\u636e\u662f\u5982\u6b64\u5206\u7c7b\uff0c\u5728\u8fd9\u4e5f\u4e00\u5e76\u5f53\u6210\u4e00\u95e8\u7f16\u7a0b\u8bed\u8a00\u770b\u5f85\uff0c\u6570\u636e\u6316\u6398\u3001\u7cbe\u51c6\u63a8\u8350\u7b49\u7c7b\u540c\uff09  \u85aa\u8d44\u65b9\u9762\uff0c\u6700\u9ad8\u7684\u662f\u6570\u636e\u6316\u6398\u548c\u63a8\u8350\u7b97\u6cd5\u7c7b\u3001\u5176\u6b21\u662f\u4e00\u4e9b\u65b0\u5174\u7f16\u7a0b\u8bed\u8a00\u5982Go\uff0cPython\u7684\u5e73\u5747\u85aa\u8d44\u8f83\u9ad8\uff0c\u8fbe\u523019K\uff0c\u9ad8\u4e8eJava\u3001PHP\u3001C\u3001C++\u7b49\u3002  \u6ce8\u610f\uff1a\u62c9\u52fe\u7f51\u53d1\u5e03\u85aa\u8d44\u662f\u4e00\u4e2a\u533a\u95f4\u8303\u56f4\uff0c\u56e0\u6b64\u672c\u6587\u91c7\u53d6\u7684\u662f\u8be5\u533a\u95f4\u7684\u5e73\u5747\u503c\uff0c\u4f46\u4ece\u73b0\u5b9e\u751f\u6d3b\u7684\u89c4\u5f8b\u770b\uff0c\u4f7f\u7528\u85aa\u8d44\u533a\u95f4\u7684\u6700\u4f4e\u503c\u6bd4\u8f83\u7b26\u5408\u903b\u8f91\u3002", 
            "title": "IT\u4e03\u5927\u9886\u57df\u7684\u6280\u672f\u7c7b\u4e2d\u7684\u540e\u7aef\u5f00\u53d1\u5c97\u4f4d\u63cf\u8ff0\u6027\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#_6", 
            "text": "# seaborn\u7684pointplot\u6216matplotlib\u7684plot\u7684\u70b9\u7684\u7c7b\u578b\nmarkers = [\n            'd', ' ', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', ' ', '|'\n        ] # '_',\nparam_dist = { city : u \u57ce\u5e02 ,  size : u \u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4 % ,  mean : u \u5e73\u5747\u85aa\u8d44 k(\uffe5) ,\n               median : u \u85aa\u8d44\u4e2d\u4f4d\u6570 k(\uffe5) ,  company_size : u \u4f01\u4e1a\u89c4\u6a21 , \n               finance_stage : u \u4f01\u4e1a\u91d1\u878d\u72b6\u51b5 ,  work_experience : u \u5de5\u4f5c\u7ecf\u9a8c ,  education : u \u5b66\u5386 }  def tech_backend_plot(second_feature, evaluate_method, lang_part=True, big_feature=u \u540e\u7aef\u5f00\u53d1 ):\n     \u8ba1\u7b97\u5404\u5927\u57ce\u5e02\u7684\u540e\u7aef\u5f00\u53d1\u7684\u7f16\u7a0b\u8bed\u8a00\u7684\u804c\u4f4d\u9700\u6c42\u548c\u85aa\u8d44\u72b6\u51b5\uff0c\u53ea\u53d6\u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4 5\u7684\u5e38\u89c1\u7f16\u7a0b\u8bed\u8a00\n    big_feature: IT\u4e03\u5927\u5206\u652f\u9886\u57df\u7684\u4e00\u4e2a\uff0c\u9ed8\u8ba4\u662f\u6280\u672f\n    second_feature: \u662f\u6570\u636e\u96c6\u4e2d\u9664\u4e86\u6280\u672f\u7684\u5176\u4ed6\u7279\u5f81\uff0c\u5305\u62eccity,company_size, education etc\u7aef\n    evaluate_method: \u8868\u793a\u7684\u662f\u5bf9data\u6570\u636e\u5206\u7ec4\u540e\u5bf9\u5404\u4e2a\u5206\u7ec4\u5b9e\u65bd\u7684\u7edf\u8ba1\u65b9\u6cd5\uff0c\u4e3b\u8981\u6709np.mean,np.median,np.size\n    lang_part: \u610f\u601d\u662f\u8981\u4e0d\u8981\u53d6\u540e\u7aef\u7f16\u7a0b\u8bed\u8a00\u7684\u4e00\u90e8\u5206\uff0c\u9ed8\u8ba4\u662fTrue,\u5426\u5219\u5c06\u7ed8\u5236\u6240\u6709\u7684\u540e\u7aef\u5f00\u53d1\u8bed\u8a00\n     \n    technology_backend = data.loc[data[ second_tag ] == big_feature,:]    \n    # \u53ea\u62bd\u53d6\u540e\u7aef\u7f16\u7a0b\u8bed\u8a00\u4e2d\u62db\u8058\u9700\u6c42\u5927\u7684\u524d7\u4e2a\u7f16\u7a0b\u8bed\u8a00\u7684\u540d\u79f0\n    targeted_lang = technology_backend['third_tag'].value_counts().index.values.tolist()[:7]\n    # \u5220\u9664 \u540e\u7aef\u5f00\u53d1\u5176\u4ed6\u8bed\u8a00 \uff0c\u5148\u7528 | .join(targeted_lang)\u518d\u6267\u884c\u4ee5\u4e0b\u8bed\u53e5\n    if u'\\u540e\\u7aef\\u5f00\\u53d1\\u5176\\u5b83' in targeted_lang:\n        targeted_lang.remove(u'\\u540e\\u7aef\\u5f00\\u53d1\\u5176\\u5b83') \n\n    tech_backend = technology_backend.groupby([second_feature,  third_tag ])[ salary ].aggregate([eval( np.  + evaluate_method)]).reset_index()    \n    # \u53ea\u8bc4\u4f30Java\u3001C\u3001C++\u3001Python\u7b496\u4e2a\u540e\u7aef\u7f16\u7a0b\u8bed\u8a00\n    if lang_part:\n        tech_backend = tech_backend[tech_backend['third_tag'].str.contains(u'Java|PHP|C|C\\+\\+|\\.NET|Python')]\n    # \u540e\u7aef\u7f16\u7a0b\u8bed\u8a00\u7684\u540d\u79f0\u5217\u8868\uff0c\u7528\u4e8e\u7ed8\u56fe\u7684tickslabels\u8bbe\u7f6e\n    second_feature_list = tech_backend[second_feature].unique().tolist()\n    # \u5bf9\u8bc4\u4f30\u804c\u4f4d\u9700\u6c42\u7684\uff0c\u91c7\u7528\u767e\u5206\u6bd4\n    if evaluate_method ==  size :\n        for i in second_feature_list:\n            one_data = tech_backend.loc[tech_backend[second_feature] == i, :]\n            index_ = one_data.index\n            total_ = one_data[evaluate_method].sum()\n            # \u5728tech_backend\u7684DataFrame\u65b0\u5efa\u4e00\u4e2a\u7279\u5f81property\uff0c\u5b58\u653e\u8ba1\u7b97\u5404\u4e2a\u7f16\u7a0b\u8bed\u8a00\u5728second_feature\u4e2d\u7684\u767e\u5206\u6bd4\uff0c\u5982second_feature\u662fcity\n            tech_backend.ix[index_,  property ] = one_data[evaluate_method] / total_ * 100\n    # \u7528\u4e8eseaborn barplot\u7684hue_order\u987a\u5e8f\u5217\u8868\n    backend_lang = tech_backend.groupby( third_tag )[evaluate_method].sum().sort_values(ascending=False).index.values.tolist()\n    # \u7528\u4e8eseaborn barplot\u7684order\u987a\u5e8f\u5217\u8868    \n    backend_second_feature = tech_backend.groupby(second_feature)[evaluate_method].sum().sort_values(ascending=False).index.values.tolist()\n\n    plt.figure(figsize=(12,10))\n    with sns.color_palette( PuBuGn_d ):\n        if evaluate_method ==  size :\n            y_str =  property \n        else:\n            y_str = evaluate_method\n        g = sns.pointplot(y=y_str, x=second_feature, hue= third_tag , hue_order=backend_lang, order=backend_second_feature,\n                       data=tech_backend, size=10, markers=markers, index=True,\n                       aspect=1.2, legend=False, dodge=True)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=45)\n    plt.ylabel(u {0} .format(param_dist.get(evaluate_method)), fontsize=16, fontproperties=font)\n    plt.xlabel( )\n    plt.title(u \u540e\u7aef\u5f00\u53d1\u7f16\u7a0b\u8bed\u8a00\u4e0e\u4e0d\u540c{0}\u7684{1} .format(param_dist.get(second_feature),param_dist.get(evaluate_method)), fontproperties=font, fontsize=23)\n    plt.gca().yaxis.grid(True, linestyle =  -. ,)\n    plt.legend(loc= best ,prop=font, fontsize=8)  tech_backend_plot( city ,  size )   tech_backend_plot( city ,  mean )   tech_backend_plot( city ,  median )   \u5317\u4eac\u3001\u4e0a\u6d77\u3001\u6df1\u5733\u3001\u5e7f\u5dde\u3001\u676d\u5dde\u7684IT\u884c\u4e1a\u9700\u6c42\u91cf\u6700\u591a\uff0c\u85aa\u8d44\u4e5f\u8f83\u9ad8\uff08\u5e7f\u5dde\u85aa\u8d44\u504f\u4f4e\uff09\uff0c\u5c5e\u4e8e\u7b2c\u4e00\u68af\u961f\uff1b\u4ece\u5404\u7f16\u7a0b\u8bed\u8a00\u770b\uff0cJava\u7edd\u5bf9\u7684\u9738\u4e3b\u5730\u4f4d\uff0c\u4f46\u5728\u4e00\u7ebf\u53d1\u8fbe\u57ce\u5e02\uff0cJava\u8bed\u8a00\u6240\u5360\u7684\u6bd4\u4f8b\u8fdc\u4f4e\u4e8e\u5176\u4ed6\u57ce\u5e02\u7684\u6bd4\u4f8b\uff0c\u5373\u4e00\u7ebf\u53d1\u8fbe\u57ce\u5e02\u5404\u79cd\u7f16\u7a0b\u8bed\u8a00\u90fd\u6709\u53d1\u5c55\u673a\u4f1a\uff0c\u800c\u4e8c\u7ebf\u57ce\u5e02\u8fd8\u5c40\u9650\u5728\u51e0\u95e8\u7f16\u7a0b\u8bed\u8a00\u4e2d\uff0c\u5982\u6d4e\u5357\uff0cJava\u5360\u6d4e\u5357\u804c\u4f4d\u9700\u6c42\u768480%\u5de6\u53f3\uff0cPHP\u5360\u6bd415%\u5de6\u53f3\uff0c.NET\u5360\u6bd45%\u5de6\u53f3\uff1bPython\u9700\u6c42\u5360\u6bd4\u6700\u5927\u7684\u662f\u5317\u4eac\uff0c\u5176\u6b21\u662f\u4e0a\u6d77\u548c\u676d\u5dde\uff0c\u76f8\u6bd4\u5176\u4ed6\u8bed\u8a00\uff0cPython\u62db\u8058\u9700\u6c42\u8f83\u5c0f\uff0c\u4f46\u85aa\u8d44\u8f83\u9ad8\u3002  tech_backend_plot( finance_stage ,  size )   \u4ece\u62db\u8058\u9700\u6c42\u4e0a\u770b\uff0cJava\u7684\u62db\u8058\u9700\u6c42\u6700\u591a\uff0c\u5176\u6b21\u662fPHP\uff0cPython\u62db\u8058\u804c\u4f4d\u8f83\u4f4e\uff0c\u4f46Python\u7684\u85aa\u8d44\u8f83\u9ad8\u3002  tech_backend_plot( finance_stage ,  mean )   tech_backend_plot( finance_stage ,  median )   tech_backend_plot( company_size ,  size )   tech_backend_plot( company_size ,  mean )   tech_backend_plot( company_size ,  median )   \u516c\u53f8\u89c4\u6a21\u4e0e\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u6298\u7ebf\u56fe\u770b\u51fa\uff0c\u5927\u578b\u516c\u53f8\u5bf9Java\u7684\u9700\u6c42\u6700\u591a\uff0c\u5c0f\u578b\u516c\u53f8\u5bf9PHP\u548cPython\u7684\u9700\u6c42\u8f83\u5927\uff08\u6ce8\u610f\uff0c\u56fe\u4e2d\u4e00\u79cd\u7c7b\u578b\u7684\u516c\u53f8\u4e2d\u5404\u4e2a\u7f16\u7a0b\u8bed\u8a00\u5360\u6bd4\u4e4b\u548c\u662f100%\uff0c\u5176\u4ed6\u6298\u7ebf\u56fe\u4e5f\u7c7b\u4f3c\uff09\u3002\u85aa\u8d44\u65b9\u9762\uff0c\u5927\u578b\u516c\u53f8\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u5176\u6b21\u662f\u4e2d\u578b\u516c\u53f8\uff0c\u6700\u4f4e\u662f\u5c0f\u578b\u516c\u53f8\u3002  tech_backend_plot( work_experience ,  size )   tech_backend_plot( work_experience ,  mean )   \u85aa\u8d44\u57fa\u672c\u4e0e\u5de5\u4f5c\u7ecf\u9a8c\u6210\u6b63\u6bd4\u3002  tech_backend_plot( education ,  median )   tech_backend_plot( education ,  mean )   tech_backend_plot( education ,  size )   \u4e0a\u56fe\u8868\u793a\u7684\u662f\u4e0d\u540c\u5b66\u5386\u7684\u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4\uff0c\u5373\u672c\u79d1\u5b66\u5386\u4e2d\uff0c\u5404\u4e2a\u540e\u7aef\u5f00\u53d1\u8bed\u8a00\u62db\u8058\u9700\u6c42\u7684\u767e\u5206\u6bd4\uff08\u672c\u79d1\u5b66\u5386\u4e2d\u8fd96\u79cd\u7f16\u7a0b\u8bed\u8a00\u7684\u767e\u5206\u6bd4\u4e4b\u548c\u4e3a100%\uff09\uff0c\u7531\u4e8eC#\u548c.NET\u5728\u7855\u58eb\u5b66\u5386\u4e0a\u6ca1\u6709\u62db\u8058\u9700\u6c42\uff0c\u6240\u4ee5\uff0c\u867d\u7136C++\u3001C\u3001Python\u7684\u7855\u58eb\u5b66\u5386\u9700\u6c42\u767e\u5206\u6bd4\u660e\u663e\u589e\u591a\uff0c\u5e76\u4e0d\u4e00\u5b9a\u4ee3\u8868\u4e86\u8fd93\u95e8\u7f16\u7a0b\u8bed\u8a00\u5bf9\u9ad8\u5b66\u5386\u7684\u7edd\u5bf9\u9700\u6c42\u8d85\u8fc7\u4e86\u5176\u4ed6\u76f8\u5bf9\u4f4e\u5b66\u5386\uff0c\u53ea\u662f\u76f8\u5bf9\u800c\u8a00\uff0cC\u548cC++\u66f4\u9752\u7750\u4e8e\u9ad8\u5b66\u5386\u6c42\u804c\u8005\u3002\u4ece\u524d\u9762\u7684\u5206\u6790\u53ef\u77e5\uff0c\u672c\u79d1\u548c\u5927\u4e13\u662f\u62db\u8058\u4f01\u4e1a\u7684\u9996\u5148\u5b66\u5386\u3002  \u85aa\u8d44\u4e0e\u5b66\u5386\u57fa\u672c\u6210\u6b63\u6bd4", 
            "title": "\u5404\u5927\u57ce\u5e02\u7684\u540e\u7aef\u5f00\u53d1\u8bed\u8a00\u7684\u804c\u4f4d\u9700\u6c42\u548c\u85aa\u8d44\u6c34\u5e73"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#python", 
            "text": "param_dist = { size : u \u62db\u8058\u804c\u4f4d\u6570\u91cf\u4e0e\u767e\u5206\u6bd4 ,  mean : u \u5e73\u5747\u85aa\u8d44 , \n               median : u \u85aa\u8d44\u4e2d\u4f4d\u6570 ,             \n             }  def series_bar_plot(lang, feature, evaluate_method):\n     \n    \u7ed8\u5236\u4e00\u95e8\u7f16\u7a0b\u8bed\u8a00\u7684\u804c\u4f4d\u9700\u6c42\u3001\u85aa\u8d44\u7684\u67f1\u72b6\u56fe\n    lang: \u7f16\u7a0b\u8bed\u8a00\u540d\u79f0\n    feature: \u6570\u636e\u5206\u7ec4\u7684\u4f9d\u636e\u7279\u5f81\n    evaluate_method: \u5b9e\u65bd\u5230\u5206\u7ec4\u540e\u7684\u6570\u636e\u7684\u7edf\u8ba1\u65b9\u6cd5\n     \n    # \u83b7\u53d6\u4e00\u95e8\u7f16\u7a0b\u8bed\u8a00\u7684\u6240\u6709\u62db\u8058\u4fe1\u606f\u6570\u636e\n    data_lang = data[data[ third_tag ] == lang]\n    # \u6839\u636efeature\u5c06\u6570\u636e\u96c6\u5206\u7ec4\uff0c\u5e76\u4f9d\u636eevaluate_method\u5bf9\u5206\u7ec4\u540e\u7684\u6570\u636e\u8fdb\u884c\u7edf\u8ba1\n    one_series = data_lang.groupby([feature])['salary'].aggregate([eval('np.'+evaluate_method)]).sort_values(evaluate_method, ascending=False)\n\n    fig, ax1 = plt.subplots(figsize=(8,6))  # \u4f7f\u7528subplots()\u521b\u5efa\u7a97\u53e3    \n    g = sns.barplot(y=one_series[evaluate_method], x=one_series.index, palette= BuGn_d , ax=ax1)\n    # \u7edf\u8ba1\u65b9\u6cd5\u662fcout/size\u5c31\u7ed8\u5236\u53ccy\u8f74\u56fe\n    if evaluate_method ==  size :\n        ax2 = ax1.twinx() # \u521b\u5efa\u7b2c\u4e8c\u4e2a\u5750\u6807\u8f74\n        x_list = range(len(one_series))\n        y_point_list = one_series[evaluate_method] / one_series[evaluate_method].sum() * 100\n        ax2.plot(x_list, y_point_list, linewidth = 3, color= g , marker= o , label=u \u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4 ) \n        ax2.legend(loc= best , prop=font)\n        ax2.set_ylabel(u'\u62db\u8058\u804c\u4f4d\u6570\u91cf\u767e\u5206\u6bd4%', fontproperties=font, fontsize = 16)\n    ax1.set_xlabel( ) \n    ax1.set_ylabel(param_dist.get(evaluate_method), fontsize=16, fontproperties=font)\n    x_ticks_l = [i for i in one_series.index]\n    ax1.set_xticklabels(x_ticks_l, fontproperties=font, fontsize=16, rotation= 90 if feature ==  finance_stage  else 30)\n    ax1.yaxis.grid(True, linestyle =  -. ,)\n    ax1.set_title(lang+param_dist.get(evaluate_method),fontproperties=font,fontsize=25)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)  series_bar_plot( Python ,  city ,  size )   series_bar_plot( Python ,  city ,  mean )   series_bar_plot( Python ,  city ,  median )   series_bar_plot( Python ,  finance_stage ,  size )   series_bar_plot( Python ,  finance_stage ,  mean )   series_bar_plot( Python ,  finance_stage ,  median )   for i in [ size ,  mean ,  median ]:\n    series_bar_plot( Python ,  company_size , i)     for i in [ size ,  mean ,  median ]:\n    series_bar_plot( Python ,  work_experience , i)     for i in [ size ,  mean ,  median ]:\n    series_bar_plot( Python ,  education , i)     Python\u7684\u62db\u8058\u9700\u6c42\u603b\u91cf\u4e0d\u591a\uff0c\u4f46\u5e73\u5747\u85aa\u8d44\u8f83\u9ad8\uff0c\u8fd9\u4e5f\u7b26\u5408\u65b0\u5174\u8bed\u8a00\u7684\u7279\u70b9\u3002  Python\u62db\u8058\u9700\u6c42\u6700\u591a\u7684\u4f9d\u65e7\u662f\u5317\u4eac\uff0c\u5176\u6b21\u4e0a\u6d77\uff0c\u5e73\u5747\u85aa\u8d44\u6700\u9ad8\u7684\u8fd8\u662f\u5317\u4eac\uff0c\u5176\u6b21\u662f\u6df1\u5733\u548c\u4e0a\u6d77\u3002\u4ece\u62db\u8058\u516c\u53f8\u7684\u89d2\u5ea6\u5206\u6790\uff0c\u4e2d\u578b\u7684\u6210\u719f\u548c\u6210\u957f\u6027\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u6c34\u5e73\u90fd\u8f83\u9ad8\uff0c\u5927\u578b\u4e0a\u5e02\u516c\u53f8\u7684\u85aa\u8d44\u9ad8\u4f46\u62db\u8058\u9700\u6c42\u6ca1\u6709\u4e2d\u578b\u516c\u53f8\u591a\uff0c50\u4eba\u4ee5\u4e0b\u7684\u521d\u521b\u516c\u53f8\u7684\u62db\u8058\u9700\u6c42\u548c\u85aa\u8d44\u90fd\u662f\u6700\u4f4e\u3002  \u5de5\u4f5c\u7ecf\u9a8c\u65b9\u9762\uff0c\u9700\u6c42\u6700\u5927\u7684\u662f3-5\u5e74\uff0c\u5176\u6b21\u662f1-3\u5e74\uff0c\u85aa\u8d44\u8ddf\u5de5\u4f5c\u7ecf\u9a8c\u57fa\u672c\u6210\u6b63\u6bd4\uff0c\u6709\u4e00\u4e2a\u7279\u4f8b\u662f\u5e94\u5c4a\u6bd5\u4e1a\u751f\uff0c\u5176\u5e73\u5747\u85aa\u8d44\u7adf\u7136\u9ad8\u4e8e\u67093\u5e74\u5de5\u4f5c\u7ecf\u9a8c\u7684\u6c42\u804c\u8005\uff01\u4ed4\u7ec6\u5206\u6790\u53d1\u73b0\uff0c\u5e94\u5c4a\u6bd5\u4e1a\u751f\u7684\u62db\u8058\u9700\u6c42\u975e\u5e38\u4e4b\u4f4e\uff0c\u6240\u4ee5\uff0c\u5e94\u5c4a\u6bd5\u4e1a\u751f\u7684\u9ad8\u85aa\u5176\u5b9e\u662f\u7531\u4e8e\u6837\u672c\u91cf\u592a\u5c11\u53c8\u53c8\u53d7\u5230\u7ec4\u5185\u79bb\u7fa4\u503c\u7684\u5e72\u6270\uff0c\u9020\u6210\u5e73\u5747\u85aa\u8d44\u5f88\u9ad8\u3002  \u67e5\u8be2\u6570\u636e\u96c6\uff0c\u53d1\u73b0\u53ea\u6709\u5317\u4eac\u9ad8\u7ef4\u6570\u91d1\u79d1\u6280\u6709\u9650\u516c\u53f8\u660e\u786e\u6807\u660e\u62db\u8058\u5e94\u5c4a\u6bd5\u4e1a\u751f\uff0c\u5e73\u5747\u85aa\u8d44\u662f22k\uff0c\u56e0\u6b64\u672c\u6587\u4e2d\u5e94\u5c4a\u6bd5\u4e1a\u751f\u7684\u4fe1\u606f\u6ca1\u6709\u592a\u5927\u53c2\u8003\u610f\u4e49\u3002  \u5e73\u5747\u85aa\u8d44\u4e0e\u5b66\u5386\u4e5f\u6210\u6b63\u6bd4\uff0c\u4f46\u672c\u79d1\u5b66\u5386\u7684\u62db\u8058\u9700\u6c42\u8fdc\u8fdc\u8d85\u8fc7\u5176\u4ed6\u5b66\u5386\u3002  # data_lang = data[data[ third_tag ] ==  Python ]\n# one_series = data_lang.groupby([ company_size ])['salary'].aggregate([np.size]).sort_values( size , ascending=False)\ndata_py = data[data[ third_tag ] ==  Python ]  data_py.loc[data_py[ work_experience ] == u \u5e94\u5c4a\u6bd5\u4e1a\u751f , :]   \n   \n     \n       \n       finance_stage \n       city \n       dist \n       salary \n       job_nature \n       industry_field \n       company \n       third_tag \n       published_time \n       second_tag \n       position_advantage \n       first_tag \n       last_login \n       work_experience \n       position_type \n       position \n       education \n       crawl \n       company_size \n       day \n     \n   \n   \n     \n       79248 \n       \u6210\u957f\u578b(\u4e0d\u9700\u8981\u878d\u8d44) \n       \u5317\u4eac \n       \u671d\u9633\u533a \n       22.5 \n       \u5168\u804c \n       \u79fb\u52a8\u4e92\u8054\u7f51 \n       \u5317\u4eac\u9ad8\u7ef4\u6570\u91d1\u79d1\u6280\u6709\u9650\u516c\u53f8 \n       Python \n       2017/8/4 10:11 \n       \u540e\u7aef\u5f00\u53d1 \n       \u5e74\u5e95\u53cc\u85aa,\u5f39\u6027\u5236\u529e\u516c,15\u5929\u5e74\u5047 \n       \u6280\u672f \n       1.500000e+12 \n       \u5e94\u5c4a\u6bd5\u4e1a\u751f \n       \u540e\u7aef\u5f00\u53d1 \n       python\u5f00\u53d1\u9ad8\u7ea7\u5de5\u7a0b\u5e08 \n       \u672c\u79d1 \n       2017/8/4 \n       50-150\u4eba \n       2017/8/4 \n     \n      # \u66ff\u6362position\u63cf\u8ff0\n# data_py[ position ] = data_py[ position ].str.replace(u (.*?)\u9ad8\u7ea7(.*) ,  \\\\1\\\\2 )\n# data_py[ position ].replace(u .*?\u7814\u53d1.* , u \u5f00\u53d1 , regex=True, inplace=True)\n# data_py[ position ].replace(u .*?\u722c\u866b.* , u \u722c\u866b , regex=True, inplace=True)\n# data_py[ position ].replace(u .*?\u6570\u636e.* , u \u6570\u636e , regex=True, inplace=True)\n# data_py[ position ].replace(u .*?\u5168\u6808.* , u \u5168\u6808 , regex=True, inplace=True)\n# data_py[ position ].replace(u .*?\u8fd0\u7ef4.* , u \u8fd0\u7ef4 , regex=True, inplace=True)\n# data_py[ position ].replace(u .*?\u7b97\u6cd5.* , u \u7b97\u6cd5 , regex=True, inplace=True)\n# data_py[ position ].replace(u .*?\u540e\u7aef.* ,u \u540e\u7aef , regex=True, inplace=True)\n# data_py[ position ].replace(u .*?\u540e\u53f0.* ,u \u540e\u7aef , regex=True, inplace=True)\n# data_py[ position ].replace(u .*?\u5b89\u5168.* ,u \u5b89\u5168 , regex=True, inplace=True)\n# data_py[ position ] = data_py[ position ].str.replace(r .*?web.* ,u \u540e\u7aef , flags=re.IGNORECASE)\n# data_py[ position ].replace(u .*?\u670d\u52a1[\u5668|\u7aef].* ,u \u540e\u7aef , regex=True, inplace=True)\n# data_py[ position ] = data_py[ position ].str.replace(r .*?python.* ,u python\u5de5\u7a0b\u5e08 , flags=re.IGNORECASE)\n# data_py[ position ].replace(u .*?[\u540e\u7aef|\u5f00\u53d1].* ,u web\u5f00\u53d1\u5de5\u7a0b\u5e08 , regex=True, inplace=True)\n# data_py[ position ].replace(u web\u5f00\u53d1\u5de5\u7a0b\u5e08 ,u python\u5f00\u53d1\u5de5\u7a0b\u5e08 , regex=True, inplace=True)\n# data_py.loc[data_py[ position ].str.contains(u \u5168\u6808 ), :].shape", 
            "title": "\u62c9\u52fe\u7f51Python\u804c\u4f4d\u63cf\u8ff0\u6027\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#python_1", 
            "text": "py_count = data_py[ position ].value_counts()\npy_count.values.sum()  numpy.int64  fig, ax1 = plt.subplots(figsize=(8,6))  # \u4f7f\u7528subplots()\u521b\u5efa\u7a97\u53e3    \ng = sns.barplot(y=py_count.values, x=py_count.index, palette= PuBu_d , ax=ax1)\n# \u7ed8\u5236\u53ccy\u8f74\u56fe\nax2 = ax1.twinx() # \u521b\u5efa\u7b2c\u4e8c\u4e2a\u5750\u6807\u8f74\nx_list = range(len(py_count))\ny_point_list = py_count.values / np.float(py_count.values.sum()) * 100\nax2.plot(x_list, y_point_list, linewidth = 3, color= b , marker= o , label=u \u804c\u4f4d\u9700\u6c42\u767e\u5206\u6bd4 ) \nax2.legend(loc= best , prop=font)\nax2.set_ylabel(u'\u62db\u8058\u804c\u4f4d\u6570\u91cf\u767e\u5206\u6bd4%', fontproperties=font, fontsize = 16)\nax1.set_xlabel( ) \nax1.set_ylabel(u \u62db\u8058\u804c\u4f4d\u6570\u91cf , fontsize=16, fontproperties=font)\nx_ticks_l = [i for i in py_count.index]\nax1.set_xticklabels(x_ticks_l, fontproperties=font, fontsize=16, rotation= 45)\nax1.yaxis.grid(True, linestyle =  -. ,)\nax1.set_title(u Python\u62db\u8058\u804c\u4f4d\u5206\u5e03\u8be6\u60c5 ,fontproperties=font,fontsize=25)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)  ([ matplotlib.axis.XTick at 0x7f8a0f50a250 ,\n   matplotlib.axis.XTick at 0x7f8a0f5d9950 ,\n   matplotlib.axis.XTick at 0x7f8a0f5e2690 ,\n   matplotlib.axis.XTick at 0x7f8a0f49b150 ,\n   matplotlib.axis.XTick at 0x7f8a0f49b850 ,\n   matplotlib.axis.XTick at 0x7f8a0f49bf50 ,\n   matplotlib.axis.XTick at 0x7f8a0f4910d0 ,\n   matplotlib.axis.XTick at 0x7f8a0f4a7b90 ,\n   matplotlib.axis.XTick at 0x7f8a0f4b22d0 ],\n  a list of 9 Text xticklabel objects )   python\u5f00\u53d1\u5de5\u7a0b\u5e08\u4e3b\u8981\u6307\u7684\u662fweb\u5f00\u53d1\uff0c\u800cpython\u5de5\u7a0b\u5e08\u662f\u62db\u8058\u5c97\u4f4d\u540d\u79f0\u6ca1\u6709\u660e\u786e\u6807\u660e\uff0c\u8981\u4ece\u5c97\u4f4d\u8be6\u60c5\u9875\u9a8c\u8bc1\u5177\u4f53\u5c97\u4f4d\u60c5\u51b5\uff0c\u5176\u4ed6\u7684\u5206\u7c7b\u6807\u7b7e\u662f\u660e\u786e\u7684\u5177\u4f53\u5c97\u4f4d\uff0c\u5982\u6570\u636e\u7c7b\uff0c\u5305\u62ec\u4e86\u6570\u636e\u5206\u6790\u3001\u6316\u6398\u7b49\u3002  \u7531\u4e8e\u6ca1\u6709\u91c7\u96c6\u804c\u4f4d\u8be6\u60c5\u9875\u4fe1\u606f\uff0c\u65e0\u6cd5\u8fdb\u4e00\u6b65\u9a8c\u8bc1\u62db\u8058\u6570\u91cf\u4ec5\u6b21\u4e8e\u5f00\u53d1\u7c7b\u7684\u6240\u8c13\u7684python\u5de5\u7a0b\u5e08\u5177\u4f53\u5c97\u4f4d\u4fe1\u606f\u3002", 
            "title": "Python\u5177\u4f53\u804c\u4f4d\u5206\u5e03"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#_7", 
            "text": "# \u7531\u4e8eposition_advantage\u4e2d\u6709float\u7c7b\u578b\uff0c\u6545\u8981\u5148\u8f6c\u6210str\nword_ = data[ position_advantage ].apply(lambda x: str(x))\n# \u5c06\u6240\u6709str\u8fde\u63a5\u8d77\u6765\nwords =    .join(word_)  from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator   #\u8bcd\u4e91\u5e93\nimport jieba.analyse\nfrom scipy.misc import imread\ntags = jieba.analyse.extract_tags(words, topK=80, withWeight=False)\ntext =   .join(tags)\ntext = unicode(text)\nd = path.dirname(__name__)\ntrump_coloring = imread(path.join(d,  heroes.png ))\n\nwc = WordCloud(font_path= ukai.ttc ,\n        background_color= white , max_words=300, mask=trump_coloring,\n        max_font_size=80, random_state=42)  # gray balck\n# generate word cloud \nwc.generate(text)\n# generate color from image\nimage_colors = ImageColorGenerator(trump_coloring)\nplt.figure(1,figsize=(8,10))\nplt.imshow(wc)\nplt.axis( off )\nplt.show()   \u5c97\u4f4d\u63cf\u8ff0\u7528\u7684\u8bcd\u6c47\u6700\u591a\u7684\u662f\u57f9\u8bad\u3001\u6241\u5e73\u3001\u5e73\u53f0\uff0c\u4f53\u73b0\u51fa\u5f53\u4ecaIT\u884c\u4e1a\u6bd4\u8f83\u6ce8\u91cd\u5458\u5de5\u7684\u57f9\u8bad\u53ca\u5b9e\u65bd\u6241\u5e73\u5316\u7ba1\u7406", 
            "title": "\u62db\u8058\u804c\u4f4d\u63cf\u8ff0\u8bcd\u4e91\u56fe"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#_8", 
            "text": "# \u5c06\u65f6\u95f4str\u8f6c\u6210datetime\ndata['time_published'] = pd.to_datetime(data['published_time'])\n# \u5c06\u8f6c\u6362\u597d\u7684\u65f6\u95f4series\u8bbe\u7f6e\u6210\u884c\u7d22\u5f15\ndata.set_index( time_published , inplace=True)  # \u63d0\u53d6\u65f6\u95f4\u7d22\u5f15\u7684\u5c0f\u65f6\ndata[ hour ] = data.index.hour\nhour_info = pd.DataFrame(data.hour.value_counts())\nhour_info[ property ] = np.round(hour_info.hour / hour_info.hour.sum() * 100, 2)  hour_cs = data.groupby([ hour ,  company_size ])[ salary ].aggregate(np.size).reset_index().sort( salary , ascending=False)  plt.figure(figsize=(8,6))\nmarkers = [\n            'd', ' ', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', ' ', '|',  _ \n        ]\ng = sns.pointplot(x= hour , y= salary , hue= company_size ,\n                  data=hour_cs, dodage=True, markers=markers, size=7)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u \u5c0f\u65f6 , fontsize=16, fontproperties=font)\nplt.ylabel(u \u62db\u8058\u804c\u4f4d\u6570\u91cf , fontsize=16, fontproperties=font)\nplt.title(u IT\u884c\u4e1a\u804c\u4f4d\u62db\u8058\u9700\u6c42 , fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc= best ,prop=font, fontsize=15)  matplotlib.legend.Legend at 0x7fc966e6bf50    hour_fs = data.groupby([ hour ,  finance_stage ])[ salary ].aggregate(np.size).reset_index().sort( salary , ascending=False)\nplt.figure(figsize=(8,6))\nmarkers = [\n            'd', ' ', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', ' ', '|',  _ \n        ]\ng = sns.pointplot(x= hour , y= salary , hue= finance_stage ,\n                  data=hour_fs, dodage=True, markers=markers, size=7)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u \u5c0f\u65f6 , fontsize=16, fontproperties=font)\nplt.ylabel(u \u62db\u8058\u804c\u4f4d\u6570\u91cf , fontsize=16, fontproperties=font)\nplt.title(u IT\u884c\u4e1a\u804c\u4f4d\u62db\u8058\u9700\u6c42 , fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc= best ,prop=font, fontsize=15)  matplotlib.legend.Legend at 0x7fc973c6ba10    data_py = data[data[ third_tag ] == u Python ]\nhour_cs = data_py.groupby([ hour ,  company_size ])[ salary ].aggregate(np.size).reset_index().sort( salary , ascending=False)\nplt.figure(figsize=(8,6))\nmarkers = [\n            'd', ' ', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', ' ', '|',  _ \n        ]\ng = sns.pointplot(x= hour , y= salary , hue= company_size ,\n                  data=hour_cs, dodage=True, markers=markers, size=7)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u \u5c0f\u65f6 , fontsize=16, fontproperties=font)\nplt.ylabel(u \u62db\u8058\u804c\u4f4d\u6570\u91cf , fontsize=16, fontproperties=font)\nplt.title(u Python\u804c\u4f4d\u62db\u8058\u9700\u6c42 , fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc= best ,prop=font, fontsize=15)  matplotlib.legend.Legend at 0x7fc965e59c10    data_py = data[data[ third_tag ] == u Python ]\nhour_fs = data_py.groupby([ hour ,  finance_stage ])[ salary ].aggregate(np.size).reset_index().sort( salary , ascending=False)\nplt.figure(figsize=(8,6))\nmarkers = [\n            'd', ' ', '.', '*', 'x', 'o', \n            '3', '4', 's', 'p', ',', 'h', '1', 'H', '+',  \n            'D', '^', '2','v', ' ', '|',  _ \n        ]\ng = sns.pointplot(x= hour , y= salary , hue= finance_stage ,\n                  data=hour_fs, dodage=True, markers=markers, size=7)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u \u5c0f\u65f6 , fontsize=16, fontproperties=font)\nplt.ylabel(u \u62db\u8058\u804c\u4f4d\u6570\u91cf , fontsize=16, fontproperties=font)\nplt.title(u Python\u804c\u4f4d\u62db\u8058\u9700\u6c42 , fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc= best ,prop=font, fontsize=15)  matplotlib.legend.Legend at 0x7fc9639932d0    plt.figure(figsize=(8,6))\ng = sns.pointplot(x=hour_info.index, y=hour_info[ property ], color= indianred , markers= . )\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u \u5c0f\u65f6 , fontsize=16, fontproperties=font)\nplt.ylabel(u \u62db\u8058\u804c\u4f4d\u767e\u5206\u6bd4 % , fontsize=16, fontproperties=font)\nplt.title(u IT\u804c\u4f4d\u62db\u8058\u53d1\u5e03\u65f6\u95f4\u89c4\u5f8b , fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc= best ,prop=font, fontsize=15)   \u4ece24\u5c0f\u65f6\u65f6\u6bb5\u7684\u62db\u8058\u4fe1\u606f\u53d1\u5e03\u91cf\u53ef\u77e5\uff0c\u4e0a\u53489-10\u70b9\u662f\u804c\u4f4d\u53d1\u5e03\u7684\u9ad8\u5cf0\u671f\uff0c\u5176\u6b21\u662f\u4e0b\u534814\u70b9\u3002\u56e0\u6b64\uff0c\u6709\u6c42\u804c\u9700\u6c42\u7684\u4e2a\u4eba\u53ef\u4ee5\u5728\u4e0a\u534811\u70b9\u4e4b\u540e\u67e5\u770b\u62c9\u52fe\u7f51\u7684\u62db\u8058\u4fe1\u606f\u3002", 
            "title": "\u62db\u8058\u804c\u4f4d\u53d1\u5e03\u65f6\u95f4\u89c4\u5f8b"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#hr", 
            "text": "df_login = pd.read_csv( /home/darren/Desktop/lagou_position/scrapy/job_info_201784.csv , encoding= utf-8 )  # \u53bb\u9664\u91cd\u590d\u7684\u62db\u8058\u804c\u4f4d\u4fe1\u606f\ndf_login.drop_duplicates(inplace=True)  d_time = df_login.published_time.str.split(   ).str.get(0)\ndf_login[ day ] = d_time\n# \u9009\u62e9\u62db\u8058\u53d1\u5e03\u65f6\u95f4\u6700\u65b0\u4e00\u5929\u7684\u6570\u636e\uff0c2017-8-4\uff0c\u62162017-8-5\uff0c\u56e0\u4e3a\u91c7\u96c6\u6570\u636e\u6700\u540e\u65f6\u95f4\u662f8\u67085\u65e5\nda = df_login[(df_login.day ==  2017/8/4 ) | (df_login.day ==  2017/8/5 )]  # \u8fdb\u4e00\u6b65\u53bb\u91cd\u6570\u636e\nda_col = da.columns.values.tolist()\nda_col.remove(u published_time )\nrow_duplicated = da[da.duplicated(da_col)].index.values\nda.drop(row_duplicated, inplace=True)\n# last_login\u683c\u5f0f\u6b63\u786e\n# da.to_csv( /home/darren/Desktop/lagou_drop_duplicated1.csv , index=False)  # \u4ee5\u4e0b\u505a\u6cd5\u62a5\u9519 \n# ValueError: timestamp out of range for platform localtime()/gmtime() function\n# last_login_.head(1).map(lambda x: datetime.datetime.utcfromtimestamp(x).strftime( %Y-%m-%d %H:%M:%S ))\n# \u91c7\u7528\u904d\u5386\u4f9d\u65e7\u4e0d\u884c\n# last_login_date = []\n# for i in xrange(len(last_login_)):       \n#     last_login_date.append(datetime.datetime.utcfromtimestamp(last_login_[i]).strftime( %Y-%m-%d %H:%M:%S ) )  # \u6beb\u79d2\u8f6c\u6362\u6210\u79d2\nlast_login_ = da[ last_login ] / 1000\n# \u5317\u4eac\u65f6\u95f42017/8/4 5\u65e5 0:0:0 \u7684\u65f6\u95f4\u6233\u5206\u522b\u4e3a 1501776000 1501862400\n# \u5148\u5224\u65ad\u6700\u540e\u767b\u5f55\u65f6\u95f4\u662f\u5426\u662f8\u67084\u65e5\nlogin_time_l = last_login_[last_login_.values  = 1501776000]\nlogin_time_ = login_time_l[login_time_l  = 1501862400]\n# \u5c06\u4e00\u5929\u767b\u5f55\u65f6\u95f4\u4ece\u79d2\u53d8\u6210\u5c0f\u65f6\nlast_login_s = ((login_time_ - 1501776000) / 3600).map(lambda x: np.int(x))  # \u7edf\u8ba1Hr\u572824\u5c0f\u65f6\u5185\u6700\u540e\u767b\u5f55\u65f6\u95f4\u5206\u5e03\u60c5\u51b5\nlast_login_time = last_login_s.value_counts()  login_property = last_login_time.values / np.float(last_login_time.values.sum()) *100\nplt.figure(figsize=(8,6))\ng = sns.pointplot(x=last_login_time.index, y=login_property, color= purple , markers= * )\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=30)\nplt.xlabel(u \u5c0f\u65f6 , fontsize=16, fontproperties=font)\nplt.ylabel(u \u767e\u5206\u6bd4 % , fontsize=16, fontproperties=font)\nplt.title(u Hr\u767b\u5f55\u65f6\u95f4\u5206\u5e03 , fontproperties=font, fontsize=23)\nplt.gca().yaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc= best ,prop=font, fontsize=15)   Hr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u5206\u5e03\u56fe\u5982\u4e0a\uff0cHr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u96c6\u4e2d\u5728\u4e0b\u5348\uff0c\u5c24\u5176\u662f15-17\u70b9\u4e4b\u95f4\uff0c\u7ed3\u5408\u540c\u4e00\u5929\u7684\u62db\u8058\u4fe1\u606f\u53d1\u5e03\u72b6\u51b5\uff0c\u6295\u9012\u7b80\u5386\u7684\u8f83\u4f73\u65f6\u95f4\u6bb5\u4e3a\u4e0a\u534811\u70b9-\u4e0b\u534813\u70b9\u4e4b\u95f4\u3002", 
            "title": "Hr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u89c4\u5f8b"
        }, 
        {
            "location": "/data_analysis/lagou_job_analysis/lagou_job_analysis_forshow/#_9", 
            "text": "\u5f53\u524d\uff0cIT\u884c\u4e1a\u53d1\u5c55\u5982\u706b\u5982\u837c\uff0c\u4eceIT\u884c\u4e1a\u7684\u5e73\u5747\u85aa\u8d44\u4fbf\u53ef\u7aa5\u4e00\u6591\u3002\u4ece\u5168\u56fd\u8303\u56f4\u770b\uff0cIT\u884c\u4e1a\u53d1\u5c55\u5e76\u4e0d\u5747\u8861\uff0c\u800c\u662f\u96c6\u4e2d\u5728\u4e00\u7ebf\u548c\u4e00\u4e9b\u70ed\u95e8\u7684\u4e8c\u7ebf\u57ce\u5e02\uff0c\u5c24\u5176\u662f\u5317\u4e0a\u6df1\u5e7f\u4ee5\u53ca\u676d\u5dde\uff0c\u5176\u4e2d\u53c8\u4ee5\u5317\u4eac\u6700\u4e3a\u53d1\u8fbe\uff01  \u4ece\u5404\u4e2a\u57ce\u5e02\u7684\u62db\u8058\u804c\u4f4d\u9700\u6c42\u770b\uff0c\u5317\u4eac\u7684\u62db\u8058\u804c\u4f4d\u6700\u591a\uff0c\u4e0a\u6d77\u6b21\u4e4b\uff0c\u4ece\u516c\u53f8\u89c4\u6a21\u770b\u4e2d\u578b\u516c\u53f8\u7684\u62db\u8058\u5bfb\u6c42\u6700\u5927\uff0c\u5927\u578b\u516c\u53f8\u6b21\u4e4b\uff0c\u5c0f\u578b\u516c\u53f8\u7684\u9700\u6c42\u91cf\u8f83\u5c0f\uff1b\u4ece\u85aa\u8d44\u4e0a\u770b\uff0c\u5927\u578b\u516c\u53f8\u7684\u85aa\u8d44\u6700\u9ad8\uff0c\u5176\u6b21\u662f\u4e2d\u578b\u516c\u53f8\uff0c\u5c0f\u516c\u53f8\u6700\u4f4e\uff0c\u56e0\u6b64\uff0cIT\u884c\u4e1a\u7684\u6700\u4f73\u6c42\u804c\u5730\u4e3a\u5317\u4eac\uff0c\u516c\u53f8\u53ef\u9009\u62e9\u4e2d\u578b\u7684\u4e0a\u5e02\u6216\u6210\u719f\u578b\u516c\u53f8\u3002  \u5f53\u7136\uff0c\u8fd9\u4ec5\u4ec5\u662f\u4ece\u804c\u4f4d\u9700\u6c42\u72b6\u51b5\u4e0a\u5206\u6790\uff0c\u5e76\u6ca1\u6709\u7ed3\u5408\u6c42\u804c\u8005\u6570\u91cf\u7b49\u5176\u4ed6\u4fe1\u606f\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8fd9\u90e8\u5206\u6570\u636e\u96be\u91c7\u96c6\uff01  IT\u884c\u4e1a\u804c\u4f4d\u9700\u6c42\u6700\u5927\u7684\u662f\u6280\u672f\u7c7b\uff0c\u85aa\u8d44\u6700\u9ad8\u7684\u662f\u91d1\u878d\u7c7b\uff0c\u5176\u6b21\u662f\u6280\u672f\u7c7b\u3002  \u4ece\u540e\u7aef\u5f00\u53d1\u7684\u5404\u4e2a\u7f16\u7a0b\u8bed\u8a00\u5206\u6790\uff0cJava\u7684\u62db\u8058\u9700\u6c42\u662f\u5904\u4e8e\u9738\u4e3b\u5730\u4f4d\uff0c\u53ea\u662f\u85aa\u8d44\u7565\u4f4e\u3002\u85aa\u8d44\u6700\u9ad8\u7684\u662f\u5404\u79cd\u7b97\u6cd5\u7c7b\uff0c\u5305\u62ec\u6570\u636e\u6316\u6398\u3001\u7cbe\u51c6\u63a8\u8350\u7b49\uff0c\u5176\u6b21\u662f\u4e00\u4e9b\u65b0\u5174\u8bed\u8a00\uff0c\u5982Go\u3001Python\u7b49\u3002  Python\u7684\u62db\u8058\u89c4\u5f8b\u548c\u540e\u7aef\u5f00\u53d1\u662f\u4e00\u81f4\u7684\uff0c\u6574\u4f53\u800c\u8a00\uff0cPython\u7684\u62db\u8058\u9700\u6c42\u603b\u91cf\u4e0d\u591a\uff0c\u4f46\u5e73\u5747\u85aa\u8d44\u8f83\u9ad8\u3002\u62db\u8058\u9700\u6c42\u8f83\u591a\u7684\u662f\u4e00\u7ebf\u57ce\u5e02\u7684\u4e2d\u578b\u516c\u53f8\uff0c\u85aa\u8d44\u4e5f\u6bd4\u8f83\u9ad8\uff0c\u4ec5\u7565\u4f4e\u4e8e\u5927\u578b\u4e0a\u5e02\u516c\u53f8\uff0c\u5b66\u5386\u8981\u6c42\u672c\u79d1\u5c45\u591a\uff0c\u5de5\u4f5c\u7ecf\u9a8c3-5\u548c1-3\u5e74\u8f83\u591a\u3002  python\u62db\u8058\u7684\u5177\u4f53\u5c97\u4f4d\u5206\u5e03\uff0c\u4ee5web\u5f00\u53d1\u5c45\u591a\uff0c\u722c\u866b\u6b21\u4e4b\uff0c\u7531\u4e8e\u6709\u5927\u91cf\u7684\u804c\u4f4d\u6807\u9898\u5e76\u6ca1\u6709\u660e\u786e\u6807\u660e\u5c97\u4f4d\u7684\u5177\u4f53\u540d\u79f0\uff0c\u56e0\u6b64\uff0c\u5177\u4f53\u5c97\u4f4d\u5206\u5e03\u5e76\u4e0d\u51c6\u786e\uff0c\u8fd9\u8fd8\u8981\u7ed3\u5408\u804c\u4f4d\u8be6\u60c5\u9875\u9762\u8fdb\u884c\u5206\u6790\u3002  \u6b64\u5916\uff0c\u6839\u636e\u62db\u8058\u5c97\u4f4d\u63cf\u8ff0\u8bcd\u6c47\u751f\u6210\u7684\u8bcd\u4e91\u56fe\u53ef\u770b\u5230\u51fa\u73b0\u9891\u7387\u6700\u9ad8\u7684\u8bcd\u6c47\u662f\u201c\u57f9\u8bad\u201d\u3001\u201c\u6241\u5e73\u201d\u3001\u201c\u5e73\u53f0\u201d\uff0c\u4f53\u73b0\u51fa\u5f53\u4ecaIT\u884c\u4e1a\u6bd4\u8f83\u6ce8\u91cd\u5458\u5de5\u7684\u57f9\u8bad\u53ca\u6ce8\u91cd\u6241\u5e73\u5316\u7ba1\u7406\u3002  \u5206\u6790\u62db\u8058\u804c\u4f4d\u7684\u53d1\u5e03\u65f6\u95f4\u548cHr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u7684\u6298\u7ebf\u56fe\u53ef\u77e5\uff0c\u804c\u4f4d\u53d1\u5e03\u4e3b\u8981\u96c6\u4e2d\u5728\u4e0a\u53489\u70b9\u5de6\u53f3\uff0c\u800cHr\u6700\u540e\u767b\u5f55\u65f6\u95f4\u96c6\u4e2d\u5728\u4e0b\u534815-17\u70b9\u4e4b\u95f4\uff0c\u56e0\u6b64\uff0c\u4e2a\u4eba\u8ba4\u4e3a\u62c9\u52fe\u7f51\u6295\u9012\u62db\u8058\u7b80\u5386\u7684\u8f83\u4f73\u65f6\u95f4\u4e3a\u4e0a\u534811\u70b9-\u4e0b\u534813\u70b9\u4e4b\u95f4\u3002", 
            "title": "\u603b\u7ed3"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/", 
            "text": "p2p\u7f51\u7ad9\u8dd1\u8def\u5224\u522b\n\n\n\u80cc\u666f\u8bf4\u660e\n\n\n\u8fd1\u51e0\u5e74\uff0cp2p\u7f51\u8d37\u884c\u4e1a\u53d1\u5c55\u7684\u662f\u82e5\u706b\u5982\u837c\uff0c\u800c\u6574\u4e2a\u884c\u4e1a\u7684\u5feb\u901f\u53d1\u5c55\u5374\u63a9\u76d6\u4e0d\u4e86\u5176\u53d1\u5c55\u7684\u4e0d\u89c4\u8303\u6027\u3002P2P\u7f51\u8d37\u6700\u5927\u7684\u4f18\u8d8a\u6027\u662f\u4f7f\u4f20\u7edf\u94f6\u884c\u96be\u4ee5\u8986\u76d6\u7684\u501f\u6b3e\u4eba\u5728\u865a\u62df\u4e16\u754c\u91cc\u80fd\u5145\u5206\u4eab\u53d7\u8d37\u6b3e\u7684\u9ad8\u6548\u4e0e\u4fbf\u6377\u3002\u4f46\u4e0e\u6b64\u540c\u65f6\uff0c\u6574\u4e2a\u884c\u4e1a\u4e5f\u662f\u6ce5\u6c99\u4ff1\u4e0b\uff0c\u826f\u83a0\u4e0d\u9f50\u3002\u4e00\u65b9\u9762P2P\u884c\u4e1a\u4ecd\u7136\u5448\u73b0\u9ad8\u901f\u589e\u957f\u6001\u52bf\uff0c\u53e6\u4e00\u65b9\u9762\u5219\u662f\u5e73\u53f0\u63d0\u73b0\u56f0\u96be\u3001\u5012\u95ed\u3001\u574f\u8d26\u98ce\u6ce2\u4e0d\u65ad\uff0c\u51fa\u73b0\u4e86\u6240\u8c13\u7684p2p\u8dd1\u8def\u73b0\u8c61\u3002\n\u672c\u6587\u4ece\u666e\u901a\u6295\u8d44\u8005\u7684\u89d2\u5ea6\u63a2\u8ba8p2p\u7f51\u8d37\u5e73\u53f0\u8dd1\u8def\u7684\u7f18\u7531\uff0c\u5206\u6790\u7f51\u8d37\u5e73\u53f0\u7684\u5404\u79cd\u6307\u6807\u4e0e\u5e73\u53f0\u7ecf\u8425\u72b6\u6001\u7684\u5173\u8054\uff0c\u5bf9p2p\u7f51\u8d37\u5e73\u53f0\u662f\u5426\u4f1a\u201c\u8dd1\u8def\u201d\u8fdb\u884c\u9884\u6d4b\u3002\n\n\n\u672c\u62a5\u544a\u7684\u6240\u6709\u6570\u636e\u6765\u6e90\u4e8exx\u4e4b\u5bb6\u7684\u6863\u6848\uff0c\u6570\u636e\u622a\u6b62\u65e5\u671f\u4e3a16\u5e7411\u6708\u3002\u4ee5xx\u4e4b\u5bb6\u6863\u6848\u4e2d\u76843800\u591a\u5bb6p2p\u7f51\u8d37\u5e73\u53f0\u4e3a\u6e90\u6570\u636e\uff0c\u9009\u62e9\u4e86\u7f51\u8d37\u5e73\u53f0\u7684\u51e0\u4e2a\u8bc4\u4f30\u6307\u6807\u5982\uff0c\u5e73\u5747\u6536\u76ca\u7387\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u5e73\u53f0\u8d44\u8d28\u3001\u6295\u8d44\u671f\u9650\u3001\u6ce8\u518c\u5730\u7b49\u4e3a\u6837\u672c\u7684\u7279\u5f81\uff0c\u4ee5\u7f51\u8d37\u5e73\u53f0\u7684\u7ecf\u8425\u72b6\u51b5\uff08\u662f\u6b63\u5e38\u8425\u4e1a\u72b6\u6001\u8fd8\u662f\u8dd1\u8def\u7b49\u975e\u6b63\u5e38\u8425\u4e1a\u72b6\u6001\uff09\u4e3a\u5206\u7c7b\u6807\u7b7e\uff0c\u5c1d\u8bd5\u5229\u7528\u673a\u5668\u5b66\u4e60\u7684\u51b3\u7b56\u6811\u5206\u7c7b\u7b97\u6cd5\u8bc4\u4f30\u548c\u9884\u6d4bp2p\u7f51\u8d37\u5e73\u53f0\u7684\u8dd1\u8def\u73b0\u8c61\u3002\n\n\n\u6570\u636e\u91c7\u96c6\u53ca\u6e05\u6d17\n\n\n\u91c7\u7528python\u7684urllib2\u548cbeautifulsoup\u8fdb\u884c\u6570\u636e\u7684\u91c7\u96c6\u548c\u89e3\u6790\uff0c\u91c7\u7528python\u7b2c\u4e09\u65b9\u5e93pandas, numpy\u5bf9\u6570\u636e\u8fdb\u884c\u6e05\u6d17\u5904\u7406\uff0c\u6570\u636e\u91c7\u96c6\u548c\u7b80\u5355\u7684\u5904\u7406\u8fc7\u7a0b\u5728\u6b64\u7565\u8fc7\u3002\n\n\n\u63a2\u7d22\u6027\u5206\u6790\n\n\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\nwhitegrid\n, palette=\nmuted\n, font_scale=1.0, color_codes=True, context=\ntalk\n)\n%matplotlib inline\nimport sys\nfrom matplotlib.ticker import MultipleLocator, FormatStrFormatter\nfrom matplotlib.font_manager import FontProperties  \nfont = FontProperties(fname=r\n/usr/share/fonts/truetype/arphic/ukai.ttc\n)\nreload(sys)\nsys.setdefaultencoding('utf-8')\n\n\n\n\n# \u8f7d\u5165\u6e05\u6d17\u540e\u7684\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u76f8\u5e94\u5904\u7406\ndall = pd.read_table(\n./p2pchanged.txt\n, sep=',')  # (3895, 12) \n\n\n\n\n# \u5404\u7279\u5f81\u5206\u522b\u4e3a\uff1a\nfeature_dict = {\nname\n: u\np2p\u5e73\u53f0\u540d\n, \naverageI\n: u\n\u5e73\u5747\u5e74\u5316\u5229\u7387\n, \n               \ndate\n: u\n\u4e0a\u7ebf\u65e5\u671f\n, \nzhuzed\n: u\n\u6ce8\u518c\u5730\n, \n                \ntouziq\n: u\n\u6295\u8d44\u671f\u9650\n, \nnetF\n: u\n\u7f51\u53cb\u8bc4\u5206\n, \n                \nbackground\n: u\n\u516c\u53f8\u7c7b\u578b\n, \ntuoguan\n: u\n\u8d44\u91d1\u6258\u7ba1\n,\n                \nzhuz\n: u\n\u6ce8\u518c\u8d44\u672c\n, \nshiz\n: u\n\u5b9e\u7f34\u8d44\u672c\n, \n                \ndatetime\n: u\n\u4e0a\u7ebf\u65f6\u95f4\n, \nclassification\n: u\n\u5206\u7c7b\u6807\u7b7e\n\n               }\n\n\n\n\n# \u6570\u636e\u96c6\u524d5\u884c\ndall.head()\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nname\n\n      \naverageI\n\n      \ndate\n\n      \nzhuzed\n\n      \nclassification\n\n      \ntouziq\n\n      \nnetF\n\n      \nbackground\n\n      \ntuoguan\n\n      \nzhuz\n\n      \nshiz\n\n      \ndatetime\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n108\u8d37\n\n      \n14.548392\n\n      \n2015-02-26\n\n      \n44.0\n\n      \n0.0\n\n      \n2.578413\n\n      \n14.351883\n\n      \n0\n\n      \n0\n\n      \n500\n\n      \n0\n\n      \n5.326389e+07\n\n    \n\n    \n\n      \n1\n\n      \n2025\u91d1\u878d\n\n      \n14.548392\n\n      \n2015-11-16\n\n      \n11.0\n\n      \n0.0\n\n      \n2.578413\n\n      \n14.351883\n\n      \n0\n\n      \n0\n\n      \n2000\n\n      \n0\n\n      \n3.054069e+07\n\n    \n\n    \n\n      \n2\n\n      \n51\u5e2e\u4f60\n\n      \n12.460000\n\n      \n2012-08-15\n\n      \n33.0\n\n      \n1.0\n\n      \n1.172000\n\n      \n16.500000\n\n      \n0\n\n      \n1\n\n      \n3000\n\n      \n2000\n\n      \n1.331839e+08\n\n    \n\n    \n\n      \n3\n\n      \n53\u8d22\u670d\n\n      \n14.548392\n\n      \n2016-04-18\n\n      \n33.0\n\n      \n1.0\n\n      \n1.100000\n\n      \n14.351883\n\n      \n0\n\n      \n0\n\n      \n10000\n\n      \n20\n\n      \n1.723509e+07\n\n    \n\n    \n\n      \n4\n\n      \n51\u94b1\u7ba1\u5bb6\n\n      \n12.000000\n\n      \n2015-11-04\n\n      \n50.0\n\n      \n1.0\n\n      \n2.578413\n\n      \n14.000000\n\n      \n0\n\n      \n1\n\n      \n10000\n\n      \n100\n\n      \n3.157749e+07\n\n    \n\n  \n\n\n\n\n\n\n\n\u5e73\u5747\u5e74\u5316\u5229\u7387\n\n\ndall[\naverageI\n] = dall[\naverageI\n].map(lambda x: np.round(x, 4))\ndall.loc[:, \nclassification\n] = dall[\nclassification\n].replace([0,1], [u'\u8dd1\u8def',u'\u6b63\u5e38\u8425\u4e1a'])\ndf = dall.loc[dall[\naverageI\n] != 14.5484, :]\n\n\n\n\nplt.figure(figsize=(8,6))\nfig = sns.distplot(df['averageI'],kde=True, vertical=False, color=\ngreen\n)\nsns.despine(top=True)\nplt.yticks(fig.get_yticks(), fig.get_yticks() * 100)\nplt.ylabel('Distribution [%]', fontsize=16)\nplt.xticks(range(0, 100, 10))\nplt.gca().yaxis.grid(True, linestyle = \n:\n)\nplt.gca().xaxis.grid(True, linestyle = \n-.\n)\nplt.xlabel(u\n\u5e73\u5747\u5e74\u5316\u5229\u7387 %\n, fontsize=16, fontproperties=font)\nplt.title(u\n\u5e73\u5747\u5e74\u5316\u5229\u7387\u7684\u5206\u5e03\n, fontsize=20, fontproperties=font)\n\n\n\n\nmatplotlib.text.Text at 0x7fe3af9f8a10\n\n\n\n\n\n\n# \u6839\u636e\u8dd1\u8def\u4e0e\u5426\u8fdb\u884c\u5206\u7ec4\u5f97\u5230\u4e86\u5e73\u5747\u5229\u7387\u7684\u5206\u7ec4\u5bf9\u8c61\nrate_cont = df.groupby([\nclassification\n])[\naverageI\n]  \n\n\n\n\nfig, ax1 = plt.subplots(figsize=(8,6))\nrate_cont.plot(kind='kde',ax=ax1, style='--', linewidth=2.5)\nrate_cont.plot(kind='hist',ax=ax1, normed=True, alpha=0.8,)\nax1.legend(loc='best', prop=font, fontsize=17)\nax1.set_ylabel('Frequency', fontsize=16)\nax1.set_xlim(-1, 95)\nax1.text(14.0, 0.115,s=u'\u6b63\u5e38\u8425\u4e1a\u5e73\u53f0\u5e73\u5747\u6536\u76ca\u7387 12.88%', fontsize=12,va=\nbottom\n,ha=\nleft\n,fontproperties=font,color='blue') \nax1.text(20.0, 0.09,s=u'\u8dd1\u8def\u5e73\u53f0\u5e73\u5747\u6536\u76ca\u7387 18.56%', fontsize=12,va=\nbottom\n,ha=\nleft\n,fontproperties=font,color='green')\nax1.annotate('',xy=(12.18,0.109),xytext=(14,0.115),arrowprops=dict(arrowstyle=\n-\n,color='blue')) \nax1.annotate('',xy=(17.9,0.08),xytext=(20,0.09),arrowprops=dict(arrowstyle=\n-\n,color='green'))\nplt.xlabel(u\n\u5e73\u5747\u5e74\u5316\u5229\u7387 %\n, fontsize=16, fontproperties=font)\nplt.title(u\np2p\u5e73\u53f0\u8dd1\u8def\u4e0e\u5426\u4e0e\u5e73\u5747\u6536\u76ca\u7387\n, fontsize=20, fontproperties=font)\nplt.yticks(ax1.get_yticks(), ax1.get_yticks() * 100)\nplt.ylabel('Distribution [%]', fontsize=16)\nplt.xticks(range(0, 100, 10))\nplt.gca().yaxis.grid(True, linestyle = \n:\n)\nplt.gca().xaxis.grid(True, linestyle = \n-.\n)\n\n\n\n\n\n\np2p\u7f51\u8d37\u5e73\u53f0\u7684\u5e73\u5747\u5e74\u5316\u6536\u76ca\u7387\u5206\u5e03\u5f88\u5e7f\uff0c\u4ece\u6700\u4f4e\u76844%\u5230\u6700\u9ad8\u768490%\u5747\u6709\uff0c\u5176\u4e2d\u6b63\u5e38\u8425\u4e1a\u7684p2p\u5e73\u53f0\u4e3b\u8981\u5206\u5e03\u57285-20%, \u800c\u8dd1\u8def\u5e73\u53f0\u4e3b\u8981\u5206\u5e03\u57288-30%\u4e4b\u95f4\u3002\u6b63\u5e38\u8425\u4e1a\u7684p2p\u5e73\u53f0\u7684\u5e73\u5747\u6536\u76ca\u7387\u4e3a12.88%\uff0c\u8dd1\u8def\u5e73\u53f0\u7684\u5e73\u5747\u6536\u76ca\u7387\u662f18.56%\u3002\n\n\n\u5730\u57df\u5206\u5e03\n\n\n# \u8f7d\u5165\u5730\u533a\u7f16\u53f7\uff0c\u517130\u4e2a\u7701\nplaces = pd.read_table(\n./regis_place.txt\n, sep=',', header=None)  # (30,2) \nplaces.columns =[\nnumber_pro\n, \nname_pro\n]\n\n\n\n\ndf_set = set(df[\nzhuzed\n].astype(np.int).values)\nplaces_set = set(places[\nnumber_pro\n])\nplaces_set ^ df_set\n\n\n\n\n{54, 63}\n\n\n\np1 = places.loc[places[\nnumber_pro\n] != 54, :]\np_sub = p1.loc[p1[\nnumber_pro\n] != 63, :][\nname_pro\n]\np_sub.shape\n\n\n\n\n(29,)\n\n\n\n# \u6839\u636e\u6ce8\u518c\u5730\u8fdb\u884c\u5206\u7ec4\npro_groupby = df.groupby(\nzhuzed\n)[\naverageI\n].aggregate([np.size, np.mean]).reset_index()\npro_name = pro_groupby[\nzhuzed\n].replace(pro_groupby[\nzhuzed\n].values, p_sub)\npro_groupby[\npro_name\n] = pro_name.map(lambda x: x.strip())\npro_groupby.sort_values(\nsize\n, ascending=False, inplace=True)\npro_groupby.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nzhuzed\n\n      \nsize\n\n      \nmean\n\n      \npro_name\n\n    \n\n  \n\n  \n\n    \n\n      \n18\n\n      \n44.0\n\n      \n479.0\n\n      \n14.446493\n\n      \n\u5e7f\u4e1c\n\n    \n\n    \n\n      \n0\n\n      \n11.0\n\n      \n335.0\n\n      \n11.644448\n\n      \n\u5317\u4eac\n\n    \n\n    \n\n      \n8\n\n      \n31.0\n\n      \n246.0\n\n      \n12.214431\n\n      \n\u4e0a\u6d77\n\n    \n\n  \n\n\n\n\n\n\n\nfig, ax1 = plt.subplots(figsize=(10,7))\ng = sns.barplot(y=\nsize\n, x=\npro_name\n, data=pro_groupby, palette=\nPuBu_d\n, ax=ax1)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=75)\n# g=sns.factorplot(y=\nzhuzed\n, data=df, kind='count', size=6, color=\nindianred\n)\nax2 = ax1.twinx()\nx_list = range(len(pro_groupby))\nax2.plot(x_list, pro_groupby[\nmean\n], linewidth = 3, color=\nskyblue\n, marker=\no\n, label=u\n\u804c\u4f4d\u9700\u6c42\u91cf\n) \nax2.set_ylabel(u\n\u5e73\u5747\u5e74\u5316\u5229\u7387 %\n, fontsize=16, fontproperties=font)\nax1.set_ylabel(u\n\u6570\u91cf\n, fontsize=16, fontproperties=font)\nax2.set_ylim(4, 20)\nax2.yaxis.grid(True, linestyle = \n:\n,)\nax1.yaxis.grid(False)\nplt.title(u\n\u5168\u56fd\u5404\u5730\u533ap2p\u7f51\u8d37\u5e73\u53f0\u6570\u91cf\u53ca\u5e73\u5747\u5e74\u5316\u5229\u7387\n, fontproperties=font, fontsize=20)\n\n\n\n\n\n\n# \u6839\u636e\u6ce8\u518c\u5730\u548c\u8dd1\u8def\u4e0e\u5426\u7684\u5206\u7c7b\u6807\u7b7e\u8fdb\u884c\u5206\u7ec4\npro_cla = df.groupby([\nzhuzed\n, \nclassification\n])[\naverageI\n].aggregate([np.size, np.mean]).reset_index()\npro_name = pro_cla[\nzhuzed\n].replace(pro_cla[\nzhuzed\n].unique(), p_sub)\npro_cla[\npro_name\n] = pro_name.map(lambda x: x.strip())\n\n\n\n\nfor i in pro_cla[\nzhuzed\n].unique():\n    total_ = pro_cla.loc[pro_cla[\nzhuzed\n] == i, \nsize\n].sum()\n    temp = pro_cla.loc[pro_cla[\nzhuzed\n] == i, \nsize\n] / total_ * 100\n    pro_cla.loc[pro_cla[\nzhuzed\n] == i, \nproperty\n] = temp\n    pro_cla.loc[pro_cla[\nzhuzed\n] == i, \ntotal_num\n] = total_   \n\n\n\n\npro_cla.sort_values([\ntotal_num\n, \nclassification\n], ascending=False, inplace=True)\npro_cla.head(15)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nzhuzed\n\n      \nclassification\n\n      \nsize\n\n      \nmean\n\n      \npro_name\n\n      \nproperty\n\n      \ntotal_num\n\n    \n\n  \n\n  \n\n    \n\n      \n37\n\n      \n44.0\n\n      \n\u8dd1\u8def\n\n      \n149.0\n\n      \n17.667383\n\n      \n\u5e7f\u4e1c\n\n      \n31.106472\n\n      \n479.0\n\n    \n\n    \n\n      \n36\n\n      \n44.0\n\n      \n\u6b63\u5e38\u8425\u4e1a\n\n      \n330.0\n\n      \n12.992212\n\n      \n\u5e7f\u4e1c\n\n      \n68.893528\n\n      \n479.0\n\n    \n\n    \n\n      \n1\n\n      \n11.0\n\n      \n\u8dd1\u8def\n\n      \n57.0\n\n      \n13.858772\n\n      \n\u5317\u4eac\n\n      \n17.014925\n\n      \n335.0\n\n    \n\n    \n\n      \n0\n\n      \n11.0\n\n      \n\u6b63\u5e38\u8425\u4e1a\n\n      \n278.0\n\n      \n11.190432\n\n      \n\u5317\u4eac\n\n      \n82.985075\n\n      \n335.0\n\n    \n\n    \n\n      \n17\n\n      \n31.0\n\n      \n\u8dd1\u8def\n\n      \n54.0\n\n      \n16.403704\n\n      \n\u4e0a\u6d77\n\n      \n21.951220\n\n      \n246.0\n\n    \n\n    \n\n      \n16\n\n      \n31.0\n\n      \n\u6b63\u5e38\u8425\u4e1a\n\n      \n192.0\n\n      \n11.036198\n\n      \n\u4e0a\u6d77\n\n      \n78.048780\n\n      \n246.0\n\n    \n\n    \n\n      \n21\n\n      \n33.0\n\n      \n\u8dd1\u8def\n\n      \n42.0\n\n      \n22.031429\n\n      \n\u6d59\u6c5f\n\n      \n23.204420\n\n      \n181.0\n\n    \n\n    \n\n      \n20\n\n      \n33.0\n\n      \n\u6b63\u5e38\u8425\u4e1a\n\n      \n139.0\n\n      \n13.863022\n\n      \n\u6d59\u6c5f\n\n      \n76.795580\n\n      \n181.0\n\n    \n\n    \n\n      \n29\n\n      \n37.0\n\n      \n\u8dd1\u8def\n\n      \n92.0\n\n      \n21.970326\n\n      \n\u5c71\u4e1c\n\n      \n57.142857\n\n      \n161.0\n\n    \n\n    \n\n      \n28\n\n      \n37.0\n\n      \n\u6b63\u5e38\u8425\u4e1a\n\n      \n69.0\n\n      \n15.144058\n\n      \n\u5c71\u4e1c\n\n      \n42.857143\n\n      \n161.0\n\n    \n\n    \n\n      \n33\n\n      \n42.0\n\n      \n\u8dd1\u8def\n\n      \n30.0\n\n      \n17.895000\n\n      \n\u6e56\u5317\n\n      \n31.578947\n\n      \n95.0\n\n    \n\n    \n\n      \n32\n\n      \n42.0\n\n      \n\u6b63\u5e38\u8425\u4e1a\n\n      \n65.0\n\n      \n13.785231\n\n      \n\u6e56\u5317\n\n      \n68.421053\n\n      \n95.0\n\n    \n\n    \n\n      \n23\n\n      \n34.0\n\n      \n\u8dd1\u8def\n\n      \n27.0\n\n      \n18.066667\n\n      \n\u5b89\u5fbd\n\n      \n36.486486\n\n      \n74.0\n\n    \n\n    \n\n      \n22\n\n      \n34.0\n\n      \n\u6b63\u5e38\u8425\u4e1a\n\n      \n47.0\n\n      \n13.342553\n\n      \n\u5b89\u5fbd\n\n      \n63.513514\n\n      \n74.0\n\n    \n\n    \n\n      \n19\n\n      \n32.0\n\n      \n\u8dd1\u8def\n\n      \n18.0\n\n      \n21.010556\n\n      \n\u6c5f\u82cf\n\n      \n25.714286\n\n      \n70.0\n\n    \n\n  \n\n\n\n\n\n\n\nplt.figure(figsize=(7, 12))\ng=sns.barplot(y=\npro_name\n, x=\nsize\n, data=pro_cla, hue=\nclassification\n)\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.ylabel(\n)\nplt.xlabel(u\n\u6570\u91cf\n, fontsize=16, fontproperties=font)\nplt.title(u\np2p\u7f51\u8d37\u5e73\u53f0\u5730\u533a\u5206\u5e03\n, fontproperties=font, fontsize=20)\nplt.gca().xaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=7,prop=font, fontsize=12)\nplt.annotate(u\n\u5c71\u4e1c\u5730\u533ap2p\u8dd1\u8def\u6bd4\u4f8b\u6700\u9ad8\u8fbe57%\n, xy = (80, 4), xytext = (100, 6), fontproperties=font, fontsize=15, arrowprops = dict(facecolor='purple'))\n\n\n\n\nmatplotlib.text.Annotation at 0x7fe3a13a9110\n\n\n\n\n\n\n\u5168\u56fdp2p\u5e73\u53f0\u7684\u6570\u91cf\u4f4d\u5c45\u524d\u4e09\u7684\u7701\u4efd\uff08\u5e02\uff09\u662f\u5e7f\u4e1c\u3001\u5317\u4eac\u3001\u4e0a\u6d77\uff0c\u8dd1\u8def\u5e73\u53f0\u6bd4\u4f8b\u6700\u9ad8\u7684\u662f\u5c71\u4e1c\uff0c\u8d85\u8fc7\u4e00\u534a\u7684p2p\u7f51\u8d37\u5e73\u53f0\u51fa\u73b0\u8dd1\u8def\u6216\u5176\u4ed6\u975e\u6b63\u5e38\u8425\u4e1a\u73b0\u8c61\u3002\n\n\np2p\u7f51\u8d37\u6210\u7acb\u65f6\u95f4\n\n\n# \u5c06\u65f6\u95f4str\u8f6c\u6210datetime\ndf['date'] = pd.to_datetime(df['date'])\n# \u5c06\u8f6c\u6362\u597d\u7684\u65f6\u95f4series\u8bbe\u7f6e\u6210\u884c\u7d22\u5f15\ndt = df.set_index(\ndate\n)\ndt[\nyear_\n] = dt.index.year\ndt[\nmonth\n] = dt.index.month\nyear_groupby = dt.groupby(\nyear_\n)[\naverageI\n].aggregate([np.size, np.mean, np.median])\nyear_groupby.drop(year_groupby.index[0], inplace=True)\nyear_groupby.reset_index(inplace=True)\n\n\n\n\nmonth_groupby = dt.groupby(\nmonth\n)[\naverageI\n].aggregate([np.size, np.mean, np.median])\nmonth_groupby.drop(month_groupby.index[0], inplace=True)\nmonth_groupby.reset_index(inplace=True)\nmonth_groupby\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nmonth\n\n      \nsize\n\n      \nmean\n\n      \nmedian\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n2\n\n      \n97.0\n\n      \n13.900103\n\n      \n12.600\n\n    \n\n    \n\n      \n1\n\n      \n3\n\n      \n202.0\n\n      \n14.094703\n\n      \n13.295\n\n    \n\n    \n\n      \n2\n\n      \n4\n\n      \n191.0\n\n      \n13.716649\n\n      \n13.000\n\n    \n\n    \n\n      \n3\n\n      \n5\n\n      \n171.0\n\n      \n14.180819\n\n      \n12.790\n\n    \n\n    \n\n      \n4\n\n      \n6\n\n      \n180.0\n\n      \n14.210944\n\n      \n13.000\n\n    \n\n    \n\n      \n5\n\n      \n7\n\n      \n193.0\n\n      \n14.886114\n\n      \n13.500\n\n    \n\n    \n\n      \n6\n\n      \n8\n\n      \n186.0\n\n      \n15.527688\n\n      \n14.000\n\n    \n\n    \n\n      \n7\n\n      \n9\n\n      \n194.0\n\n      \n14.236392\n\n      \n13.195\n\n    \n\n    \n\n      \n8\n\n      \n10\n\n      \n171.0\n\n      \n15.033860\n\n      \n14.000\n\n    \n\n    \n\n      \n9\n\n      \n11\n\n      \n200.0\n\n      \n15.484450\n\n      \n14.300\n\n    \n\n    \n\n      \n10\n\n      \n12\n\n      \n239.0\n\n      \n13.877448\n\n      \n13.440\n\n    \n\n  \n\n\n\n\n\n\n\np2p_date_dict = {\nyear_\n: u\n\u5e74\u4efd\n, \nmonth\n: u\n\u6708\u4efd\n}\n\n\n\n\ndef p2p_date_plot(dt, groupby_item):\n    data = dt.groupby(groupby_item)[\naverageI\n].aggregate([np.size, np.mean, np.median])\n    data.drop(data.index[0], inplace=True)\n    data.reset_index(inplace=True)  \n    fig, ax1 = plt.subplots(figsize=(8,6))\n    g = sns.barplot(y=\nsize\n, x=groupby_item, data=data, palette=\nBuGn_d\n, ax=ax1)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=60)\n    ax2 = ax1.twinx()\n    x_list = range(len(data))\n    ax2.plot(x_list, data[\nmean\n], linewidth = 3, color=\ndarkgreen\n, marker=\no\n, label=u\n\u5229\u7387\n) \n    ax2.set_ylabel(u\n\u5e73\u5747\u5e74\u5316\u5229\u7387 %\n, fontsize=16, fontproperties=font)\n    ax1.set_ylabel(u\n\u6570\u91cf\n, fontsize=16, fontproperties=font)\n    ax1.set_xlabel(\n)\n    ax2.yaxis.grid(True, linestyle = \n:\n, linewidth=2, color=\ngreen\n, alpha=0.2)\n    ax1.yaxis.grid(False)\n    if groupby_item == \nmonth\n:\n        ax2.set_ylim(10, 18) \n        # ax2.axhline(y=14.7,linewidth=2, xmin=0.5, xmax=0.8, color='r')        \n        # \u5e73\u884cx\u8f74\u7684\u77e9\u5f62\uff0c\u53c2\u6570\uff1aymin,ymax,xmin=0,xmin=1        \n        ax2.axhspan(14.7, 15.7, 0.49, 0.6, facecolor=\nskyblue\n, alpha=0.8)\n        ax2.axhspan(14.7, 15.7, 0.74, 0.85, facecolor=\nskyblue\n, alpha=0.8)\n        plt.annotate(\n, xy = (8.1, 15.7), xytext = (7.5, 16.7), fontproperties=font, fontsize=15, arrowprops = dict(facecolor='skyblue'))        \n        plt.annotate(\n, xy = (5, 15.7), xytext = (7, 16.7), fontproperties=font, fontsize=15, arrowprops = dict(facecolor='skyblue'))        \n    plt.title(u\np2p\u7f51\u8d37\u5e73\u53f0\u6570\u91cf\u53ca\u5e73\u5747\u5e74\u5316\u5229\u7387\u4e0e\u6210\u7acb{}\n.format(p2p_date_dict.get(groupby_item)), fontproperties=font, fontsize=20)\n    plt.legend(loc=\nbest\n,prop=font, fontsize=17)\n\n\n\n\nfor i in p2p_date_dict:   \n    p2p_date_plot(dt, i)\n\n\n\n\n\n\n\n\n\u7edf\u8ba1\u6570\u636e\u663e\u793a\u6211\u56fd\u6700\u65e9\u7684p2p\u7f51\u8d37\u5e73\u53f0\u6210\u7acb\u4e8e2004\u5e744\u6708\uff0c\u622a\u6b62\u523016\u5e7411\u6708\u521d\uff0c\u5168\u56fd\u6ce8\u518c\u6210\u7acb\u4e86\u8fd14000\u5bb6p2p\u7f51\u8d37\u5e73\u53f0\u3002\u6211\u56fd\u7684p2p\u7f51\u8d37\u884c\u4e1a\u57282013\u5e74\u8fdb\u884c\u9ad8\u901f\u53d1\u5c55\u671f\uff0c\u52302014\u5e74\u5e95\u53ca2015\u5e74\u521d\u5230\u8fbe\u9876\u5cf0\uff0c\u968f\u540e\u589e\u901f\u653e\u6162\u3002\n\n\n\u4ece\u5e73\u5747\u5229\u7387\u4e0a\u770b\uff0c2013\u5e74\u8fbe\u5230\u6700\u5927\u503c\uff0c\u968f\u540e\u6025\u5267\u964d\u4f4e;\u4ece\u5229\u7387\u4e0e\u6708\u4efd\u7684\u5173\u7cfb\u53ef\u770b\u51fa\uff0c7-8\u300110-11\u6708\u4efd\u7684\u5e73\u5747\u5229\u7387\u9ad8\u4e8e\u5176\u4ed6\u6708\u4efd\uff0c\u96be\u9053\u8ddf\u5e02\u573a\u6d41\u52a8\u8d44\u91d1\u7d27\u7f3a\u7a0b\u5ea6\u76f8\u5173\uff1f\n\n\n\u8d44\u91d1\u6258\u7ba1\n\n\nfig, ax = plt.subplots(figsize=(8,6))\nsns.barplot(x=\ntuoguan\n, y=\naverageI\n, hue=\nclassification\n, hue_order=[u\n\u8dd1\u8def\n, u\n\u6b63\u5e38\u8425\u4e1a\n], data=df, palette=\nhusl\n, ax=ax)\nax.set_xticklabels([u\n\u65e0\u6258\u7ba1\n, u\n\u6258\u7ba1\n], fontproperties=font, fontsize=16)\nax2 = ax.twinx()\n# \u6258\u7ba1\u72b6\u51b5\u767e\u5206\u6bd4\ndft = df[\ntuoguan\n].value_counts() / df.shape[0] * 100\nax2.plot([0,1], dft.values, linewidth = 1, color=\nb\n, marker=\n*\n, markersize=20, label=u\n\u767e\u5206\u6bd4%\n) \nax.set_ylabel(u\n\u5e73\u5747\u5e74\u5316\u5229\u7387%\n, fontsize=16, fontproperties=font)\nax2.set_ylabel(u\n\u767e\u5206\u6bd4%\n, fontsize=16, fontproperties=font)\nax.yaxis.grid(True, linestyle = \n-.\n,)\nax2.yaxis.grid(False)\nax.legend(loc=9,prop=font, fontsize=17)\nax2.legend(loc=1,prop=font, fontsize=17)\nax.set_xlabel(\n)\nplt.title(u\np2p\u5e73\u53f0\u8d44\u91d1\u6258\u7ba1\u72b6\u51b5\n, fontproperties=font, fontsize=20)\n\n\n\n\nmatplotlib.text.Text at 0x7fe397039310\n\n\n\n\n\n\n\u53ea\u6709\u7ea645%\u7684\u7f51\u8d37\u5e73\u53f0\u8fdb\u884c\u4e86\u8d44\u91d1\u6258\u7ba1\uff0c\u8fdb\u884c\u8d44\u91d1\u6258\u7ba1\u7684p2p\u7f51\u8d37\u5e73\u53f0\u7684\u5e73\u5747\u5229\u7387\u4f4e\u4e8e\u672a\u8fdb\u884c\u8d44\u91d1\u6258\u7ba1\u7684\u5e73\u53f0\uff0c\u8dd1\u8def\u6216\u51fa\u73b0\u5176\u4ed6\u7ecf\u8425\u72b6\u51b5\u7684\u5e73\u5747\u5229\u7387\u5747\u9ad8\u4e8e\u6b63\u5e38\u8425\u4e1a\u7684\u5e73\u53f0\u3002\n\n\n\u7f51\u53cb\u8bc4\u5206\n\n\ndf[\nnet_score\n] = df[\nnetF\n].astype(np.int)\nnet_friend_score = df.groupby(\nclassification\n)[\nnet_score\n].value_counts().unstack().unstack().unstack().fillna(0)\nnet_friend_score[\ntotal\n] = net_friend_score.sum(axis=1)\nnet_friend_score_cum = net_friend_score.div(net_friend_score[\ntotal\n], axis=0)*100\nnet_friend_score_cum.drop(\ntotal\n, axis=1, inplace=True)\nnet_friend_score.drop(\ntotal\n, axis=1, inplace=True)\nfig1, (ax1, ax2) = plt.subplots(2,1, sharex=True, figsize=(12,9)) \nnet_friend_score_cum.plot(kind='bar',ax=ax1, stacked=True, label=\n)\nnet_friend_score.plot(kind='bar',ax=ax2, stacked=True)\nax1.legend(loc=1, prop=font, fontsize=17)\nax2.legend(loc='best', prop=font, fontsize=17)\nax2.xaxis.grid(False)\nax2.yaxis.grid(True, linestyle=\n-.\n)\nax1.yaxis.grid(True, linestyle=\n-.\n)\nax2.set_ylabel(u\n\u6570\u91cf\n, fontsize=16, fontproperties=font)\nax1.set_ylabel(u\n\u767e\u5206\u6bd4%\n, fontsize=16, fontproperties=font)\nax2.annotate(\n5\n, xy = (1, 10), xytext = (2.5, 160), fontproperties=font, fontsize=15, arrowprops = dict(facecolor=\nm\n))        \nax1.annotate(u\n\u603b\u6570\u4e3a5\n, xy = (1, 76), xytext = (1.5,60), fontproperties=font, fontsize=15, arrowprops = dict(facecolor=\nm\n))        \nplt.xlabel(u\n\u7f51\u53cb\u8bc4\u5206\n, fontproperties=font, fontsize=17)\n\n\n\n\nmatplotlib.text.Text at 0x7fe3912ed850\n\n\n\n\n\n\n\u7f51\u53cb\u8bc4\u5206\u680f\u5305\u62ec\u56db\u9879\uff0c\u6bcf\u9879\u8bb05\u5206\uff0c\u6ee1\u5206\u603b\u517120\u5206\u3002\u5728\u6570\u636e\u5904\u7406\u65f6\u5c06\u6bcf\u4e00\u8bc4\u5206\u9879\u76ee\u7684\u65e0\u8bc4\u5206\u7684\u6216\u5c0f\u4e8e1.0\u5206\u7684\u7edf\u7edf\u8bb0\u4e3a1.0\u5206\uff0c\u56e0\u6b64\uff0c\u6700\u4f4e\u5206\u4e3a4.0\u5206\uff0c\u6700\u9ad8\u4e3a20\u5206\u3002\u6839\u636e\u76f8\u5bf9\u7d2f\u8ba1\u67f1\u72b6\u56fe\uff0c\u7f51\u53cb\u8bc4\u5206\u8f83\u9ad8\u7684\u7f51\u8d37\u5e73\u53f0\u51fa\u73b0\u8dd1\u8def\u7684\u6bd4\u4f8b\u8f83\u4f4e\u3002\u7531\u4e8e5\u5206\u7684\u5e73\u53f0\u6570\u91cf\u53ea\u67095\u5bb6\uff0c\u9020\u6210\u767e\u5206\u6570\u504f\u79bb\u8f83\u5927\u3002\n\n\np2p\u7f51\u8d37\u5e73\u53f0\u80cc\u666f\n\n\nbackground = df.groupby(\nclassification\n)[\nbackground\n].value_counts().unstack().unstack().unstack().fillna(0)\n# [0,1,2,3],[u'\u79c1\u8425\n\u6c11\u8425\u7cfb',u'\u4e0a\u5e02\u516c\u53f8\u7cfb',u'\u94f6\u884c\u7cfb',u'\u56fd\u8d44\u7cfb']\nbackground[\ntotal\n] = background.sum(axis=1)\nbackground_cum = background.div(background[\ntotal\n], axis=0)*100\nbackground_cum.drop(\ntotal\n, axis=1, inplace=True)\nbackground.drop(\ntotal\n, axis=1, inplace=True)\nfig1, (ax1, ax2) = plt.subplots(2,1, sharex=True, figsize=(12,9)) \nbackground_cum.plot(kind='bar',ax=ax1, stacked=True, label=\n)\nbackground.plot(kind='bar',ax=ax2, stacked=True)\nax1.legend(loc=9, prop=font, fontsize=17)\nax2.legend(loc='best', prop=font, fontsize=17)\nax2.xaxis.grid(False)\nax2.yaxis.grid(True, linestyle=\n-.\n)\nax1.yaxis.grid(True, linestyle=\n-.\n)\nax2.set_ylabel(u\n\u6570\u91cf\n, fontsize=16, fontproperties=font)\nax1.set_ylabel(u\n\u767e\u5206\u6bd4%\n, fontsize=16, fontproperties=font)\nax2.set_xticklabels([u'\u79c1\u8425\n\u6c11\u8425\u7cfb',u'\u4e0a\u5e02\u516c\u53f8\u7cfb',u'\u94f6\u884c\u7cfb',u'\u56fd\u8d44\u7cfb'], rotation=30, fontproperties=font)\nax2.annotate(u'\u63d0\u73b0\u56f0\u96be1\u5bb6',xy=(3,150),xytext=(2.5,300),fontproperties=font,arrowprops=dict(arrowstyle=\n-\n,color='green',linewidth=3)) \nplt.xlabel(u\n\u5e73\u53f0\u8d44\u8d28\n, fontproperties=font, fontsize=17)\n\n\n\n\nmatplotlib.text.Text at 0x7f14b5933510\n\n\n\n\n\n\np2p\u5e73\u53f0\u8d44\u8d28\uff08\u5e73\u53f0\u80cc\u666f\uff09\u5212\u5206\u4e3a\u6c11\u8425\n\u79c1\u8425\u7cfb\u3001\u4e0a\u5e02\u516c\u53f8\u7cfb\u3001\u94f6\u884c\u7cfb\u3001\u56fd\u8d44\u7cfb\uff0c\u5176\u4e2d\u6c11\u8425\u7cfb\u7f51\u8d37\u8dd1\u8def\u6bd4\u4f8b\u6700\u9ad8\uff0c\u56fd\u8d44\u7cfb\u6709\u63d0\u73b0\u56f0\u96be1\u5bb6\uff0c\u4e0a\u5e02\u516c\u53f8\u548c\u94f6\u884c\u7cfb\u65e0\u8dd1\u8def\u3002\n\n\n\u6295\u8d44\u671f\u9650\n\n\ndf.loc[:, \ntouziq\n] = df[\ntouziq\n].map(lambda x: np.round(x, 4))\ndf_span = df.loc[df[\ntouziq\n] != 2.5784, :]  # (1524, 12)\ndf_span.loc[:, \ntouziq\n] = df_span[\ntouziq\n].map(lambda x: np.round(x))\ndf_span.loc[df_span[\ntouziq\n] == 0, \ntouziq\n] = 0.5\ndf_span.loc[:, \ntouziq\n] = df_span['touziq'].astype(np.int64)\n\n\n\n\nplt.figure(figsize=(10,6))\ng = sns.barplot(x=\ntouziq\n, y=\naverageI\n, data=df_span, hue=\nclassification\n)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\nplt.ylabel(u\n\u5e73\u5747\u5e74\u5316\u5229\u7387%\n, fontsize=16, fontproperties=font)\nplt.xlabel(u\n\u6295\u8d44\u671f\u9650(\u6708)\n, fontsize=16, fontproperties=font)\nplt.title(u\np2p\u5e73\u53f0\u5e73\u5747\u5e74\u5316\u5229\u7387\u4e0e\u6295\u8d44\u671f\u9650\n, fontproperties=font, fontsize=20)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=\nbest\n,prop=font, fontsize=17)\n\n\n\n\nmatplotlib.legend.Legend at 0x7f14b2acf0d0\n\n\n\n\n\n\nspan = df_span.groupby(\nclassification\n)[\ntouziq\n].value_counts().unstack().unstack().unstack().fillna(0)\nspan[\ntotal\n] = span.sum(axis=1)\nspan_cum = span.div(span[\ntotal\n], axis=0)*100\nspan_cum.drop(\ntotal\n, axis=1, inplace=True)\nspan.drop(\ntotal\n, axis=1, inplace=True)\nfig1, (ax1, ax2) = plt.subplots(2,1, sharex=True, figsize=(12,9)) \nspan_cum.plot(kind='bar',ax=ax1, stacked=True, label=\n)\nspan.plot(kind='bar',ax=ax2, stacked=True)\nax1.legend(loc=2, prop=font, fontsize=17)\nax2.legend(loc='best', prop=font, fontsize=17)\nax2.xaxis.grid(False)\nax2.yaxis.grid(True, linestyle=\n-.\n)\nax1.yaxis.grid(True, linestyle=\n-.\n)\nax2.set_ylabel(u\n\u6570\u91cf\n, fontsize=16, fontproperties=font)\nax1.set_ylabel(u\n\u767e\u5206\u6bd4%\n, fontsize=16, fontproperties=font) \nax2.annotate(u'\u5c0f\u4e8e1\u4e2a\u6708',xy=(0,30),xytext=(0,100),fontproperties=font,arrowprops=dict(arrowstyle=\n-\n,color='k',linewidth=3)) \nplt.xlabel(u\n\u6295\u8d44\u671f\u9650(\u6708)\n, fontproperties=font, fontsize=17)\n\n\n\n\nmatplotlib.text.Text at 0x7f14b0e47550\n\n\n\n\n\n\np2p\u7f51\u8d37\u7684\u6295\u8d44\u671f\u9650\u53d8\u5316\u8303\u56f4\u5f88\u5bbd\u6cdb\uff0c\u5c11\u7684\u77ed\u5219\u51e0\u5929\uff0c\u591a\u7684\u957f\u8fbe\u51e0\u5e74\u3002\u4e3a\u4e86\u65b9\u4fbf\uff0c\u5c06\u79d2\u6807\u3001\u5929\u6807\u7b49\u5c0f\u4e8e1\u4e2a\u6708\u7684\u7f51\u8d37\u5e73\u53f0\u8bb0\u4e3a\u5c0f\u4e8e1\u4e2a\u6708(0)\uff0c\u5c06\u5927\u4e8e\u7b49\u4e8e24\u4e2a\u6708\u7684\u5e73\u53f0\u8bb0\u4e3a24\u4e2a\u6708\u3002\u5927\u90e8\u5206\u7f51\u8d37\u5e73\u53f0\u7684\u6295\u8d44\u671f\u9650\u5c0f\u4e8e\u534a\u5e74\uff0c\u5c24\u5176\u96c6\u4e2d\u57281\u6708\u30012\u6708\u30013\u6708\u6807\u53ca\u5929\u6807\u4e0a\u3002\u800c\u8dd1\u8def\u7684\u7f51\u8d37\u5e73\u53f0\u4e5f\u591a\u96c6\u4e2d\u5728\u77ed\u671f\u6295\u8d44\u4e0a\u3002\u4e00\u5e74\u4ee5\u4e0a\u7684\u6295\u8d44\u671f\u9650\u7684\u5e73\u53f0\u6ca1\u6709\u8dd1\u8def\u73b0\u8c61\u3002\u56e0\u6b64\uff0c\u5728\u9009\u62e9p2p\u5e73\u53f0\u65f6\uff0c\u8981\u9009\u62e9\u6295\u8d44\u671f\u9650\u957f\u7684\u4e3a\u5b9c\u3002\n\n\np2p\u8dd1\u8def\u539f\u56e0\u5206\u6790\u53ca\u9884\u6d4b\n\n\n\u901a\u8fc7\u524d\u9762\u7684\u7b80\u5355\u7684\u63a2\u7d22\u5206\u6790\u6211\u4eec\u5bf9p2p\u7f51\u8d37\u5e73\u53f0\u7684\u51e0\u4e2a\u6837\u672c\u7279\u5f81\u4e0e\u5e73\u53f0\u8dd1\u8def\u7684\u5173\u7cfb\u6709\u4e86\u4e00\u5b9a\u8ba4\u8bc6\uff0c\u4e0b\u9762\u5c1d\u8bd5\u5229\u7528\u673a\u5668\u5b66\u4e60\u7684\u51b3\u7b56\u6811\u5206\u7c7b\u7b97\u6cd5\u6765\u5206\u6790\u548c\u9884\u6d4bp2p\u7f51\u8d37\u5e73\u53f0\u7684\u8dd1\u8def\u73b0\u8c61\u3002\n\n\n\u6837\u672c\u7279\u5f81\u9009\u62e9\n\n\n\u91c7\u7528\u76f8\u5173\u7cfb\u6570\u77e9\u9635\u548c\u9012\u5f52\u7279\u5f81\u6d88\u9664\u6cd5(RFE)\u8bc4\u4f30\u7279\u5f81\u6307\u6807\u7684\u91cd\u8981\u6027\uff0c\u8fdb\u800c\u9009\u62e9\u5408\u9002\u7684\u6837\u54c1\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u8bad\u7ec3\u3002\n\n\n# dall.shape  # (3895, 12)\n# dall.head(3)\n# dall.isnull()\ndall.count()\n((dall.shape[0] - dall.count()) / dall.shape[0] * 100). round(2)\n\n\n\n\nname              0.0\naverageI          0.0\ndate              0.0\nzhuzed            0.0\nclassification    0.0\ntouziq            0.0\nnetF              0.0\nbackground        0.0\ntuoguan           0.0\nzhuz              0.0\nshiz              0.0\ndatetime          0.0\ndtype: float64\n\n\n\ndall.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nname\n\n      \naverageI\n\n      \ndate\n\n      \nzhuzed\n\n      \nclassification\n\n      \ntouziq\n\n      \nnetF\n\n      \nbackground\n\n      \ntuoguan\n\n      \nzhuz\n\n      \nshiz\n\n      \ndatetime\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n108\u8d37\n\n      \n14.548392\n\n      \n2015-02-26\n\n      \n44.0\n\n      \n0.0\n\n      \n2.578413\n\n      \n14.351883\n\n      \n0\n\n      \n0\n\n      \n500\n\n      \n0\n\n      \n5.326389e+07\n\n    \n\n    \n\n      \n1\n\n      \n2025\u91d1\u878d\n\n      \n14.548392\n\n      \n2015-11-16\n\n      \n11.0\n\n      \n0.0\n\n      \n2.578413\n\n      \n14.351883\n\n      \n0\n\n      \n0\n\n      \n2000\n\n      \n0\n\n      \n3.054069e+07\n\n    \n\n    \n\n      \n2\n\n      \n51\u5e2e\u4f60\n\n      \n12.460000\n\n      \n2012-08-15\n\n      \n33.0\n\n      \n1.0\n\n      \n1.172000\n\n      \n16.500000\n\n      \n0\n\n      \n1\n\n      \n3000\n\n      \n2000\n\n      \n1.331839e+08\n\n    \n\n  \n\n\n\n\n\n\n\n# \u6682\u4e14\u4e0d\u8003\u8651p2p\u7f51\u8d37\u5e73\u53f0\u540d\u79f0\u548c\u6210\u7acb\u65e5\u671f\ndata = dall.drop([\nname\n, \ndate\n,], axis=1)  \ncols = data.columns.tolist()\ndata.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \naverageI\n\n      \nzhuzed\n\n      \nclassification\n\n      \ntouziq\n\n      \nnetF\n\n      \nbackground\n\n      \ntuoguan\n\n      \nzhuz\n\n      \nshiz\n\n      \ndatetime\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n14.548392\n\n      \n44.0\n\n      \n0.0\n\n      \n2.578413\n\n      \n14.351883\n\n      \n0\n\n      \n0\n\n      \n500\n\n      \n0\n\n      \n5.326389e+07\n\n    \n\n    \n\n      \n1\n\n      \n14.548392\n\n      \n11.0\n\n      \n0.0\n\n      \n2.578413\n\n      \n14.351883\n\n      \n0\n\n      \n0\n\n      \n2000\n\n      \n0\n\n      \n3.054069e+07\n\n    \n\n    \n\n      \n2\n\n      \n12.460000\n\n      \n33.0\n\n      \n1.0\n\n      \n1.172000\n\n      \n16.500000\n\n      \n0\n\n      \n1\n\n      \n3000\n\n      \n2000\n\n      \n1.331839e+08\n\n    \n\n  \n\n\n\n\n\n\n\n# corrcoef\u51fd\u6570\u8ba1\u7b97\u76f8\u5173\u7cfb\u6570,\u66f4\u7cbe\u786e\u5730\u662f\u76f8\u5173\u7cfb\u6570\u77e9\u9635\ncm = np.corrcoef(data[cols].values.T)\nplt.figure(figsize=(10,8))\ng = sns.heatmap(cm, cbar=True, annot=True, \n            square=True, fmt=\n.2f\n, \n            annot_kws={'size': 15}, \n           yticklabels=cols,xticklabels=cols)\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n\n\n\n\n([\nmatplotlib.axis.XTick at 0x7f4cbaab8c50\n,\n  \nmatplotlib.axis.XTick at 0x7f4cbab0e050\n,\n  \nmatplotlib.axis.XTick at 0x7f4cba9db890\n,\n  \nmatplotlib.axis.XTick at 0x7f4cba9dbdd0\n,\n  \nmatplotlib.axis.XTick at 0x7f4cba9e3310\n,\n  \nmatplotlib.axis.XTick at 0x7f4cba9e39d0\n,\n  \nmatplotlib.axis.XTick at 0x7f4cba9ec110\n,\n  \nmatplotlib.axis.XTick at 0x7f4cba9ec810\n,\n  \nmatplotlib.axis.XTick at 0x7f4cba9ecc90\n,\n  \nmatplotlib.axis.XTick at 0x7f4cba9f93d0\n],\n \na list of 10 Text xticklabel objects\n)\n\n\n\n\n\n\u4ece\u76f8\u5173\u7cfb\u6570\u77e9\u9635\uff0c\u6295\u8d44\u671f\u9650\u548c\u5e73\u5747\u5229\u7387\u4e0e\u5206\u7c7b\u6807\u7b7e\uff08\u662f\u5426\u8dd1\u8def\uff09\u6709\u8f83\u5f3a\u7684\u7ebf\u6027\u76f8\u5173\u6027\uff0c\u6ce8\u518c\u8d44\u672c\u7ebf\u6027\u76f8\u5173\u6027\u6700\u4f4e\uff0c\u5176\u4ed6\u7684\u7279\u5f81\u6709\u4e00\u5b9a\u7684\u7ebf\u6027\u76f8\u5173\u6027\uff0c\u4f46\u5f3a\u5ea6\u8f83\u5f31\u3002\n\n\nimport datetime\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RandomizedLasso\nfrom sklearn.linear_model import RandomizedLogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\n\n\n\n\ny = data.pop(\nclassification\n)\nX = data\nfeatures = X.columns.values\n\n\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nsc = StandardScaler()\nsc.fit(X_train)  # \u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\nX_train_std = sc.transform(X_train)  # \u8fdb\u884c\u6807\u51c6\u53d8\u6362\uff0c\u53d8\u6210\u6807\u51c6\u6b63\u6001\u5206\u5e03\nX_test_std = sc.transform(X_test)\n\n\n\n\n\n\u9012\u5f52\u6d88\u9664\u7279\u5f81\u6cd5\u4f7f\u7528\u4e00\u4e2a\u57fa\u6a21\u578b\u6765\u8fdb\u884c\u591a\u8f6e\u8bad\u7ec3\uff0c\u6bcf\u8f6e\u8bad\u7ec3\u540e\uff0c\u9009\u51fa\u6700\u597d\u7684\u7684\u7279\u5f81\uff0c\n\u7136\u540e\u5728\u5269\u4f59\u7684\u7279\u5f81\u4e0a\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\u3002\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u7279\u5f81\u88ab\u6d88\u9664\u7684\u6b21\u5e8f\u5c31\u662f\u7279\u5f81\u7684\u6392\u5e8f\u3002\nRFE\u7684\u7a33\u5b9a\u6027\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u5728\u8fed\u4ee3\u7684\u65f6\u5019\u5e95\u5c42\u7528\u54ea\u79cd\u6a21\u578b\u3002\u53c2\u6570estimator\u4e3a\u57fa\u6a21\u578b\uff0c\n\u53c2\u6570n_features_to_select\u4e3a\u9009\u62e9\u7684\u7279\u5f81\u4e2a\u6570\u3002\n\n \nestimator = LogisticRegression()\nselector = RFE(estimator, n_features_to_select=1, step=1)  \nselector = selector.fit(X_train_std, y_train) \nbag = sorted(zip(features, selector.ranking_, selector.support_),\n             key=lambda x: x[1])\nbag\n\n\n\n\n[('background', 1, True),\n ('tuoguan', 2, False),\n ('shiz', 3, False),\n ('averageI', 4, False),\n ('netF', 5, False),\n ('zhuz', 6, False),\n ('touziq', 7, False),\n ('zhuzed', 8, False),\n ('datetime', 9, False)]\n\n\n\n\n\u7a33\u5b9a\u6027\u9009\u62e9\u662f\u4e00\u79cd\u57fa\u4e8e\u4e8c\u6b21\u62bd\u6837\u548c\u9009\u62e9\u7b97\u6cd5\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u9009\u62e9\u7b97\u6cd5\u53ef\u4ee5\u662f\u56de\u5f52\u3001SVM\u6216\u5176\u4ed6\n\u7c7b\u4f3c\u7684\u65b9\u6cd5\u3002\u5b83\u7684\u4e3b\u8981\u601d\u60f3\u662f\u5728\u4e0d\u540c\u7684\u6570\u636e\u5b50\u96c6\u548c\u7279\u5f81\u5b50\u96c6\u4e0a\u8fd0\u884c\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\uff0c\u4e0d\u65ad\u7684\u91cd\u590d\uff0c\n\u6700\u7ec8\u6c47\u603b\u7279\u5f81\u9009\u62e9\u7ed3\u679c\uff0c\u6bd4\u5982\u53ef\u4ee5\u7edf\u8ba1\u67d0\u4e2a\u7279\u5f81\u88ab\u8ba4\u4e3a\u662f\u91cd\u8981\u7279\u5f81\u7684\u9891\u7387\uff08\u88ab\u9009\u4e3a\u91cd\u8981\u7279\u5f81\u7684\n\u6b21\u6570\u9664\u4ee5\u5b83\u6240\u5728\u7684\u5b50\u96c6\u88ab\u6d4b\u8bd5\u7684\u6b21\u6570\uff09\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u91cd\u8981\u7279\u5f81\u7684\u5f97\u5206\u4f1a\u63a5\u8fd1100%\u3002\u7a0d\u5fae\u5f31\u4e00\u70b9\n\u7684\u7279\u5f81\u5f97\u5206\u4f1a\u662f\u975e0\u7684\u6570\uff0c\u800c\u6700\u65e0\u7528\u7684\u7279\u5f81\u5f97\u5206\u5c06\u4f1a\u63a5\u8fd1\u4e8e0\u3002\nsklearn\u63d0\u4f9b\u4e86\u968f\u673alasso\u548c\u968f\u673a\u903b\u8f91\u56de\u5f52\u3002\n\n\nrlg = RandomizedLogisticRegression()\nrlg.fit(X_train, y_train)\nbag_rr = sorted(zip(features, rlg.scores_), key=lambda x: x[1], reverse=True)\nbag_rr\n\n\n\n\n[('averageI', 1.0),\n ('netF', 1.0),\n ('background', 1.0),\n ('tuoguan', 1.0),\n ('touziq', 0.56000000000000005),\n ('zhuzed', 0.53500000000000003),\n ('shiz', 0.40000000000000002),\n ('datetime', 0.23000000000000001),\n ('zhuz', 0.0)]\n\n\n\n\u7efc\u5408\u76f8\u5173\u7cfb\u6570\u77e9\u9635\u3001\u9012\u5f52\u6d88\u9664\u7279\u5f81\u6cd5\u3001\u7a33\u5b9a\u6027\u9009\u62e9\u7684\u8bc4\u4f30\u7ed3\u679c\uff0c\u5e73\u5747\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u5e73\u53f0\u80cc\u666f\u3001\u6709\u65e0\u6258\u7ba1\u56db\u4e2a\u7279\u5f81\u4e0ep2p\u7f51\u8d37\u5e73\u53f0\u7684\u662f\u5426\u8dd1\u8def\u7ebf\u6027\u76f8\u5173\u6027\u8f83\u5927\uff0c\u6211\u4eec\u5148\u91c7\u7528\u8fd9\u56db\u4e2a\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u6784\u5efa\u3002\n\n\n\u5206\u7c7b\u6a21\u578b\u6784\u5efa\n\n\n# \u7528sklearn\u7684learning_curve\u5f97\u5230training_score\u548ccv_score\uff0c\u4f7f\u7528matplotlib\u753b\u51falearning curve\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=5, n_jobs=1, \n                        train_sizes=np.linspace(.05, 1., 20), \n                        verbose=0, plot=True, text_=None):\n    \n\n    \u753b\u51fadata\u5728\u67d0\u6a21\u578b\u4e0a\u7684learning curve.\n    \u53c2\u6570\u89e3\u91ca\n    ----------\n    estimator : \u4f7f\u7528\u7684\u5206\u7c7b\u5668\u3002\n    title : \u56fe\u7684\u6807\u9898\u3002\n    X : \u8f93\u5165\u7684feature\uff0cnumpy\u7c7b\u578b\n    y : \u8f93\u5165\u7684target vector\n    ylim : tuple\u683c\u5f0f\u7684(ymin, ymax), \u8bbe\u5b9a\u56fe\u50cf\u4e2d\u7eb5\u5750\u6807\u7684\u6700\u4f4e\u70b9\u548c\u6700\u9ad8\u70b9\n    cv : \u505across-validation\u7684\u65f6\u5019\uff0c\u6570\u636e\u5206\u6210\u7684\u4efd\u6570\uff0c\u5176\u4e2d\u4e00\u4efd\u4f5c\u4e3acv\u96c6\uff0c\u5176\u4f59n-1\u4efd\u4f5c\u4e3atraining(\u9ed8\u8ba4\u4e3a3\u4efd)\n    n_jobs : \u5e76\u884c\u7684\u7684\u4efb\u52a1\u6570(\u9ed8\u8ba41)\n    \n\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n    train_scores_mean = np.mean(train_scores, axis=1)  # train_scores\u662f\u4e00\u4e2a\uff12\uff10\u884c\uff15\u5217\u7684ndarry,20\u4e3a\u4ece\u6837\u672c\u53d6\u7684\u4e0d\u540c\u6bd4\u4f8b\u7684\u6837\u672c\u6570\u636e\u4f5c\u4e3aX, \u800c\uff15\u8868\u793a\uff15\u6b21\u4ea4\u53c9\u9a8c\u8bc1\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    if plot:\n        plt.figure(figsize=(7,7))\n        plt.title(title)\n        if ylim is not None:\n            plt.ylim(*ylim)\n        plt.xlabel(\nsamples\n)\n        plt.ylabel(\nscores\n)\n        # plt.gca().invert_yaxis() \u4f8b\u5982y\u8f74\u5750\u68073000-10000\uff0c\u8c03\u6574\u4e3a10000-3000\u6765\u663e\u793a\n        plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, \n                         alpha=0.2, color=\nb\n)\n        plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, \n                         alpha=0.2, color=\nr\n)\n        plt.plot(train_sizes, train_scores_mean, '^-', color=\nblue\n, label=\ntrain score\n)\n        plt.plot(train_sizes, test_scores_mean, 'v-', color=\nred\n, label=\ncross_validation score\n)\n        plt.legend(loc=\nbest\n)\n        plt.gca().yaxis.grid(True, linestyle = \n-.\n)\n        plt.gca().xaxis.grid(True, linestyle = \n-.\n)   \n        plt.text(500, 0.754, text_, size = 12, color = \nk\n, weight = \nlight\n, bbox = dict(facecolor = \npurple\n, alpha = 0.3))   \n        # plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n        plt.show()        \n\n\n\n\nLogisticReregession \u5206\u7c7b\u6a21\u578b\u6784\u5efa\n\n\ndef evaluate_feature(df, feature_add, C_):\n    \n\u8bc4\u4f30\u589e\u52a0\u65b0\u7684\u7279\u5f81\u7684\u5206\u7c7b\u51c6\u786e\u7387\n\n    raw_feature = ['averageI','classification','netF',\n                   'background','tuoguan']\n    raw_feature.extend(feature_add) if type(feature_add) == list else raw_feature.append(feature_add)\n    data = df[raw_feature]\n    y = data.pop(\nclassification\n)\n    X = data\n    for i in X.columns.tolist():\n        if i in [\nbackground\n, \ntuoguan\n, \nzhuzed\n]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if \ntouziq\n in X_dummies.columns.tolist():\n            X_dummies[\ntouziq\n] = X_dummies[\ntouziq\n].astype(np.int)\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    lr = LogisticRegression(C=C_, penalty=\nl2\n, random_state=24, tol=1e-6)\n    lr.fit(X_train, y_train)\n    y_pred = lr.predict(X_test)\n    num_test = len(y_test)\n    result = (num_test - (y_test != y_pred).sum()) / float(num_test) * 100\n    feature_str = \nadd feature:\n + \n,\n.join(feature_add) if feature_add else \n    \n    content = \n{2} accuracy_score:{0} C:{1}\n.format(np.round(result, 4), C_, feature_str)\n    plot_learning_curve(lr, \nlearning curve\n, X_train, y_train, text_=content)    \n\n\n\n\nfor i in [None, \ntouziq\n, \nzhuzed\n]:\n    add_feature = []\n    if i is not None:\n        add_feature.append(i)\n    evaluate_feature(dall, add_feature, 0.5)    \n\n\n\n\n\n\n\n\n\n\nfor C in [0.01, 0.05, 0.1, 0.5, 1]:\n    evaluate_feature(dall, [\ntouziq\n], C)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\u5f53\u9009\u62e9\u5e73\u5747\u5e74\u5316\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u5e73\u53f0\u8d44\u8d28\u56db\u4e2a\u7279\u5f81\uff0c\u6b63\u5219\u5316\u7cfb\u6570\u4e3a0.5\u5019\uff0cLogisticRegression\u7684\u5206\u7c7b\u51c6\u786e\u7387\u4e3a76.5%\uff0c\u5f53\u589e\u52a0\u6295\u8d44\u671f\u9650\u7684\u5206\u7c7b\u7279\u5f81\u65f6\u5019\uff0c\u51c6\u786e\u7387\u7565\u6709\u63d0\u9ad8\u8fbe\u523077.1%\uff0c\u5f53\u589e\u52a0\u6ce8\u518c\u5730\u7684\u5206\u7c7b\u7279\u5f81\u65f6\u5019\uff0c\u51c6\u786e\u7387\u53cd\u800c\u964d\u4f4e\u3002\n\n\ndef evaluate_feature(df, C_):\n    \n\u8bc4\u4f30\u589e\u52a0\u65b0\u7684\u7279\u5f81\u7684\u5206\u7c7b\u51c6\u786e\u7387\n\n    # raw_feature = features\n    # ['averageI','classification','netF', 'background','tuoguan']\n    # raw_feature.extend(feature_add) if type(feature_add) == list else raw_feature.append(feature_add)\n    # data = df[raw_feature]\n    feature_add = \n\n    data = df.drop([\nname\n, \ndatetime\n,], axis=1) \n    y = data.pop(\nclassification\n)\n    X = data[['averageI','netF', 'background','tuoguan', \n              'touziq', 'shiz', 'date']]  # \ndatetime\n'zhuzed'\n    # \u52a0\u5165\u6ce8\u518c\u5730\u5bf9\u5206\u7c7b\u6548\u679c\u6ca1\u6709\u660e\u663e\u5e2e\u52a9\uff0c\u5373\u4f7f\u51cf\u5c11\u6ce8\u518c\u5730\u7684\u7c7b\u522b\u4e5f\u65e0\u76ca\u6700\u7ec8\u5206\u7c7b\u6548\u679c\n    if \nzhuzed\n in X.columns.tolist():\n        set_zhu_all = set(data[\nzhuzed\n].unique().tolist())\n        set_zhu_pa = set(data[\nzhuzed\n].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[\nzhuzed\n] = X[\nzhuzed\n].replace(zhu_replace,[100] * len(zhu_replace))\n    if \ndate\n in X.columns.tolist():\n        date_str = X[\ndate\n].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime(\n2016-12\n)\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(\n \n).str.get(0).astype(int) \n        X[\ndate\n] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [\nbackground\n, \ntuoguan\n, \nzhuzed\n]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if \ntouziq\n in X_dummies.columns.tolist():\n            X_dummies[\ntouziq\n] = X_dummies[\ntouziq\n].astype(np.int)\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    lr = LogisticRegression(C=C_, penalty=\nl2\n, random_state=24, tol=1e-6)\n    lr.fit(X_train, y_train)\n    y_pred = lr.predict(X_test)\n    num_test = len(y_test)\n    result = (num_test - (y_test != y_pred).sum()) / float(num_test) * 100\n    feature_str = \nadd feature:\n + \n,\n.join(feature_add) if feature_add else \n    \n    content = \n{2} accuracy_score:{0} C:{1}\n.format(np.round(result, 4), C_, feature_str)\n    plot_learning_curve(lr, \nlearning curve\n, X_train, y_train, text_=content)    \n\n\n\n\nevaluate_feature(dall, 0.1)    \n\n\n\n\n\n\n\u9009\u53d6\u5e73\u5747\u5e74\u5316\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u5e73\u53f0\u8d44\u8d28\u3001\u6ce8\u518c\u65e5\u671f\uff0c\u5b9e\u7f34\u8d44\u672c\u4e3a\u5206\u7c7b\u7279\u5f81\uff0c\u4f7f\u7528LogisticRegression\u6784\u5efa\u5206\u7c7b\u5668\uff0c\u5f53\u6b63\u5219\u5316\u4e3aC=0.1\u65f6\u5019\uff0c\u6d4b\u8bd5\u96c6\u5206\u7c7b\u51c6\u53d6\u7387\u4e3a77.9%\u3002\n\n\n\u968f\u673a\u68ee\u6797\u5206\u7c7b\u6a21\u578b\u6784\u5efa\n\n\n\u9009\u53d6\u5e73\u5747\u5e74\u5316\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u5e73\u53f0\u8d44\u8d28\u3001\u6295\u8d44\u671f\u3001\u6ce8\u518c\u65e5\u671f\u3001\u5b9e\u7f34\u8d44\u672c\u4e3a\u5206\u7c7b\u7279\u5f81\uff0c\u968f\u673a\u68ee\u6797\u8fdb\u884c\u5206\u7c7b\uff0c\u5c1d\u8bd5\u5bf9\u5173\u952e\u53c2\u6570\u8fdb\u884c\u8c03\u8bd5\u3002\n\n\ndef rf_test_n_estimator(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop(\nclassification\n)\n    X = data\n    if \nzhuzed\n in X.columns.tolist():\n        set_zhu_all = set(data[\nzhuzed\n].unique().tolist())\n        set_zhu_pa = set(data[\nzhuzed\n].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[\nzhuzed\n] = X[\nzhuzed\n].replace(zhu_replace,[100] * len(zhu_replace))\n    if \ndate\n in X.columns.tolist():\n        date_str = X[\ndate\n].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime(\n2016-12\n)\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(\n \n).str.get(0).astype(int) \n        X[\ndate\n] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [\nbackground\n, \ntuoguan\n, \nzhuzed\n]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if \ntouziq\n in X_dummies.columns.tolist():\n            X_dummies[\ntouziq\n] = X_dummies[\ntouziq\n].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(10, 210, 20):\n        clf = RandomForestClassifier(n_estimators=i, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n        # cross_val_score_ = dict(zip(cross_val_score_i, cross_val_score))\n        # print(\nAccuracy: %0.2f (+/- %0.2f) [%s]\n % (scores.mean(), scores.std(), label))\n\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'n_estimator\u6570\u91cf', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)           \n\n\n\n\nrf_test_n_estimator(dall)   \n\n\n\n\n\n\ndef rf_test_max_depth(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop(\nclassification\n)\n    X = data\n    if \nzhuzed\n in X.columns.tolist():\n        set_zhu_all = set(data[\nzhuzed\n].unique().tolist())\n        set_zhu_pa = set(data[\nzhuzed\n].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[\nzhuzed\n] = X[\nzhuzed\n].replace(zhu_replace,[100] * len(zhu_replace))\n    if \ndate\n in X.columns.tolist():\n        date_str = X[\ndate\n].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime(\n2016-12\n)\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(\n \n).str.get(0).astype(int) \n        X[\ndate\n] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [\nbackground\n, \ntuoguan\n, \nzhuzed\n]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if \ntouziq\n in X_dummies.columns.tolist():\n            X_dummies[\ntouziq\n] = X_dummies[\ntouziq\n].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(5, 26, 5):\n        clf = RandomForestClassifier(max_depth=i, n_estimators=100, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'max_depth', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)         \n\n\n\n\nrf_test_max_depth(dall)\n\n\n\n\n\n\ndef rf_test_max_feature(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop(\nclassification\n)\n    X = data\n    if \nzhuzed\n in X.columns.tolist():\n        set_zhu_all = set(data[\nzhuzed\n].unique().tolist())\n        set_zhu_pa = set(data[\nzhuzed\n].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[\nzhuzed\n] = X[\nzhuzed\n].replace(zhu_replace,[100] * len(zhu_replace))\n    if \ndate\n in X.columns.tolist():\n        date_str = X[\ndate\n].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime(\n2016-12\n)\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(\n \n).str.get(0).astype(int) \n        X[\ndate\n] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [\nbackground\n, \ntuoguan\n, \nzhuzed\n]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if \ntouziq\n in X_dummies.columns.tolist():\n            X_dummies[\ntouziq\n] = X_dummies[\ntouziq\n].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(1, len(X.columns.tolist())):\n        clf = RandomForestClassifier(max_features=i, max_depth=10, n_estimators=100, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'max_feature', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)         \n\n\n\n\nrf_test_max_feature(dall)\n\n\n\n\n\n\ndef rf_test_min_samples_split(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop(\nclassification\n)\n    X = data\n    if \nzhuzed\n in X.columns.tolist():\n        set_zhu_all = set(data[\nzhuzed\n].unique().tolist())\n        set_zhu_pa = set(data[\nzhuzed\n].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[\nzhuzed\n] = X[\nzhuzed\n].replace(zhu_replace,[100] * len(zhu_replace))\n    if \ndate\n in X.columns.tolist():\n        date_str = X[\ndate\n].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime(\n2016-12\n)\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(\n \n).str.get(0).astype(int) \n        X[\ndate\n] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [\nbackground\n, \ntuoguan\n, \nzhuzed\n]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if \ntouziq\n in X_dummies.columns.tolist():\n            X_dummies[\ntouziq\n] = X_dummies[\ntouziq\n].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(2, 11, 2):\n        clf = RandomForestClassifier(min_samples_split=i, max_features=3, max_depth=10, n_estimators=100, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'min_sample_split', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)\n\n\n\n\nrf_test_min_samples_split(dall) \n\n\n\n\n\n\ndef rf_test_min_samples_leaf(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop(\nclassification\n)\n    X = data\n    if \nzhuzed\n in X.columns.tolist():\n        set_zhu_all = set(data[\nzhuzed\n].unique().tolist())\n        set_zhu_pa = set(data[\nzhuzed\n].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[\nzhuzed\n] = X[\nzhuzed\n].replace(zhu_replace,[100] * len(zhu_replace))\n    if \ndate\n in X.columns.tolist():\n        date_str = X[\ndate\n].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime(\n2016-12\n)\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(\n \n).str.get(0).astype(int) \n        X[\ndate\n] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [\nbackground\n, \ntuoguan\n, \nzhuzed\n]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if \ntouziq\n in X_dummies.columns.tolist():\n            X_dummies[\ntouziq\n] = X_dummies[\ntouziq\n].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(2, 11, 2):\n        clf = RandomForestClassifier(min_samples_leaf=i, min_samples_split=2, max_features=3, max_depth=10, n_estimators=100, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'min_sample_leaf', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)\n\n\n\n\nrf_test_min_samples_leaf(dall)\n\n\n\n\n\n\ndef rf(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop(\nclassification\n)\n    X = data\n    if \nzhuzed\n in X.columns.tolist():\n        set_zhu_all = set(data[\nzhuzed\n].unique().tolist())\n        set_zhu_pa = set(data[\nzhuzed\n].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[\nzhuzed\n] = X[\nzhuzed\n].replace(zhu_replace,[100] * len(zhu_replace))\n    if \ndate\n in X.columns.tolist():\n        date_str = X[\ndate\n].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime(\n2016-12\n)\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(\n \n).str.get(0).astype(int) \n        X[\ndate\n] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [\nbackground\n, \ntuoguan\n, \nzhuzed\n]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if \ntouziq\n in X_dummies.columns.tolist():\n            X_dummies[\ntouziq\n] = X_dummies[\ntouziq\n].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    clf = RandomForestClassifier(min_samples_leaf=6, min_samples_split=8, max_features=3, max_depth=10, n_estimators=100, random_state=24)\n    clf.fit(X_train, y_train)    \n    y_pred = clf.predict(X_test)\n    num_test = len(y_test)\n    result = (num_test - (y_test != y_pred).sum()) / float(num_test) * 100\n    plot_learning_curve(clf, \nlearning curve\n, X_train, y_train, text_=result)        \n    #print '\\t%s\\t%s\\t%s\\t%s' % ('\u5206\u7c7b','\u7cbe\u786e\u7387','\u53ec\u56de\u7387','f1-score')\n    evaluate_result_rf = classification_report(y_test, y_pred)\n    #print '0 \uff1ap2p\u5e73\u53f0\u8dd1\u8def(\u6216\u51fa\u73b0\u5176\u4ed6\u975e\u6b63\u5e38\u8fd0\u8425\u7684\u95ee\u9898)' \n    #print '1 \uff1a\u6b63\u5e38\u8fd0\u8425' \n    return evaluate_result_rf   \n\n\n\n\nevaluate_result_rf = rf(dall)\n\n\n\n\n\n\nevaluate_result_rf\n\n\n\n\n'             precision    recall  f1-score   support\\n\\n        0.0       0.82      0.82      0.82       392\\n        1.0       0.82      0.82      0.82       387\\n\\navg / total       0.82      0.82      0.82       779\\n'\n\n\n\n\u4f7f\u7528GridSearchCV\u8fdb\u4e00\u6b65\u641c\u7d22\u6700\u4f18\u53c2\u6570\n\n\ndef randomforest_classifier_gs(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop(\nclassification\n)\n    X = data\n    if \nzhuzed\n in X.columns.tolist():\n        set_zhu_all = set(data[\nzhuzed\n].unique().tolist())\n        set_zhu_pa = set(data[\nzhuzed\n].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[\nzhuzed\n] = X[\nzhuzed\n].replace(zhu_replace,[100] * len(zhu_replace))\n    if \ndate\n in X.columns.tolist():\n        date_str = X[\ndate\n].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime(\n2016-12\n)\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(\n \n).str.get(0).astype(int) \n        X[\ndate\n] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [\nbackground\n, \ntuoguan\n, \nzhuzed\n]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if \ntouziq\n in X_dummies.columns.tolist():\n            X_dummies[\ntouziq\n] = X_dummies[\ntouziq\n].astype(np.int)\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n\n    pipeline = Pipeline([('clf', RandomForestClassifier(criterion='gini'))])\n    parameters = {\n                  'clf__n_estimators': (100, 120, 140),\n                  'clf__max_depth': (10, 12),\n                  'clf__min_samples_split': (7, 8, 9),\n                  'clf__min_samples_leaf': (5, 6, 7),\n                  'clf__max_features': (3, 5)\n                  }\n    grid_search = GridSearchCV(pipeline, parameters, n_jobs=2, verbose=1, scoring='accuracy')\n    grid_search.fit(X_train, y_train)\n    accuracy_score = \nbest_accuray_score: {}\n.format(grid_search.best_score_) \n    best_parameters = grid_search.best_estimator_.get_params()\n    parameters = sorted(parameters.keys())\n    #print \n\\t%s: %r\n % (param_name, best_parameters[param_name])\n    predictions = grid_search.predict(X_test)\n    print '\\t%s\\t%s\\t%s\\t%s' % ('\u5206\u7c7b','\u7cbe\u786e\u7387','\u53ec\u56de\u7387','f1-score')\n    evaluate_result = classification_report(y_test, predictions)\n    #print '0 \uff1ap2p\u5e73\u53f0\u8dd1\u8def(\u6216\u51fa\u73b0\u5176\u4ed6\u975e\u6b63\u5e38\u8fd0\u8425\u7684\u95ee\u9898)' \n    #print '1 \uff1a\u6b63\u5e38\u8fd0\u8425' \n    return accuracy_score, best_parameters, evaluate_result    \n\n\n\n\nrandomforest_classifier_gs(dall)\n\n\n\n\n('best_accuray_score: 0.821566110398',\n {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n              max_depth=10, max_features=3, max_leaf_nodes=None,\n              min_impurity_split=1e-07, min_samples_leaf=6,\n              min_samples_split=7, min_weight_fraction_leaf=0.0,\n              n_estimators=120, n_jobs=1, oob_score=False, random_state=None,\n              verbose=0, warm_start=False),\n  'clf__bootstrap': True,\n  'clf__class_weight': None,\n  'clf__criterion': 'gini',\n  'clf__max_depth': 10,\n  'clf__max_features': 3,\n  'clf__max_leaf_nodes': None,\n  'clf__min_impurity_split': 1e-07,\n  'clf__min_samples_leaf': 6,\n  'clf__min_samples_split': 7,\n  'clf__min_weight_fraction_leaf': 0.0,\n  'clf__n_estimators': 120,\n  'clf__n_jobs': 1,\n  'clf__oob_score': False,\n  'clf__random_state': None,\n  'clf__verbose': 0,\n  'clf__warm_start': False,\n  'steps': [('clf',\n    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                max_depth=10, max_features=3, max_leaf_nodes=None,\n                min_impurity_split=1e-07, min_samples_leaf=6,\n                min_samples_split=7, min_weight_fraction_leaf=0.0,\n                n_estimators=120, n_jobs=1, oob_score=False, random_state=None,\n                verbose=0, warm_start=False))]},\n '             precision    recall  f1-score   support\\n\\n        0.0       0.83      0.81      0.82       392\\n        1.0       0.81      0.83      0.82       387\\n\\navg / total       0.82      0.82      0.82       779\\n')\n\n\n\n\u9009\u53d6\u5e73\u5747\u5e74\u5316\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u5e73\u53f0\u8d44\u8d28\u3001\u6295\u8d44\u671f\u3001\u6ce8\u518c\u65e5\u671f\u3001\u5b9e\u7f34\u8d44\u672c\u4e3a\u5206\u7c7b\u7279\u5f81\uff0cRandomForestClassifier\u7684\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u670982%\uff0c\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u4e5f\u662f82%\uff0c\u4f46\u4ecelearning curve\u80fd\u770b\u51fa\u5b58\u5728\u7740\u8fc7\u62df\u5408\u73b0\u8c61\u3002\n\n\n\u603b\u7ed3\n\n\n\u901a\u8fc7LogistciRegression\u548cRandomForestClassifier\u5efa\u7acb\u7684\u5206\u7c7b\u6a21\u578b\u7684\u5206\u7c7b\u6548\u679c\u5747\u8f83\u5dee\u3002\u9020\u6210\u4ee5\u4e0a\u539f\u56e0\u8ddf\u6570\u636e\u6e90\u6709\u4e00\u5b9a\u5173\u7cfb\u3002\u6709\u5173p2p\u7f51\u8d37\u5e73\u53f0\u7684\u8bc4\u4f30\u6307\u6807\u6709\u5f88\u591a\uff0c\u672c\u62a5\u544a\u53ea\u9009\u62e9\u4e865\u4e2a\u7279\u5f81\u7ed9\u673a\u5668\u7b97\u6cd5\u5b66\u4e60\u548c\u8bad\u7ec3\uff0c\u5176\u4ed6\u6307\u6807\u5982\u7f51\u8d37\u5e73\u53f0\u7684\u5de5\u5546\u6ce8\u518c\u4fe1\u606f\u3001\u7f51\u7ad9ICP\u3001\u878d\u8d44\u53ca\u98ce\u6295\u4fe1\u606f\u7b49\u6682\u6ca1\u8003\u8651\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u6570\u636e\u7684\u7f3a\u5931\u503c\u8f83\u591a\uff0c\u6bd4\u5982\u5e73\u5747\u5229\u7387\u8fd9\u4e00\u4e2a\u6307\u6807\uff0c\u5728\u5206\u6790\u76843800\u591a\u5bb6p2p\u5e73\u53f0\u4e2d\u67091695\u5bb6\u65e0\u6b64\u9879\u6570\u636e\uff0c\u8fd9\u4e9b\u90fd\u4f1a\u5f71\u54cd\u5230\u5206\u7c7b\u6a21\u578b\u7684\u5206\u7c7b\u53ca\u9884\u6d4b\u6548\u679c\u3002\n\n\np2p\u5e73\u53f0\u8dd1\u8def\u539f\u56e0\u53ef\u7b80\u5355\u5730\u5206\u4e3a\u8bc8\u9a97\u7c7b\u548c\u7ecf\u8425\u4e0d\u5584\u7c7b\u3002\u5e9e\u6c0f\u9a97\u5c40\u3001\u6076\u610f\u81ea\u878d\u7b49\u5c5e\u4e8e\u8bc8\u9a97\u7c7b\u3002\u7531\u4e8e\u7f51\u8d37\u5e73\u53f0\u7ecf\u8425\u8fc7\u7a0b\u7684\u6210\u672c\u504f\u9ad8\uff0c\u98ce\u63a7\u4e0d\u8fc7\u5173\u800c\u5bfc\u81f4\u7684\u7ecf\u8425\u4e0d\u5584\uff0c\u5f15\u8d77\u8fd0\u8425\u5e73\u53f0\u8d44\u91d1\u94fe\u65ad\u88c2\uff0c\u6700\u7ec8\u5173\u95e8\u8dd1\u8def\u3002\u4e00\u822c\u800c\u8a00\uff0c\u8dd1\u8def\u5e73\u53f0\u6709\u4e00\u4e9b\u7279\u70b9\uff0c\u5982\u8d44\u4ea7\u9879\u76ee\u4fe1\u606f\u62ab\u9732\u4e0d\u660e\uff0c\u98ce\u63a7\u4e0d\u8fbe\u6807\u6216\u6839\u672c\u65e0\u98ce\u63a7\u4e00\u73af\uff0c\u79d2\u6807\u3001\u5929\u6807\u3001\u9ad8\u606f\u6807\u6bd4\u4f8b\u9ad8\uff0c\u6295\u8d44\u8005\u7528\u6237\u4f53\u9a8c\u5ea6\u5dee\u7b49\u3002\n\n\n\u672c\u6587\u9996\u5148\u5bf9p2p\u7f51\u8d37\u5e73\u53f0\u7684\u7279\u5f81\u4e0e\u662f\u5426\u8dd1\u8def\u7684\u5173\u7cfb\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u968f\u540e\u5c1d\u8bd5\u56fe\u901a\u8fc7sklearn\u63d0\u4f9b\u7684\u4e24\u79cd\u5206\u7c7b\u7b97\u6cd5\u5bf9p2p\u7f51\u8d37\u5e73\u53f0\u7684\u8dd1\u8def\u73b0\u8c61\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\uff0c\u6548\u679c\u4e00\u822c\uff08\u51c6\u786e\u73870.82\uff09\uff0c\u63a8\u6d4b\u539f\u56e0\u4e3b\u8981\u5728\u6837\u672c\u6570\u636e\u7f3a\u5931\u8f83\u591a\u53ca\u6837\u672c\u7279\u5f81\u4e0d\u5168\u9762\u3002\u56e0\u6b64\uff0c\u8981\u5bf9\u7f51\u8d37\u5e73\u53f0\u7684\u8dd1\u8def\u4e0e\u5426\u8fdb\u884c\u66f4\u7cbe\u786e\u7684\u9884\u6d4b\uff0c\u5c31\u8981\u66f4\u8fdb\u4e00\u6b65\u5730\u91c7\u53d6\u4e00\u4e9b\u63aa\u65bd\u8003\u5bdf\u7f51\u8d37\u5e73\u53f0\uff0c\u6bd4\u5982\uff0c\u5bf9\u7f51\u8d37\u5e73\u53f0\u7684\u76f8\u5173\u5de5\u5546\u4fe1\u606f\u8fdb\u884c\u67e5\u8be2\u548c\u786e\u8ba4\uff0c\u67e5\u8be2\u7f51\u8d37\u5e73\u53f0\u662f\u5426\u63a5\u53d7\u8fc7\u98ce\u6295\uff0c\u53ef\u53c2\u8003\u7b2c\u4e09\u65b9\u7f51\u8d37\u673a\u6784\u7684\u8bc4\u7ea7\u6570\u636e\uff0c\u5bf9\u5e73\u53f0\u8fdb\u884c\u5b9e\u5730\u8003\u5bdf\u7b49\u7b49\u3002\u53ea\u6709\u5bf9\u7f51\u8d37\u5e73\u53f0\u8fdb\u884c\u5168\u9762\u7684\u8003\u5bdf\u548c\u5224\u65ad\u624d\u80fd\u6700\u5927\u5730\u964d\u4f4e\u7f51\u8d37\u6295\u8d44\u98ce\u9669\u3002", 
            "title": "p2p\u7f51\u7ad9\u8dd1\u8def\u5224\u522b"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#p2p", 
            "text": "", 
            "title": "p2p\u7f51\u7ad9\u8dd1\u8def\u5224\u522b"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_1", 
            "text": "\u8fd1\u51e0\u5e74\uff0cp2p\u7f51\u8d37\u884c\u4e1a\u53d1\u5c55\u7684\u662f\u82e5\u706b\u5982\u837c\uff0c\u800c\u6574\u4e2a\u884c\u4e1a\u7684\u5feb\u901f\u53d1\u5c55\u5374\u63a9\u76d6\u4e0d\u4e86\u5176\u53d1\u5c55\u7684\u4e0d\u89c4\u8303\u6027\u3002P2P\u7f51\u8d37\u6700\u5927\u7684\u4f18\u8d8a\u6027\u662f\u4f7f\u4f20\u7edf\u94f6\u884c\u96be\u4ee5\u8986\u76d6\u7684\u501f\u6b3e\u4eba\u5728\u865a\u62df\u4e16\u754c\u91cc\u80fd\u5145\u5206\u4eab\u53d7\u8d37\u6b3e\u7684\u9ad8\u6548\u4e0e\u4fbf\u6377\u3002\u4f46\u4e0e\u6b64\u540c\u65f6\uff0c\u6574\u4e2a\u884c\u4e1a\u4e5f\u662f\u6ce5\u6c99\u4ff1\u4e0b\uff0c\u826f\u83a0\u4e0d\u9f50\u3002\u4e00\u65b9\u9762P2P\u884c\u4e1a\u4ecd\u7136\u5448\u73b0\u9ad8\u901f\u589e\u957f\u6001\u52bf\uff0c\u53e6\u4e00\u65b9\u9762\u5219\u662f\u5e73\u53f0\u63d0\u73b0\u56f0\u96be\u3001\u5012\u95ed\u3001\u574f\u8d26\u98ce\u6ce2\u4e0d\u65ad\uff0c\u51fa\u73b0\u4e86\u6240\u8c13\u7684p2p\u8dd1\u8def\u73b0\u8c61\u3002\n\u672c\u6587\u4ece\u666e\u901a\u6295\u8d44\u8005\u7684\u89d2\u5ea6\u63a2\u8ba8p2p\u7f51\u8d37\u5e73\u53f0\u8dd1\u8def\u7684\u7f18\u7531\uff0c\u5206\u6790\u7f51\u8d37\u5e73\u53f0\u7684\u5404\u79cd\u6307\u6807\u4e0e\u5e73\u53f0\u7ecf\u8425\u72b6\u6001\u7684\u5173\u8054\uff0c\u5bf9p2p\u7f51\u8d37\u5e73\u53f0\u662f\u5426\u4f1a\u201c\u8dd1\u8def\u201d\u8fdb\u884c\u9884\u6d4b\u3002  \u672c\u62a5\u544a\u7684\u6240\u6709\u6570\u636e\u6765\u6e90\u4e8exx\u4e4b\u5bb6\u7684\u6863\u6848\uff0c\u6570\u636e\u622a\u6b62\u65e5\u671f\u4e3a16\u5e7411\u6708\u3002\u4ee5xx\u4e4b\u5bb6\u6863\u6848\u4e2d\u76843800\u591a\u5bb6p2p\u7f51\u8d37\u5e73\u53f0\u4e3a\u6e90\u6570\u636e\uff0c\u9009\u62e9\u4e86\u7f51\u8d37\u5e73\u53f0\u7684\u51e0\u4e2a\u8bc4\u4f30\u6307\u6807\u5982\uff0c\u5e73\u5747\u6536\u76ca\u7387\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u5e73\u53f0\u8d44\u8d28\u3001\u6295\u8d44\u671f\u9650\u3001\u6ce8\u518c\u5730\u7b49\u4e3a\u6837\u672c\u7684\u7279\u5f81\uff0c\u4ee5\u7f51\u8d37\u5e73\u53f0\u7684\u7ecf\u8425\u72b6\u51b5\uff08\u662f\u6b63\u5e38\u8425\u4e1a\u72b6\u6001\u8fd8\u662f\u8dd1\u8def\u7b49\u975e\u6b63\u5e38\u8425\u4e1a\u72b6\u6001\uff09\u4e3a\u5206\u7c7b\u6807\u7b7e\uff0c\u5c1d\u8bd5\u5229\u7528\u673a\u5668\u5b66\u4e60\u7684\u51b3\u7b56\u6811\u5206\u7c7b\u7b97\u6cd5\u8bc4\u4f30\u548c\u9884\u6d4bp2p\u7f51\u8d37\u5e73\u53f0\u7684\u8dd1\u8def\u73b0\u8c61\u3002", 
            "title": "\u80cc\u666f\u8bf4\u660e"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_2", 
            "text": "\u91c7\u7528python\u7684urllib2\u548cbeautifulsoup\u8fdb\u884c\u6570\u636e\u7684\u91c7\u96c6\u548c\u89e3\u6790\uff0c\u91c7\u7528python\u7b2c\u4e09\u65b9\u5e93pandas, numpy\u5bf9\u6570\u636e\u8fdb\u884c\u6e05\u6d17\u5904\u7406\uff0c\u6570\u636e\u91c7\u96c6\u548c\u7b80\u5355\u7684\u5904\u7406\u8fc7\u7a0b\u5728\u6b64\u7565\u8fc7\u3002", 
            "title": "\u6570\u636e\u91c7\u96c6\u53ca\u6e05\u6d17"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_3", 
            "text": "import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style= whitegrid , palette= muted , font_scale=1.0, color_codes=True, context= talk )\n%matplotlib inline\nimport sys\nfrom matplotlib.ticker import MultipleLocator, FormatStrFormatter\nfrom matplotlib.font_manager import FontProperties  \nfont = FontProperties(fname=r /usr/share/fonts/truetype/arphic/ukai.ttc )\nreload(sys)\nsys.setdefaultencoding('utf-8')  # \u8f7d\u5165\u6e05\u6d17\u540e\u7684\u6570\u636e\u96c6\uff0c\u8fdb\u884c\u76f8\u5e94\u5904\u7406\ndall = pd.read_table( ./p2pchanged.txt , sep=',')  # (3895, 12)   # \u5404\u7279\u5f81\u5206\u522b\u4e3a\uff1a\nfeature_dict = { name : u p2p\u5e73\u53f0\u540d ,  averageI : u \u5e73\u5747\u5e74\u5316\u5229\u7387 , \n                date : u \u4e0a\u7ebf\u65e5\u671f ,  zhuzed : u \u6ce8\u518c\u5730 , \n                 touziq : u \u6295\u8d44\u671f\u9650 ,  netF : u \u7f51\u53cb\u8bc4\u5206 , \n                 background : u \u516c\u53f8\u7c7b\u578b ,  tuoguan : u \u8d44\u91d1\u6258\u7ba1 ,\n                 zhuz : u \u6ce8\u518c\u8d44\u672c ,  shiz : u \u5b9e\u7f34\u8d44\u672c , \n                 datetime : u \u4e0a\u7ebf\u65f6\u95f4 ,  classification : u \u5206\u7c7b\u6807\u7b7e \n               }  # \u6570\u636e\u96c6\u524d5\u884c\ndall.head()   \n   \n     \n       \n       name \n       averageI \n       date \n       zhuzed \n       classification \n       touziq \n       netF \n       background \n       tuoguan \n       zhuz \n       shiz \n       datetime \n     \n   \n   \n     \n       0 \n       108\u8d37 \n       14.548392 \n       2015-02-26 \n       44.0 \n       0.0 \n       2.578413 \n       14.351883 \n       0 \n       0 \n       500 \n       0 \n       5.326389e+07 \n     \n     \n       1 \n       2025\u91d1\u878d \n       14.548392 \n       2015-11-16 \n       11.0 \n       0.0 \n       2.578413 \n       14.351883 \n       0 \n       0 \n       2000 \n       0 \n       3.054069e+07 \n     \n     \n       2 \n       51\u5e2e\u4f60 \n       12.460000 \n       2012-08-15 \n       33.0 \n       1.0 \n       1.172000 \n       16.500000 \n       0 \n       1 \n       3000 \n       2000 \n       1.331839e+08 \n     \n     \n       3 \n       53\u8d22\u670d \n       14.548392 \n       2016-04-18 \n       33.0 \n       1.0 \n       1.100000 \n       14.351883 \n       0 \n       0 \n       10000 \n       20 \n       1.723509e+07 \n     \n     \n       4 \n       51\u94b1\u7ba1\u5bb6 \n       12.000000 \n       2015-11-04 \n       50.0 \n       1.0 \n       2.578413 \n       14.000000 \n       0 \n       1 \n       10000 \n       100 \n       3.157749e+07", 
            "title": "\u63a2\u7d22\u6027\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_4", 
            "text": "dall[ averageI ] = dall[ averageI ].map(lambda x: np.round(x, 4))\ndall.loc[:,  classification ] = dall[ classification ].replace([0,1], [u'\u8dd1\u8def',u'\u6b63\u5e38\u8425\u4e1a'])\ndf = dall.loc[dall[ averageI ] != 14.5484, :]  plt.figure(figsize=(8,6))\nfig = sns.distplot(df['averageI'],kde=True, vertical=False, color= green )\nsns.despine(top=True)\nplt.yticks(fig.get_yticks(), fig.get_yticks() * 100)\nplt.ylabel('Distribution [%]', fontsize=16)\nplt.xticks(range(0, 100, 10))\nplt.gca().yaxis.grid(True, linestyle =  : )\nplt.gca().xaxis.grid(True, linestyle =  -. )\nplt.xlabel(u \u5e73\u5747\u5e74\u5316\u5229\u7387 % , fontsize=16, fontproperties=font)\nplt.title(u \u5e73\u5747\u5e74\u5316\u5229\u7387\u7684\u5206\u5e03 , fontsize=20, fontproperties=font)  matplotlib.text.Text at 0x7fe3af9f8a10    # \u6839\u636e\u8dd1\u8def\u4e0e\u5426\u8fdb\u884c\u5206\u7ec4\u5f97\u5230\u4e86\u5e73\u5747\u5229\u7387\u7684\u5206\u7ec4\u5bf9\u8c61\nrate_cont = df.groupby([ classification ])[ averageI ]    fig, ax1 = plt.subplots(figsize=(8,6))\nrate_cont.plot(kind='kde',ax=ax1, style='--', linewidth=2.5)\nrate_cont.plot(kind='hist',ax=ax1, normed=True, alpha=0.8,)\nax1.legend(loc='best', prop=font, fontsize=17)\nax1.set_ylabel('Frequency', fontsize=16)\nax1.set_xlim(-1, 95)\nax1.text(14.0, 0.115,s=u'\u6b63\u5e38\u8425\u4e1a\u5e73\u53f0\u5e73\u5747\u6536\u76ca\u7387 12.88%', fontsize=12,va= bottom ,ha= left ,fontproperties=font,color='blue') \nax1.text(20.0, 0.09,s=u'\u8dd1\u8def\u5e73\u53f0\u5e73\u5747\u6536\u76ca\u7387 18.56%', fontsize=12,va= bottom ,ha= left ,fontproperties=font,color='green')\nax1.annotate('',xy=(12.18,0.109),xytext=(14,0.115),arrowprops=dict(arrowstyle= - ,color='blue')) \nax1.annotate('',xy=(17.9,0.08),xytext=(20,0.09),arrowprops=dict(arrowstyle= - ,color='green'))\nplt.xlabel(u \u5e73\u5747\u5e74\u5316\u5229\u7387 % , fontsize=16, fontproperties=font)\nplt.title(u p2p\u5e73\u53f0\u8dd1\u8def\u4e0e\u5426\u4e0e\u5e73\u5747\u6536\u76ca\u7387 , fontsize=20, fontproperties=font)\nplt.yticks(ax1.get_yticks(), ax1.get_yticks() * 100)\nplt.ylabel('Distribution [%]', fontsize=16)\nplt.xticks(range(0, 100, 10))\nplt.gca().yaxis.grid(True, linestyle =  : )\nplt.gca().xaxis.grid(True, linestyle =  -. )   p2p\u7f51\u8d37\u5e73\u53f0\u7684\u5e73\u5747\u5e74\u5316\u6536\u76ca\u7387\u5206\u5e03\u5f88\u5e7f\uff0c\u4ece\u6700\u4f4e\u76844%\u5230\u6700\u9ad8\u768490%\u5747\u6709\uff0c\u5176\u4e2d\u6b63\u5e38\u8425\u4e1a\u7684p2p\u5e73\u53f0\u4e3b\u8981\u5206\u5e03\u57285-20%, \u800c\u8dd1\u8def\u5e73\u53f0\u4e3b\u8981\u5206\u5e03\u57288-30%\u4e4b\u95f4\u3002\u6b63\u5e38\u8425\u4e1a\u7684p2p\u5e73\u53f0\u7684\u5e73\u5747\u6536\u76ca\u7387\u4e3a12.88%\uff0c\u8dd1\u8def\u5e73\u53f0\u7684\u5e73\u5747\u6536\u76ca\u7387\u662f18.56%\u3002", 
            "title": "\u5e73\u5747\u5e74\u5316\u5229\u7387"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_5", 
            "text": "# \u8f7d\u5165\u5730\u533a\u7f16\u53f7\uff0c\u517130\u4e2a\u7701\nplaces = pd.read_table( ./regis_place.txt , sep=',', header=None)  # (30,2) \nplaces.columns =[ number_pro ,  name_pro ]  df_set = set(df[ zhuzed ].astype(np.int).values)\nplaces_set = set(places[ number_pro ])\nplaces_set ^ df_set  {54, 63}  p1 = places.loc[places[ number_pro ] != 54, :]\np_sub = p1.loc[p1[ number_pro ] != 63, :][ name_pro ]\np_sub.shape  (29,)  # \u6839\u636e\u6ce8\u518c\u5730\u8fdb\u884c\u5206\u7ec4\npro_groupby = df.groupby( zhuzed )[ averageI ].aggregate([np.size, np.mean]).reset_index()\npro_name = pro_groupby[ zhuzed ].replace(pro_groupby[ zhuzed ].values, p_sub)\npro_groupby[ pro_name ] = pro_name.map(lambda x: x.strip())\npro_groupby.sort_values( size , ascending=False, inplace=True)\npro_groupby.head(3)   \n   \n     \n       \n       zhuzed \n       size \n       mean \n       pro_name \n     \n   \n   \n     \n       18 \n       44.0 \n       479.0 \n       14.446493 \n       \u5e7f\u4e1c \n     \n     \n       0 \n       11.0 \n       335.0 \n       11.644448 \n       \u5317\u4eac \n     \n     \n       8 \n       31.0 \n       246.0 \n       12.214431 \n       \u4e0a\u6d77 \n     \n      fig, ax1 = plt.subplots(figsize=(10,7))\ng = sns.barplot(y= size , x= pro_name , data=pro_groupby, palette= PuBu_d , ax=ax1)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=75)\n# g=sns.factorplot(y= zhuzed , data=df, kind='count', size=6, color= indianred )\nax2 = ax1.twinx()\nx_list = range(len(pro_groupby))\nax2.plot(x_list, pro_groupby[ mean ], linewidth = 3, color= skyblue , marker= o , label=u \u804c\u4f4d\u9700\u6c42\u91cf ) \nax2.set_ylabel(u \u5e73\u5747\u5e74\u5316\u5229\u7387 % , fontsize=16, fontproperties=font)\nax1.set_ylabel(u \u6570\u91cf , fontsize=16, fontproperties=font)\nax2.set_ylim(4, 20)\nax2.yaxis.grid(True, linestyle =  : ,)\nax1.yaxis.grid(False)\nplt.title(u \u5168\u56fd\u5404\u5730\u533ap2p\u7f51\u8d37\u5e73\u53f0\u6570\u91cf\u53ca\u5e73\u5747\u5e74\u5316\u5229\u7387 , fontproperties=font, fontsize=20)   # \u6839\u636e\u6ce8\u518c\u5730\u548c\u8dd1\u8def\u4e0e\u5426\u7684\u5206\u7c7b\u6807\u7b7e\u8fdb\u884c\u5206\u7ec4\npro_cla = df.groupby([ zhuzed ,  classification ])[ averageI ].aggregate([np.size, np.mean]).reset_index()\npro_name = pro_cla[ zhuzed ].replace(pro_cla[ zhuzed ].unique(), p_sub)\npro_cla[ pro_name ] = pro_name.map(lambda x: x.strip())  for i in pro_cla[ zhuzed ].unique():\n    total_ = pro_cla.loc[pro_cla[ zhuzed ] == i,  size ].sum()\n    temp = pro_cla.loc[pro_cla[ zhuzed ] == i,  size ] / total_ * 100\n    pro_cla.loc[pro_cla[ zhuzed ] == i,  property ] = temp\n    pro_cla.loc[pro_cla[ zhuzed ] == i,  total_num ] = total_     pro_cla.sort_values([ total_num ,  classification ], ascending=False, inplace=True)\npro_cla.head(15)   \n   \n     \n       \n       zhuzed \n       classification \n       size \n       mean \n       pro_name \n       property \n       total_num \n     \n   \n   \n     \n       37 \n       44.0 \n       \u8dd1\u8def \n       149.0 \n       17.667383 \n       \u5e7f\u4e1c \n       31.106472 \n       479.0 \n     \n     \n       36 \n       44.0 \n       \u6b63\u5e38\u8425\u4e1a \n       330.0 \n       12.992212 \n       \u5e7f\u4e1c \n       68.893528 \n       479.0 \n     \n     \n       1 \n       11.0 \n       \u8dd1\u8def \n       57.0 \n       13.858772 \n       \u5317\u4eac \n       17.014925 \n       335.0 \n     \n     \n       0 \n       11.0 \n       \u6b63\u5e38\u8425\u4e1a \n       278.0 \n       11.190432 \n       \u5317\u4eac \n       82.985075 \n       335.0 \n     \n     \n       17 \n       31.0 \n       \u8dd1\u8def \n       54.0 \n       16.403704 \n       \u4e0a\u6d77 \n       21.951220 \n       246.0 \n     \n     \n       16 \n       31.0 \n       \u6b63\u5e38\u8425\u4e1a \n       192.0 \n       11.036198 \n       \u4e0a\u6d77 \n       78.048780 \n       246.0 \n     \n     \n       21 \n       33.0 \n       \u8dd1\u8def \n       42.0 \n       22.031429 \n       \u6d59\u6c5f \n       23.204420 \n       181.0 \n     \n     \n       20 \n       33.0 \n       \u6b63\u5e38\u8425\u4e1a \n       139.0 \n       13.863022 \n       \u6d59\u6c5f \n       76.795580 \n       181.0 \n     \n     \n       29 \n       37.0 \n       \u8dd1\u8def \n       92.0 \n       21.970326 \n       \u5c71\u4e1c \n       57.142857 \n       161.0 \n     \n     \n       28 \n       37.0 \n       \u6b63\u5e38\u8425\u4e1a \n       69.0 \n       15.144058 \n       \u5c71\u4e1c \n       42.857143 \n       161.0 \n     \n     \n       33 \n       42.0 \n       \u8dd1\u8def \n       30.0 \n       17.895000 \n       \u6e56\u5317 \n       31.578947 \n       95.0 \n     \n     \n       32 \n       42.0 \n       \u6b63\u5e38\u8425\u4e1a \n       65.0 \n       13.785231 \n       \u6e56\u5317 \n       68.421053 \n       95.0 \n     \n     \n       23 \n       34.0 \n       \u8dd1\u8def \n       27.0 \n       18.066667 \n       \u5b89\u5fbd \n       36.486486 \n       74.0 \n     \n     \n       22 \n       34.0 \n       \u6b63\u5e38\u8425\u4e1a \n       47.0 \n       13.342553 \n       \u5b89\u5fbd \n       63.513514 \n       74.0 \n     \n     \n       19 \n       32.0 \n       \u8dd1\u8def \n       18.0 \n       21.010556 \n       \u6c5f\u82cf \n       25.714286 \n       70.0 \n     \n      plt.figure(figsize=(7, 12))\ng=sns.barplot(y= pro_name , x= size , data=pro_cla, hue= classification )\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.ylabel( )\nplt.xlabel(u \u6570\u91cf , fontsize=16, fontproperties=font)\nplt.title(u p2p\u7f51\u8d37\u5e73\u53f0\u5730\u533a\u5206\u5e03 , fontproperties=font, fontsize=20)\nplt.gca().xaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc=7,prop=font, fontsize=12)\nplt.annotate(u \u5c71\u4e1c\u5730\u533ap2p\u8dd1\u8def\u6bd4\u4f8b\u6700\u9ad8\u8fbe57% , xy = (80, 4), xytext = (100, 6), fontproperties=font, fontsize=15, arrowprops = dict(facecolor='purple'))  matplotlib.text.Annotation at 0x7fe3a13a9110    \u5168\u56fdp2p\u5e73\u53f0\u7684\u6570\u91cf\u4f4d\u5c45\u524d\u4e09\u7684\u7701\u4efd\uff08\u5e02\uff09\u662f\u5e7f\u4e1c\u3001\u5317\u4eac\u3001\u4e0a\u6d77\uff0c\u8dd1\u8def\u5e73\u53f0\u6bd4\u4f8b\u6700\u9ad8\u7684\u662f\u5c71\u4e1c\uff0c\u8d85\u8fc7\u4e00\u534a\u7684p2p\u7f51\u8d37\u5e73\u53f0\u51fa\u73b0\u8dd1\u8def\u6216\u5176\u4ed6\u975e\u6b63\u5e38\u8425\u4e1a\u73b0\u8c61\u3002", 
            "title": "\u5730\u57df\u5206\u5e03"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#p2p_1", 
            "text": "# \u5c06\u65f6\u95f4str\u8f6c\u6210datetime\ndf['date'] = pd.to_datetime(df['date'])\n# \u5c06\u8f6c\u6362\u597d\u7684\u65f6\u95f4series\u8bbe\u7f6e\u6210\u884c\u7d22\u5f15\ndt = df.set_index( date )\ndt[ year_ ] = dt.index.year\ndt[ month ] = dt.index.month\nyear_groupby = dt.groupby( year_ )[ averageI ].aggregate([np.size, np.mean, np.median])\nyear_groupby.drop(year_groupby.index[0], inplace=True)\nyear_groupby.reset_index(inplace=True)  month_groupby = dt.groupby( month )[ averageI ].aggregate([np.size, np.mean, np.median])\nmonth_groupby.drop(month_groupby.index[0], inplace=True)\nmonth_groupby.reset_index(inplace=True)\nmonth_groupby   \n   \n     \n       \n       month \n       size \n       mean \n       median \n     \n   \n   \n     \n       0 \n       2 \n       97.0 \n       13.900103 \n       12.600 \n     \n     \n       1 \n       3 \n       202.0 \n       14.094703 \n       13.295 \n     \n     \n       2 \n       4 \n       191.0 \n       13.716649 \n       13.000 \n     \n     \n       3 \n       5 \n       171.0 \n       14.180819 \n       12.790 \n     \n     \n       4 \n       6 \n       180.0 \n       14.210944 \n       13.000 \n     \n     \n       5 \n       7 \n       193.0 \n       14.886114 \n       13.500 \n     \n     \n       6 \n       8 \n       186.0 \n       15.527688 \n       14.000 \n     \n     \n       7 \n       9 \n       194.0 \n       14.236392 \n       13.195 \n     \n     \n       8 \n       10 \n       171.0 \n       15.033860 \n       14.000 \n     \n     \n       9 \n       11 \n       200.0 \n       15.484450 \n       14.300 \n     \n     \n       10 \n       12 \n       239.0 \n       13.877448 \n       13.440 \n     \n      p2p_date_dict = { year_ : u \u5e74\u4efd ,  month : u \u6708\u4efd }  def p2p_date_plot(dt, groupby_item):\n    data = dt.groupby(groupby_item)[ averageI ].aggregate([np.size, np.mean, np.median])\n    data.drop(data.index[0], inplace=True)\n    data.reset_index(inplace=True)  \n    fig, ax1 = plt.subplots(figsize=(8,6))\n    g = sns.barplot(y= size , x=groupby_item, data=data, palette= BuGn_d , ax=ax1)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16, rotation=60)\n    ax2 = ax1.twinx()\n    x_list = range(len(data))\n    ax2.plot(x_list, data[ mean ], linewidth = 3, color= darkgreen , marker= o , label=u \u5229\u7387 ) \n    ax2.set_ylabel(u \u5e73\u5747\u5e74\u5316\u5229\u7387 % , fontsize=16, fontproperties=font)\n    ax1.set_ylabel(u \u6570\u91cf , fontsize=16, fontproperties=font)\n    ax1.set_xlabel( )\n    ax2.yaxis.grid(True, linestyle =  : , linewidth=2, color= green , alpha=0.2)\n    ax1.yaxis.grid(False)\n    if groupby_item ==  month :\n        ax2.set_ylim(10, 18) \n        # ax2.axhline(y=14.7,linewidth=2, xmin=0.5, xmax=0.8, color='r')        \n        # \u5e73\u884cx\u8f74\u7684\u77e9\u5f62\uff0c\u53c2\u6570\uff1aymin,ymax,xmin=0,xmin=1        \n        ax2.axhspan(14.7, 15.7, 0.49, 0.6, facecolor= skyblue , alpha=0.8)\n        ax2.axhspan(14.7, 15.7, 0.74, 0.85, facecolor= skyblue , alpha=0.8)\n        plt.annotate( , xy = (8.1, 15.7), xytext = (7.5, 16.7), fontproperties=font, fontsize=15, arrowprops = dict(facecolor='skyblue'))        \n        plt.annotate( , xy = (5, 15.7), xytext = (7, 16.7), fontproperties=font, fontsize=15, arrowprops = dict(facecolor='skyblue'))        \n    plt.title(u p2p\u7f51\u8d37\u5e73\u53f0\u6570\u91cf\u53ca\u5e73\u5747\u5e74\u5316\u5229\u7387\u4e0e\u6210\u7acb{} .format(p2p_date_dict.get(groupby_item)), fontproperties=font, fontsize=20)\n    plt.legend(loc= best ,prop=font, fontsize=17)  for i in p2p_date_dict:   \n    p2p_date_plot(dt, i)    \u7edf\u8ba1\u6570\u636e\u663e\u793a\u6211\u56fd\u6700\u65e9\u7684p2p\u7f51\u8d37\u5e73\u53f0\u6210\u7acb\u4e8e2004\u5e744\u6708\uff0c\u622a\u6b62\u523016\u5e7411\u6708\u521d\uff0c\u5168\u56fd\u6ce8\u518c\u6210\u7acb\u4e86\u8fd14000\u5bb6p2p\u7f51\u8d37\u5e73\u53f0\u3002\u6211\u56fd\u7684p2p\u7f51\u8d37\u884c\u4e1a\u57282013\u5e74\u8fdb\u884c\u9ad8\u901f\u53d1\u5c55\u671f\uff0c\u52302014\u5e74\u5e95\u53ca2015\u5e74\u521d\u5230\u8fbe\u9876\u5cf0\uff0c\u968f\u540e\u589e\u901f\u653e\u6162\u3002  \u4ece\u5e73\u5747\u5229\u7387\u4e0a\u770b\uff0c2013\u5e74\u8fbe\u5230\u6700\u5927\u503c\uff0c\u968f\u540e\u6025\u5267\u964d\u4f4e;\u4ece\u5229\u7387\u4e0e\u6708\u4efd\u7684\u5173\u7cfb\u53ef\u770b\u51fa\uff0c7-8\u300110-11\u6708\u4efd\u7684\u5e73\u5747\u5229\u7387\u9ad8\u4e8e\u5176\u4ed6\u6708\u4efd\uff0c\u96be\u9053\u8ddf\u5e02\u573a\u6d41\u52a8\u8d44\u91d1\u7d27\u7f3a\u7a0b\u5ea6\u76f8\u5173\uff1f", 
            "title": "p2p\u7f51\u8d37\u6210\u7acb\u65f6\u95f4"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_6", 
            "text": "fig, ax = plt.subplots(figsize=(8,6))\nsns.barplot(x= tuoguan , y= averageI , hue= classification , hue_order=[u \u8dd1\u8def , u \u6b63\u5e38\u8425\u4e1a ], data=df, palette= husl , ax=ax)\nax.set_xticklabels([u \u65e0\u6258\u7ba1 , u \u6258\u7ba1 ], fontproperties=font, fontsize=16)\nax2 = ax.twinx()\n# \u6258\u7ba1\u72b6\u51b5\u767e\u5206\u6bd4\ndft = df[ tuoguan ].value_counts() / df.shape[0] * 100\nax2.plot([0,1], dft.values, linewidth = 1, color= b , marker= * , markersize=20, label=u \u767e\u5206\u6bd4% ) \nax.set_ylabel(u \u5e73\u5747\u5e74\u5316\u5229\u7387% , fontsize=16, fontproperties=font)\nax2.set_ylabel(u \u767e\u5206\u6bd4% , fontsize=16, fontproperties=font)\nax.yaxis.grid(True, linestyle =  -. ,)\nax2.yaxis.grid(False)\nax.legend(loc=9,prop=font, fontsize=17)\nax2.legend(loc=1,prop=font, fontsize=17)\nax.set_xlabel( )\nplt.title(u p2p\u5e73\u53f0\u8d44\u91d1\u6258\u7ba1\u72b6\u51b5 , fontproperties=font, fontsize=20)  matplotlib.text.Text at 0x7fe397039310    \u53ea\u6709\u7ea645%\u7684\u7f51\u8d37\u5e73\u53f0\u8fdb\u884c\u4e86\u8d44\u91d1\u6258\u7ba1\uff0c\u8fdb\u884c\u8d44\u91d1\u6258\u7ba1\u7684p2p\u7f51\u8d37\u5e73\u53f0\u7684\u5e73\u5747\u5229\u7387\u4f4e\u4e8e\u672a\u8fdb\u884c\u8d44\u91d1\u6258\u7ba1\u7684\u5e73\u53f0\uff0c\u8dd1\u8def\u6216\u51fa\u73b0\u5176\u4ed6\u7ecf\u8425\u72b6\u51b5\u7684\u5e73\u5747\u5229\u7387\u5747\u9ad8\u4e8e\u6b63\u5e38\u8425\u4e1a\u7684\u5e73\u53f0\u3002", 
            "title": "\u8d44\u91d1\u6258\u7ba1"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_7", 
            "text": "df[ net_score ] = df[ netF ].astype(np.int)\nnet_friend_score = df.groupby( classification )[ net_score ].value_counts().unstack().unstack().unstack().fillna(0)\nnet_friend_score[ total ] = net_friend_score.sum(axis=1)\nnet_friend_score_cum = net_friend_score.div(net_friend_score[ total ], axis=0)*100\nnet_friend_score_cum.drop( total , axis=1, inplace=True)\nnet_friend_score.drop( total , axis=1, inplace=True)\nfig1, (ax1, ax2) = plt.subplots(2,1, sharex=True, figsize=(12,9)) \nnet_friend_score_cum.plot(kind='bar',ax=ax1, stacked=True, label= )\nnet_friend_score.plot(kind='bar',ax=ax2, stacked=True)\nax1.legend(loc=1, prop=font, fontsize=17)\nax2.legend(loc='best', prop=font, fontsize=17)\nax2.xaxis.grid(False)\nax2.yaxis.grid(True, linestyle= -. )\nax1.yaxis.grid(True, linestyle= -. )\nax2.set_ylabel(u \u6570\u91cf , fontsize=16, fontproperties=font)\nax1.set_ylabel(u \u767e\u5206\u6bd4% , fontsize=16, fontproperties=font)\nax2.annotate( 5 , xy = (1, 10), xytext = (2.5, 160), fontproperties=font, fontsize=15, arrowprops = dict(facecolor= m ))        \nax1.annotate(u \u603b\u6570\u4e3a5 , xy = (1, 76), xytext = (1.5,60), fontproperties=font, fontsize=15, arrowprops = dict(facecolor= m ))        \nplt.xlabel(u \u7f51\u53cb\u8bc4\u5206 , fontproperties=font, fontsize=17)  matplotlib.text.Text at 0x7fe3912ed850    \u7f51\u53cb\u8bc4\u5206\u680f\u5305\u62ec\u56db\u9879\uff0c\u6bcf\u9879\u8bb05\u5206\uff0c\u6ee1\u5206\u603b\u517120\u5206\u3002\u5728\u6570\u636e\u5904\u7406\u65f6\u5c06\u6bcf\u4e00\u8bc4\u5206\u9879\u76ee\u7684\u65e0\u8bc4\u5206\u7684\u6216\u5c0f\u4e8e1.0\u5206\u7684\u7edf\u7edf\u8bb0\u4e3a1.0\u5206\uff0c\u56e0\u6b64\uff0c\u6700\u4f4e\u5206\u4e3a4.0\u5206\uff0c\u6700\u9ad8\u4e3a20\u5206\u3002\u6839\u636e\u76f8\u5bf9\u7d2f\u8ba1\u67f1\u72b6\u56fe\uff0c\u7f51\u53cb\u8bc4\u5206\u8f83\u9ad8\u7684\u7f51\u8d37\u5e73\u53f0\u51fa\u73b0\u8dd1\u8def\u7684\u6bd4\u4f8b\u8f83\u4f4e\u3002\u7531\u4e8e5\u5206\u7684\u5e73\u53f0\u6570\u91cf\u53ea\u67095\u5bb6\uff0c\u9020\u6210\u767e\u5206\u6570\u504f\u79bb\u8f83\u5927\u3002", 
            "title": "\u7f51\u53cb\u8bc4\u5206"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#p2p_2", 
            "text": "background = df.groupby( classification )[ background ].value_counts().unstack().unstack().unstack().fillna(0)\n# [0,1,2,3],[u'\u79c1\u8425 \u6c11\u8425\u7cfb',u'\u4e0a\u5e02\u516c\u53f8\u7cfb',u'\u94f6\u884c\u7cfb',u'\u56fd\u8d44\u7cfb']\nbackground[ total ] = background.sum(axis=1)\nbackground_cum = background.div(background[ total ], axis=0)*100\nbackground_cum.drop( total , axis=1, inplace=True)\nbackground.drop( total , axis=1, inplace=True)\nfig1, (ax1, ax2) = plt.subplots(2,1, sharex=True, figsize=(12,9)) \nbackground_cum.plot(kind='bar',ax=ax1, stacked=True, label= )\nbackground.plot(kind='bar',ax=ax2, stacked=True)\nax1.legend(loc=9, prop=font, fontsize=17)\nax2.legend(loc='best', prop=font, fontsize=17)\nax2.xaxis.grid(False)\nax2.yaxis.grid(True, linestyle= -. )\nax1.yaxis.grid(True, linestyle= -. )\nax2.set_ylabel(u \u6570\u91cf , fontsize=16, fontproperties=font)\nax1.set_ylabel(u \u767e\u5206\u6bd4% , fontsize=16, fontproperties=font)\nax2.set_xticklabels([u'\u79c1\u8425 \u6c11\u8425\u7cfb',u'\u4e0a\u5e02\u516c\u53f8\u7cfb',u'\u94f6\u884c\u7cfb',u'\u56fd\u8d44\u7cfb'], rotation=30, fontproperties=font)\nax2.annotate(u'\u63d0\u73b0\u56f0\u96be1\u5bb6',xy=(3,150),xytext=(2.5,300),fontproperties=font,arrowprops=dict(arrowstyle= - ,color='green',linewidth=3)) \nplt.xlabel(u \u5e73\u53f0\u8d44\u8d28 , fontproperties=font, fontsize=17)  matplotlib.text.Text at 0x7f14b5933510    p2p\u5e73\u53f0\u8d44\u8d28\uff08\u5e73\u53f0\u80cc\u666f\uff09\u5212\u5206\u4e3a\u6c11\u8425 \u79c1\u8425\u7cfb\u3001\u4e0a\u5e02\u516c\u53f8\u7cfb\u3001\u94f6\u884c\u7cfb\u3001\u56fd\u8d44\u7cfb\uff0c\u5176\u4e2d\u6c11\u8425\u7cfb\u7f51\u8d37\u8dd1\u8def\u6bd4\u4f8b\u6700\u9ad8\uff0c\u56fd\u8d44\u7cfb\u6709\u63d0\u73b0\u56f0\u96be1\u5bb6\uff0c\u4e0a\u5e02\u516c\u53f8\u548c\u94f6\u884c\u7cfb\u65e0\u8dd1\u8def\u3002", 
            "title": "p2p\u7f51\u8d37\u5e73\u53f0\u80cc\u666f"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_8", 
            "text": "df.loc[:,  touziq ] = df[ touziq ].map(lambda x: np.round(x, 4))\ndf_span = df.loc[df[ touziq ] != 2.5784, :]  # (1524, 12)\ndf_span.loc[:,  touziq ] = df_span[ touziq ].map(lambda x: np.round(x))\ndf_span.loc[df_span[ touziq ] == 0,  touziq ] = 0.5\ndf_span.loc[:,  touziq ] = df_span['touziq'].astype(np.int64)  plt.figure(figsize=(10,6))\ng = sns.barplot(x= touziq , y= averageI , data=df_span, hue= classification )\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\nplt.ylabel(u \u5e73\u5747\u5e74\u5316\u5229\u7387% , fontsize=16, fontproperties=font)\nplt.xlabel(u \u6295\u8d44\u671f\u9650(\u6708) , fontsize=16, fontproperties=font)\nplt.title(u p2p\u5e73\u53f0\u5e73\u5747\u5e74\u5316\u5229\u7387\u4e0e\u6295\u8d44\u671f\u9650 , fontproperties=font, fontsize=20)\nplt.gca().yaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc= best ,prop=font, fontsize=17)  matplotlib.legend.Legend at 0x7f14b2acf0d0    span = df_span.groupby( classification )[ touziq ].value_counts().unstack().unstack().unstack().fillna(0)\nspan[ total ] = span.sum(axis=1)\nspan_cum = span.div(span[ total ], axis=0)*100\nspan_cum.drop( total , axis=1, inplace=True)\nspan.drop( total , axis=1, inplace=True)\nfig1, (ax1, ax2) = plt.subplots(2,1, sharex=True, figsize=(12,9)) \nspan_cum.plot(kind='bar',ax=ax1, stacked=True, label= )\nspan.plot(kind='bar',ax=ax2, stacked=True)\nax1.legend(loc=2, prop=font, fontsize=17)\nax2.legend(loc='best', prop=font, fontsize=17)\nax2.xaxis.grid(False)\nax2.yaxis.grid(True, linestyle= -. )\nax1.yaxis.grid(True, linestyle= -. )\nax2.set_ylabel(u \u6570\u91cf , fontsize=16, fontproperties=font)\nax1.set_ylabel(u \u767e\u5206\u6bd4% , fontsize=16, fontproperties=font) \nax2.annotate(u'\u5c0f\u4e8e1\u4e2a\u6708',xy=(0,30),xytext=(0,100),fontproperties=font,arrowprops=dict(arrowstyle= - ,color='k',linewidth=3)) \nplt.xlabel(u \u6295\u8d44\u671f\u9650(\u6708) , fontproperties=font, fontsize=17)  matplotlib.text.Text at 0x7f14b0e47550    p2p\u7f51\u8d37\u7684\u6295\u8d44\u671f\u9650\u53d8\u5316\u8303\u56f4\u5f88\u5bbd\u6cdb\uff0c\u5c11\u7684\u77ed\u5219\u51e0\u5929\uff0c\u591a\u7684\u957f\u8fbe\u51e0\u5e74\u3002\u4e3a\u4e86\u65b9\u4fbf\uff0c\u5c06\u79d2\u6807\u3001\u5929\u6807\u7b49\u5c0f\u4e8e1\u4e2a\u6708\u7684\u7f51\u8d37\u5e73\u53f0\u8bb0\u4e3a\u5c0f\u4e8e1\u4e2a\u6708(0)\uff0c\u5c06\u5927\u4e8e\u7b49\u4e8e24\u4e2a\u6708\u7684\u5e73\u53f0\u8bb0\u4e3a24\u4e2a\u6708\u3002\u5927\u90e8\u5206\u7f51\u8d37\u5e73\u53f0\u7684\u6295\u8d44\u671f\u9650\u5c0f\u4e8e\u534a\u5e74\uff0c\u5c24\u5176\u96c6\u4e2d\u57281\u6708\u30012\u6708\u30013\u6708\u6807\u53ca\u5929\u6807\u4e0a\u3002\u800c\u8dd1\u8def\u7684\u7f51\u8d37\u5e73\u53f0\u4e5f\u591a\u96c6\u4e2d\u5728\u77ed\u671f\u6295\u8d44\u4e0a\u3002\u4e00\u5e74\u4ee5\u4e0a\u7684\u6295\u8d44\u671f\u9650\u7684\u5e73\u53f0\u6ca1\u6709\u8dd1\u8def\u73b0\u8c61\u3002\u56e0\u6b64\uff0c\u5728\u9009\u62e9p2p\u5e73\u53f0\u65f6\uff0c\u8981\u9009\u62e9\u6295\u8d44\u671f\u9650\u957f\u7684\u4e3a\u5b9c\u3002", 
            "title": "\u6295\u8d44\u671f\u9650"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#p2p_3", 
            "text": "\u901a\u8fc7\u524d\u9762\u7684\u7b80\u5355\u7684\u63a2\u7d22\u5206\u6790\u6211\u4eec\u5bf9p2p\u7f51\u8d37\u5e73\u53f0\u7684\u51e0\u4e2a\u6837\u672c\u7279\u5f81\u4e0e\u5e73\u53f0\u8dd1\u8def\u7684\u5173\u7cfb\u6709\u4e86\u4e00\u5b9a\u8ba4\u8bc6\uff0c\u4e0b\u9762\u5c1d\u8bd5\u5229\u7528\u673a\u5668\u5b66\u4e60\u7684\u51b3\u7b56\u6811\u5206\u7c7b\u7b97\u6cd5\u6765\u5206\u6790\u548c\u9884\u6d4bp2p\u7f51\u8d37\u5e73\u53f0\u7684\u8dd1\u8def\u73b0\u8c61\u3002", 
            "title": "p2p\u8dd1\u8def\u539f\u56e0\u5206\u6790\u53ca\u9884\u6d4b"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_9", 
            "text": "\u91c7\u7528\u76f8\u5173\u7cfb\u6570\u77e9\u9635\u548c\u9012\u5f52\u7279\u5f81\u6d88\u9664\u6cd5(RFE)\u8bc4\u4f30\u7279\u5f81\u6307\u6807\u7684\u91cd\u8981\u6027\uff0c\u8fdb\u800c\u9009\u62e9\u5408\u9002\u7684\u6837\u54c1\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u8bad\u7ec3\u3002  # dall.shape  # (3895, 12)\n# dall.head(3)\n# dall.isnull()\ndall.count()\n((dall.shape[0] - dall.count()) / dall.shape[0] * 100). round(2)  name              0.0\naverageI          0.0\ndate              0.0\nzhuzed            0.0\nclassification    0.0\ntouziq            0.0\nnetF              0.0\nbackground        0.0\ntuoguan           0.0\nzhuz              0.0\nshiz              0.0\ndatetime          0.0\ndtype: float64  dall.head(3)   \n   \n     \n       \n       name \n       averageI \n       date \n       zhuzed \n       classification \n       touziq \n       netF \n       background \n       tuoguan \n       zhuz \n       shiz \n       datetime \n     \n   \n   \n     \n       0 \n       108\u8d37 \n       14.548392 \n       2015-02-26 \n       44.0 \n       0.0 \n       2.578413 \n       14.351883 \n       0 \n       0 \n       500 \n       0 \n       5.326389e+07 \n     \n     \n       1 \n       2025\u91d1\u878d \n       14.548392 \n       2015-11-16 \n       11.0 \n       0.0 \n       2.578413 \n       14.351883 \n       0 \n       0 \n       2000 \n       0 \n       3.054069e+07 \n     \n     \n       2 \n       51\u5e2e\u4f60 \n       12.460000 \n       2012-08-15 \n       33.0 \n       1.0 \n       1.172000 \n       16.500000 \n       0 \n       1 \n       3000 \n       2000 \n       1.331839e+08 \n     \n      # \u6682\u4e14\u4e0d\u8003\u8651p2p\u7f51\u8d37\u5e73\u53f0\u540d\u79f0\u548c\u6210\u7acb\u65e5\u671f\ndata = dall.drop([ name ,  date ,], axis=1)  \ncols = data.columns.tolist()\ndata.head(3)   \n   \n     \n       \n       averageI \n       zhuzed \n       classification \n       touziq \n       netF \n       background \n       tuoguan \n       zhuz \n       shiz \n       datetime \n     \n   \n   \n     \n       0 \n       14.548392 \n       44.0 \n       0.0 \n       2.578413 \n       14.351883 \n       0 \n       0 \n       500 \n       0 \n       5.326389e+07 \n     \n     \n       1 \n       14.548392 \n       11.0 \n       0.0 \n       2.578413 \n       14.351883 \n       0 \n       0 \n       2000 \n       0 \n       3.054069e+07 \n     \n     \n       2 \n       12.460000 \n       33.0 \n       1.0 \n       1.172000 \n       16.500000 \n       0 \n       1 \n       3000 \n       2000 \n       1.331839e+08 \n     \n      # corrcoef\u51fd\u6570\u8ba1\u7b97\u76f8\u5173\u7cfb\u6570,\u66f4\u7cbe\u786e\u5730\u662f\u76f8\u5173\u7cfb\u6570\u77e9\u9635\ncm = np.corrcoef(data[cols].values.T)\nplt.figure(figsize=(10,8))\ng = sns.heatmap(cm, cbar=True, annot=True, \n            square=True, fmt= .2f , \n            annot_kws={'size': 15}, \n           yticklabels=cols,xticklabels=cols)\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)  ([ matplotlib.axis.XTick at 0x7f4cbaab8c50 ,\n   matplotlib.axis.XTick at 0x7f4cbab0e050 ,\n   matplotlib.axis.XTick at 0x7f4cba9db890 ,\n   matplotlib.axis.XTick at 0x7f4cba9dbdd0 ,\n   matplotlib.axis.XTick at 0x7f4cba9e3310 ,\n   matplotlib.axis.XTick at 0x7f4cba9e39d0 ,\n   matplotlib.axis.XTick at 0x7f4cba9ec110 ,\n   matplotlib.axis.XTick at 0x7f4cba9ec810 ,\n   matplotlib.axis.XTick at 0x7f4cba9ecc90 ,\n   matplotlib.axis.XTick at 0x7f4cba9f93d0 ],\n  a list of 10 Text xticklabel objects )   \u4ece\u76f8\u5173\u7cfb\u6570\u77e9\u9635\uff0c\u6295\u8d44\u671f\u9650\u548c\u5e73\u5747\u5229\u7387\u4e0e\u5206\u7c7b\u6807\u7b7e\uff08\u662f\u5426\u8dd1\u8def\uff09\u6709\u8f83\u5f3a\u7684\u7ebf\u6027\u76f8\u5173\u6027\uff0c\u6ce8\u518c\u8d44\u672c\u7ebf\u6027\u76f8\u5173\u6027\u6700\u4f4e\uff0c\u5176\u4ed6\u7684\u7279\u5f81\u6709\u4e00\u5b9a\u7684\u7ebf\u6027\u76f8\u5173\u6027\uff0c\u4f46\u5f3a\u5ea6\u8f83\u5f31\u3002  import datetime\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RandomizedLasso\nfrom sklearn.linear_model import RandomizedLogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV  y = data.pop( classification )\nX = data\nfeatures = X.columns.values  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\nsc = StandardScaler()\nsc.fit(X_train)  # \u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\nX_train_std = sc.transform(X_train)  # \u8fdb\u884c\u6807\u51c6\u53d8\u6362\uff0c\u53d8\u6210\u6807\u51c6\u6b63\u6001\u5206\u5e03\nX_test_std = sc.transform(X_test)  \n\u9012\u5f52\u6d88\u9664\u7279\u5f81\u6cd5\u4f7f\u7528\u4e00\u4e2a\u57fa\u6a21\u578b\u6765\u8fdb\u884c\u591a\u8f6e\u8bad\u7ec3\uff0c\u6bcf\u8f6e\u8bad\u7ec3\u540e\uff0c\u9009\u51fa\u6700\u597d\u7684\u7684\u7279\u5f81\uff0c\n\u7136\u540e\u5728\u5269\u4f59\u7684\u7279\u5f81\u4e0a\u91cd\u590d\u8fd9\u4e2a\u8fc7\u7a0b\u3002\u6574\u4e2a\u8fc7\u7a0b\u4e2d\u7279\u5f81\u88ab\u6d88\u9664\u7684\u6b21\u5e8f\u5c31\u662f\u7279\u5f81\u7684\u6392\u5e8f\u3002\nRFE\u7684\u7a33\u5b9a\u6027\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u5728\u8fed\u4ee3\u7684\u65f6\u5019\u5e95\u5c42\u7528\u54ea\u79cd\u6a21\u578b\u3002\u53c2\u6570estimator\u4e3a\u57fa\u6a21\u578b\uff0c\n\u53c2\u6570n_features_to_select\u4e3a\u9009\u62e9\u7684\u7279\u5f81\u4e2a\u6570\u3002  \nestimator = LogisticRegression()\nselector = RFE(estimator, n_features_to_select=1, step=1)  \nselector = selector.fit(X_train_std, y_train) \nbag = sorted(zip(features, selector.ranking_, selector.support_),\n             key=lambda x: x[1])\nbag  [('background', 1, True),\n ('tuoguan', 2, False),\n ('shiz', 3, False),\n ('averageI', 4, False),\n ('netF', 5, False),\n ('zhuz', 6, False),\n ('touziq', 7, False),\n ('zhuzed', 8, False),\n ('datetime', 9, False)]  \n\u7a33\u5b9a\u6027\u9009\u62e9\u662f\u4e00\u79cd\u57fa\u4e8e\u4e8c\u6b21\u62bd\u6837\u548c\u9009\u62e9\u7b97\u6cd5\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u9009\u62e9\u7b97\u6cd5\u53ef\u4ee5\u662f\u56de\u5f52\u3001SVM\u6216\u5176\u4ed6\n\u7c7b\u4f3c\u7684\u65b9\u6cd5\u3002\u5b83\u7684\u4e3b\u8981\u601d\u60f3\u662f\u5728\u4e0d\u540c\u7684\u6570\u636e\u5b50\u96c6\u548c\u7279\u5f81\u5b50\u96c6\u4e0a\u8fd0\u884c\u7279\u5f81\u9009\u62e9\u7b97\u6cd5\uff0c\u4e0d\u65ad\u7684\u91cd\u590d\uff0c\n\u6700\u7ec8\u6c47\u603b\u7279\u5f81\u9009\u62e9\u7ed3\u679c\uff0c\u6bd4\u5982\u53ef\u4ee5\u7edf\u8ba1\u67d0\u4e2a\u7279\u5f81\u88ab\u8ba4\u4e3a\u662f\u91cd\u8981\u7279\u5f81\u7684\u9891\u7387\uff08\u88ab\u9009\u4e3a\u91cd\u8981\u7279\u5f81\u7684\n\u6b21\u6570\u9664\u4ee5\u5b83\u6240\u5728\u7684\u5b50\u96c6\u88ab\u6d4b\u8bd5\u7684\u6b21\u6570\uff09\u3002\u7406\u60f3\u60c5\u51b5\u4e0b\uff0c\u91cd\u8981\u7279\u5f81\u7684\u5f97\u5206\u4f1a\u63a5\u8fd1100%\u3002\u7a0d\u5fae\u5f31\u4e00\u70b9\n\u7684\u7279\u5f81\u5f97\u5206\u4f1a\u662f\u975e0\u7684\u6570\uff0c\u800c\u6700\u65e0\u7528\u7684\u7279\u5f81\u5f97\u5206\u5c06\u4f1a\u63a5\u8fd1\u4e8e0\u3002\nsklearn\u63d0\u4f9b\u4e86\u968f\u673alasso\u548c\u968f\u673a\u903b\u8f91\u56de\u5f52\u3002 \nrlg = RandomizedLogisticRegression()\nrlg.fit(X_train, y_train)\nbag_rr = sorted(zip(features, rlg.scores_), key=lambda x: x[1], reverse=True)\nbag_rr  [('averageI', 1.0),\n ('netF', 1.0),\n ('background', 1.0),\n ('tuoguan', 1.0),\n ('touziq', 0.56000000000000005),\n ('zhuzed', 0.53500000000000003),\n ('shiz', 0.40000000000000002),\n ('datetime', 0.23000000000000001),\n ('zhuz', 0.0)]  \u7efc\u5408\u76f8\u5173\u7cfb\u6570\u77e9\u9635\u3001\u9012\u5f52\u6d88\u9664\u7279\u5f81\u6cd5\u3001\u7a33\u5b9a\u6027\u9009\u62e9\u7684\u8bc4\u4f30\u7ed3\u679c\uff0c\u5e73\u5747\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u5e73\u53f0\u80cc\u666f\u3001\u6709\u65e0\u6258\u7ba1\u56db\u4e2a\u7279\u5f81\u4e0ep2p\u7f51\u8d37\u5e73\u53f0\u7684\u662f\u5426\u8dd1\u8def\u7ebf\u6027\u76f8\u5173\u6027\u8f83\u5927\uff0c\u6211\u4eec\u5148\u91c7\u7528\u8fd9\u56db\u4e2a\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u6784\u5efa\u3002", 
            "title": "\u6837\u672c\u7279\u5f81\u9009\u62e9"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_10", 
            "text": "# \u7528sklearn\u7684learning_curve\u5f97\u5230training_score\u548ccv_score\uff0c\u4f7f\u7528matplotlib\u753b\u51falearning curve\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=5, n_jobs=1, \n                        train_sizes=np.linspace(.05, 1., 20), \n                        verbose=0, plot=True, text_=None):\n     \n    \u753b\u51fadata\u5728\u67d0\u6a21\u578b\u4e0a\u7684learning curve.\n    \u53c2\u6570\u89e3\u91ca\n    ----------\n    estimator : \u4f7f\u7528\u7684\u5206\u7c7b\u5668\u3002\n    title : \u56fe\u7684\u6807\u9898\u3002\n    X : \u8f93\u5165\u7684feature\uff0cnumpy\u7c7b\u578b\n    y : \u8f93\u5165\u7684target vector\n    ylim : tuple\u683c\u5f0f\u7684(ymin, ymax), \u8bbe\u5b9a\u56fe\u50cf\u4e2d\u7eb5\u5750\u6807\u7684\u6700\u4f4e\u70b9\u548c\u6700\u9ad8\u70b9\n    cv : \u505across-validation\u7684\u65f6\u5019\uff0c\u6570\u636e\u5206\u6210\u7684\u4efd\u6570\uff0c\u5176\u4e2d\u4e00\u4efd\u4f5c\u4e3acv\u96c6\uff0c\u5176\u4f59n-1\u4efd\u4f5c\u4e3atraining(\u9ed8\u8ba4\u4e3a3\u4efd)\n    n_jobs : \u5e76\u884c\u7684\u7684\u4efb\u52a1\u6570(\u9ed8\u8ba41)\n     \n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n    train_scores_mean = np.mean(train_scores, axis=1)  # train_scores\u662f\u4e00\u4e2a\uff12\uff10\u884c\uff15\u5217\u7684ndarry,20\u4e3a\u4ece\u6837\u672c\u53d6\u7684\u4e0d\u540c\u6bd4\u4f8b\u7684\u6837\u672c\u6570\u636e\u4f5c\u4e3aX, \u800c\uff15\u8868\u793a\uff15\u6b21\u4ea4\u53c9\u9a8c\u8bc1\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    if plot:\n        plt.figure(figsize=(7,7))\n        plt.title(title)\n        if ylim is not None:\n            plt.ylim(*ylim)\n        plt.xlabel( samples )\n        plt.ylabel( scores )\n        # plt.gca().invert_yaxis() \u4f8b\u5982y\u8f74\u5750\u68073000-10000\uff0c\u8c03\u6574\u4e3a10000-3000\u6765\u663e\u793a\n        plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, \n                         alpha=0.2, color= b )\n        plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, \n                         alpha=0.2, color= r )\n        plt.plot(train_sizes, train_scores_mean, '^-', color= blue , label= train score )\n        plt.plot(train_sizes, test_scores_mean, 'v-', color= red , label= cross_validation score )\n        plt.legend(loc= best )\n        plt.gca().yaxis.grid(True, linestyle =  -. )\n        plt.gca().xaxis.grid(True, linestyle =  -. )   \n        plt.text(500, 0.754, text_, size = 12, color =  k , weight =  light , bbox = dict(facecolor =  purple , alpha = 0.3))   \n        # plt.text(60, .025, r'$\\mu=100,\\ \\sigma=15$')\n        plt.show()", 
            "title": "\u5206\u7c7b\u6a21\u578b\u6784\u5efa"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#logisticreregession", 
            "text": "def evaluate_feature(df, feature_add, C_):\n     \u8bc4\u4f30\u589e\u52a0\u65b0\u7684\u7279\u5f81\u7684\u5206\u7c7b\u51c6\u786e\u7387 \n    raw_feature = ['averageI','classification','netF',\n                   'background','tuoguan']\n    raw_feature.extend(feature_add) if type(feature_add) == list else raw_feature.append(feature_add)\n    data = df[raw_feature]\n    y = data.pop( classification )\n    X = data\n    for i in X.columns.tolist():\n        if i in [ background ,  tuoguan ,  zhuzed ]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if  touziq  in X_dummies.columns.tolist():\n            X_dummies[ touziq ] = X_dummies[ touziq ].astype(np.int)\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    lr = LogisticRegression(C=C_, penalty= l2 , random_state=24, tol=1e-6)\n    lr.fit(X_train, y_train)\n    y_pred = lr.predict(X_test)\n    num_test = len(y_test)\n    result = (num_test - (y_test != y_pred).sum()) / float(num_test) * 100\n    feature_str =  add feature:  +  , .join(feature_add) if feature_add else      \n    content =  {2} accuracy_score:{0} C:{1} .format(np.round(result, 4), C_, feature_str)\n    plot_learning_curve(lr,  learning curve , X_train, y_train, text_=content)      for i in [None,  touziq ,  zhuzed ]:\n    add_feature = []\n    if i is not None:\n        add_feature.append(i)\n    evaluate_feature(dall, add_feature, 0.5)         for C in [0.01, 0.05, 0.1, 0.5, 1]:\n    evaluate_feature(dall, [ touziq ], C)       \u5f53\u9009\u62e9\u5e73\u5747\u5e74\u5316\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u5e73\u53f0\u8d44\u8d28\u56db\u4e2a\u7279\u5f81\uff0c\u6b63\u5219\u5316\u7cfb\u6570\u4e3a0.5\u5019\uff0cLogisticRegression\u7684\u5206\u7c7b\u51c6\u786e\u7387\u4e3a76.5%\uff0c\u5f53\u589e\u52a0\u6295\u8d44\u671f\u9650\u7684\u5206\u7c7b\u7279\u5f81\u65f6\u5019\uff0c\u51c6\u786e\u7387\u7565\u6709\u63d0\u9ad8\u8fbe\u523077.1%\uff0c\u5f53\u589e\u52a0\u6ce8\u518c\u5730\u7684\u5206\u7c7b\u7279\u5f81\u65f6\u5019\uff0c\u51c6\u786e\u7387\u53cd\u800c\u964d\u4f4e\u3002  def evaluate_feature(df, C_):\n     \u8bc4\u4f30\u589e\u52a0\u65b0\u7684\u7279\u5f81\u7684\u5206\u7c7b\u51c6\u786e\u7387 \n    # raw_feature = features\n    # ['averageI','classification','netF', 'background','tuoguan']\n    # raw_feature.extend(feature_add) if type(feature_add) == list else raw_feature.append(feature_add)\n    # data = df[raw_feature]\n    feature_add =  \n    data = df.drop([ name ,  datetime ,], axis=1) \n    y = data.pop( classification )\n    X = data[['averageI','netF', 'background','tuoguan', \n              'touziq', 'shiz', 'date']]  #  datetime 'zhuzed'\n    # \u52a0\u5165\u6ce8\u518c\u5730\u5bf9\u5206\u7c7b\u6548\u679c\u6ca1\u6709\u660e\u663e\u5e2e\u52a9\uff0c\u5373\u4f7f\u51cf\u5c11\u6ce8\u518c\u5730\u7684\u7c7b\u522b\u4e5f\u65e0\u76ca\u6700\u7ec8\u5206\u7c7b\u6548\u679c\n    if  zhuzed  in X.columns.tolist():\n        set_zhu_all = set(data[ zhuzed ].unique().tolist())\n        set_zhu_pa = set(data[ zhuzed ].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[ zhuzed ] = X[ zhuzed ].replace(zhu_replace,[100] * len(zhu_replace))\n    if  date  in X.columns.tolist():\n        date_str = X[ date ].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime( 2016-12 )\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(   ).str.get(0).astype(int) \n        X[ date ] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [ background ,  tuoguan ,  zhuzed ]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if  touziq  in X_dummies.columns.tolist():\n            X_dummies[ touziq ] = X_dummies[ touziq ].astype(np.int)\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    lr = LogisticRegression(C=C_, penalty= l2 , random_state=24, tol=1e-6)\n    lr.fit(X_train, y_train)\n    y_pred = lr.predict(X_test)\n    num_test = len(y_test)\n    result = (num_test - (y_test != y_pred).sum()) / float(num_test) * 100\n    feature_str =  add feature:  +  , .join(feature_add) if feature_add else      \n    content =  {2} accuracy_score:{0} C:{1} .format(np.round(result, 4), C_, feature_str)\n    plot_learning_curve(lr,  learning curve , X_train, y_train, text_=content)      evaluate_feature(dall, 0.1)       \u9009\u53d6\u5e73\u5747\u5e74\u5316\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u5e73\u53f0\u8d44\u8d28\u3001\u6ce8\u518c\u65e5\u671f\uff0c\u5b9e\u7f34\u8d44\u672c\u4e3a\u5206\u7c7b\u7279\u5f81\uff0c\u4f7f\u7528LogisticRegression\u6784\u5efa\u5206\u7c7b\u5668\uff0c\u5f53\u6b63\u5219\u5316\u4e3aC=0.1\u65f6\u5019\uff0c\u6d4b\u8bd5\u96c6\u5206\u7c7b\u51c6\u53d6\u7387\u4e3a77.9%\u3002", 
            "title": "LogisticReregession \u5206\u7c7b\u6a21\u578b\u6784\u5efa"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_11", 
            "text": "\u9009\u53d6\u5e73\u5747\u5e74\u5316\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u5e73\u53f0\u8d44\u8d28\u3001\u6295\u8d44\u671f\u3001\u6ce8\u518c\u65e5\u671f\u3001\u5b9e\u7f34\u8d44\u672c\u4e3a\u5206\u7c7b\u7279\u5f81\uff0c\u968f\u673a\u68ee\u6797\u8fdb\u884c\u5206\u7c7b\uff0c\u5c1d\u8bd5\u5bf9\u5173\u952e\u53c2\u6570\u8fdb\u884c\u8c03\u8bd5\u3002  def rf_test_n_estimator(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop( classification )\n    X = data\n    if  zhuzed  in X.columns.tolist():\n        set_zhu_all = set(data[ zhuzed ].unique().tolist())\n        set_zhu_pa = set(data[ zhuzed ].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[ zhuzed ] = X[ zhuzed ].replace(zhu_replace,[100] * len(zhu_replace))\n    if  date  in X.columns.tolist():\n        date_str = X[ date ].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime( 2016-12 )\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(   ).str.get(0).astype(int) \n        X[ date ] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [ background ,  tuoguan ,  zhuzed ]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if  touziq  in X_dummies.columns.tolist():\n            X_dummies[ touziq ] = X_dummies[ touziq ].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(10, 210, 20):\n        clf = RandomForestClassifier(n_estimators=i, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n        # cross_val_score_ = dict(zip(cross_val_score_i, cross_val_score))\n        # print( Accuracy: %0.2f (+/- %0.2f) [%s]  % (scores.mean(), scores.std(), label))\n\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'n_estimator\u6570\u91cf', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)             rf_test_n_estimator(dall)      def rf_test_max_depth(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop( classification )\n    X = data\n    if  zhuzed  in X.columns.tolist():\n        set_zhu_all = set(data[ zhuzed ].unique().tolist())\n        set_zhu_pa = set(data[ zhuzed ].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[ zhuzed ] = X[ zhuzed ].replace(zhu_replace,[100] * len(zhu_replace))\n    if  date  in X.columns.tolist():\n        date_str = X[ date ].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime( 2016-12 )\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(   ).str.get(0).astype(int) \n        X[ date ] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [ background ,  tuoguan ,  zhuzed ]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if  touziq  in X_dummies.columns.tolist():\n            X_dummies[ touziq ] = X_dummies[ touziq ].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(5, 26, 5):\n        clf = RandomForestClassifier(max_depth=i, n_estimators=100, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'max_depth', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)           rf_test_max_depth(dall)   def rf_test_max_feature(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop( classification )\n    X = data\n    if  zhuzed  in X.columns.tolist():\n        set_zhu_all = set(data[ zhuzed ].unique().tolist())\n        set_zhu_pa = set(data[ zhuzed ].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[ zhuzed ] = X[ zhuzed ].replace(zhu_replace,[100] * len(zhu_replace))\n    if  date  in X.columns.tolist():\n        date_str = X[ date ].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime( 2016-12 )\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(   ).str.get(0).astype(int) \n        X[ date ] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [ background ,  tuoguan ,  zhuzed ]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if  touziq  in X_dummies.columns.tolist():\n            X_dummies[ touziq ] = X_dummies[ touziq ].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(1, len(X.columns.tolist())):\n        clf = RandomForestClassifier(max_features=i, max_depth=10, n_estimators=100, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'max_feature', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)           rf_test_max_feature(dall)   def rf_test_min_samples_split(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop( classification )\n    X = data\n    if  zhuzed  in X.columns.tolist():\n        set_zhu_all = set(data[ zhuzed ].unique().tolist())\n        set_zhu_pa = set(data[ zhuzed ].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[ zhuzed ] = X[ zhuzed ].replace(zhu_replace,[100] * len(zhu_replace))\n    if  date  in X.columns.tolist():\n        date_str = X[ date ].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime( 2016-12 )\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(   ).str.get(0).astype(int) \n        X[ date ] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [ background ,  tuoguan ,  zhuzed ]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if  touziq  in X_dummies.columns.tolist():\n            X_dummies[ touziq ] = X_dummies[ touziq ].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(2, 11, 2):\n        clf = RandomForestClassifier(min_samples_split=i, max_features=3, max_depth=10, n_estimators=100, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'min_sample_split', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)  rf_test_min_samples_split(dall)    def rf_test_min_samples_leaf(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop( classification )\n    X = data\n    if  zhuzed  in X.columns.tolist():\n        set_zhu_all = set(data[ zhuzed ].unique().tolist())\n        set_zhu_pa = set(data[ zhuzed ].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[ zhuzed ] = X[ zhuzed ].replace(zhu_replace,[100] * len(zhu_replace))\n    if  date  in X.columns.tolist():\n        date_str = X[ date ].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime( 2016-12 )\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(   ).str.get(0).astype(int) \n        X[ date ] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [ background ,  tuoguan ,  zhuzed ]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if  touziq  in X_dummies.columns.tolist():\n            X_dummies[ touziq ] = X_dummies[ touziq ].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    cross_score = []\n    cross_score_i = []\n    for i in range(2, 11, 2):\n        clf = RandomForestClassifier(min_samples_leaf=i, min_samples_split=2, max_features=3, max_depth=10, n_estimators=100, random_state=24)\n        scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n        mean_score = scores.mean()\n        cross_score.append(mean_score)\n        cross_score_i.append(i)\n    x_num = len(cross_score)\n    fig, ax = plt.subplots(figsize=(8,6)) \n    sns.pointplot(range(x_num), cross_score, ax=ax)\n    ax.set_ylabel(u'\u4ea4\u53c9\u9a8c\u8bc1\u51c6\u786e\u7387', fontsize=15, fontproperties=font)\n    ax.set_xlabel(u'min_sample_leaf', fontsize=15, fontproperties=font)\n    ax.set_xticklabels(cross_score_i, rotation=30)  rf_test_min_samples_leaf(dall)   def rf(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop( classification )\n    X = data\n    if  zhuzed  in X.columns.tolist():\n        set_zhu_all = set(data[ zhuzed ].unique().tolist())\n        set_zhu_pa = set(data[ zhuzed ].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[ zhuzed ] = X[ zhuzed ].replace(zhu_replace,[100] * len(zhu_replace))\n    if  date  in X.columns.tolist():\n        date_str = X[ date ].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime( 2016-12 )\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(   ).str.get(0).astype(int) \n        X[ date ] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [ background ,  tuoguan ,  zhuzed ]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if  touziq  in X_dummies.columns.tolist():\n            X_dummies[ touziq ] = X_dummies[ touziq ].astype(np.int)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n    clf = RandomForestClassifier(min_samples_leaf=6, min_samples_split=8, max_features=3, max_depth=10, n_estimators=100, random_state=24)\n    clf.fit(X_train, y_train)    \n    y_pred = clf.predict(X_test)\n    num_test = len(y_test)\n    result = (num_test - (y_test != y_pred).sum()) / float(num_test) * 100\n    plot_learning_curve(clf,  learning curve , X_train, y_train, text_=result)        \n    #print '\\t%s\\t%s\\t%s\\t%s' % ('\u5206\u7c7b','\u7cbe\u786e\u7387','\u53ec\u56de\u7387','f1-score')\n    evaluate_result_rf = classification_report(y_test, y_pred)\n    #print '0 \uff1ap2p\u5e73\u53f0\u8dd1\u8def(\u6216\u51fa\u73b0\u5176\u4ed6\u975e\u6b63\u5e38\u8fd0\u8425\u7684\u95ee\u9898)' \n    #print '1 \uff1a\u6b63\u5e38\u8fd0\u8425' \n    return evaluate_result_rf     evaluate_result_rf = rf(dall)   evaluate_result_rf  '             precision    recall  f1-score   support\\n\\n        0.0       0.82      0.82      0.82       392\\n        1.0       0.82      0.82      0.82       387\\n\\navg / total       0.82      0.82      0.82       779\\n'  \u4f7f\u7528GridSearchCV\u8fdb\u4e00\u6b65\u641c\u7d22\u6700\u4f18\u53c2\u6570  def randomforest_classifier_gs(df):   \n    feature = ['averageI','classification','netF',\n                   'background','tuoguan','touziq','date', 'shiz']\n    data = df[feature]\n    y = data.pop( classification )\n    X = data\n    if  zhuzed  in X.columns.tolist():\n        set_zhu_all = set(data[ zhuzed ].unique().tolist())\n        set_zhu_pa = set(data[ zhuzed ].value_counts().index[:1].tolist())\n        zhu_replace = list(set_zhu_all - set_zhu_pa)       \n        X[ zhuzed ] = X[ zhuzed ].replace(zhu_replace,[100] * len(zhu_replace))\n    if  date  in X.columns.tolist():\n        date_str = X[ date ].str.slice(0,7)\n        date_ = pd.to_datetime(date_str)\n        last = pd.to_datetime( 2016-12 )\n        day_dela = (last - date_)\n        day_str = day_dela.astype(str)\n        day_ = day_str.str.split(   ).str.get(0).astype(int) \n        X[ date ] = (day_ / 30).astype(np.int)\n    for i in X.columns.tolist():\n        if i in [ background ,  tuoguan ,  zhuzed ]:\n            dummies_ = pd.get_dummies(X[i], prefix=i)\n            X_dummies = pd.concat([X, dummies_], axis=1)\n            X_dummies.drop([i], axis=1, inplace=True)\n\n    if  touziq  in X_dummies.columns.tolist():\n            X_dummies[ touziq ] = X_dummies[ touziq ].astype(np.int)\n    X_train, X_test, y_train, y_test = train_test_split(X_dummies, y, test_size=0.2, random_state=0)\n\n    pipeline = Pipeline([('clf', RandomForestClassifier(criterion='gini'))])\n    parameters = {\n                  'clf__n_estimators': (100, 120, 140),\n                  'clf__max_depth': (10, 12),\n                  'clf__min_samples_split': (7, 8, 9),\n                  'clf__min_samples_leaf': (5, 6, 7),\n                  'clf__max_features': (3, 5)\n                  }\n    grid_search = GridSearchCV(pipeline, parameters, n_jobs=2, verbose=1, scoring='accuracy')\n    grid_search.fit(X_train, y_train)\n    accuracy_score =  best_accuray_score: {} .format(grid_search.best_score_) \n    best_parameters = grid_search.best_estimator_.get_params()\n    parameters = sorted(parameters.keys())\n    #print  \\t%s: %r  % (param_name, best_parameters[param_name])\n    predictions = grid_search.predict(X_test)\n    print '\\t%s\\t%s\\t%s\\t%s' % ('\u5206\u7c7b','\u7cbe\u786e\u7387','\u53ec\u56de\u7387','f1-score')\n    evaluate_result = classification_report(y_test, predictions)\n    #print '0 \uff1ap2p\u5e73\u53f0\u8dd1\u8def(\u6216\u51fa\u73b0\u5176\u4ed6\u975e\u6b63\u5e38\u8fd0\u8425\u7684\u95ee\u9898)' \n    #print '1 \uff1a\u6b63\u5e38\u8fd0\u8425' \n    return accuracy_score, best_parameters, evaluate_result      randomforest_classifier_gs(dall)  ('best_accuray_score: 0.821566110398',\n {'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n              max_depth=10, max_features=3, max_leaf_nodes=None,\n              min_impurity_split=1e-07, min_samples_leaf=6,\n              min_samples_split=7, min_weight_fraction_leaf=0.0,\n              n_estimators=120, n_jobs=1, oob_score=False, random_state=None,\n              verbose=0, warm_start=False),\n  'clf__bootstrap': True,\n  'clf__class_weight': None,\n  'clf__criterion': 'gini',\n  'clf__max_depth': 10,\n  'clf__max_features': 3,\n  'clf__max_leaf_nodes': None,\n  'clf__min_impurity_split': 1e-07,\n  'clf__min_samples_leaf': 6,\n  'clf__min_samples_split': 7,\n  'clf__min_weight_fraction_leaf': 0.0,\n  'clf__n_estimators': 120,\n  'clf__n_jobs': 1,\n  'clf__oob_score': False,\n  'clf__random_state': None,\n  'clf__verbose': 0,\n  'clf__warm_start': False,\n  'steps': [('clf',\n    RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                max_depth=10, max_features=3, max_leaf_nodes=None,\n                min_impurity_split=1e-07, min_samples_leaf=6,\n                min_samples_split=7, min_weight_fraction_leaf=0.0,\n                n_estimators=120, n_jobs=1, oob_score=False, random_state=None,\n                verbose=0, warm_start=False))]},\n '             precision    recall  f1-score   support\\n\\n        0.0       0.83      0.81      0.82       392\\n        1.0       0.81      0.83      0.82       387\\n\\navg / total       0.82      0.82      0.82       779\\n')  \u9009\u53d6\u5e73\u5747\u5e74\u5316\u5229\u7387\u3001\u7f51\u53cb\u8bc4\u5206\u3001\u8d44\u91d1\u6258\u7ba1\u3001\u5e73\u53f0\u8d44\u8d28\u3001\u6295\u8d44\u671f\u3001\u6ce8\u518c\u65e5\u671f\u3001\u5b9e\u7f34\u8d44\u672c\u4e3a\u5206\u7c7b\u7279\u5f81\uff0cRandomForestClassifier\u7684\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u670982%\uff0c\u7cbe\u786e\u7387\u3001\u53ec\u56de\u7387\u4e5f\u662f82%\uff0c\u4f46\u4ecelearning curve\u80fd\u770b\u51fa\u5b58\u5728\u7740\u8fc7\u62df\u5408\u73b0\u8c61\u3002", 
            "title": "\u968f\u673a\u68ee\u6797\u5206\u7c7b\u6a21\u578b\u6784\u5efa"
        }, 
        {
            "location": "/data_analysis/p2p_runaway_analysis/p2p_runaway_classify_analysis_forshow/#_12", 
            "text": "\u901a\u8fc7LogistciRegression\u548cRandomForestClassifier\u5efa\u7acb\u7684\u5206\u7c7b\u6a21\u578b\u7684\u5206\u7c7b\u6548\u679c\u5747\u8f83\u5dee\u3002\u9020\u6210\u4ee5\u4e0a\u539f\u56e0\u8ddf\u6570\u636e\u6e90\u6709\u4e00\u5b9a\u5173\u7cfb\u3002\u6709\u5173p2p\u7f51\u8d37\u5e73\u53f0\u7684\u8bc4\u4f30\u6307\u6807\u6709\u5f88\u591a\uff0c\u672c\u62a5\u544a\u53ea\u9009\u62e9\u4e865\u4e2a\u7279\u5f81\u7ed9\u673a\u5668\u7b97\u6cd5\u5b66\u4e60\u548c\u8bad\u7ec3\uff0c\u5176\u4ed6\u6307\u6807\u5982\u7f51\u8d37\u5e73\u53f0\u7684\u5de5\u5546\u6ce8\u518c\u4fe1\u606f\u3001\u7f51\u7ad9ICP\u3001\u878d\u8d44\u53ca\u98ce\u6295\u4fe1\u606f\u7b49\u6682\u6ca1\u8003\u8651\u3002\u6b64\u5916\uff0c\u7531\u4e8e\u6570\u636e\u7684\u7f3a\u5931\u503c\u8f83\u591a\uff0c\u6bd4\u5982\u5e73\u5747\u5229\u7387\u8fd9\u4e00\u4e2a\u6307\u6807\uff0c\u5728\u5206\u6790\u76843800\u591a\u5bb6p2p\u5e73\u53f0\u4e2d\u67091695\u5bb6\u65e0\u6b64\u9879\u6570\u636e\uff0c\u8fd9\u4e9b\u90fd\u4f1a\u5f71\u54cd\u5230\u5206\u7c7b\u6a21\u578b\u7684\u5206\u7c7b\u53ca\u9884\u6d4b\u6548\u679c\u3002  p2p\u5e73\u53f0\u8dd1\u8def\u539f\u56e0\u53ef\u7b80\u5355\u5730\u5206\u4e3a\u8bc8\u9a97\u7c7b\u548c\u7ecf\u8425\u4e0d\u5584\u7c7b\u3002\u5e9e\u6c0f\u9a97\u5c40\u3001\u6076\u610f\u81ea\u878d\u7b49\u5c5e\u4e8e\u8bc8\u9a97\u7c7b\u3002\u7531\u4e8e\u7f51\u8d37\u5e73\u53f0\u7ecf\u8425\u8fc7\u7a0b\u7684\u6210\u672c\u504f\u9ad8\uff0c\u98ce\u63a7\u4e0d\u8fc7\u5173\u800c\u5bfc\u81f4\u7684\u7ecf\u8425\u4e0d\u5584\uff0c\u5f15\u8d77\u8fd0\u8425\u5e73\u53f0\u8d44\u91d1\u94fe\u65ad\u88c2\uff0c\u6700\u7ec8\u5173\u95e8\u8dd1\u8def\u3002\u4e00\u822c\u800c\u8a00\uff0c\u8dd1\u8def\u5e73\u53f0\u6709\u4e00\u4e9b\u7279\u70b9\uff0c\u5982\u8d44\u4ea7\u9879\u76ee\u4fe1\u606f\u62ab\u9732\u4e0d\u660e\uff0c\u98ce\u63a7\u4e0d\u8fbe\u6807\u6216\u6839\u672c\u65e0\u98ce\u63a7\u4e00\u73af\uff0c\u79d2\u6807\u3001\u5929\u6807\u3001\u9ad8\u606f\u6807\u6bd4\u4f8b\u9ad8\uff0c\u6295\u8d44\u8005\u7528\u6237\u4f53\u9a8c\u5ea6\u5dee\u7b49\u3002  \u672c\u6587\u9996\u5148\u5bf9p2p\u7f51\u8d37\u5e73\u53f0\u7684\u7279\u5f81\u4e0e\u662f\u5426\u8dd1\u8def\u7684\u5173\u7cfb\u8fdb\u884c\u5b9a\u6027\u5206\u6790\uff0c\u968f\u540e\u5c1d\u8bd5\u56fe\u901a\u8fc7sklearn\u63d0\u4f9b\u7684\u4e24\u79cd\u5206\u7c7b\u7b97\u6cd5\u5bf9p2p\u7f51\u8d37\u5e73\u53f0\u7684\u8dd1\u8def\u73b0\u8c61\u8fdb\u884c\u5206\u7c7b\u9884\u6d4b\uff0c\u6548\u679c\u4e00\u822c\uff08\u51c6\u786e\u73870.82\uff09\uff0c\u63a8\u6d4b\u539f\u56e0\u4e3b\u8981\u5728\u6837\u672c\u6570\u636e\u7f3a\u5931\u8f83\u591a\u53ca\u6837\u672c\u7279\u5f81\u4e0d\u5168\u9762\u3002\u56e0\u6b64\uff0c\u8981\u5bf9\u7f51\u8d37\u5e73\u53f0\u7684\u8dd1\u8def\u4e0e\u5426\u8fdb\u884c\u66f4\u7cbe\u786e\u7684\u9884\u6d4b\uff0c\u5c31\u8981\u66f4\u8fdb\u4e00\u6b65\u5730\u91c7\u53d6\u4e00\u4e9b\u63aa\u65bd\u8003\u5bdf\u7f51\u8d37\u5e73\u53f0\uff0c\u6bd4\u5982\uff0c\u5bf9\u7f51\u8d37\u5e73\u53f0\u7684\u76f8\u5173\u5de5\u5546\u4fe1\u606f\u8fdb\u884c\u67e5\u8be2\u548c\u786e\u8ba4\uff0c\u67e5\u8be2\u7f51\u8d37\u5e73\u53f0\u662f\u5426\u63a5\u53d7\u8fc7\u98ce\u6295\uff0c\u53ef\u53c2\u8003\u7b2c\u4e09\u65b9\u7f51\u8d37\u673a\u6784\u7684\u8bc4\u7ea7\u6570\u636e\uff0c\u5bf9\u5e73\u53f0\u8fdb\u884c\u5b9e\u5730\u8003\u5bdf\u7b49\u7b49\u3002\u53ea\u6709\u5bf9\u7f51\u8d37\u5e73\u53f0\u8fdb\u884c\u5168\u9762\u7684\u8003\u5bdf\u548c\u5224\u65ad\u624d\u80fd\u6700\u5927\u5730\u964d\u4f4e\u7f51\u8d37\u6295\u8d44\u98ce\u9669\u3002", 
            "title": "\u603b\u7ed3"
        }, 
        {
            "location": "/data_analysis/stocks_analysis/stock_index_tackle/", 
            "text": "\u80a1\u7968\u7ebf\u6027\u56de\u5f52\u5206\u6790\n\n\n\u80a1\u7968\u6570\u636e\u91c7\u96c6\n\n\n\u4f7f\u7528tushare\u63d0\u4f9b\u7684\u63a5\u53e3\u91c7\u96c62017\u5e743000\u591a\u4e2a\u80a1\u4fe1\u606f\uff0c\u540c\u65f6\u91c7\u96c6\u4e86\u4e09\u5e74\u7684\u5927\u76d8\u4fe1\u606f\uff0c\u4f7f\u7528pymysql\u4e0emysql\u6570\u636e\u5e93\u8fdb\u884c\u4ea4\u4e92\uff0c\u5177\u4f53\u91c7\u96c6\u8fc7\u7a0b\u7565\u8fc7\u3002\n\n\n\u6570\u636e\u6e05\u6d17\u4e0e\u5206\u6790\n\n\ntushare\u63d0\u4f9b\u7684\u65b0\u6d6a\u8d22\u7ecf\u4e0a\u7684\u6570\u636e\uff0c\u6570\u636e\u65e0\u660e\u663e\u7684\u7f3a\u5931\u548c\u9519\u8bef\u3002\n\u9996\u5148\u9009\u62e9\u5408\u9002\u7684\u80a1\u6307\u6307\u6570\uff0c\u7136\u540e\u5bf9\u4e2a\u80a1\u4e0e\u5927\u76d8\u6307\u6570\u7684\u5173\u7cfb\u8fdb\u884c\u5206\u6790\uff0c\u5373\u5c1d\u8bd5\u4f7f\u7528\u7ebf\u6027\u56de\u5f52\u5bf9\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u5173\u7cfb\u8fdb\u884c\u5206\u6790\uff0c\u8fdb\u800c\u627e\u51fa\u4e00\u4e9b\u201c\u5f3a\u52bf\u201d\u80a1\u7968\u3002\n\n\n\u5047\u5b9a\u80a1\u7968\u6295\u8d44\u6536\u76ca\u7387\u4e0e\u5e02\u573a\u6536\u76ca\u7387\u5b58\u5728\u7740\u7ebf\u6027\u76f8\u5173\u5173\u7cfb\uff0c\u5219\u80a1\u7968\u6295\u8d44\u6536\u76ca\u7387\u7075\u654f\u5ea6\u7cfb\u6570\u53ef\u4ee5\u7528\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u4f30\u8ba1\uff0c\u5176\u516c\u5f0f\u5982\u4e0b\uff1a\n\n R = \\alpha + \\beta R_M + \\epsilon \n\n\n\n\nR\u2014\u8d44\u4ea7\u7684\u9884\u671f\u6295\u8d44\u6536\u76ca\u7387\uff1b\n$R_M$\u2014\u8d44\u672c\u5e02\u573a\u7684\u5e73\u5747\u6295\u8d44\u6536\u76ca\u7387\uff1b\n\u03b2\u2014\u98ce\u9669\u77eb\u6b63\u7cfb\u6570\uff0c\u5373\u5bf9\u8d44\u672c\u5e02\u573a\u7cfb\u7edf\u98ce\u9669\u53d8\u5316\u7684\u654f\u611f\u7a0b\u5ea6\uff1b\n$\\alpha$\u2014\u5e38\u6570\u9879\uff0c\u8d85\u51fa\u5e02\u573a\u7684\u90e8\u5206\uff1b\n\u03b5\u2014\u8bef\u5dee\u9879\uff1b\n\n\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(style=\nwhitegrid\n, palette=\nmuted\n, font_scale=1.0, color_codes=True, context=\ntalk\n)\n%matplotlib inline\nfrom matplotlib.font_manager import FontProperties  \nfont = FontProperties(fname=r\n/usr/share/fonts/truetype/arphic/ukai.ttc\n)\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\nimport datetime\nimport pymysql\nfrom scipy import stats\n\n\n\n\n\u80a1\u6307\u6570\u636e\u5904\u7406\n\n\n# \u5904\u7406\u80a1\u6307\u6570\u636e\nsi = pd.read_csv(\n./stock_index_all.csv\n, parse_dates=True, index_col=\nsdate\n)\nsi.shape  # (4404,8)\nsname = si[\nsindex\n].unique()\nsi[\nsindex\n].replace(sname, [u\n\u521b\u4e1a\u677f\n,u\n\u6caa\u6df1300\n,u\n\u4e0a\u8bc1\n,\n                             u\n\u6df1\u5733\u6210\u6307\n,u\n\u4e0a\u8bc150\n,u\n\u4e2d\u5c0f\u677f\n], inplace=True)\n\n\n\n\n# \u900f\u89c6\u8868\nsi_pv = si.pivot_table(index=si.index, columns=\nsindex\n)\nsi_pv.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nopen\n\n      \nclose\n\n      \n...\n\n      \nprice_change\n\n      \np_change\n\n    \n\n    \n\n      \nsindex\n\n      \n\u4e0a\u8bc1\n\n      \n\u4e0a\u8bc150\n\n      \n\u4e2d\u5c0f\u677f\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6caa\u6df1300\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u4e0a\u8bc150\n\n      \n\u4e2d\u5c0f\u677f\n\n      \n\u521b\u4e1a\u677f\n\n      \n...\n\n      \n\u4e2d\u5c0f\u677f\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6caa\u6df1300\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u4e0a\u8bc150\n\n      \n\u4e2d\u5c0f\u677f\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6caa\u6df1300\n\n      \n\u6df1\u5733\u6210\u6307\n\n    \n\n    \n\n      \nsdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2014-10-14\n\n      \n2362.802\n\n      \n1603.347\n\n      \n5593.922\n\n      \n1546.666\n\n      \n2451.094\n\n      \n8150.859\n\n      \n2359.475\n\n      \n1600.299\n\n      \n5577.213\n\n      \n1539.119\n\n      \n...\n\n      \n-22.859\n\n      \n-9.208\n\n      \n-8.384\n\n      \n-24.106\n\n      \n-0.28\n\n      \n-0.35\n\n      \n-0.41\n\n      \n-0.59\n\n      \n-0.34\n\n      \n-0.29\n\n    \n\n    \n\n      \n2014-10-15\n\n      \n2358.233\n\n      \n1599.895\n\n      \n5577.844\n\n      \n1539.347\n\n      \n2444.538\n\n      \n8141.143\n\n      \n2373.670\n\n      \n1612.772\n\n      \n5611.542\n\n      \n1545.623\n\n      \n...\n\n      \n34.329\n\n      \n6.504\n\n      \n17.312\n\n      \n58.163\n\n      \n0.60\n\n      \n0.78\n\n      \n0.62\n\n      \n0.42\n\n      \n0.71\n\n      \n0.71\n\n    \n\n    \n\n      \n2014-10-16\n\n      \n2361.130\n\n      \n1602.383\n\n      \n5587.709\n\n      \n1539.858\n\n      \n2448.968\n\n      \n8156.785\n\n      \n2356.499\n\n      \n1608.735\n\n      \n5525.425\n\n      \n1526.560\n\n      \n...\n\n      \n-86.117\n\n      \n-19.063\n\n      \n-19.479\n\n      \n-87.437\n\n      \n-0.72\n\n      \n-0.25\n\n      \n-1.53\n\n      \n-1.23\n\n      \n-0.79\n\n      \n-1.07\n\n    \n\n  \n\n\n\n\n3 rows \u00d7 42 columns\n\n\n\n\n\n# \u5220\u9664\u80a1\u6307\u7f3a\u5931\u6570\u636e\uff0c\u539f\u59cb\u6570\u636e\u9519\u8bef\nss = si_pv[\nopen\n][u\n\u4e0a\u8bc1\n]\nsst = si_pv[ss.isnull()].index.date\nmiss_date = []\nfor i in sst:\n    date_str = datetime.datetime.strftime(i, \n%Y-%m-%d\n)\n    miss_date.append(date_str)\nmiss_date\n\n\n\n\n['2015-02-24', '2015-10-07', '2017-02-02', '2017-05-30']\n\n\n\nsi_pv.drop(sst, inplace=True)\nsi_pv.shape  # (733, 42)\n\n\n\n\n(733, 42)\n\n\n\nsi_close = si_pv[\nclose\n]\nsi_change = si_pv[\np_change\n]\nsi_volume = si_pv[\nvolume\n]\n\n\n\n\nsi_close.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \nsindex\n\n      \n\u4e0a\u8bc1\n\n      \n\u4e0a\u8bc150\n\n      \n\u4e2d\u5c0f\u677f\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6caa\u6df1300\n\n      \n\u6df1\u5733\u6210\u6307\n\n    \n\n    \n\n      \nsdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2014-10-14\n\n      \n2359.475\n\n      \n1600.299\n\n      \n5577.213\n\n      \n1539.119\n\n      \n2446.562\n\n      \n8139.961\n\n    \n\n    \n\n      \n2014-10-15\n\n      \n2373.670\n\n      \n1612.772\n\n      \n5611.542\n\n      \n1545.623\n\n      \n2463.874\n\n      \n8198.124\n\n    \n\n    \n\n      \n2014-10-16\n\n      \n2356.499\n\n      \n1608.735\n\n      \n5525.425\n\n      \n1526.560\n\n      \n2444.395\n\n      \n8110.687\n\n    \n\n  \n\n\n\n\n\n\n\nsi_close.plot(figsize=(8,6))\nplt.xlabel(u\n\u65e5\u671f\n, fontsize=16, fontproperties=font)\nplt.title(u\n\u5404\u80a1\u6307\u6307\u6570\u53d8\u5316\n, fontsize=25, fontproperties=font)\n# plt.yticks(ax1.get_yticks(), ax1.get_yticks() * 100)\nplt.ylabel('\u6307\u6570', fontproperties=font, fontsize=16)\nplt.gca().yaxis.grid(True, linestyle = \n:\n)\nplt.gca().xaxis.grid(True, linestyle = \n:\n)\nplt.legend(loc='best', prop=font, fontsize=12)\n\n\n\n\nmatplotlib.legend.Legend at 0x7f99aaf3b410\n\n\n\n\n\n\nfig1, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(10, 13))\nsi_close.plot(ax=ax1, use_index=False, xticks=[], legend=False, fontsize=16)\nsi_change.plot(ax=ax2, use_index=False, xticks=[], legend=False, fontsize=16)\nsi_change_cumsum = si_change.cumsum()\nsi_change_cumsum.plot(ax=ax3, fontsize=16, legend=False)\nax1.set_title(u\n\u5404\u80a1\u6307\u53d8\u5316\n, fontproperties=font, fontsize=19)\nax2.set_title(u\n\u6da8\u8dcc\u5e45\u53d8\u5316\n, fontproperties=font, fontsize=19)\nax3.set_title(u\n\u6da8\u8dcc\u5e45\u7d2f\u8ba1\u53d8\u5316\n, fontproperties=font, fontsize=19)\nplt.tight_layout() \nplt.xlabel(u\n\u65e5\u671f\n, fontproperties=font, fontsize=16)\nplt.legend(loc='best', prop=font, fontsize=15)\n\n\n\n\nmatplotlib.legend.Legend at 0x7f99aa280f90\n\n\n\n\n\n\n# 2017\u5e74\u7684\u80a1\u6307\u6570\u636e\nssi_close = si_close['2017-1':'2017-10']\nssi_change = si_change['2017-1':'2017-10']\nssi_volume = si_volume['2017-1':'2017-10']\nssi_close.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \nsindex\n\n      \n\u4e0a\u8bc1\n\n      \n\u4e0a\u8bc150\n\n      \n\u4e2d\u5c0f\u677f\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6caa\u6df1300\n\n      \n\u6df1\u5733\u6210\u6307\n\n    \n\n    \n\n      \nsdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2017-01-03\n\n      \n3135.92\n\n      \n2307.89\n\n      \n6510.90\n\n      \n1963.26\n\n      \n3342.23\n\n      \n10262.85\n\n    \n\n    \n\n      \n2017-01-04\n\n      \n3158.79\n\n      \n2322.21\n\n      \n6600.20\n\n      \n1991.57\n\n      \n3368.31\n\n      \n10384.87\n\n    \n\n    \n\n      \n2017-01-05\n\n      \n3165.41\n\n      \n2322.68\n\n      \n6587.13\n\n      \n1983.97\n\n      \n3367.79\n\n      \n10371.47\n\n    \n\n  \n\n\n\n\n\n\n\nfig2, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(8, 13))\nssi_close.plot(ax=ax1, use_index=False, xticks=[], fontsize=16,legend=False)\nssi_change.plot(ax=ax2, use_index=False, xticks=[],legend=False, fontsize=16)\nssi_change_cumsum = ssi_change.cumsum()\nssi_change_cumsum.plot(ax=ax3, fontsize=16, legend=True)\nax1.set_title(u\n\u5404\u80a1\u6307\u53d8\u5316\n, fontproperties=font, fontsize=19)\nax2.set_title(u\n\u6da8\u8dcc\u5e45\u53d8\u5316\n, fontproperties=font, fontsize=19)\nax3.set_title(u\n\u6da8\u8dcc\u5e45\u7d2f\u8ba1\u53d8\u5316\n, fontproperties=font, fontsize=19)\nplt.tight_layout() \nplt.legend(loc='best', prop=font, fontsize=15)\nplt.xlabel(u\n\u65e5\u671f\n, fontproperties=font, fontsize=16)\n\n\n\n\nmatplotlib.text.Text at 0x7f99a8429ed0\n\n\n\n\n\n\ndef corr_plot(dataframe, method='pearson', plot_title=None, figsize=(10,8)):\n    si_corr = dataframe.corr(method=method)    \n    siname = si_corr.columns.values\n    plt.figure(figsize=figsize)\n    g = sns.heatmap(si_corr, cbar=True, annot=True, \n                square=True, fmt=\n.2f\n, \n                annot_kws={'size': 12}, \n               yticklabels=siname,xticklabels=siname)\n    plt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n    plt.xlabel(\n)\n    plt.ylabel(\n)\n    plt.title(plot_title, fontproperties=font, fontsize=20)\n\n\n\n\ncorr_plot(ssi_change, u\n\u8fd1\u4e00\u5e74\u5404\u80a1\u6307\u76f8\u5173\u5173\u7cfb\n)\n\n\n\n\n\n\ncorr_plot(si_change, u\n\u8fd1\u4e09\u5e74\u5404\u80a1\u6307\u76f8\u5173\u5173\u7cfb\n)\n\n\n\n\n\n\nssi_change.shape  # (190, 6)\nssi_change.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \nsindex\n\n      \n\u4e0a\u8bc1\n\n      \n\u4e0a\u8bc150\n\n      \n\u4e2d\u5c0f\u677f\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6caa\u6df1300\n\n      \n\u6df1\u5733\u6210\u6307\n\n    \n\n    \n\n      \nsdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2017-01-03\n\n      \n1.04\n\n      \n0.92\n\n      \n0.60\n\n      \n0.06\n\n      \n0.97\n\n      \n0.84\n\n    \n\n    \n\n      \n2017-01-04\n\n      \n0.73\n\n      \n0.62\n\n      \n1.37\n\n      \n1.44\n\n      \n0.78\n\n      \n1.19\n\n    \n\n    \n\n      \n2017-01-05\n\n      \n0.21\n\n      \n0.02\n\n      \n-0.20\n\n      \n-0.38\n\n      \n-0.01\n\n      \n-0.13\n\n    \n\n  \n\n\n\n\n\n\n\nssi_change.describe()\n\n\n\n\n\n\n\n  \n\n    \n\n      \nsindex\n\n      \n\u4e0a\u8bc1\n\n      \n\u4e0a\u8bc150\n\n      \n\u4e2d\u5c0f\u677f\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6caa\u6df1300\n\n      \n\u6df1\u5733\u6210\u6307\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n188.000000\n\n      \n188.000000\n\n      \n188.000000\n\n      \n188.000000\n\n      \n188.000000\n\n      \n188.000000\n\n    \n\n    \n\n      \nmean\n\n      \n0.047606\n\n      \n0.094096\n\n      \n0.096436\n\n      \n-0.011862\n\n      \n0.091064\n\n      \n0.059202\n\n    \n\n    \n\n      \nstd\n\n      \n0.534457\n\n      \n0.635277\n\n      \n0.831965\n\n      \n1.024665\n\n      \n0.575751\n\n      \n0.829573\n\n    \n\n    \n\n      \nmin\n\n      \n-1.630000\n\n      \n-1.570000\n\n      \n-2.820000\n\n      \n-5.110000\n\n      \n-1.840000\n\n      \n-3.570000\n\n    \n\n    \n\n      \n25%\n\n      \n-0.300000\n\n      \n-0.330000\n\n      \n-0.445000\n\n      \n-0.630000\n\n      \n-0.292500\n\n      \n-0.432500\n\n    \n\n    \n\n      \n50%\n\n      \n0.070000\n\n      \n0.065000\n\n      \n0.085000\n\n      \n0.060000\n\n      \n0.095000\n\n      \n0.110000\n\n    \n\n    \n\n      \n75%\n\n      \n0.362500\n\n      \n0.472500\n\n      \n0.652500\n\n      \n0.557500\n\n      \n0.392500\n\n      \n0.592500\n\n    \n\n    \n\n      \nmax\n\n      \n1.830000\n\n      \n2.740000\n\n      \n2.720000\n\n      \n3.620000\n\n      \n1.800000\n\n      \n2.220000\n\n    \n\n  \n\n\n\n\n\n\n\n\u6839\u636e\u7ebf\u56fe\u548cpearson\u76f8\u5173\u5173\u7cfb\u56fe\uff0c\u5404\u5927\u80a1\u6307\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\uff0c\u5c24\u5176\u662f\u4e0a\u8bc1\u3001\u6df1\u5733\u6210\u6307\u3001\u521b\u4e1a\u677f\uff0c\u7531\u6b64\u53ef\u4ee5\u9009\u62e9\u4e0a\u8bc1\u4e3a\u8861\u91cf\u7684\u80a1\u6307\u6307\u6570\u3002\n\n\n\u4e2a\u80a1\u6570\u636e\u5904\u7406\n\n\nstock_id= pd.read_csv(\n./stock_id.csv\n, header=None, dtype=str)\nstock_id.head(10)\nstock_id.shape\n\n\n\n\n(3413, 1)\n\n\n\nstocks = pd.read_csv(\n./stocks_all.csv\n, parse_dates=True, index_col=\nssdate\n, dtype=str)\n\n\n\n\nfor i in [\nopen\n, \nclose\n, \nvolume\n, \np_change\n]:    \n    stocks[i] = stocks[i].astype(np.float)\nstocks.dtypes\n\n\n\n\nssindex      object\nopen        float64\nclose       float64\nvolume      float64\np_change    float64\ndtype: object\n\n\n\nstocks.head(2)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nssindex\n\n      \nopen\n\n      \nclose\n\n      \nvolume\n\n      \np_change\n\n    \n\n    \n\n      \nssdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2017-01-03\n\n      \n300425\n\n      \n30.47\n\n      \n30.64\n\n      \n10473.89\n\n      \n0.86\n\n    \n\n    \n\n      \n2017-01-04\n\n      \n300425\n\n      \n30.64\n\n      \n30.97\n\n      \n10098.92\n\n      \n1.08\n\n    \n\n  \n\n\n\n\n\n\n\nstocks.count()\n\n\n\n\nssindex     543445\nopen        543445\nclose       543445\nvolume      543445\np_change    543445\ndtype: int64\n\n\n\nssi_change.count()\n\n\n\n\nsindex\n\u4e0a\u8bc1       188\n\u4e0a\u8bc150     188\n\u4e2d\u5c0f\u677f      188\n\u521b\u4e1a\u677f      188\n\u6caa\u6df1300    188\n\u6df1\u5733\u6210\u6307     188\ndtype: int64\n\n\n\n\u4e2a\u80a1\u6570\u636e\u57fa\u672c\u65e0\u7f3a\u5931\u503c\uff0c\u7edf\u8ba1\u4e8617\u5e74\u622a\u81f3\u76ee\u524d\u5171\u8ba1188\u5929\u4ea4\u6613\u65e5\u7684\u6570\u636e\n\n\n\u7ebf\u6027\u56de\u5f52\u5206\u6790\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u5173\u7cfb\n\n\n# \u80a1\u7968id\nstocks_id = stocks[\nssindex\n].unique()\nregress_weights = pd.DataFrame()\ncolumns=[\nssindex\n, \nsindex\n, \nbeta\n, \nalpha\n, \nr_value\n, \np_value\n, \nsigma\n, \ncoeff\n]\nfor i in stocks_id:\n    one_stock = stocks.loc[stocks[\nssindex\n] == i, [\np_change\n]]    \n    index_stock = ssi_change[[u\n\u4e0a\u8bc1\n, u\n\u521b\u4e1a\u677f\n, u\n\u6df1\u5733\u6210\u6307\n]]\n    result = pd.merge(one_stock, index_stock, left_index=True, right_index=True)\n    corr_s = result.corr()\n    corrs = corr_s.loc[corr_s.index == \np_change\n, corr_s.index != \np_change\n]\n    for j in ([u\n\u4e0a\u8bc1\n, u\n\u521b\u4e1a\u677f\n, u\n\u6df1\u5733\u6210\u6307\n]):\n        # \u4e2a\u80a1\u4e0e\u5927\u76d8\u6307\u6570\n        cof = stats.linregress(result[j], result[\np_change\n])\n        cof = list(cof)\n        cof.insert(0, j)\n        cof.insert(0, i)\n        cof.append(corrs[j].values[0])\n        regress_weights = regress_weights.append(pd.Series(cof), ignore_index=True)\nregress_weights.columns = columns\n# regress_weights.to_csv(\n./stocks_linear_reg.csv\n, index=False)\n\n\n\n\nregress_weights.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nssindex\n\n      \nsindex\n\n      \nbeta\n\n      \nalpha\n\n      \nr_value\n\n      \np_value\n\n      \nsigma\n\n      \ncoeff\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n300425\n\n      \n\u4e0a\u8bc1\n\n      \n1.982162\n\n      \n-0.226491\n\n      \n0.435494\n\n      \n4.212572e-10\n\n      \n0.300425\n\n      \n0.435494\n\n    \n\n    \n\n      \n1\n\n      \n300425\n\n      \n\u521b\u4e1a\u677f\n\n      \n1.370130\n\n      \n-0.115876\n\n      \n0.577131\n\n      \n4.361627e-18\n\n      \n0.142157\n\n      \n0.577131\n\n    \n\n    \n\n      \n2\n\n      \n300425\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n1.630604\n\n      \n-0.228663\n\n      \n0.556075\n\n      \n1.188637e-16\n\n      \n0.178702\n\n      \n0.556075\n\n    \n\n  \n\n\n\n\n\n\n\ntarget_cof = regress_weights[regress_weights[\nalpha\n] \n 0.2]  # 11%\u80a1\u7968alpha \n 0.2\ntarget_stock_index_temp = target_cof[\nssindex\n].unique()  # 443\ntarget_stock_index = list(set(target_stock_index1) | set(target_stock_index_temp))\n\n\n\n\nrw = pd.pivot_table(regress_weights, index=[\nssindex\n], columns=[\nsindex\n])\n\n\n\n\nrw.head(2)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nbeta\n\n      \nalpha\n\n      \nr_value\n\n      \np_value\n\n      \nsigma\n\n      \ncoeff\n\n    \n\n    \n\n      \nsindex\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n    \n\n    \n\n      \nssindex\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n000001\n\n      \n1.009117\n\n      \n0.124561\n\n      \n0.371582\n\n      \n0.094619\n\n      \n0.144137\n\n      \n0.120661\n\n      \n0.422698\n\n      \n0.100032\n\n      \n0.241593\n\n      \n1.515277e-09\n\n      \n0.171984\n\n      \n0.000838\n\n      \n0.158640\n\n      \n0.090845\n\n      \n0.109434\n\n      \n0.422698\n\n      \n0.100032\n\n      \n0.241593\n\n    \n\n    \n\n      \n000002\n\n      \n0.772420\n\n      \n0.061969\n\n      \n0.555449\n\n      \n0.155289\n\n      \n0.193293\n\n      \n0.154671\n\n      \n0.179175\n\n      \n0.026400\n\n      \n0.193210\n\n      \n1.522864e-02\n\n      \n0.722779\n\n      \n0.008779\n\n      \n0.315248\n\n      \n0.174413\n\n      \n0.209659\n\n      \n0.179175\n\n      \n0.026400\n\n      \n0.193210\n\n    \n\n  \n\n\n\n\n\n\n\nrwc = rw.swaplevel(0, 1, axis=1)  # \u53cd\u8f6c\u5217\u5c42\u6b21\u5316\u7d22\u5f15\nrwc.head(2)\n\n\n\n\n\n\n\n  \n\n    \n\n      \nsindex\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n    \n\n    \n\n      \n\n      \nbeta\n\n      \nbeta\n\n      \nbeta\n\n      \nalpha\n\n      \nalpha\n\n      \nalpha\n\n      \nr_value\n\n      \nr_value\n\n      \nr_value\n\n      \np_value\n\n      \np_value\n\n      \np_value\n\n      \nsigma\n\n      \nsigma\n\n      \nsigma\n\n      \ncoeff\n\n      \ncoeff\n\n      \ncoeff\n\n    \n\n    \n\n      \nssindex\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n000001\n\n      \n1.009117\n\n      \n0.124561\n\n      \n0.371582\n\n      \n0.094619\n\n      \n0.144137\n\n      \n0.120661\n\n      \n0.422698\n\n      \n0.100032\n\n      \n0.241593\n\n      \n1.515277e-09\n\n      \n0.171984\n\n      \n0.000838\n\n      \n0.158640\n\n      \n0.090845\n\n      \n0.109434\n\n      \n0.422698\n\n      \n0.100032\n\n      \n0.241593\n\n    \n\n    \n\n      \n000002\n\n      \n0.772420\n\n      \n0.061969\n\n      \n0.555449\n\n      \n0.155289\n\n      \n0.193293\n\n      \n0.154671\n\n      \n0.179175\n\n      \n0.026400\n\n      \n0.193210\n\n      \n1.522864e-02\n\n      \n0.722779\n\n      \n0.008779\n\n      \n0.315248\n\n      \n0.174413\n\n      \n0.209659\n\n      \n0.179175\n\n      \n0.026400\n\n      \n0.193210\n\n    \n\n  \n\n\n\n\n\n\n\nrw[\nsigma\n].describe()\n\n\n\n\n\n\n\n  \n\n    \n\n      \nsindex\n\n      \n\u4e0a\u8bc1\n\n      \n\u521b\u4e1a\u677f\n\n      \n\u6df1\u5733\u6210\u6307\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n3039.000000\n\n      \n3039.000000\n\n      \n3039.000000\n\n    \n\n    \n\n      \nmean\n\n      \n0.318601\n\n      \n0.160160\n\n      \n0.197206\n\n    \n\n    \n\n      \nstd\n\n      \n0.173631\n\n      \n0.088121\n\n      \n0.111256\n\n    \n\n    \n\n      \nmin\n\n      \n0.080941\n\n      \n0.047468\n\n      \n0.055388\n\n    \n\n    \n\n      \n25%\n\n      \n0.218256\n\n      \n0.108247\n\n      \n0.132529\n\n    \n\n    \n\n      \n50%\n\n      \n0.275778\n\n      \n0.137372\n\n      \n0.168823\n\n    \n\n    \n\n      \n75%\n\n      \n0.357421\n\n      \n0.179410\n\n      \n0.221232\n\n    \n\n    \n\n      \nmax\n\n      \n1.294449\n\n      \n0.745507\n\n      \n0.837215\n\n    \n\n  \n\n\n\n\n\n\n\np_value_l = regress_weights[regress_weights[\np_value\n] \n= 0.05]\ntarget_stock_index1 = p_value_l[\nssindex\n].unique()\ntarget_stock_index1.shape  #  (234,)\n\n\n\n\n\u6839\u636e\u4e2a\u80a1\u4e0e\u5927\u76d8\u8fdb\u884c\u7ebf\u6027\u56de\u5f52\uff0c\u5f97\u5230\u4e09\u4e2a\u56de\u5f52\u53c2\u6570\u5c06\uff0c\u5176\u4e2d\uff0c\u6839\u636ealpha\u7684\u6b63\u8d1f\u53f7\u53ef\u4ee5\u5224\u65ad\u4e2a\u80a1\u662f\u5426\u4f18\u4e8e\u5927\u76d8\uff08\u8d85\u51fa\u5e02\u573a\u7684\u7a0b\u5ea6\uff09\uff0cbeta\u662f\u5426\u5927\u4e8e\uff11\u8868\u793a\u4e86\u5bf9\u5927\u76d8\u7684\u654f\u611f\u7a0b\u5ea6\uff08\u5927\u4e8e\uff11\u8868\u793a\u654f\u611f\uff0c\u53cd\u4e4b\u8868\u793a\u4e0d\u654f\u611f\uff09\uff0csigma\u53ef\u8fd1\u4f3c\u770b\u6210\u4e2a\u80a1\u6ce2\u52a8\u98ce\u9669\n\n\n# \u56de\u5f52\u7cfb\u6570\u76f8\u5173\u6027\u2014\u2014spearman\u76f8\u5173\u7cfb\u6570\nfor j in [u\n\u4e0a\u8bc1\n, u\n\u521b\u4e1a\u677f\n, u\n\u6df1\u5733\u6210\u6307\n]:\n    temp = rwc[j][[\nalpha\n, \nbeta\n, \nsigma\n]]\n    corr_plot(temp, method=\nspearman\n, plot_title = u\n{}\u56de\u5f52\u7cfb\u6570\u76f8\u5173\u5173\u7cfb\n.format(j), figsize=(8,6))\n\n\n\n\n\n\n\n\n\n\n# \u56de\u5f52\u7cfb\u6570\u76f8\u5173\u6027\u2014\u2014pearson\u76f8\u5173\u7cfb\u6570\nfor j in [u\n\u4e0a\u8bc1\n, u\n\u521b\u4e1a\u677f\n, u\n\u6df1\u5733\u6210\u6307\n]:\n    temp = rwc[j][[\nalpha\n, \nbeta\n, \nsigma\n]]\n    corr_plot(temp, method=\npearson\n, plot_title = u\n{}\u56de\u5f52\u7cfb\u6570\u76f8\u5173\u5173\u7cfb\n.format(j), figsize=(8,6))\n\n\n\n\n\n\n\n\n\n\nalpha_stock = pd.DataFrame()\nalpha_stock[u\n\u4e0a\u8bc1\n] = rw[\nalpha\n][u\n\u4e0a\u8bc1\n]\nalpha_stock[u\n\u521b\u4e1a\u677f\n] = rw[\nalpha\n][u\n\u521b\u4e1a\u677f\n]\nalpha_stock[u\n\u6df1\u5733\u6210\u6307\n] = rw[\nalpha\n][u\n\u6df1\u5733\u6210\u6307\n]\n\n\n\n\ndef distribution_plot(df, plot_title=\n):\n    for i in [\nbeta\n, \nalpha\n, \nsigma\n]:    \n        fig1, (ax1, ax2) = plt.subplots(2, 1,figsize=(8,12))\n        df[i].plot(kind='hist',ax=ax1, normed=True, alpha=0.7,bins=50)\n        df[i].plot(kind='kde',ax=ax2, style='-.', linewidth=3)\n        ax1.legend(loc='best', prop=font, fontsize=17)\n        ax2.legend(loc='best', prop=font, fontsize=17)\n        ax1.set_title(u\n{0}{1}\u5206\u5e03\n.format(plot_title, i), fontproperties=font, fontsize=19)\n        ax2.set_title(u\n{0}{1}\u5206\u5e03\n.format(plot_title, i), fontproperties=font, fontsize=19)\n        plt.tight_layout() \n\n\n\n\nditribution_plot(rw)\n\n\n\n\n\n\n\n\n\n\n$\\alpha$\u548c$\\beta$\u5206\u5e03\u7c7b\u4f3c\u6b63\u6001\u5206\u5e03\uff0c\u4f46$\\alpha$\u660e\u663e\u7684\u53f3\u504f\uff0c\u8868\u660e\u6709\u4e00\u4e9b$\\alpha$\u504f\u5927\uff0c\u4ece\u76f8\u5173\u5173\u7cfb\u56fe\u53ef\u770b\u51fa$\\alpha$\u548c$\\beta$\u6709\u4e00\u5b9a\u7684\u8d1f\u76f8\u5173\u6027\uff0c$\\alpha$\u548c$\\sigma$\u6709\u8f83\u5927\u7684\u6b63\u76f8\u5173\u6027\uff0c\u800c$\\beta$\u4e0e$\\sigma$\u6709\u8f83\u5f31\u7684\u6b63\u76f8\u5173\u6027\u3002\n\n\n\u901a\u8fc7\u6bd4\u8f83\u6bcf\u6708\u4e2a\u80a1\u6da8\u8dcc\u5e45\u4e0e\u5927\u76d8\u6307\u6570\u6da8\u8dcc\u5e45\uff0c\u7b80\u5355\u7684\u5224\u65ad\u4e2a\u80a1\u5f3a\u5f31\uff0c\u7136\u540e\u901a\u8fc7\u7ebf\u6027\u56de\u5f52\u7cfb\u6570\u8fdb\u884c\u8fdb\u4e00\u6b65\u5224\u65ad\n\n\nstocks_id = stocks[\nssindex\n].unique()\ni = stocks_id[0]\none_stock = stocks.loc[stocks[\nssindex\n] == i, [\np_change\n]]    \nindex_stock = ssi_change[[u\n\u4e0a\u8bc1\n]]\nresult = pd.merge(one_stock, index_stock, left_index=True, right_index=True)\nresult.tail(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \np_change\n\n      \n\u4e0a\u8bc1\n\n    \n\n    \n\n      \nssdate\n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2017-10-10\n\n      \n2.71\n\n      \n0.26\n\n    \n\n    \n\n      \n2017-10-11\n\n      \n0.18\n\n      \n0.16\n\n    \n\n    \n\n      \n2017-10-12\n\n      \n-1.05\n\n      \n-0.06\n\n    \n\n  \n\n\n\n\n\n\n\ndef stock_change_cumsum(stock_time, ssi_change):\n    stocks_id = stock_time[\nssindex\n].unique()    \n    index_stock = ssi_change[[u\n\u4e0a\u8bc1\n]]  \n    move_sum = pd.DataFrame()\n    for k in stocks_id:\n        one_stock = stock_time.loc[stock_time[\nssindex\n] == k, [\np_change\n]]    \n        result = pd.merge(one_stock, index_stock, left_index=True, right_index=True)\n        for i in np.unique(result.index.year):\n            for j in np.unique(result.index.month):\n                if j \n 10:\n                    strm = \n0\n + str(j)\n                else:\n                    strm = str(j)\n                temp = str(i) + \n-\n + strm\n                try:\n                    stock_sum = result[temp].sum()\n                except KeyError as e:\n                    print(e)\n                else:\n                    stock_sum = stock_sum.append(pd.Series(dict(sdate=temp)))\n                    stock_sum = stock_sum.append(pd.Series(dict(sindex=k)))\n                    stock_sum = stock_sum.append(pd.Series(dict(gap_sh=stock_sum[\np_change\n] - stock_sum[u\n\u4e0a\u8bc1\n])))\n                    stock_sum.pop(u'\u4e0a\u8bc1')\n                    move_sum = move_sum.append(stock_sum, ignore_index=True)\n    return move_sum\n\n\n\n\ntt = stock_change_cumsum(stocks, ssi_change)\n# tt.to_csv(\n./stocks_month_change.csv\n, index=False)\n\n\n\n\ntt.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \ngap_sh\n\n      \np_change\n\n      \nsdate\n\n      \nsindex\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n-15.70\n\n      \n-13.92\n\n      \n2017-01\n\n      \n300425\n\n    \n\n    \n\n      \n1\n\n      \n3.05\n\n      \n5.66\n\n      \n2017-02\n\n      \n300425\n\n    \n\n    \n\n      \n2\n\n      \n-6.62\n\n      \n-7.20\n\n      \n2017-03\n\n      \n300425\n\n    \n\n  \n\n\n\n\n\n\n\nstocks_month_sum = pd.pivot_table(tt, index=[\nsindex\n], columns=[\nsdate\n])\nstocks_month_sum.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \ngap_sh\n\n      \np_change\n\n    \n\n    \n\n      \nsdate\n\n      \n2017-01\n\n      \n2017-02\n\n      \n2017-03\n\n      \n2017-04\n\n      \n2017-05\n\n      \n2017-06\n\n      \n2017-07\n\n      \n2017-08\n\n      \n2017-09\n\n      \n2017-10\n\n      \n2017-01\n\n      \n2017-02\n\n      \n2017-03\n\n      \n2017-04\n\n      \n2017-05\n\n      \n2017-06\n\n      \n2017-07\n\n      \n2017-08\n\n      \n2017-09\n\n      \n2017-10\n\n    \n\n    \n\n      \nsindex\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n000001\n\n      \n0.73\n\n      \n-0.99\n\n      \n-2.71\n\n      \n0.11\n\n      \n3.61\n\n      \n-0.32\n\n      \n12.20\n\n      \n3.36\n\n      \n-0.90\n\n      \n2.78\n\n      \n2.51\n\n      \n1.62\n\n      \n-3.29\n\n      \n-1.98\n\n      \n2.44\n\n      \n2.09\n\n      \n14.73\n\n      \n6.06\n\n      \n-1.26\n\n      \n3.9\n\n    \n\n    \n\n      \n000002\n\n      \n-1.37\n\n      \n-3.32\n\n      \n1.04\n\n      \n-3.21\n\n      \n10.22\n\n      \n16.76\n\n      \n-10.07\n\n      \n0.32\n\n      \n13.89\n\n      \n2.08\n\n      \n0.97\n\n      \n-0.71\n\n      \n0.46\n\n      \n-5.30\n\n      \n9.05\n\n      \n17.36\n\n      \n-6.11\n\n      \n3.02\n\n      \n13.53\n\n      \n3.2\n\n    \n\n    \n\n      \n000004\n\n      \n-17.16\n\n      \n-0.62\n\n      \n-7.19\n\n      \nNaN\n\n      \nNaN\n\n      \n-34.40\n\n      \n-15.69\n\n      \n1.25\n\n      \n4.56\n\n      \n4.08\n\n      \n-15.38\n\n      \n1.99\n\n      \n-7.77\n\n      \nNaN\n\n      \nNaN\n\n      \n-32.43\n\n      \n-13.16\n\n      \n3.95\n\n      \n4.20\n\n      \n5.2\n\n    \n\n  \n\n\n\n\n\n\n\nsms = stocks_month_sum[\ngap_sh\n]\nsms[\nsum_all\n] = sms.sum(axis=1)\nsms[\nmean\n] = sms.mean(axis=1)\nsms[\nmedian\n] = sms.median(axis=1)\nsms.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \nsdate\n\n      \n2017-01\n\n      \n2017-02\n\n      \n2017-03\n\n      \n2017-04\n\n      \n2017-05\n\n      \n2017-06\n\n      \n2017-07\n\n      \n2017-08\n\n      \n2017-09\n\n      \n2017-10\n\n      \nsum_all\n\n      \nmean\n\n      \nmedian\n\n    \n\n    \n\n      \nsindex\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n000001\n\n      \n0.73\n\n      \n-0.99\n\n      \n-2.71\n\n      \n0.11\n\n      \n3.61\n\n      \n-0.32\n\n      \n12.20\n\n      \n3.36\n\n      \n-0.90\n\n      \n2.78\n\n      \n17.87\n\n      \n3.249091\n\n      \n1.755000\n\n    \n\n    \n\n      \n000002\n\n      \n-1.37\n\n      \n-3.32\n\n      \n1.04\n\n      \n-3.21\n\n      \n10.22\n\n      \n16.76\n\n      \n-10.07\n\n      \n0.32\n\n      \n13.89\n\n      \n2.08\n\n      \n26.34\n\n      \n4.789091\n\n      \n1.560000\n\n    \n\n    \n\n      \n000004\n\n      \n-17.16\n\n      \n-0.62\n\n      \n-7.19\n\n      \nNaN\n\n      \nNaN\n\n      \n-34.40\n\n      \n-15.69\n\n      \n1.25\n\n      \n4.56\n\n      \n4.08\n\n      \n-65.17\n\n      \n-14.482222\n\n      \n-10.836111\n\n    \n\n  \n\n\n\n\n\n\n\nstock_t = sms[sms[[\nmedian\n]] \n 1].dropna(how=\nall\n)\nstock_t.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \nsdate\n\n      \n2017-01\n\n      \n2017-02\n\n      \n2017-03\n\n      \n2017-04\n\n      \n2017-05\n\n      \n2017-06\n\n      \n2017-07\n\n      \n2017-08\n\n      \n2017-09\n\n      \n2017-10\n\n      \nsum_all\n\n      \nmean\n\n      \nmedian\n\n    \n\n    \n\n      \nsindex\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n000001\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \n1.755000\n\n    \n\n    \n\n      \n000002\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \n1.560000\n\n    \n\n    \n\n      \n000016\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \n2.442727\n\n    \n\n  \n\n\n\n\n\n\n\n# \u4e2a\u80a1\u6da8\u8dcc\u5e45\u5927\u4e8e\u5927\u76d8\u6da8\u8dcc\u5e45\u8bb0\u4e3a1\u5426\u5219\u8bb0\u4e3a0\nmonth_stock_sh = stocks_month_sum[\ngap_sh\n]\nstock_p = pd.DataFrame()\nfor i in  month_stock_sh.columns:\n    single_month = month_stock_sh[i].apply(lambda x: 1 if x \n 0 else 0)\n    stock_p[i] = single_month\nstock_p[\npositive_num\n] = stock_p.sum(axis=1)\nstock_p.sort_values(\npositive_num\n, ascending=False, inplace=True)\nstock_p.shape\n\n\n\n\n(3039, 11)\n\n\n\n# 10\u4e2a\u67083039\u591a\u7684\u80a1\u7968\uff0c\u670982%\u7684\u80a1\u7968\u5728\u517110\u4e2a\u6708\u4efd\u4e2d\u4e0d\u8d85\u8fc75\u4e2a\u6708\u7684\u6536\u76ca\u662f\u5927\u4e8e\u5927\u76d8\u7684\uff0c\n# \u6bd4\u5982\u67094\u4e2a\u6708\u7684\u6536\u76ca\u5927\u4e8e\u540c\u671f\u7684\u5927\u76d8\u7684\u7684\u80a1\u7968\u6570\u76ee\u4e3a852\nstock_p[\npositive_num\n].value_counts()\n\n\n\n\n4     852\n5     689\n3     664\n6     341\n2     241\n7     119\n1      63\n8      56\n9       8\n0       4\n10      2\nName: positive_num, dtype: int64\n\n\n\n# \u4e2a\u80a1\u6da8\u8dcc\u5e45\u5927\u4e8e\u5927\u76d8\u8d85\u8fc76\u4e2a\u6708\u7684\u4e3a\u91cd\u70b9\u7814\u7a76\u5bf9\u8c61\ntarget_stock_index_ = stock_p[stock_p[\npositive_num\n] \n 6].index.values\nlen(target_stock_index_)\n\n\n\n\n185\n\n\n\ntarget_stocks = pd.DataFrame()\nfor i in target_stock_index_:\n        if target_stocks.empty:\n            target_stocks = stocks[stocks[\nssindex\n] == i]\n        else:\n            target_stocks = pd.concat([target_stocks, stocks[stocks[\nssindex\n] == i]], ignore_index=False)\ntarget_stocks.shape  # (34276, 5)\n# target_stocks.to_csv(\n./target_stocks_201710.csv\n, index=False)\n\n\n\n\ndef target_stock_plot(stock_id, stocks, stock_index_change):\n    target_stocks = pd.DataFrame()\n    for i in stock_id:\n        if target_stocks.empty:\n            target_stocks = stocks[stocks[\nssindex\n] == i]\n        else:\n            target_stocks = pd.concat([target_stocks, stocks[stocks[\nssindex\n] == i]], ignore_index=False)\n    sigma_large = target_stocks[target_stocks[\np_change\n] \n 11][\nssindex\n].unique()\n    tst = target_stocks.reset_index()\n    tst.set_index(\nssindex\n, inplace=True)\n    tst.drop(sigma_large, axis=0, inplace=True)\n    tst = tst.reset_index()\n    tst.set_index(\nssdate\n, inplace=True)\n    ts_sh = tst[tst[\nssindex\n].str.startswith(\n6\n)]\n    ts_sz = tst[tst[\nssindex\n].str.startswith(\n0\n)]\n    ts_cy = tst[tst[\nssindex\n].str.startswith(\n3\n)]\n    pivot_t = list()\n    for i in [ts_sh, ts_sz, ts_cy]:\n        pivot_t.append(pd.pivot_table(i, index=[i.index], columns=[i[\nssindex\n]]))    \n    stock_tar_sh = pivot_t[0]\n    stock_tar_sz = pivot_t[1]\n    stock_tar_cy = pivot_t[2]\n    ssindex_tar = stock_index_change[[u\n\u4e0a\u8bc1\n, u\n\u6df1\u5733\u6210\u6307\n, u\n\u521b\u4e1a\u677f\n]]\n    sh_pchange = pd.merge(stock_tar_sh[\np_change\n], ssindex_tar, how=\nright\n, left_index=True, right_index=True)\n    sz_pchange = pd.merge(stock_tar_sz[\np_change\n], ssindex_tar, how=\nright\n, left_index=True, right_index=True)\n    cy_pchange = pd.merge(stock_tar_cy[\np_change\n], ssindex_tar, how=\nright\n, left_index=True, right_index=True)\n    return [sh_pchange, sz_pchange, cy_pchange]\n\n\n\n\ndata_list = target_stock_plot(target_stock_index_, stocks, ssi_change)\n\n\n\n\ntarget_stocks.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nssindex\n\n      \nopen\n\n      \nclose\n\n      \nvolume\n\n      \np_change\n\n    \n\n    \n\n      \nssdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2017-01-03\n\n      \n600309\n\n      \n21.55\n\n      \n22.84\n\n      \n273738.59\n\n      \n6.08\n\n    \n\n    \n\n      \n2017-01-04\n\n      \n600309\n\n      \n22.84\n\n      \n23.71\n\n      \n273070.53\n\n      \n3.81\n\n    \n\n    \n\n      \n2017-01-05\n\n      \n600309\n\n      \n23.72\n\n      \n23.47\n\n      \n110848.12\n\n      \n-1.01\n\n    \n\n  \n\n\n\n\n\n\n\ntspv_ = target_stocks[[\nssindex\n, \nvolume\n, \np_change\n]]\ntspv = pd.pivot_table(tspv, index=[tspv.index], columns=[tspv.ssindex])\ntspv.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nvolume\n\n      \n...\n\n      \np_change\n\n    \n\n    \n\n      \nssindex\n\n      \n000039\n\n      \n000063\n\n      \n000090\n\n      \n000333\n\n      \n000338\n\n      \n000402\n\n      \n000418\n\n      \n000423\n\n      \n000426\n\n      \n000429\n\n      \n...\n\n      \n603577\n\n      \n603579\n\n      \n603589\n\n      \n603638\n\n      \n603689\n\n      \n603778\n\n      \n603859\n\n      \n603868\n\n      \n603939\n\n      \n603989\n\n    \n\n    \n\n      \nssdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2017-01-03\n\n      \n54452.85\n\n      \n200629.84\n\n      \n62564.77\n\n      \n441082.41\n\n      \n129824.97\n\n      \n124258.15\n\n      \n20953.93\n\n      \n44567.78\n\n      \n68529.82\n\n      \n76185.64\n\n      \n...\n\n      \n10.00\n\n      \nNaN\n\n      \n0.34\n\n      \nNaN\n\n      \nNaN\n\n      \n-0.61\n\n      \n6.42\n\n      \n1.02\n\n      \n0.17\n\n      \n1.28\n\n    \n\n    \n\n      \n2017-01-04\n\n      \n71462.32\n\n      \n181859.92\n\n      \n79045.98\n\n      \n358068.31\n\n      \n278103.72\n\n      \n128683.01\n\n      \n19167.08\n\n      \n63958.45\n\n      \n84513.59\n\n      \n55327.64\n\n      \n...\n\n      \n9.99\n\n      \nNaN\n\n      \n3.57\n\n      \nNaN\n\n      \nNaN\n\n      \n1.55\n\n      \n1.07\n\n      \n-0.04\n\n      \n0.10\n\n      \n0.32\n\n    \n\n    \n\n      \n2017-01-05\n\n      \n254709.69\n\n      \n302294.81\n\n      \n81780.03\n\n      \n191762.12\n\n      \n200137.56\n\n      \n67855.99\n\n      \n11631.32\n\n      \n45589.55\n\n      \n81008.58\n\n      \n66012.42\n\n      \n...\n\n      \n10.02\n\n      \nNaN\n\n      \n-1.59\n\n      \nNaN\n\n      \nNaN\n\n      \n-0.04\n\n      \n4.23\n\n      \n-0.82\n\n      \n0.20\n\n      \n-2.62\n\n    \n\n  \n\n\n\n\n3 rows \u00d7 370 columns\n\n\n\n\n\n# \u5229\u7528\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u8bc4\u4f30\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u5173\u7cfb\uff0c\u8fdb\u4e00\u6b65\u786e\u5b9a\u5f3a\u52bf\u4e2a\u80a1\ndef regression_stock(stock_data, stock_index_change, stocks_id):    \n    regress_weights = pd.DataFrame()\n    columns=[\nssindex\n, \nsindex\n, \nbeta\n, \nalpha\n, \nr_value\n, \np_value\n, \nsigma\n, \ncoeff\n]\n    for i in stocks_id:\n        one_stock = stock_data.loc[stock_data[\nssindex\n] == i, [\np_change\n]]    \n        index_stock = stock_index_change[[u\n\u4e0a\u8bc1\n]]\n        result = pd.merge(one_stock, index_stock, left_index=True, right_index=True)\n        corr_s = result.corr()\n        corrs = corr_s.loc[corr_s.index == \np_change\n, corr_s.index != \np_change\n]\n        for j in [u\n\u4e0a\u8bc1\n]:\n            cof = stats.linregress(result[j], result[\np_change\n])\n            cof = list(cof)\n            cof.insert(0, j)\n            cof.insert(0, i)\n            cof.append(corrs[j].values[0])\n            regress_weights = regress_weights.append(pd.Series(cof), ignore_index=True)\n\n    regress_weights.columns = columns\n    return regress_weights\n\n\n\n\ntarget_stock_w = regression_stock(target_stocks, ssi_change, target_stock_index_)\n\n\n\n\ntarget_stock_w.set_index(\nssindex\n, inplace=True)\n\n\n\n\ntarget_stock_w.describe()\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nbeta\n\n      \nalpha\n\n      \nr_value\n\n      \np_value\n\n      \nsigma\n\n      \ncoeff\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n185.000000\n\n      \n185.000000\n\n      \n185.000000\n\n      \n1.850000e+02\n\n      \n185.000000\n\n      \n185.000000\n\n    \n\n    \n\n      \nmean\n\n      \n1.364059\n\n      \n0.208562\n\n      \n0.310617\n\n      \n1.952266e-02\n\n      \n0.315013\n\n      \n0.310617\n\n    \n\n    \n\n      \nstd\n\n      \n0.589382\n\n      \n0.231631\n\n      \n0.109439\n\n      \n7.449688e-02\n\n      \n0.133513\n\n      \n0.109439\n\n    \n\n    \n\n      \nmin\n\n      \n0.055238\n\n      \n-0.327113\n\n      \n0.037926\n\n      \n2.076057e-25\n\n      \n0.106718\n\n      \n0.037926\n\n    \n\n    \n\n      \n25%\n\n      \n0.965545\n\n      \n0.091520\n\n      \n0.244631\n\n      \n5.001486e-08\n\n      \n0.230257\n\n      \n0.244631\n\n    \n\n    \n\n      \n50%\n\n      \n1.324876\n\n      \n0.173365\n\n      \n0.315984\n\n      \n1.127948e-05\n\n      \n0.275821\n\n      \n0.315984\n\n    \n\n    \n\n      \n75%\n\n      \n1.774391\n\n      \n0.262506\n\n      \n0.385492\n\n      \n1.014028e-03\n\n      \n0.366257\n\n      \n0.385492\n\n    \n\n    \n\n      \nmax\n\n      \n2.917665\n\n      \n1.377041\n\n      \n0.665457\n\n      \n6.053448e-01\n\n      \n0.841204\n\n      \n0.665457\n\n    \n\n  \n\n\n\n\n\n\n\n\u9009\u62e9$\\alpha$ \n 0.2\u7684\u80a1\u7968\n\n\ntarget_cof = target_stock_w[target_stock_w[\nalpha\n] \n 0.2]  \ntarget_stock_index_ = target_cof.index.unique()  \ntsw = target_stock_w.loc[target_stock_index_, :]\ntsw.shape\n\n\n\n\n(72, 7)\n\n\n\ntsw.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nsindex\n\n      \nbeta\n\n      \nalpha\n\n      \nr_value\n\n      \np_value\n\n      \nsigma\n\n      \ncoeff\n\n    \n\n    \n\n      \nssindex\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n600309\n\n      \n\u4e0a\u8bc1\n\n      \n1.528217\n\n      \n0.427141\n\n      \n0.340176\n\n      \n0.000002\n\n      \n0.309757\n\n      \n0.340176\n\n    \n\n    \n\n      \n300323\n\n      \n\u4e0a\u8bc1\n\n      \n1.151786\n\n      \n0.427385\n\n      \n0.191409\n\n      \n0.009246\n\n      \n0.437794\n\n      \n0.191409\n\n    \n\n    \n\n      \n000568\n\n      \n\u4e0a\u8bc1\n\n      \n1.194345\n\n      \n0.285961\n\n      \n0.332146\n\n      \n0.000003\n\n      \n0.248692\n\n      \n0.332146\n\n    \n\n  \n\n\n\n\n\n\n\ntsw.describe()\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nbeta\n\n      \nalpha\n\n      \nr_value\n\n      \np_value\n\n      \nsigma\n\n      \ncoeff\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n72.000000\n\n      \n72.000000\n\n      \n72.000000\n\n      \n7.200000e+01\n\n      \n72.000000\n\n      \n72.000000\n\n    \n\n    \n\n      \nmean\n\n      \n1.376637\n\n      \n0.395819\n\n      \n0.261814\n\n      \n3.424837e-02\n\n      \n0.382494\n\n      \n0.261814\n\n    \n\n    \n\n      \nstd\n\n      \n0.661657\n\n      \n0.260708\n\n      \n0.097494\n\n      \n9.132718e-02\n\n      \n0.167683\n\n      \n0.097494\n\n    \n\n    \n\n      \nmin\n\n      \n0.089285\n\n      \n0.201078\n\n      \n0.048533\n\n      \n2.479784e-12\n\n      \n0.134731\n\n      \n0.048533\n\n    \n\n    \n\n      \n25%\n\n      \n0.890088\n\n      \n0.243439\n\n      \n0.196778\n\n      \n2.918321e-06\n\n      \n0.258856\n\n      \n0.196778\n\n    \n\n    \n\n      \n50%\n\n      \n1.293436\n\n      \n0.278410\n\n      \n0.274410\n\n      \n1.628649e-04\n\n      \n0.333847\n\n      \n0.274410\n\n    \n\n    \n\n      \n75%\n\n      \n1.871676\n\n      \n0.427202\n\n      \n0.337566\n\n      \n8.272103e-03\n\n      \n0.460708\n\n      \n0.337566\n\n    \n\n    \n\n      \nmax\n\n      \n2.917665\n\n      \n1.377041\n\n      \n0.482065\n\n      \n5.083502e-01\n\n      \n0.841204\n\n      \n0.482065\n\n    \n\n  \n\n\n\n\n\n\n\n\u9009\u62e9$\\beta$ \n 1\u7684\u80a1\u7968\n\n\ntsw_cof = tsw[tsw[\nbeta\n] \n 1.1]  \nstock_index_final = tsw_cof.index.unique()  \ntsw_sec = tsw.loc[stock_index_final, :]\ntsw_sec.describe()\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nbeta\n\n      \nalpha\n\n      \nr_value\n\n      \np_value\n\n      \nsigma\n\n      \ncoeff\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n25.000000\n\n      \n25.000000\n\n      \n25.000000\n\n      \n25.000000\n\n      \n25.000000\n\n      \n25.000000\n\n    \n\n    \n\n      \nmean\n\n      \n0.680083\n\n      \n0.314594\n\n      \n0.177388\n\n      \n0.092120\n\n      \n0.293871\n\n      \n0.177388\n\n    \n\n    \n\n      \nstd\n\n      \n0.284923\n\n      \n0.118889\n\n      \n0.079043\n\n      \n0.138273\n\n      \n0.138153\n\n      \n0.079043\n\n    \n\n    \n\n      \nmin\n\n      \n0.089285\n\n      \n0.203866\n\n      \n0.048533\n\n      \n0.000018\n\n      \n0.134731\n\n      \n0.048533\n\n    \n\n    \n\n      \n25%\n\n      \n0.465821\n\n      \n0.237999\n\n      \n0.109585\n\n      \n0.001386\n\n      \n0.227418\n\n      \n0.109585\n\n    \n\n    \n\n      \n50%\n\n      \n0.710655\n\n      \n0.264513\n\n      \n0.193048\n\n      \n0.007947\n\n      \n0.246998\n\n      \n0.193048\n\n    \n\n    \n\n      \n75%\n\n      \n0.897701\n\n      \n0.343124\n\n      \n0.232177\n\n      \n0.134383\n\n      \n0.299470\n\n      \n0.232177\n\n    \n\n    \n\n      \nmax\n\n      \n1.098548\n\n      \n0.609608\n\n      \n0.307354\n\n      \n0.508350\n\n      \n0.675432\n\n      \n0.307354\n\n    \n\n  \n\n\n\n\n\n\n\nstock_index_final\n\n\n\n\nIndex([u'002415', u'002008', u'600519', u'000333', u'601933', u'601888',\n       u'002508', u'600622', u'600690', u'603288', u'300136', u'000418',\n       u'600809', u'300176', u'601318', u'601398', u'600276', u'601155',\n       u'603689', u'603579', u'600887', u'002032', u'600196', u'603228',\n       u'000651'],\n      dtype='object', name=u'ssindex')\n\n\n\ndata_list = target_stock_plot(stock_index_final, stocks, ssi_change)\n\n\n\n\ndef target_stocks_final_plot(data, plot_title=\n):\n    fig1, (ax1,ax2,ax3) = plt.subplots(3,1, figsize=(8,18), sharex=True)\n    data[0].cumsum().plot(ax=ax1)\n    data[1].cumsum().plot(ax=ax2)\n    data[2].cumsum().plot(ax=ax3)    \n    ax1.legend(loc=2, prop=font, fontsize=17)\n    ax2.legend(loc='best', prop=font, fontsize=17)\n    ax3.legend(loc='best', prop=font, fontsize=17) \n    ax1.set_title(u\n\u6caa\u5e02\n, fontproperties=font, fontsize=19)\n    ax2.set_title(u\n\u6df1\u5e02\n, fontproperties=font, fontsize=19)\n    ax3.set_title(u\n\u521b\u4e1a\u677f\n, fontproperties=font, fontsize=19)\n    ax1.set_xlabel(\n)\n    ax2.set_xlabel(\n)\n    ax3.set_xlabel(\n)    \n    plt.tight_layout() \n\n\n\n\ntarget_stocks_final_plot(data_list)\n\n\n\n\n\n\n\u6700\u7ec8\u9009\u62e9\u4e8622\u652f\u80a1\u7968\uff0c\u6caa\u5e02\u3001\u6df1\u5e02\u3001\u521b\u4e1a\u677f\u5206\u522b\u4e3a13\u30017\u30012\u652f\uff0c\u660e\u663e\u770b\u51fa\u9009\u62e9\u768422\u652f\u80a1\u7968\u6da8\u5e45\u660e\u663e\u9ad8\u4e8e\u5927\u76d8\uff0c\u6b64\u5916\u8868\u73b0\u51fa\u6caa\u5e02\u5f3a\uff0c\u521b\u4e1a\u677f\u5f31\uff0c\u8fd9\u8ddf17\u5e74\u7684\u6574\u4f53\u5e02\u573a\u73af\u5883\u6709\u5173\u3002\n\n\n\u603b\u4e4b\uff0c\u901a\u8fc7\u6ed1\u52a8\u8ba1\u7b97\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u6da8\u5e45\u5f3a\u5f31\u521d\u6b65\u7b5b\u9009\u5f3a\u52bf\u7684\u4e2a\u80a1\uff0c\u5373\u9009\u62e9\u90a3\u4e9b\u6bcf\u6708\u6da8\u5e45\u8d85\u8fc7\u5927\u76d8\u4e14\u6708\u6570\u91cf\u8d85\u8fc76\u4e2a\u7684\u80a1\u7968\uff0c\u7136\u540e\u901a\u8fc7\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5efa\u7acb\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u7ebf\u6027\u5173\u7cfb\uff0c\u5229\u7528\u7ebf\u6027\u56de\u5f52\u7cfb\u6570\u8fdb\u4e00\u6b65\u5224\u65ad\u5f3a\u52bf\u80a1\u7968\u3002\u8fd9\u662f\u56e0\u4e3a\u5efa\u7acb\u7684\u7ebf\u6027\u6a21\u578b $ R = \\alpha + \\beta R_M + \\epsilon $ \u7684\u7cfb\u6570\u03b2\u7684\u5927\u5c0f\u8868\u793a\u6536\u76ca\u7684\u6ce2\u52a8\u6027\u7684\u5927\u5c0f\uff0c\u5f53\u03b2\u7cfb\u6570\u5927\u4e8e1\u65f6\uff0c\u8be5\u8d44\u4ea7\u98ce\u9669\u5927\u4e8e\u5e02\u573a\u5e73\u5747\u98ce\u9669\uff1b\u53cd\u4e4b\uff0c\u5f53\u03b2\u7cfb\u6570\u5c0f\u4e8e1\u65f6\uff0c\u8be5\u8d44\u4ea7\u98ce\u9669\u5c0f\u4e8e\u5e02\u573a\u5e73\u5747\u98ce\u9669\u3002\u800c\u03b1\u53ef\u770b\u6210\u4e2a\u80a1\u8d85\u51fa\u80a1\u7968\u5e02\u573a\u7684\u53c2\u6570\uff0c\u5927\u4e8e0\u8868\u793a\u4f18\u4e8e\u5e02\u573a\uff0c\u5c0f\u4e8e0\u8868\u793a\u52a3\u4e8e\u5e02\u573a\u3002\n\n\n\u672c\u6587\u53ea\u662f\u5229\u7528\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5bf9\u80a1\u7968\u7684\u7b80\u5355\u5206\u6790\uff0c\u5e76\u672a\u5229\u7528\u80a1\u7968\u7684\u6210\u4ea4\u91cf\u4fe1\u606f\u3001\u677f\u5757\u4fe1\u606f\u7b49\uff0c\u4e5f\u672a\u5b9e\u73b0\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u6216\u9009\u80a1\u6a21\u578b\u6784\u5efa\uff0c\u5f85\u540e\u7eed\uff01", 
            "title": "\u80a1\u7968\u7ebf\u6027\u56de\u5f52\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/stocks_analysis/stock_index_tackle/#_1", 
            "text": "", 
            "title": "\u80a1\u7968\u7ebf\u6027\u56de\u5f52\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/stocks_analysis/stock_index_tackle/#_2", 
            "text": "\u4f7f\u7528tushare\u63d0\u4f9b\u7684\u63a5\u53e3\u91c7\u96c62017\u5e743000\u591a\u4e2a\u80a1\u4fe1\u606f\uff0c\u540c\u65f6\u91c7\u96c6\u4e86\u4e09\u5e74\u7684\u5927\u76d8\u4fe1\u606f\uff0c\u4f7f\u7528pymysql\u4e0emysql\u6570\u636e\u5e93\u8fdb\u884c\u4ea4\u4e92\uff0c\u5177\u4f53\u91c7\u96c6\u8fc7\u7a0b\u7565\u8fc7\u3002", 
            "title": "\u80a1\u7968\u6570\u636e\u91c7\u96c6"
        }, 
        {
            "location": "/data_analysis/stocks_analysis/stock_index_tackle/#_3", 
            "text": "tushare\u63d0\u4f9b\u7684\u65b0\u6d6a\u8d22\u7ecf\u4e0a\u7684\u6570\u636e\uff0c\u6570\u636e\u65e0\u660e\u663e\u7684\u7f3a\u5931\u548c\u9519\u8bef\u3002\n\u9996\u5148\u9009\u62e9\u5408\u9002\u7684\u80a1\u6307\u6307\u6570\uff0c\u7136\u540e\u5bf9\u4e2a\u80a1\u4e0e\u5927\u76d8\u6307\u6570\u7684\u5173\u7cfb\u8fdb\u884c\u5206\u6790\uff0c\u5373\u5c1d\u8bd5\u4f7f\u7528\u7ebf\u6027\u56de\u5f52\u5bf9\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u5173\u7cfb\u8fdb\u884c\u5206\u6790\uff0c\u8fdb\u800c\u627e\u51fa\u4e00\u4e9b\u201c\u5f3a\u52bf\u201d\u80a1\u7968\u3002  \u5047\u5b9a\u80a1\u7968\u6295\u8d44\u6536\u76ca\u7387\u4e0e\u5e02\u573a\u6536\u76ca\u7387\u5b58\u5728\u7740\u7ebf\u6027\u76f8\u5173\u5173\u7cfb\uff0c\u5219\u80a1\u7968\u6295\u8d44\u6536\u76ca\u7387\u7075\u654f\u5ea6\u7cfb\u6570\u53ef\u4ee5\u7528\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u4f30\u8ba1\uff0c\u5176\u516c\u5f0f\u5982\u4e0b\uff1a  R = \\alpha + \\beta R_M + \\epsilon    R\u2014\u8d44\u4ea7\u7684\u9884\u671f\u6295\u8d44\u6536\u76ca\u7387\uff1b\n$R_M$\u2014\u8d44\u672c\u5e02\u573a\u7684\u5e73\u5747\u6295\u8d44\u6536\u76ca\u7387\uff1b\n\u03b2\u2014\u98ce\u9669\u77eb\u6b63\u7cfb\u6570\uff0c\u5373\u5bf9\u8d44\u672c\u5e02\u573a\u7cfb\u7edf\u98ce\u9669\u53d8\u5316\u7684\u654f\u611f\u7a0b\u5ea6\uff1b\n$\\alpha$\u2014\u5e38\u6570\u9879\uff0c\u8d85\u51fa\u5e02\u573a\u7684\u90e8\u5206\uff1b\n\u03b5\u2014\u8bef\u5dee\u9879\uff1b  import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(style= whitegrid , palette= muted , font_scale=1.0, color_codes=True, context= talk )\n%matplotlib inline\nfrom matplotlib.font_manager import FontProperties  \nfont = FontProperties(fname=r /usr/share/fonts/truetype/arphic/ukai.ttc )\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\nimport datetime\nimport pymysql\nfrom scipy import stats", 
            "title": "\u6570\u636e\u6e05\u6d17\u4e0e\u5206\u6790"
        }, 
        {
            "location": "/data_analysis/stocks_analysis/stock_index_tackle/#_4", 
            "text": "# \u5904\u7406\u80a1\u6307\u6570\u636e\nsi = pd.read_csv( ./stock_index_all.csv , parse_dates=True, index_col= sdate )\nsi.shape  # (4404,8)\nsname = si[ sindex ].unique()\nsi[ sindex ].replace(sname, [u \u521b\u4e1a\u677f ,u \u6caa\u6df1300 ,u \u4e0a\u8bc1 ,\n                             u \u6df1\u5733\u6210\u6307 ,u \u4e0a\u8bc150 ,u \u4e2d\u5c0f\u677f ], inplace=True)  # \u900f\u89c6\u8868\nsi_pv = si.pivot_table(index=si.index, columns= sindex )\nsi_pv.head(3)   \n   \n     \n       \n       open \n       close \n       ... \n       price_change \n       p_change \n     \n     \n       sindex \n       \u4e0a\u8bc1 \n       \u4e0a\u8bc150 \n       \u4e2d\u5c0f\u677f \n       \u521b\u4e1a\u677f \n       \u6caa\u6df1300 \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u4e0a\u8bc150 \n       \u4e2d\u5c0f\u677f \n       \u521b\u4e1a\u677f \n       ... \n       \u4e2d\u5c0f\u677f \n       \u521b\u4e1a\u677f \n       \u6caa\u6df1300 \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u4e0a\u8bc150 \n       \u4e2d\u5c0f\u677f \n       \u521b\u4e1a\u677f \n       \u6caa\u6df1300 \n       \u6df1\u5733\u6210\u6307 \n     \n     \n       sdate \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2014-10-14 \n       2362.802 \n       1603.347 \n       5593.922 \n       1546.666 \n       2451.094 \n       8150.859 \n       2359.475 \n       1600.299 \n       5577.213 \n       1539.119 \n       ... \n       -22.859 \n       -9.208 \n       -8.384 \n       -24.106 \n       -0.28 \n       -0.35 \n       -0.41 \n       -0.59 \n       -0.34 \n       -0.29 \n     \n     \n       2014-10-15 \n       2358.233 \n       1599.895 \n       5577.844 \n       1539.347 \n       2444.538 \n       8141.143 \n       2373.670 \n       1612.772 \n       5611.542 \n       1545.623 \n       ... \n       34.329 \n       6.504 \n       17.312 \n       58.163 \n       0.60 \n       0.78 \n       0.62 \n       0.42 \n       0.71 \n       0.71 \n     \n     \n       2014-10-16 \n       2361.130 \n       1602.383 \n       5587.709 \n       1539.858 \n       2448.968 \n       8156.785 \n       2356.499 \n       1608.735 \n       5525.425 \n       1526.560 \n       ... \n       -86.117 \n       -19.063 \n       -19.479 \n       -87.437 \n       -0.72 \n       -0.25 \n       -1.53 \n       -1.23 \n       -0.79 \n       -1.07 \n     \n     3 rows \u00d7 42 columns   # \u5220\u9664\u80a1\u6307\u7f3a\u5931\u6570\u636e\uff0c\u539f\u59cb\u6570\u636e\u9519\u8bef\nss = si_pv[ open ][u \u4e0a\u8bc1 ]\nsst = si_pv[ss.isnull()].index.date\nmiss_date = []\nfor i in sst:\n    date_str = datetime.datetime.strftime(i,  %Y-%m-%d )\n    miss_date.append(date_str)\nmiss_date  ['2015-02-24', '2015-10-07', '2017-02-02', '2017-05-30']  si_pv.drop(sst, inplace=True)\nsi_pv.shape  # (733, 42)  (733, 42)  si_close = si_pv[ close ]\nsi_change = si_pv[ p_change ]\nsi_volume = si_pv[ volume ]  si_close.head(3)   \n   \n     \n       sindex \n       \u4e0a\u8bc1 \n       \u4e0a\u8bc150 \n       \u4e2d\u5c0f\u677f \n       \u521b\u4e1a\u677f \n       \u6caa\u6df1300 \n       \u6df1\u5733\u6210\u6307 \n     \n     \n       sdate \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2014-10-14 \n       2359.475 \n       1600.299 \n       5577.213 \n       1539.119 \n       2446.562 \n       8139.961 \n     \n     \n       2014-10-15 \n       2373.670 \n       1612.772 \n       5611.542 \n       1545.623 \n       2463.874 \n       8198.124 \n     \n     \n       2014-10-16 \n       2356.499 \n       1608.735 \n       5525.425 \n       1526.560 \n       2444.395 \n       8110.687 \n     \n      si_close.plot(figsize=(8,6))\nplt.xlabel(u \u65e5\u671f , fontsize=16, fontproperties=font)\nplt.title(u \u5404\u80a1\u6307\u6307\u6570\u53d8\u5316 , fontsize=25, fontproperties=font)\n# plt.yticks(ax1.get_yticks(), ax1.get_yticks() * 100)\nplt.ylabel('\u6307\u6570', fontproperties=font, fontsize=16)\nplt.gca().yaxis.grid(True, linestyle =  : )\nplt.gca().xaxis.grid(True, linestyle =  : )\nplt.legend(loc='best', prop=font, fontsize=12)  matplotlib.legend.Legend at 0x7f99aaf3b410    fig1, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(10, 13))\nsi_close.plot(ax=ax1, use_index=False, xticks=[], legend=False, fontsize=16)\nsi_change.plot(ax=ax2, use_index=False, xticks=[], legend=False, fontsize=16)\nsi_change_cumsum = si_change.cumsum()\nsi_change_cumsum.plot(ax=ax3, fontsize=16, legend=False)\nax1.set_title(u \u5404\u80a1\u6307\u53d8\u5316 , fontproperties=font, fontsize=19)\nax2.set_title(u \u6da8\u8dcc\u5e45\u53d8\u5316 , fontproperties=font, fontsize=19)\nax3.set_title(u \u6da8\u8dcc\u5e45\u7d2f\u8ba1\u53d8\u5316 , fontproperties=font, fontsize=19)\nplt.tight_layout() \nplt.xlabel(u \u65e5\u671f , fontproperties=font, fontsize=16)\nplt.legend(loc='best', prop=font, fontsize=15)  matplotlib.legend.Legend at 0x7f99aa280f90    # 2017\u5e74\u7684\u80a1\u6307\u6570\u636e\nssi_close = si_close['2017-1':'2017-10']\nssi_change = si_change['2017-1':'2017-10']\nssi_volume = si_volume['2017-1':'2017-10']\nssi_close.head(3)   \n   \n     \n       sindex \n       \u4e0a\u8bc1 \n       \u4e0a\u8bc150 \n       \u4e2d\u5c0f\u677f \n       \u521b\u4e1a\u677f \n       \u6caa\u6df1300 \n       \u6df1\u5733\u6210\u6307 \n     \n     \n       sdate \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2017-01-03 \n       3135.92 \n       2307.89 \n       6510.90 \n       1963.26 \n       3342.23 \n       10262.85 \n     \n     \n       2017-01-04 \n       3158.79 \n       2322.21 \n       6600.20 \n       1991.57 \n       3368.31 \n       10384.87 \n     \n     \n       2017-01-05 \n       3165.41 \n       2322.68 \n       6587.13 \n       1983.97 \n       3367.79 \n       10371.47 \n     \n      fig2, (ax1, ax2, ax3) = plt.subplots(3,1, figsize=(8, 13))\nssi_close.plot(ax=ax1, use_index=False, xticks=[], fontsize=16,legend=False)\nssi_change.plot(ax=ax2, use_index=False, xticks=[],legend=False, fontsize=16)\nssi_change_cumsum = ssi_change.cumsum()\nssi_change_cumsum.plot(ax=ax3, fontsize=16, legend=True)\nax1.set_title(u \u5404\u80a1\u6307\u53d8\u5316 , fontproperties=font, fontsize=19)\nax2.set_title(u \u6da8\u8dcc\u5e45\u53d8\u5316 , fontproperties=font, fontsize=19)\nax3.set_title(u \u6da8\u8dcc\u5e45\u7d2f\u8ba1\u53d8\u5316 , fontproperties=font, fontsize=19)\nplt.tight_layout() \nplt.legend(loc='best', prop=font, fontsize=15)\nplt.xlabel(u \u65e5\u671f , fontproperties=font, fontsize=16)  matplotlib.text.Text at 0x7f99a8429ed0    def corr_plot(dataframe, method='pearson', plot_title=None, figsize=(10,8)):\n    si_corr = dataframe.corr(method=method)    \n    siname = si_corr.columns.values\n    plt.figure(figsize=figsize)\n    g = sns.heatmap(si_corr, cbar=True, annot=True, \n                square=True, fmt= .2f , \n                annot_kws={'size': 12}, \n               yticklabels=siname,xticklabels=siname)\n    plt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n    plt.xlabel( )\n    plt.ylabel( )\n    plt.title(plot_title, fontproperties=font, fontsize=20)  corr_plot(ssi_change, u \u8fd1\u4e00\u5e74\u5404\u80a1\u6307\u76f8\u5173\u5173\u7cfb )   corr_plot(si_change, u \u8fd1\u4e09\u5e74\u5404\u80a1\u6307\u76f8\u5173\u5173\u7cfb )   ssi_change.shape  # (190, 6)\nssi_change.head(3)   \n   \n     \n       sindex \n       \u4e0a\u8bc1 \n       \u4e0a\u8bc150 \n       \u4e2d\u5c0f\u677f \n       \u521b\u4e1a\u677f \n       \u6caa\u6df1300 \n       \u6df1\u5733\u6210\u6307 \n     \n     \n       sdate \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2017-01-03 \n       1.04 \n       0.92 \n       0.60 \n       0.06 \n       0.97 \n       0.84 \n     \n     \n       2017-01-04 \n       0.73 \n       0.62 \n       1.37 \n       1.44 \n       0.78 \n       1.19 \n     \n     \n       2017-01-05 \n       0.21 \n       0.02 \n       -0.20 \n       -0.38 \n       -0.01 \n       -0.13 \n     \n      ssi_change.describe()   \n   \n     \n       sindex \n       \u4e0a\u8bc1 \n       \u4e0a\u8bc150 \n       \u4e2d\u5c0f\u677f \n       \u521b\u4e1a\u677f \n       \u6caa\u6df1300 \n       \u6df1\u5733\u6210\u6307 \n     \n   \n   \n     \n       count \n       188.000000 \n       188.000000 \n       188.000000 \n       188.000000 \n       188.000000 \n       188.000000 \n     \n     \n       mean \n       0.047606 \n       0.094096 \n       0.096436 \n       -0.011862 \n       0.091064 \n       0.059202 \n     \n     \n       std \n       0.534457 \n       0.635277 \n       0.831965 \n       1.024665 \n       0.575751 \n       0.829573 \n     \n     \n       min \n       -1.630000 \n       -1.570000 \n       -2.820000 \n       -5.110000 \n       -1.840000 \n       -3.570000 \n     \n     \n       25% \n       -0.300000 \n       -0.330000 \n       -0.445000 \n       -0.630000 \n       -0.292500 \n       -0.432500 \n     \n     \n       50% \n       0.070000 \n       0.065000 \n       0.085000 \n       0.060000 \n       0.095000 \n       0.110000 \n     \n     \n       75% \n       0.362500 \n       0.472500 \n       0.652500 \n       0.557500 \n       0.392500 \n       0.592500 \n     \n     \n       max \n       1.830000 \n       2.740000 \n       2.720000 \n       3.620000 \n       1.800000 \n       2.220000 \n     \n      \u6839\u636e\u7ebf\u56fe\u548cpearson\u76f8\u5173\u5173\u7cfb\u56fe\uff0c\u5404\u5927\u80a1\u6307\u6709\u4e00\u5b9a\u7684\u76f8\u5173\u6027\uff0c\u5c24\u5176\u662f\u4e0a\u8bc1\u3001\u6df1\u5733\u6210\u6307\u3001\u521b\u4e1a\u677f\uff0c\u7531\u6b64\u53ef\u4ee5\u9009\u62e9\u4e0a\u8bc1\u4e3a\u8861\u91cf\u7684\u80a1\u6307\u6307\u6570\u3002", 
            "title": "\u80a1\u6307\u6570\u636e\u5904\u7406"
        }, 
        {
            "location": "/data_analysis/stocks_analysis/stock_index_tackle/#_5", 
            "text": "stock_id= pd.read_csv( ./stock_id.csv , header=None, dtype=str)\nstock_id.head(10)\nstock_id.shape  (3413, 1)  stocks = pd.read_csv( ./stocks_all.csv , parse_dates=True, index_col= ssdate , dtype=str)  for i in [ open ,  close ,  volume ,  p_change ]:    \n    stocks[i] = stocks[i].astype(np.float)\nstocks.dtypes  ssindex      object\nopen        float64\nclose       float64\nvolume      float64\np_change    float64\ndtype: object  stocks.head(2)   \n   \n     \n       \n       ssindex \n       open \n       close \n       volume \n       p_change \n     \n     \n       ssdate \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2017-01-03 \n       300425 \n       30.47 \n       30.64 \n       10473.89 \n       0.86 \n     \n     \n       2017-01-04 \n       300425 \n       30.64 \n       30.97 \n       10098.92 \n       1.08 \n     \n      stocks.count()  ssindex     543445\nopen        543445\nclose       543445\nvolume      543445\np_change    543445\ndtype: int64  ssi_change.count()  sindex\n\u4e0a\u8bc1       188\n\u4e0a\u8bc150     188\n\u4e2d\u5c0f\u677f      188\n\u521b\u4e1a\u677f      188\n\u6caa\u6df1300    188\n\u6df1\u5733\u6210\u6307     188\ndtype: int64  \u4e2a\u80a1\u6570\u636e\u57fa\u672c\u65e0\u7f3a\u5931\u503c\uff0c\u7edf\u8ba1\u4e8617\u5e74\u622a\u81f3\u76ee\u524d\u5171\u8ba1188\u5929\u4ea4\u6613\u65e5\u7684\u6570\u636e", 
            "title": "\u4e2a\u80a1\u6570\u636e\u5904\u7406"
        }, 
        {
            "location": "/data_analysis/stocks_analysis/stock_index_tackle/#_6", 
            "text": "# \u80a1\u7968id\nstocks_id = stocks[ ssindex ].unique()\nregress_weights = pd.DataFrame()\ncolumns=[ ssindex ,  sindex ,  beta ,  alpha ,  r_value ,  p_value ,  sigma ,  coeff ]\nfor i in stocks_id:\n    one_stock = stocks.loc[stocks[ ssindex ] == i, [ p_change ]]    \n    index_stock = ssi_change[[u \u4e0a\u8bc1 , u \u521b\u4e1a\u677f , u \u6df1\u5733\u6210\u6307 ]]\n    result = pd.merge(one_stock, index_stock, left_index=True, right_index=True)\n    corr_s = result.corr()\n    corrs = corr_s.loc[corr_s.index ==  p_change , corr_s.index !=  p_change ]\n    for j in ([u \u4e0a\u8bc1 , u \u521b\u4e1a\u677f , u \u6df1\u5733\u6210\u6307 ]):\n        # \u4e2a\u80a1\u4e0e\u5927\u76d8\u6307\u6570\n        cof = stats.linregress(result[j], result[ p_change ])\n        cof = list(cof)\n        cof.insert(0, j)\n        cof.insert(0, i)\n        cof.append(corrs[j].values[0])\n        regress_weights = regress_weights.append(pd.Series(cof), ignore_index=True)\nregress_weights.columns = columns\n# regress_weights.to_csv( ./stocks_linear_reg.csv , index=False)  regress_weights.head(3)   \n   \n     \n       \n       ssindex \n       sindex \n       beta \n       alpha \n       r_value \n       p_value \n       sigma \n       coeff \n     \n   \n   \n     \n       0 \n       300425 \n       \u4e0a\u8bc1 \n       1.982162 \n       -0.226491 \n       0.435494 \n       4.212572e-10 \n       0.300425 \n       0.435494 \n     \n     \n       1 \n       300425 \n       \u521b\u4e1a\u677f \n       1.370130 \n       -0.115876 \n       0.577131 \n       4.361627e-18 \n       0.142157 \n       0.577131 \n     \n     \n       2 \n       300425 \n       \u6df1\u5733\u6210\u6307 \n       1.630604 \n       -0.228663 \n       0.556075 \n       1.188637e-16 \n       0.178702 \n       0.556075 \n     \n      target_cof = regress_weights[regress_weights[ alpha ]   0.2]  # 11%\u80a1\u7968alpha   0.2\ntarget_stock_index_temp = target_cof[ ssindex ].unique()  # 443\ntarget_stock_index = list(set(target_stock_index1) | set(target_stock_index_temp))  rw = pd.pivot_table(regress_weights, index=[ ssindex ], columns=[ sindex ])  rw.head(2)   \n   \n     \n       \n       beta \n       alpha \n       r_value \n       p_value \n       sigma \n       coeff \n     \n     \n       sindex \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n     \n     \n       ssindex \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       000001 \n       1.009117 \n       0.124561 \n       0.371582 \n       0.094619 \n       0.144137 \n       0.120661 \n       0.422698 \n       0.100032 \n       0.241593 \n       1.515277e-09 \n       0.171984 \n       0.000838 \n       0.158640 \n       0.090845 \n       0.109434 \n       0.422698 \n       0.100032 \n       0.241593 \n     \n     \n       000002 \n       0.772420 \n       0.061969 \n       0.555449 \n       0.155289 \n       0.193293 \n       0.154671 \n       0.179175 \n       0.026400 \n       0.193210 \n       1.522864e-02 \n       0.722779 \n       0.008779 \n       0.315248 \n       0.174413 \n       0.209659 \n       0.179175 \n       0.026400 \n       0.193210 \n     \n      rwc = rw.swaplevel(0, 1, axis=1)  # \u53cd\u8f6c\u5217\u5c42\u6b21\u5316\u7d22\u5f15\nrwc.head(2)   \n   \n     \n       sindex \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n     \n     \n       \n       beta \n       beta \n       beta \n       alpha \n       alpha \n       alpha \n       r_value \n       r_value \n       r_value \n       p_value \n       p_value \n       p_value \n       sigma \n       sigma \n       sigma \n       coeff \n       coeff \n       coeff \n     \n     \n       ssindex \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       000001 \n       1.009117 \n       0.124561 \n       0.371582 \n       0.094619 \n       0.144137 \n       0.120661 \n       0.422698 \n       0.100032 \n       0.241593 \n       1.515277e-09 \n       0.171984 \n       0.000838 \n       0.158640 \n       0.090845 \n       0.109434 \n       0.422698 \n       0.100032 \n       0.241593 \n     \n     \n       000002 \n       0.772420 \n       0.061969 \n       0.555449 \n       0.155289 \n       0.193293 \n       0.154671 \n       0.179175 \n       0.026400 \n       0.193210 \n       1.522864e-02 \n       0.722779 \n       0.008779 \n       0.315248 \n       0.174413 \n       0.209659 \n       0.179175 \n       0.026400 \n       0.193210 \n     \n      rw[ sigma ].describe()   \n   \n     \n       sindex \n       \u4e0a\u8bc1 \n       \u521b\u4e1a\u677f \n       \u6df1\u5733\u6210\u6307 \n     \n   \n   \n     \n       count \n       3039.000000 \n       3039.000000 \n       3039.000000 \n     \n     \n       mean \n       0.318601 \n       0.160160 \n       0.197206 \n     \n     \n       std \n       0.173631 \n       0.088121 \n       0.111256 \n     \n     \n       min \n       0.080941 \n       0.047468 \n       0.055388 \n     \n     \n       25% \n       0.218256 \n       0.108247 \n       0.132529 \n     \n     \n       50% \n       0.275778 \n       0.137372 \n       0.168823 \n     \n     \n       75% \n       0.357421 \n       0.179410 \n       0.221232 \n     \n     \n       max \n       1.294449 \n       0.745507 \n       0.837215 \n     \n      p_value_l = regress_weights[regress_weights[ p_value ]  = 0.05]\ntarget_stock_index1 = p_value_l[ ssindex ].unique()\ntarget_stock_index1.shape  #  (234,)  \u6839\u636e\u4e2a\u80a1\u4e0e\u5927\u76d8\u8fdb\u884c\u7ebf\u6027\u56de\u5f52\uff0c\u5f97\u5230\u4e09\u4e2a\u56de\u5f52\u53c2\u6570\u5c06\uff0c\u5176\u4e2d\uff0c\u6839\u636ealpha\u7684\u6b63\u8d1f\u53f7\u53ef\u4ee5\u5224\u65ad\u4e2a\u80a1\u662f\u5426\u4f18\u4e8e\u5927\u76d8\uff08\u8d85\u51fa\u5e02\u573a\u7684\u7a0b\u5ea6\uff09\uff0cbeta\u662f\u5426\u5927\u4e8e\uff11\u8868\u793a\u4e86\u5bf9\u5927\u76d8\u7684\u654f\u611f\u7a0b\u5ea6\uff08\u5927\u4e8e\uff11\u8868\u793a\u654f\u611f\uff0c\u53cd\u4e4b\u8868\u793a\u4e0d\u654f\u611f\uff09\uff0csigma\u53ef\u8fd1\u4f3c\u770b\u6210\u4e2a\u80a1\u6ce2\u52a8\u98ce\u9669  # \u56de\u5f52\u7cfb\u6570\u76f8\u5173\u6027\u2014\u2014spearman\u76f8\u5173\u7cfb\u6570\nfor j in [u \u4e0a\u8bc1 , u \u521b\u4e1a\u677f , u \u6df1\u5733\u6210\u6307 ]:\n    temp = rwc[j][[ alpha ,  beta ,  sigma ]]\n    corr_plot(temp, method= spearman , plot_title = u {}\u56de\u5f52\u7cfb\u6570\u76f8\u5173\u5173\u7cfb .format(j), figsize=(8,6))     # \u56de\u5f52\u7cfb\u6570\u76f8\u5173\u6027\u2014\u2014pearson\u76f8\u5173\u7cfb\u6570\nfor j in [u \u4e0a\u8bc1 , u \u521b\u4e1a\u677f , u \u6df1\u5733\u6210\u6307 ]:\n    temp = rwc[j][[ alpha ,  beta ,  sigma ]]\n    corr_plot(temp, method= pearson , plot_title = u {}\u56de\u5f52\u7cfb\u6570\u76f8\u5173\u5173\u7cfb .format(j), figsize=(8,6))     alpha_stock = pd.DataFrame()\nalpha_stock[u \u4e0a\u8bc1 ] = rw[ alpha ][u \u4e0a\u8bc1 ]\nalpha_stock[u \u521b\u4e1a\u677f ] = rw[ alpha ][u \u521b\u4e1a\u677f ]\nalpha_stock[u \u6df1\u5733\u6210\u6307 ] = rw[ alpha ][u \u6df1\u5733\u6210\u6307 ]  def distribution_plot(df, plot_title= ):\n    for i in [ beta ,  alpha ,  sigma ]:    \n        fig1, (ax1, ax2) = plt.subplots(2, 1,figsize=(8,12))\n        df[i].plot(kind='hist',ax=ax1, normed=True, alpha=0.7,bins=50)\n        df[i].plot(kind='kde',ax=ax2, style='-.', linewidth=3)\n        ax1.legend(loc='best', prop=font, fontsize=17)\n        ax2.legend(loc='best', prop=font, fontsize=17)\n        ax1.set_title(u {0}{1}\u5206\u5e03 .format(plot_title, i), fontproperties=font, fontsize=19)\n        ax2.set_title(u {0}{1}\u5206\u5e03 .format(plot_title, i), fontproperties=font, fontsize=19)\n        plt.tight_layout()   ditribution_plot(rw)     $\\alpha$\u548c$\\beta$\u5206\u5e03\u7c7b\u4f3c\u6b63\u6001\u5206\u5e03\uff0c\u4f46$\\alpha$\u660e\u663e\u7684\u53f3\u504f\uff0c\u8868\u660e\u6709\u4e00\u4e9b$\\alpha$\u504f\u5927\uff0c\u4ece\u76f8\u5173\u5173\u7cfb\u56fe\u53ef\u770b\u51fa$\\alpha$\u548c$\\beta$\u6709\u4e00\u5b9a\u7684\u8d1f\u76f8\u5173\u6027\uff0c$\\alpha$\u548c$\\sigma$\u6709\u8f83\u5927\u7684\u6b63\u76f8\u5173\u6027\uff0c\u800c$\\beta$\u4e0e$\\sigma$\u6709\u8f83\u5f31\u7684\u6b63\u76f8\u5173\u6027\u3002  \u901a\u8fc7\u6bd4\u8f83\u6bcf\u6708\u4e2a\u80a1\u6da8\u8dcc\u5e45\u4e0e\u5927\u76d8\u6307\u6570\u6da8\u8dcc\u5e45\uff0c\u7b80\u5355\u7684\u5224\u65ad\u4e2a\u80a1\u5f3a\u5f31\uff0c\u7136\u540e\u901a\u8fc7\u7ebf\u6027\u56de\u5f52\u7cfb\u6570\u8fdb\u884c\u8fdb\u4e00\u6b65\u5224\u65ad  stocks_id = stocks[ ssindex ].unique()\ni = stocks_id[0]\none_stock = stocks.loc[stocks[ ssindex ] == i, [ p_change ]]    \nindex_stock = ssi_change[[u \u4e0a\u8bc1 ]]\nresult = pd.merge(one_stock, index_stock, left_index=True, right_index=True)\nresult.tail(3)   \n   \n     \n       \n       p_change \n       \u4e0a\u8bc1 \n     \n     \n       ssdate \n       \n       \n     \n   \n   \n     \n       2017-10-10 \n       2.71 \n       0.26 \n     \n     \n       2017-10-11 \n       0.18 \n       0.16 \n     \n     \n       2017-10-12 \n       -1.05 \n       -0.06 \n     \n      def stock_change_cumsum(stock_time, ssi_change):\n    stocks_id = stock_time[ ssindex ].unique()    \n    index_stock = ssi_change[[u \u4e0a\u8bc1 ]]  \n    move_sum = pd.DataFrame()\n    for k in stocks_id:\n        one_stock = stock_time.loc[stock_time[ ssindex ] == k, [ p_change ]]    \n        result = pd.merge(one_stock, index_stock, left_index=True, right_index=True)\n        for i in np.unique(result.index.year):\n            for j in np.unique(result.index.month):\n                if j   10:\n                    strm =  0  + str(j)\n                else:\n                    strm = str(j)\n                temp = str(i) +  -  + strm\n                try:\n                    stock_sum = result[temp].sum()\n                except KeyError as e:\n                    print(e)\n                else:\n                    stock_sum = stock_sum.append(pd.Series(dict(sdate=temp)))\n                    stock_sum = stock_sum.append(pd.Series(dict(sindex=k)))\n                    stock_sum = stock_sum.append(pd.Series(dict(gap_sh=stock_sum[ p_change ] - stock_sum[u \u4e0a\u8bc1 ])))\n                    stock_sum.pop(u'\u4e0a\u8bc1')\n                    move_sum = move_sum.append(stock_sum, ignore_index=True)\n    return move_sum  tt = stock_change_cumsum(stocks, ssi_change)\n# tt.to_csv( ./stocks_month_change.csv , index=False)  tt.head(3)   \n   \n     \n       \n       gap_sh \n       p_change \n       sdate \n       sindex \n     \n   \n   \n     \n       0 \n       -15.70 \n       -13.92 \n       2017-01 \n       300425 \n     \n     \n       1 \n       3.05 \n       5.66 \n       2017-02 \n       300425 \n     \n     \n       2 \n       -6.62 \n       -7.20 \n       2017-03 \n       300425 \n     \n      stocks_month_sum = pd.pivot_table(tt, index=[ sindex ], columns=[ sdate ])\nstocks_month_sum.head(3)   \n   \n     \n       \n       gap_sh \n       p_change \n     \n     \n       sdate \n       2017-01 \n       2017-02 \n       2017-03 \n       2017-04 \n       2017-05 \n       2017-06 \n       2017-07 \n       2017-08 \n       2017-09 \n       2017-10 \n       2017-01 \n       2017-02 \n       2017-03 \n       2017-04 \n       2017-05 \n       2017-06 \n       2017-07 \n       2017-08 \n       2017-09 \n       2017-10 \n     \n     \n       sindex \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       000001 \n       0.73 \n       -0.99 \n       -2.71 \n       0.11 \n       3.61 \n       -0.32 \n       12.20 \n       3.36 \n       -0.90 \n       2.78 \n       2.51 \n       1.62 \n       -3.29 \n       -1.98 \n       2.44 \n       2.09 \n       14.73 \n       6.06 \n       -1.26 \n       3.9 \n     \n     \n       000002 \n       -1.37 \n       -3.32 \n       1.04 \n       -3.21 \n       10.22 \n       16.76 \n       -10.07 \n       0.32 \n       13.89 \n       2.08 \n       0.97 \n       -0.71 \n       0.46 \n       -5.30 \n       9.05 \n       17.36 \n       -6.11 \n       3.02 \n       13.53 \n       3.2 \n     \n     \n       000004 \n       -17.16 \n       -0.62 \n       -7.19 \n       NaN \n       NaN \n       -34.40 \n       -15.69 \n       1.25 \n       4.56 \n       4.08 \n       -15.38 \n       1.99 \n       -7.77 \n       NaN \n       NaN \n       -32.43 \n       -13.16 \n       3.95 \n       4.20 \n       5.2 \n     \n      sms = stocks_month_sum[ gap_sh ]\nsms[ sum_all ] = sms.sum(axis=1)\nsms[ mean ] = sms.mean(axis=1)\nsms[ median ] = sms.median(axis=1)\nsms.head(3)   \n   \n     \n       sdate \n       2017-01 \n       2017-02 \n       2017-03 \n       2017-04 \n       2017-05 \n       2017-06 \n       2017-07 \n       2017-08 \n       2017-09 \n       2017-10 \n       sum_all \n       mean \n       median \n     \n     \n       sindex \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       000001 \n       0.73 \n       -0.99 \n       -2.71 \n       0.11 \n       3.61 \n       -0.32 \n       12.20 \n       3.36 \n       -0.90 \n       2.78 \n       17.87 \n       3.249091 \n       1.755000 \n     \n     \n       000002 \n       -1.37 \n       -3.32 \n       1.04 \n       -3.21 \n       10.22 \n       16.76 \n       -10.07 \n       0.32 \n       13.89 \n       2.08 \n       26.34 \n       4.789091 \n       1.560000 \n     \n     \n       000004 \n       -17.16 \n       -0.62 \n       -7.19 \n       NaN \n       NaN \n       -34.40 \n       -15.69 \n       1.25 \n       4.56 \n       4.08 \n       -65.17 \n       -14.482222 \n       -10.836111 \n     \n      stock_t = sms[sms[[ median ]]   1].dropna(how= all )\nstock_t.head(3)   \n   \n     \n       sdate \n       2017-01 \n       2017-02 \n       2017-03 \n       2017-04 \n       2017-05 \n       2017-06 \n       2017-07 \n       2017-08 \n       2017-09 \n       2017-10 \n       sum_all \n       mean \n       median \n     \n     \n       sindex \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       000001 \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       1.755000 \n     \n     \n       000002 \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       1.560000 \n     \n     \n       000016 \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       2.442727 \n     \n      # \u4e2a\u80a1\u6da8\u8dcc\u5e45\u5927\u4e8e\u5927\u76d8\u6da8\u8dcc\u5e45\u8bb0\u4e3a1\u5426\u5219\u8bb0\u4e3a0\nmonth_stock_sh = stocks_month_sum[ gap_sh ]\nstock_p = pd.DataFrame()\nfor i in  month_stock_sh.columns:\n    single_month = month_stock_sh[i].apply(lambda x: 1 if x   0 else 0)\n    stock_p[i] = single_month\nstock_p[ positive_num ] = stock_p.sum(axis=1)\nstock_p.sort_values( positive_num , ascending=False, inplace=True)\nstock_p.shape  (3039, 11)  # 10\u4e2a\u67083039\u591a\u7684\u80a1\u7968\uff0c\u670982%\u7684\u80a1\u7968\u5728\u517110\u4e2a\u6708\u4efd\u4e2d\u4e0d\u8d85\u8fc75\u4e2a\u6708\u7684\u6536\u76ca\u662f\u5927\u4e8e\u5927\u76d8\u7684\uff0c\n# \u6bd4\u5982\u67094\u4e2a\u6708\u7684\u6536\u76ca\u5927\u4e8e\u540c\u671f\u7684\u5927\u76d8\u7684\u7684\u80a1\u7968\u6570\u76ee\u4e3a852\nstock_p[ positive_num ].value_counts()  4     852\n5     689\n3     664\n6     341\n2     241\n7     119\n1      63\n8      56\n9       8\n0       4\n10      2\nName: positive_num, dtype: int64  # \u4e2a\u80a1\u6da8\u8dcc\u5e45\u5927\u4e8e\u5927\u76d8\u8d85\u8fc76\u4e2a\u6708\u7684\u4e3a\u91cd\u70b9\u7814\u7a76\u5bf9\u8c61\ntarget_stock_index_ = stock_p[stock_p[ positive_num ]   6].index.values\nlen(target_stock_index_)  185  target_stocks = pd.DataFrame()\nfor i in target_stock_index_:\n        if target_stocks.empty:\n            target_stocks = stocks[stocks[ ssindex ] == i]\n        else:\n            target_stocks = pd.concat([target_stocks, stocks[stocks[ ssindex ] == i]], ignore_index=False)\ntarget_stocks.shape  # (34276, 5)\n# target_stocks.to_csv( ./target_stocks_201710.csv , index=False)  def target_stock_plot(stock_id, stocks, stock_index_change):\n    target_stocks = pd.DataFrame()\n    for i in stock_id:\n        if target_stocks.empty:\n            target_stocks = stocks[stocks[ ssindex ] == i]\n        else:\n            target_stocks = pd.concat([target_stocks, stocks[stocks[ ssindex ] == i]], ignore_index=False)\n    sigma_large = target_stocks[target_stocks[ p_change ]   11][ ssindex ].unique()\n    tst = target_stocks.reset_index()\n    tst.set_index( ssindex , inplace=True)\n    tst.drop(sigma_large, axis=0, inplace=True)\n    tst = tst.reset_index()\n    tst.set_index( ssdate , inplace=True)\n    ts_sh = tst[tst[ ssindex ].str.startswith( 6 )]\n    ts_sz = tst[tst[ ssindex ].str.startswith( 0 )]\n    ts_cy = tst[tst[ ssindex ].str.startswith( 3 )]\n    pivot_t = list()\n    for i in [ts_sh, ts_sz, ts_cy]:\n        pivot_t.append(pd.pivot_table(i, index=[i.index], columns=[i[ ssindex ]]))    \n    stock_tar_sh = pivot_t[0]\n    stock_tar_sz = pivot_t[1]\n    stock_tar_cy = pivot_t[2]\n    ssindex_tar = stock_index_change[[u \u4e0a\u8bc1 , u \u6df1\u5733\u6210\u6307 , u \u521b\u4e1a\u677f ]]\n    sh_pchange = pd.merge(stock_tar_sh[ p_change ], ssindex_tar, how= right , left_index=True, right_index=True)\n    sz_pchange = pd.merge(stock_tar_sz[ p_change ], ssindex_tar, how= right , left_index=True, right_index=True)\n    cy_pchange = pd.merge(stock_tar_cy[ p_change ], ssindex_tar, how= right , left_index=True, right_index=True)\n    return [sh_pchange, sz_pchange, cy_pchange]  data_list = target_stock_plot(target_stock_index_, stocks, ssi_change)  target_stocks.head(3)   \n   \n     \n       \n       ssindex \n       open \n       close \n       volume \n       p_change \n     \n     \n       ssdate \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2017-01-03 \n       600309 \n       21.55 \n       22.84 \n       273738.59 \n       6.08 \n     \n     \n       2017-01-04 \n       600309 \n       22.84 \n       23.71 \n       273070.53 \n       3.81 \n     \n     \n       2017-01-05 \n       600309 \n       23.72 \n       23.47 \n       110848.12 \n       -1.01 \n     \n      tspv_ = target_stocks[[ ssindex ,  volume ,  p_change ]]\ntspv = pd.pivot_table(tspv, index=[tspv.index], columns=[tspv.ssindex])\ntspv.head(3)   \n   \n     \n       \n       volume \n       ... \n       p_change \n     \n     \n       ssindex \n       000039 \n       000063 \n       000090 \n       000333 \n       000338 \n       000402 \n       000418 \n       000423 \n       000426 \n       000429 \n       ... \n       603577 \n       603579 \n       603589 \n       603638 \n       603689 \n       603778 \n       603859 \n       603868 \n       603939 \n       603989 \n     \n     \n       ssdate \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2017-01-03 \n       54452.85 \n       200629.84 \n       62564.77 \n       441082.41 \n       129824.97 \n       124258.15 \n       20953.93 \n       44567.78 \n       68529.82 \n       76185.64 \n       ... \n       10.00 \n       NaN \n       0.34 \n       NaN \n       NaN \n       -0.61 \n       6.42 \n       1.02 \n       0.17 \n       1.28 \n     \n     \n       2017-01-04 \n       71462.32 \n       181859.92 \n       79045.98 \n       358068.31 \n       278103.72 \n       128683.01 \n       19167.08 \n       63958.45 \n       84513.59 \n       55327.64 \n       ... \n       9.99 \n       NaN \n       3.57 \n       NaN \n       NaN \n       1.55 \n       1.07 \n       -0.04 \n       0.10 \n       0.32 \n     \n     \n       2017-01-05 \n       254709.69 \n       302294.81 \n       81780.03 \n       191762.12 \n       200137.56 \n       67855.99 \n       11631.32 \n       45589.55 \n       81008.58 \n       66012.42 \n       ... \n       10.02 \n       NaN \n       -1.59 \n       NaN \n       NaN \n       -0.04 \n       4.23 \n       -0.82 \n       0.20 \n       -2.62 \n     \n     3 rows \u00d7 370 columns   # \u5229\u7528\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u8bc4\u4f30\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u5173\u7cfb\uff0c\u8fdb\u4e00\u6b65\u786e\u5b9a\u5f3a\u52bf\u4e2a\u80a1\ndef regression_stock(stock_data, stock_index_change, stocks_id):    \n    regress_weights = pd.DataFrame()\n    columns=[ ssindex ,  sindex ,  beta ,  alpha ,  r_value ,  p_value ,  sigma ,  coeff ]\n    for i in stocks_id:\n        one_stock = stock_data.loc[stock_data[ ssindex ] == i, [ p_change ]]    \n        index_stock = stock_index_change[[u \u4e0a\u8bc1 ]]\n        result = pd.merge(one_stock, index_stock, left_index=True, right_index=True)\n        corr_s = result.corr()\n        corrs = corr_s.loc[corr_s.index ==  p_change , corr_s.index !=  p_change ]\n        for j in [u \u4e0a\u8bc1 ]:\n            cof = stats.linregress(result[j], result[ p_change ])\n            cof = list(cof)\n            cof.insert(0, j)\n            cof.insert(0, i)\n            cof.append(corrs[j].values[0])\n            regress_weights = regress_weights.append(pd.Series(cof), ignore_index=True)\n\n    regress_weights.columns = columns\n    return regress_weights  target_stock_w = regression_stock(target_stocks, ssi_change, target_stock_index_)  target_stock_w.set_index( ssindex , inplace=True)  target_stock_w.describe()   \n   \n     \n       \n       beta \n       alpha \n       r_value \n       p_value \n       sigma \n       coeff \n     \n   \n   \n     \n       count \n       185.000000 \n       185.000000 \n       185.000000 \n       1.850000e+02 \n       185.000000 \n       185.000000 \n     \n     \n       mean \n       1.364059 \n       0.208562 \n       0.310617 \n       1.952266e-02 \n       0.315013 \n       0.310617 \n     \n     \n       std \n       0.589382 \n       0.231631 \n       0.109439 \n       7.449688e-02 \n       0.133513 \n       0.109439 \n     \n     \n       min \n       0.055238 \n       -0.327113 \n       0.037926 \n       2.076057e-25 \n       0.106718 \n       0.037926 \n     \n     \n       25% \n       0.965545 \n       0.091520 \n       0.244631 \n       5.001486e-08 \n       0.230257 \n       0.244631 \n     \n     \n       50% \n       1.324876 \n       0.173365 \n       0.315984 \n       1.127948e-05 \n       0.275821 \n       0.315984 \n     \n     \n       75% \n       1.774391 \n       0.262506 \n       0.385492 \n       1.014028e-03 \n       0.366257 \n       0.385492 \n     \n     \n       max \n       2.917665 \n       1.377041 \n       0.665457 \n       6.053448e-01 \n       0.841204 \n       0.665457 \n     \n      \u9009\u62e9$\\alpha$   0.2\u7684\u80a1\u7968  target_cof = target_stock_w[target_stock_w[ alpha ]   0.2]  \ntarget_stock_index_ = target_cof.index.unique()  \ntsw = target_stock_w.loc[target_stock_index_, :]\ntsw.shape  (72, 7)  tsw.head(3)   \n   \n     \n       \n       sindex \n       beta \n       alpha \n       r_value \n       p_value \n       sigma \n       coeff \n     \n     \n       ssindex \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       600309 \n       \u4e0a\u8bc1 \n       1.528217 \n       0.427141 \n       0.340176 \n       0.000002 \n       0.309757 \n       0.340176 \n     \n     \n       300323 \n       \u4e0a\u8bc1 \n       1.151786 \n       0.427385 \n       0.191409 \n       0.009246 \n       0.437794 \n       0.191409 \n     \n     \n       000568 \n       \u4e0a\u8bc1 \n       1.194345 \n       0.285961 \n       0.332146 \n       0.000003 \n       0.248692 \n       0.332146 \n     \n      tsw.describe()   \n   \n     \n       \n       beta \n       alpha \n       r_value \n       p_value \n       sigma \n       coeff \n     \n   \n   \n     \n       count \n       72.000000 \n       72.000000 \n       72.000000 \n       7.200000e+01 \n       72.000000 \n       72.000000 \n     \n     \n       mean \n       1.376637 \n       0.395819 \n       0.261814 \n       3.424837e-02 \n       0.382494 \n       0.261814 \n     \n     \n       std \n       0.661657 \n       0.260708 \n       0.097494 \n       9.132718e-02 \n       0.167683 \n       0.097494 \n     \n     \n       min \n       0.089285 \n       0.201078 \n       0.048533 \n       2.479784e-12 \n       0.134731 \n       0.048533 \n     \n     \n       25% \n       0.890088 \n       0.243439 \n       0.196778 \n       2.918321e-06 \n       0.258856 \n       0.196778 \n     \n     \n       50% \n       1.293436 \n       0.278410 \n       0.274410 \n       1.628649e-04 \n       0.333847 \n       0.274410 \n     \n     \n       75% \n       1.871676 \n       0.427202 \n       0.337566 \n       8.272103e-03 \n       0.460708 \n       0.337566 \n     \n     \n       max \n       2.917665 \n       1.377041 \n       0.482065 \n       5.083502e-01 \n       0.841204 \n       0.482065 \n     \n      \u9009\u62e9$\\beta$   1\u7684\u80a1\u7968  tsw_cof = tsw[tsw[ beta ]   1.1]  \nstock_index_final = tsw_cof.index.unique()  \ntsw_sec = tsw.loc[stock_index_final, :]\ntsw_sec.describe()   \n   \n     \n       \n       beta \n       alpha \n       r_value \n       p_value \n       sigma \n       coeff \n     \n   \n   \n     \n       count \n       25.000000 \n       25.000000 \n       25.000000 \n       25.000000 \n       25.000000 \n       25.000000 \n     \n     \n       mean \n       0.680083 \n       0.314594 \n       0.177388 \n       0.092120 \n       0.293871 \n       0.177388 \n     \n     \n       std \n       0.284923 \n       0.118889 \n       0.079043 \n       0.138273 \n       0.138153 \n       0.079043 \n     \n     \n       min \n       0.089285 \n       0.203866 \n       0.048533 \n       0.000018 \n       0.134731 \n       0.048533 \n     \n     \n       25% \n       0.465821 \n       0.237999 \n       0.109585 \n       0.001386 \n       0.227418 \n       0.109585 \n     \n     \n       50% \n       0.710655 \n       0.264513 \n       0.193048 \n       0.007947 \n       0.246998 \n       0.193048 \n     \n     \n       75% \n       0.897701 \n       0.343124 \n       0.232177 \n       0.134383 \n       0.299470 \n       0.232177 \n     \n     \n       max \n       1.098548 \n       0.609608 \n       0.307354 \n       0.508350 \n       0.675432 \n       0.307354 \n     \n      stock_index_final  Index([u'002415', u'002008', u'600519', u'000333', u'601933', u'601888',\n       u'002508', u'600622', u'600690', u'603288', u'300136', u'000418',\n       u'600809', u'300176', u'601318', u'601398', u'600276', u'601155',\n       u'603689', u'603579', u'600887', u'002032', u'600196', u'603228',\n       u'000651'],\n      dtype='object', name=u'ssindex')  data_list = target_stock_plot(stock_index_final, stocks, ssi_change)  def target_stocks_final_plot(data, plot_title= ):\n    fig1, (ax1,ax2,ax3) = plt.subplots(3,1, figsize=(8,18), sharex=True)\n    data[0].cumsum().plot(ax=ax1)\n    data[1].cumsum().plot(ax=ax2)\n    data[2].cumsum().plot(ax=ax3)    \n    ax1.legend(loc=2, prop=font, fontsize=17)\n    ax2.legend(loc='best', prop=font, fontsize=17)\n    ax3.legend(loc='best', prop=font, fontsize=17) \n    ax1.set_title(u \u6caa\u5e02 , fontproperties=font, fontsize=19)\n    ax2.set_title(u \u6df1\u5e02 , fontproperties=font, fontsize=19)\n    ax3.set_title(u \u521b\u4e1a\u677f , fontproperties=font, fontsize=19)\n    ax1.set_xlabel( )\n    ax2.set_xlabel( )\n    ax3.set_xlabel( )    \n    plt.tight_layout()   target_stocks_final_plot(data_list)   \u6700\u7ec8\u9009\u62e9\u4e8622\u652f\u80a1\u7968\uff0c\u6caa\u5e02\u3001\u6df1\u5e02\u3001\u521b\u4e1a\u677f\u5206\u522b\u4e3a13\u30017\u30012\u652f\uff0c\u660e\u663e\u770b\u51fa\u9009\u62e9\u768422\u652f\u80a1\u7968\u6da8\u5e45\u660e\u663e\u9ad8\u4e8e\u5927\u76d8\uff0c\u6b64\u5916\u8868\u73b0\u51fa\u6caa\u5e02\u5f3a\uff0c\u521b\u4e1a\u677f\u5f31\uff0c\u8fd9\u8ddf17\u5e74\u7684\u6574\u4f53\u5e02\u573a\u73af\u5883\u6709\u5173\u3002  \u603b\u4e4b\uff0c\u901a\u8fc7\u6ed1\u52a8\u8ba1\u7b97\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u6da8\u5e45\u5f3a\u5f31\u521d\u6b65\u7b5b\u9009\u5f3a\u52bf\u7684\u4e2a\u80a1\uff0c\u5373\u9009\u62e9\u90a3\u4e9b\u6bcf\u6708\u6da8\u5e45\u8d85\u8fc7\u5927\u76d8\u4e14\u6708\u6570\u91cf\u8d85\u8fc76\u4e2a\u7684\u80a1\u7968\uff0c\u7136\u540e\u901a\u8fc7\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5efa\u7acb\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u7ebf\u6027\u5173\u7cfb\uff0c\u5229\u7528\u7ebf\u6027\u56de\u5f52\u7cfb\u6570\u8fdb\u4e00\u6b65\u5224\u65ad\u5f3a\u52bf\u80a1\u7968\u3002\u8fd9\u662f\u56e0\u4e3a\u5efa\u7acb\u7684\u7ebf\u6027\u6a21\u578b $ R = \\alpha + \\beta R_M + \\epsilon $ \u7684\u7cfb\u6570\u03b2\u7684\u5927\u5c0f\u8868\u793a\u6536\u76ca\u7684\u6ce2\u52a8\u6027\u7684\u5927\u5c0f\uff0c\u5f53\u03b2\u7cfb\u6570\u5927\u4e8e1\u65f6\uff0c\u8be5\u8d44\u4ea7\u98ce\u9669\u5927\u4e8e\u5e02\u573a\u5e73\u5747\u98ce\u9669\uff1b\u53cd\u4e4b\uff0c\u5f53\u03b2\u7cfb\u6570\u5c0f\u4e8e1\u65f6\uff0c\u8be5\u8d44\u4ea7\u98ce\u9669\u5c0f\u4e8e\u5e02\u573a\u5e73\u5747\u98ce\u9669\u3002\u800c\u03b1\u53ef\u770b\u6210\u4e2a\u80a1\u8d85\u51fa\u80a1\u7968\u5e02\u573a\u7684\u53c2\u6570\uff0c\u5927\u4e8e0\u8868\u793a\u4f18\u4e8e\u5e02\u573a\uff0c\u5c0f\u4e8e0\u8868\u793a\u52a3\u4e8e\u5e02\u573a\u3002  \u672c\u6587\u53ea\u662f\u5229\u7528\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5bf9\u80a1\u7968\u7684\u7b80\u5355\u5206\u6790\uff0c\u5e76\u672a\u5229\u7528\u80a1\u7968\u7684\u6210\u4ea4\u91cf\u4fe1\u606f\u3001\u677f\u5757\u4fe1\u606f\u7b49\uff0c\u4e5f\u672a\u5b9e\u73b0\u80a1\u7968\u4ef7\u683c\u9884\u6d4b\u6216\u9009\u80a1\u6a21\u578b\u6784\u5efa\uff0c\u5f85\u540e\u7eed\uff01", 
            "title": "\u7ebf\u6027\u56de\u5f52\u5206\u6790\u4e2a\u80a1\u4e0e\u5927\u76d8\u7684\u5173\u7cfb"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/", 
            "text": "\\mathbb{\u903b\u8f91\u56de\u5f52\u4e0epython \u4ee3\u7801\u5b9e\u73b0}\n\n\n\n\n\u903b\u8f91\u56de\u5f52(Logistic Regression, LR)\u53c8\u79f0\u4e3a\u903b\u8f91\u56de\u5f52\u5206\u6790\uff0c\u662f\u5206\u7c7b\u548c\u9884\u6d4b\u7b97\u6cd5\u4e2d\u7684\u4e00\u79cd\u3002\u901a\u8fc7\u5386\u53f2\u6570\u636e\u7684\u8868\u73b0\u5bf9\u672a\u6765\u7ed3\u679c\u53d1\u751f\u7684\u6982\u7387\u8fdb\u884c\u9884\u6d4b\u3002\n\n\n\u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5546\u54c1\u7684\u8d2d\u4e70\u6982\u7387\u8bbe\u7f6e\u4e3a\u56e0\u53d8\u91cf\uff0c\u5c06\u7528\u6237\u7684\u7279\u5f81\u5c5e\u6027\uff0c\u4f8b\u5982\u6027\u522b\uff0c\u5e74\u9f84\uff0c\u6ce8\u518c\u65f6\u95f4\u7b49\u8bbe\u7f6e\u4e3a\u81ea\u53d8\u91cf\u3002\u6839\u636e\u7279\u5f81\u5c5e\u6027\u9884\u6d4b\u8d2d\u4e70\u7684\u6982\u7387\u3002\u903b\u8f91\u56de\u5f52\u4e0e\u7ebf\u6027\u56de\u5f52\u5206\u6790\uff08Linear Regression\uff09\u6709\u5f88\u591a\u76f8\u4f3c\u4e4b\u5904\uff0c\u4e0b\u9762\u5148\u6765\u770b\u4e0b\u7ebf\u6027\u56de\u5f52\u5206\u6790\n\n\n\u7ebf\u6027\u56de\u5f52\u5206\u6790\n\n\n\u9996\u5148\uff0c\u6e29\u6545\u4e00\u4e0b\u76f4\u7ebf\u65b9\u7a0b\n\n\n\n\n\n y = ax + b \n\n\n\n\n\u81ea\u53d8\u91cfx\u4e58\u4ee5\u659c\u7387a\u518d\u52a0\u4e0a\u622a\u8dddb\u5c31\u5f97\u5230\u4e86\u56e0\u53d8\u91cfy\n\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# from matplotlib.font_manager import FontProperties\nx = np.arange(-10, 10)\na, b = 2, 5\nfig, ax = plt.subplots(figsize=(8, 8))\n# \u9690\u85cf\u4e0a\u8fb9\u548c\u53f3\u8fb9\nax.spines[\ntop\n].set_color(\nnone\n) \nax.spines[\nright\n].set_color(\nnone\n) \n# \u79fb\u52a8\u53e6\u5916\u4e24\u4e2a\u8f74\nax.xaxis.set_ticks_position(\nbottom\n)\nax.spines['bottom'].set_position(('data', 0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data', 0))\nax.plot(x, a*x+b, linewidth=2, label=\ny=2x+5\n)\nax.legend()\nax.grid(True, linestyle=\n:\n, linewidth=1.5, alpha=0.8)\n\n\n\n\n\n\n\u4e00\u5143\u4e00\u6b21\u65b9\u7a0b\n \n\\quad y \\ = \\ ax \\ + \\ b \\quad \u4f8b\u5982\uff1a\\ y = 2x + 5\n\n\n\n\n\u53ef\u4ee5\u5199\u6210\uff1a  \n\\quad y \\ = \\ w_0 \\times x_0 \\ + \\ w_1 \\times x_1 \\quad \u5176\u4e2dw_0 =5, \\ x_0=1, \\ w_1=2, \\ x_1=x\n\n\n\n\n\u4e8c\u5143\u4e00\u6b21\u65b9\u7a0b\n \n\\quad y \\ = \\ ax \\ + \\ bx \\ + \\ c \n\n\n\n\n\u53ef\u4ee5\u5199\u6210\uff1a  \n\\quad y \\ = \\ w_0 \\times x_0 \\ + \\ w_1 \\times x_1 \\ + \\ w_2 \\times x_2 \\quad \u5176\u4e2dx_0=1, \\ w_0=c\n\n\n\n\nn\u5143\u4e00\u6b21\u65b9\u7a0b\u8868\u8fbe\u5f0f\u53ca\u77e9\u9635\u8868\u793a\uff1a\n\n\n\n\ny \\ = \\ w_0\\times x_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdot\\cdot\\cdot \\ w_n \\times x_n \\ \n\n\n\n\n\n\n=\\underbrace{\\begin{bmatrix} w_0 & w_1 & w_2 & \\cdots\\ &w_n \\end{bmatrix}}_{\u6743\u91cd\u7cfb\u6570\u5411\u91cf\\bf w} {\\ \\bullet}  \\underbrace{\\begin{bmatrix} x_{0} \\\\ x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_n \\end{bmatrix}}_{\u6837\u672c\u7279\u5f81\u77e9\u9635\\bf x}\n\n\n\n\n\n\n=\\ {\\bf w^T x} \\quad {\u5176\u4e2dx_0=1}\n\n\n\n\n\u56de\u5f52\u5206\u6790\u7528\u6765\u63cf\u8ff0\u81ea\u53d8\u91cfx\u548c\u56e0\u53d8\u91cfY\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6216\u8005\u8bf4\u81ea\u53d8\u91cfX\u5bf9\u56e0\u53d8\u91cfY\u7684\u5f71\u54cd\u7a0b\u5ea6\uff0c\u5e76\u5bf9\u56e0\u53d8\u91cfY\u8fdb\u884c\u9884\u6d4b\u3002\n \n\u5176\u4e2d\u56e0\u53d8\u91cf(y)\u662f\u6211\u4eec\u5e0c\u671b\u83b7\u5f97\u7684\u7ed3\u679c\uff0c\u81ea\u53d8\u91cf(x)\u662f\u5f71\u54cd\u7ed3\u679c\u7684\u6f5c\u5728\u56e0\u7d20\uff0c\u81ea\u53d8\u91cf\u53ef\u4ee5\u6709\u4e00\u4e2a\uff0c\u4e5f\u53ef\u4ee5\u6709\u591a\u4e2a\u3002\u4e00\u4e2a\u81ea\u53d8\u91cf\u7684\u53eb\u505a\u4e00\u5143\u56de\u5f52\u5206\u6790\uff0c\u8d85\u8fc7\u4e00\u4e2a\u81ea\u53d8\u91cf\u7684\u53eb\u505a\u591a\u5143\u56de\u5f52\u5206\u6790\u3002\n\n\n\u56de\u5f52\u5206\u6790\u5176\u5b9e\u5c31\u662f\u5bf9\u5df2\u77e5\u516c\u5f0f\u7684\u672a\u77e5\u53c2\u6570\u8fdb\u884c\u4f30\u8ba1\uff0c\u5728\u7ed9\u5b9a\u8bad\u7ec3\u6837\u672c\u70b9\u548c\u5df2\u77e5\u7684\u516c\u5f0f\u540e\uff0c\u53bb\u6c42\u89e3\u4e00\u4e2a\u6216\u591a\u4e2a\u672a\u77e5\u53c2\u6570\uff0c\u76f4\u5230\u627e\u5230\u90a3\u4e2a\u6700\u7b26\u5408\u6837\u672c\u70b9\u5206\u5e03\u7684\u53c2\u6570\uff08\u6216\u53c2\u6570\u7ec4\u5408\uff09\u3002\u6ce8\u610f\uff0c\u56de\u5f52\u7684\u524d\u63d0\u662f\u516c\u5f0f\u5df2\u77e5\uff0c\u5426\u5219\u56de\u5f52\u65e0\u6cd5\u8fdb\u884c\u3002\u6839\u636e\u516c\u5f0f\u7684\u4e0d\u540c\uff0c\u56de\u5f52\u5206\u4e3a\u7ebf\u6027\u56de\u5f52\u548c\u975e\u7ebf\u6027\u56de\u5f52\u3002\u7ebf\u6027\u56de\u5f52\u4e2d\u516c\u5f0f\u90fd\u662f\u201c\u4e00\u6b21\u201d\u7684\uff08\u4e00\u5143\u4e00\u6b21\u65b9\u7a0b\uff0c\u4e8c\u5143\u4e00\u6b21\u65b9\u7a0b...\uff09\uff0c\u800c\u975e\u7ebf\u6027\u5219\u53ef\u4ee5\u6709\u5404\u79cd\u5f62\u5f0f\uff08N\u5143N\u6b21\u65b9\u7a0b\uff0clog\u65b9\u7a0b...\uff09\u3002\n\n\n\u4e0b\u9762\u662f\u4e00\u7ec4\u5e7f\u544a\u8d39\u7528\u548c\u66dd\u5149\u6b21\u6570\u7684\u6570\u636e\uff0c\u8d39\u7528\u548c\u66dd\u5149\u6b21\u6570\u4e00\u4e00\u5bf9\u5e94\u3002\u5176\u4e2d\u66dd\u5149\u6b21\u6570\u662f\u6211\u4eec\u5e0c\u671b\u77e5\u9053\u7684\u7ed3\u679c\uff0c\u8d39\u7528\u662f\u5f71\u54cd\u66dd\u5149\u6b21\u6570\u7684\u56e0\u7d20\uff0c\u6211\u4eec\u5c06\u8d39\u7528\u8bbe\u7f6e\u4e3a\u81ea\u53d8\u91cfX\uff0c\u5c06\u66dd\u5149\u6b21\u6570\u8bbe\u7f6e\u4e3a\u56e0\u53d8\u91cfY\uff0c\u901a\u8fc7\u4e00\u5143\u7ebf\u6027\u56de\u5f52\u65b9\u7a0b\u548c\u5224\u5b9a\u7cfb\u6570\u53ef\u4ee5\u53d1\u73b0\u8d39\u7528(X)\u5bf9\u66dd\u5149\u6b21\u6570(Y)\u7684\u5f71\u54cd\u3002\n\n\n\n\n\n\u4ee5\u4e0b\u4e3a\u4e00\u5143\u56de\u5f52\u7ebf\u6027\u65b9\u5f0f\u8868\u8fbe\u5f62\u5f0f\uff0c\n\\hat{y} \\ = \\ w_0 \\ + \\ w_1 x_1\n\n\n\n\n\u5176\u4e2d\n\\bf{\\hat{y}}\n\u662f\u9884\u6d4b\u7684\u56e0\u53d8\u91cf\uff0c\n\\bf{x_1}\n\u662f\u81ea\u53d8\u91cf\n\\bf{X}\n\u7684\u4e00\u4e2a\u5177\u4f53\u503c\uff0c\u6211\u4eec\u53ea\u9700\u6c42\u51fa\u622a\u8ddd\nw_0\n\u548c\u659c\u7387\nw_1\n\u5c31\u53ef\u4ee5\u83b7\u5f97\u8d39\u7528\u548c\u66dd\u5149\u6b21\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5c31\u53ef\u4ee5\u5bf9\u66dd\u5149\u6b21\u6570\u8fdb\u884c\u9884\u6d4b\u3002\u901a\u5e38\uff0c\u53ef\u4ee5\u7528\u7528\u6700\u5c0f\u4e8c\u4e58\u6cd5\u6765\u8ba1\u7b97\u622a\u8dddb0\u548c\u659c\u7387b1\u3002\u6700\u5c0f\u4e8c\u4e58\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u8bef\u5dee\u7684\u5e73\u65b9\u548c\u5bfb\u627e\u6570\u636e\u7684\u6700\u4f73\u51fd\u6570\u5339\u914d\u3002\n\n\n\n\n\u5173\u4e8e\u51e0\u4e2a\u5c0f\u4f8b\u5b50\u53ef\u4ee5\u70b9\u51fb\n\u8fd9\u91cc\n\u548c\n\u8fd9\u91cc\n\n\n\u903b\u8f91\u56de\u5f52\uff08Logistic Regression\uff09\n\n\nLogistic Regression \u662f\u7ebf\u6027\u56de\u5f52\u7684\u4e00\u79cd\uff0c\u662f\u5de5\u4e1a\u754c\u6bd4\u8f83\u5e38\u7528\u7684\u6709\u76d1\u7763\u5f0f\u7684\u5206\u7c7b\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u67d0\u79cd\u4e8b\u7269\u7684\u53ef\u80fd\u6027\uff0c\u6bd4\u5982\uff0c\u7528\u4e8e\u5e7f\u544a\u9884\u6d4b\uff08ctr\u9884\u4f30\uff09\uff0c\u6839\u636e\u4e0d\u540c\u5e7f\u544a\u7684\u70b9\u51fb\u7684\u5386\u53f2\u6570\u636e\uff0c\u6765\u9884\u6d4b\u67d0\u5e7f\u544a\u7684\u70b9\u51fb\u7387\u7684\u53ef\u80fd\u6027\uff0c\u7136\u540e\uff0c\u628a\u6700\u53ef\u80fd\u88ab\u7528\u6237\u70b9\u51fb\u7684\u5e7f\u544a\u6446\u5728\u7528\u6237\u80fd\u770b\u5230\u7684\u5730\u65b9\uff0c\u5f53\u7528\u6237\u70b9\u51fb\u4e86\u8be5\u5e7f\u544a\uff0c\u7f51\u7ad9\u5c31\u6709\u94b1\u6536\u4e86\u3002\n\n\n\u73b0\u5b9e\u751f\u6d3b\u4e2d\uff0c\u6211\u4eec\u4e0d\u4ec5\u9700\u8981\u56de\u5f52\u4ea7\u751f\u4e00\u4e2a\u53ef\u4ee5\u6709\u5f88\u591a\u53d8\u5316\u7684\u56e0\u53d8\u91cf\uff0c\u6709\u65f6\u8fd8\u9700\u8981\u4ea7\u751f\u7c7b\u4f3c\u6982\u7387\u503c\u76840~1\u4e4b\u95f4\u7684\u6570\u503c\uff08\u6bd4\u5982\u67d0\u4e00\u53cc\u978b\u5b50\u4eca\u5929\u80fd\u5426\u5356\u51fa\u53bb\uff1f\u6216\u8005\u67d0\u4e00\u4e2a\u5e7f\u544a\u80fd\u5426\u88ab\u7528\u6237\u70b9\u51fb? \u6211\u4eec\u5e0c\u671b\u5f97\u5230\u8fd9\u4e2a\u6570\u503c\u6765\u8f85\u52a9\u51b3\u7b56\u978b\u5b50\u4e0a\u4e0d\u4e0a\u67b6\uff0c\u4ee5\u53ca\u5e7f\u544a\u5c55\u4e0d\u5c55\u793a\uff09\u3002\u8fd9\u4e2a\u6570\u503c\u5fc5\u987b\u662f0~1\u4e4b\u95f4\uff0c\u4f46\u663e\u7136\u7ebf\u6027\u56de\u5f52\u4e0d\u6ee1\u8db3\u8fd9\u4e2a\u533a\u95f4\u8981\u6c42\u3002\u4e8e\u662f\u5f15\u5165\u4e86Logistic\u65b9\u7a0b\uff0c\u6765\u505a\u5f52\u4e00\u5316\uff0c\u5373\u4ea7\u751f\u4e86\u903b\u8f91\u56de\u5f52\u3002\n\n\n\u5728\u4ecb\u7ecd\u903b\u8f91\u56de\u5f52\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u770b\u4e00\u4e2a\u5c0f\u4f8b\u5b50\uff1a\n\u9e22\u5c3e\u82b1\u6570\u636e\u96c6\u5305\u62ec\u4e09\u79cd\u9e22\u5c3e\u82b1\uff0c\u5c71\u9e22\u5c3e\u82b1(Iris Setosa)\u3001\u53d8\u8272\u9e22\u5c3e\u82b1(Iris\u3000Versicolor)\u3001\u7ef4\u5409\u5c3c\u4e9a\u9e22\u5c3e\u82b1(Iris Virginica)\n\n\n\u641e\u6e05\u51e0\u4e2a\u6982\u5ff5\uff1a\n\n\n\n\u6837\u672c\n\n\n\u7279\u5f81\n\n\n\u5206\u7c7b\u6807\u7b7e\n\n\n\u8bad\u7ec3\u96c6(train)\n\n\n\u6d4b\u8bd5\u96c6(test)\n\n\n\n\u83ba(dai)\u5c3e\u82b1\u6570\u636e\u96c6\uff1a\n150\u884c\\ \\times \\ 5\u5217\n\n\n\n\n\u7279\u5f81\uff1a4\u4e2a\uff0c\u5206\u522b\u662f\u82b1\u74e3\u957f\u5ea6\u548c\u5bbd\u5ea6\uff0c\u82b1\u843c\u957f\u5ea6\u548c\u5bbd\u5ea6\uff0c\u5355\u4f4dcm\n\n\n\u5206\u7c7b\u6807\u7b7e\uff1a\u6700\u540e\u4e00\u5217\uff0c\u4e09\u79cd\u53d6\u503c\uff0c\u5206\u522b\u4ee3\u8868\u4e09\u79cd\u7c7b\u578b\u7684\u83ba\u5c3e\u82b1\n\n\n\n\nimport pandas as pd\ndf = pd.read_excel(\n./Iris.xls\n, sheetname=\nIris\n)\nprint(type(df))\nprint(df.shape)\ndf.head(4)\n#df.tail(4)\n#df.iloc[49:54, :]\n\n\n\n\nclass 'pandas.core.frame.DataFrame'\n\n(150, 5)\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nsepal length\n\n      \nsepal width\n\n      \npetal length\n\n      \npetal width\n\n      \niris\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n5.1\n\n      \n3.5\n\n      \n1.4\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n    \n\n      \n1\n\n      \n4.9\n\n      \n3.0\n\n      \n1.4\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n    \n\n      \n2\n\n      \n4.7\n\n      \n3.2\n\n      \n1.3\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n    \n\n      \n3\n\n      \n4.6\n\n      \n3.1\n\n      \n1.5\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n  \n\n\n\n\n\n\n\nsigmoid\u51fd\u6570\n\n\nsigmoid\u51fd\u6570\uff0c\u6570\u5b66\u8868\u8fbe\u5f0f\uff1a\n\ns\\left(h\\right) \\ = \\ \\frac{1}{1 \\ + \\ e^{-h}}\n\n\u6ce8\u610f\uff0ch\u5728\u8fd9\u4e0d\u4ec5\u4ec5\u4ee3\u8868\u6211\u4eec\u901a\u5e38\u610f\u4e49\u7684\u81ea\u53d8\u91cfx\uff0c\u8fd8\u53ef\u4ee3\u8868\u591a\u4e2a\u81ea\u53d8\u91cf\u7684\u7ec4\u5408\u3002\n\n\n\nLogistic regression\u53ef\u4ee5\u7528\u6765\u505a\u56de\u5f52\uff0c\u4e5f\u53ef\u4ee5\u7528\u6765\u5206\u7c7b\uff08\u4e3b\u8981\u7528\u4e8e\u4e8c\u5206\u7c7b\uff09\u3002\u4ece\u4e0a\u56fe\u53ef\u4ee5\u770b\u5230sigmoid\u51fd\u6570\u662f\u4e00\u4e2as\u5f62\u7684\u66f2\u7ebf\uff0c\ns\\left(h\\right)\n\u7684\u53d6\u503c\u5728(0, 1)\u4e4b\u95f4\uff0c\u5f53h=0\u65f6\uff0c\n\\ s\\left(h\\right)=0.5\\ \n,\u5728h\u8fdc\u79bb0\u7684\u5730\u65b9\u51fd\u6570\u7684\u503c\u4f1a\u5f88\u5feb\u63a5\u8fd10\u62161\u3002\u8fd9\u4e2a\u6027\u8d28\u4f7f\u6211\u4eec\u80fd\u591f\u4ee5\u6982\u7387\u7684\u65b9\u5f0f\u6765\u89e3\u91ca\u3002\n\n\nsigmoid\u51fd\u6570\u63a8\u5bfc\n\n\n\u5176\u5b9e\uff0c\u76f8\u6bd4\u7ebf\u6027\u56de\u5f52\u65b9\u7a0b\uff0c\u903b\u8f91\u56de\u5f52\u662f\u5728\u7ebf\u6027\u56de\u5f52\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u903b\u8f91\u51fd\u6570\uff0c\u5373\u5c06\n\\ y \\ = \\ ax \\ + \\ b \\ \n\u4f5c\u4e3a\u81ea\u53d8\u91cf\u5e26\u5165\u4e86sigmoid\u51fd\u6570\u91cc\uff08\u6b64\u65f6\nh=y= ax \\ + \\ b \n\uff09\u3002\n\u4ece\u4e00\u4e2a\u4f8b\u5b50\u8bf4\u8d77,\u6211\u4eec\u901a\u8fc7\u7528\u6237\u7684\u5c5e\u6027\u548c\u7279\u5f81\u6765\u5224\u65ad\u7528\u6237\u6700\u7ec8\u662f\u5426\u4f1a\u8fdb\u884c\u8d2d\u4e70\u4e00\u79cd\u5546\u54c1\u3002\u5176\u4e2d\u8d2d\u4e70\u7684\u6982\u7387\u662f\u56e0\u53d8\u91cfy\uff0c\u7528\u6237\u7684\u5c5e\u6027\u548c\u7279\u5f81\u662f\u81ea\u53d8\u91cfX\u3002y\u503c\u8d8a\u5927\u8bf4\u660e\u7528\u6237\u8d2d\u4e70\u7684\u53ef\u80fd\u6027\u8d8a\u5927\u3002\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528InOdds(E)\u8868\u793a\u8fd9\u4e2a\u8d2d\u4e70\u4e8b\u4ef6\uff0c\u8be5\u4e8b\u4ef6\u53d1\u751f\u7684\u53ef\u80fd\u6027\uff08odds\uff09\u6765\u8868\u793a\u8d2d\u4e70\uff08P(E) \n=\n P\uff09\u4e0e\u672a\u8d2d\u4e70\uff08P(E')\uff09\u7684\u53ef\u80fd\u6027\u6bd4\u503c\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a\n\nInOdds\\left(E\\right)=W_0 + W_1 \\times X_1 + W_2 \\times X_2 + \\cdots + W_n \\times X_n +  \\epsilon\n\n\nOdds\\left(E\\right) = \\frac{P \\left(E \\right)}{P \\left(E' \\right)} = \\frac{P \\left(E \\right)}{1 - P \\left(E \\right)} = \\frac{P}{1 - P}\n\n\n\n\nOdds\u662f\u4e00\u4e2a\u4ece0\u5230\u65e0\u7a77\u7684\u6570\u5b57\uff0cOdds\u7684\u503c\u8d8a\u5927\uff0c\u8868\u660e\u4e8b\u4ef6\u53d1\u751f\u7684\u53ef\u80fd\u6027\u8d8a\u5927\u3002\u4e0b\u9762\u6211\u4eec\u8981\u5c06Odds\u8f6c\u5316\u4e3a0-1\u4e4b\u95f4\u7684\u6982\u7387\u51fd\u6570\u3002\u9996\u5148\u5bf9Odds\u53d6\u81ea\u7136\u5bf9\u6570\uff0c\u5f97\u5230logit\u65b9\u7a0b\uff0clogit\u662f\u4e00\u4e2a\u8303\u56f4\u5728\u8d1f\u65e0\u7a77\u5230\u6b63\u65e0\u7a77\u7684\u503c\u3002\n\n\n\n\nlogit(p) = lnOdds(p) = ln \\frac{p}{1 - p} = lnp - ln(1-p)\n\n\n\n\n\n\n\u57fa\u4e8e\u4e0a\u9762\u7684logit\u65b9\u7a0b\uff0c\u83b7\u5f97\u4ee5\u4e0b\u516c\u5f0f\uff1a\n\n\n\n\nlogit(\\pi) = lnOdds(\\pi) = ln\\frac{P(E)}{P(1-E)} = W_0 + W_1 \\times X_1 + W_2 \\times X_2 + \\cdots + W_n \\times X_n +  \\epsilon\n\n\n\n\n\u5176\u4e2d\u4f7f\u7528\u4e86\n\\pi\n\u66ff\u6362\u4e86\u516c\u5f0f\u4e2d\u7684P(E)\uff0c\u5373\n\\pi = P(E)\n\u3002\u6839\u636e\u6307\u6570\u51fd\u6570\u548c\u5bf9\u6570\u51fd\u6570\u89c4\u5219\u5f97\u5230\u4ee5\u4e0b\u516c\u5f0f\uff1a\n\n\n\n\n\\frac{P(E)}{1 - P(E)} = Odds(E) = e^{W_0 + W_1 \\times X_1 + W_2 \\times X_2 + \\cdots + W_n \\times X_n +  \\epsilon}\n\n\n\n\n\u79fb\u9879\uff0c\u5316\u7b80\u5f97\u5230\u903b\u8f91\u56de\u5f52\u65b9\u7a0b\uff1a\n\n\n\n\n p = P(E) = \\frac{e^{w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n}}{1 + e^{w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n}} = \\frac{1}{1 + e^{-(w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n)}} \n\n\n\n\n\u903b\u8f91\u56de\u5f52\u6a21\u578b\u89e3\u8bfb\n\n\n\u903b\u8f91\u56de\u5f52\u51fd\u6570\uff1a\n \n\n\\quad s\\left(h\\right) \\ = \\ \\frac{1}{1 \\ + \\ e^{-h}}\\quad\n \u3000\n\n\u5176\u4e2d, \nh = w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n \n \n\n\n\u5047\u8bbe\u6709n\u4e2a\u6837\u672c{\n\\bf X\n, y}\uff0cy\u662f\u5206\u7c7b\u6807\u8bb0\uff0c\u53d6\u503c\u662f0\u62161\uff0c\u8868\u793a\u8d1f\u7c7b\u8fd8\u662f\u6b63\u7c7b\uff0c\n\\bf X\n\u662fm\u7ef4\u7684\u6837\u672c\u7279\u5f81\u5411\u91cf\uff0c\u90a3\u4e48\u8fd9\u4e2a\u6837\u672c\n\\bf X\n\u5c5e\u4e8e\u6b63\u7c7b\uff0c\u4e5f\u5c31\u662fy=1\u7684\u201c\u6982\u7387\u201d\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u903b\u8f91\u51fd\u6570\u6765\u8868\u793a\uff1a\n\n\n\n\np(y=1 \\mid x; w) = s(w^T x) = \\frac{1}{1 + e^{- w^T x}}\n\n\u8fd9\u91cc\u7684\n\\bf w\n\u662f\u6a21\u578b\u53c2\u6570\uff0c\u4e5f\u79f0\u56de\u5f52\u7cfb\u6570\uff0c\n\\ s\n\u662fsigmoid\u51fd\u6570\u3002\n\n\n\u51b3\u7b56\u51fd\u6570\u662f\uff1a\n\n\n\\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n1 &\\ \\quad if\\ p(y=1 \\mid x)\\geq 0.5 \\\\\n0 &\\ \\quad otherwise.\n\\end{aligned}\n\\right.\n\n\n\u901a\u5e38\uff0c\u6211\u4eec\u9009\u62e90.5\u4f5c\u4e3a\u9608\u503c\uff0c\u5f53\u6709\u7279\u5b9a\u7684\u9700\u6c42\u65f6\u53ef\u4ee5\u9009\u62e9\u4e0d\u540c\u9608\u503c\uff0c\u5982\u679c\u5bf9\u6b63\u4f8b\u7684\u5224\u522b\u51c6\u786e\u6027\u8981\u6c42\u9ad8\uff0c\u53ef\u4ee5\u9009\u62e9\u9608\u503c\u5927\u4e00\u4e9b\uff0c\u5bf9\u6b63\u4f8b\u7684\u53ec\u56de\u8981\u6c42\u9ad8\uff0c\u5219\u53ef\u4ee5\u9009\u62e9\u9608\u503c\u5c0f\u4e00\u4e9b\u3002\n\n\n\u6a21\u578b\u53c2\u6570\u6c42\u89e3\n\n\n\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\n\n\n\n\u6211\u4eec\u8981\u7528\u903b\u8f91\u56de\u5f52\u51fd\u6570\u53bb\u505a\u5206\u7c7b\uff0c\u5fc5\u987b\u8981\u6c42\u51fa\u6a21\u578b\u7cfb\u6570\n\\bf w\n\uff0c\u90a3\u4e48\u5982\u4f55\u6c42\u89e3\n\\bf w\n\u5462\uff1f\n\u7b54\u6848\u662f\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08maximum likelihood\uff09+ \u68af\u5ea6\u4e0b\u964d\uff08gradient descent\uff09\u3002\n\n\n\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u672c\u8d28\u662f\uff0c\u9009\u62e9\u6700\u4f73\u7684\u53c2\u6570\n\\bf w\n,\u6765\u6700\u5927\u5316\u6837\u672c\u6570\u636e\u7684\u53ef\u80fd\u6027\u3002\u5047\u8bbe\u7ed9\u5b9a\u6837\u672c\nX_1, X_2 \\cdots X_n\n, \u90a3\u4e48\u5173\u4e8e\u53c2\u6570\n\\bf w\n\u7684\u53ef\u80fd\u6027\u51fd\u6570(\u53ef\u80fd\u6027\u51fd\u6570\u5c31\u662f\u6837\u672c\u6570\u636e\u4f5c\u4e3a\u53c2\u6570w\u7684\u51fd\u6570\u7684\u6982\u7387)\uff1a\n\nlik(w) = f(X_1, X_2, X_3, \\cdots X_n \\mid w)\n\n\u5982\u679c\nX_1, X_2, X_3, \\cdots X_n\n\u4e4b\u95f4\u662f\u76f8\u4e92\u72ec\u7acb\u7684\uff0c\u53ef\u80fd\u6027\u51fd\u6570\u53ef\u4ee5\u7b80\u5199\u4e3a\u5982\u4e0b\uff1a\n\nlik(w) = \\prod_{i=1}^n f(X_i \\mid w) \\quad likelihood \\ function\n\n\n\n\n\u4e00\u822c\u60c5\u51b5\uff0c\u6211\u4eec\u8981\u4f7f\u7528log\u53ef\u80fd\u6027\u51fd\u6570\uff0c\u539f\u56e0\uff1a\n\n\n1.\u5bf9\u4e0a\u9762\u7684likelihood function\u4e24\u8fb9\u540c\u65f6\u53d6\u5bf9\u6570\uff0c\u5c31\u5f97\u5230\u4e86log likelihood function\uff0c\u8fd9\u6837\u4e58\u79ef\u8f6c\u6362\u4e3a\u6c42\u548c\uff0c\u4ece\u800c\u4f7f\u5f97\u51fd\u6570\u7684\u6c42\u5bfc\u66f4\u5bb9\u6613\uff1b\n\n\n2.\u5982\u679c\u6211\u4eec\u6709\u5f88\u591a\u7684\u6837\u672c\u6570\u636e\uff0c\u82e5\u76f4\u63a5\u7528likelihood function\uff0c\u8be5\u51fd\u6570\u662f\u8fde\u4e58\u7684\uff0c\u800c\u4e14\u901a\u5e38\u8fd9\u4e9b\u9879\u90fd\u8f83\u5c0f\uff0c\u6545\u53ef\u80fd\u6027\u51fd\u6570\u5c31\u4f1a\u53d8\u5f97\u5f88\u5c0f\u3002\u6240\u4ee5\uff0c\u5e94\u8be5\u91c7\u7528log\u53ef\u80fd\u6027\u51fd\u6570\uff0c\u53ef\u4ee5\u9632\u6b62\u5f53\u6837\u672c\u53ef\u80fd\u6027\u5f88\u5c0f\u65f6\uff0c\u53ef\u80fd\u51fa\u73b0\u7684\u6570\u503c\u4e0b\u6ea2;\n\n\n3.log\u51fd\u6570\u662f\u5355\u8c03\u7684\uff0c\u6700\u5927\u5316\u53ef\u80fd\u6027\u51fd\u6570\u7684\u503c\u4e5f\u5c31\u662f\u6700\u5927\u5316log\u53ef\u80fd\u6027\u51fd\u6570\u7684\u503c\u3002log\u53ef\u80fd\u6027\u51fd\u6570\u516c\u5f0f\u5982\u4e0b\uff1a\n\nl(w) = log(\\ lik(w)\\ ) = \\sum_{i=1}^n log(\\ f(X_i \\mid w)\\ )\n\n\n\n\n\u7528\u53ef\u80fd\u6027\u51fd\u6570\u6765\u5b9a\u4e49\u4e0a\u9762\u7684\u6a21\u578b\u7cfb\u6570w\uff0c\u8981\u5229\u7528\u4e8c\u9879\u5206\u5e03\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a\n\nL(w) = \\prod_{i=1}^n p(y^{(i)} \\mid x^{(i)};w) = \n\\prod_{i=1}^n (s(h^{(i)})^{y^{(i)}} (1 - s(h^{(i)}))^{1 - y^{(i)}}\n\n\u5176\u4e2d\uff0c\ny^{(i)}\n\u8868\u793a\u7b2ci\u4e2a\u6837\u672c\u5bf9\u5e94\u7684\u5206\u7c7b\u6807\u8bb0\u503c\uff0c\nx^{(i)}\n\u8868\u793a\u7b2ci\u4e2a\u6837\u672c\u7684\u7279\u5f81\uff0c\nh^{(i)}\n\u4e3a\u7b2ci\u4e2a\u6837\u672c\u5bf9\u5e94\u7684\u5047\u8bbe\u51fd\u6570\u7684\u503c\uff0c\nh = h(w) = w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n\\ \n\u4e0a\u9762\u5f0f\u5b50\u4e24\u8fb9\u540c\u65f6\u6c42log\uff0c\u5f97\u5230\u6700\u7ec8\u7684log\u53ef\u80fd\u6027\u51fd\u6570\uff1a\n\nl(w) = log(L(w)) = \\sum_{i=1}^n y^{(i)} log(s(h^{(i)})) + (1 - y^{(i)}) log(1 - s(h^{(i)}))\n\n\n\u903b\u8f91\u56de\u5f52\u7684cost\u51fd\u6570\n\n\n\n\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5c31\u662f\u8981\u6c42\u5f97\u4f7fl(w)\u53d6\u6700\u5927\u503c\u65f6\u7684w\uff0c\u8fd9\u91cc\u53ef\u4ee5\u4f7f\u7528\u68af\u5ea6\u4e0a\u5347\u6cd5\u6c42\u89e3\uff0c\u82e5\u8981\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\uff0c\u5c31\u8981\u4e58\u4ee5\u4e00\u4e2a\u8d1f\u6570\uff0c\u5728\u8fd9\uff0c\u6211\u4eec\u53ef\u4ee5\u5148\u76f4\u63a5\u4e58\u4ee5-1\u5f97\u5230\u5982\u4e0b\u516c\u5f0f\uff1a\n\nJ(w) = -l(w) = -log(L(w)) = \\sum_{i=1}^n -y^{(i)} log(s(h^{(i)})) - (1 - y^{(i)}) log(1 - s(h^{(i)}))\n\n\u73b0\u5728\uff0c\u6211\u4eec\u5c31\u5206\u6790\u4e00\u4e2a\u6837\u672c\uff0c\u90a3\u4e48\u53ef\u4ee5\u628a\u4e0a\u9762\u7684cost\u51fd\u6570\u5199\u6210\u5982\u4e0b\u5f62\u5f0f\uff1a\n\n\n\n\nJ(w) = -ylog(s(h)) - (1 - y)log(1 - s(h))\n\n\n\n\n\u7576y=0\u6642\uff0c\u4e0a\u5f0f\u7684\u524d\u9762\u4e00\u9805\n-ylog(s(h)) = 0\n\uff0c\u800c\u7576y=1\u6642\uff0c\u5f8c\u9762\u4e00\u9805\n(1 - y)log(1 - s(h)) = 0\n\uff0c\u6545\u4e0a\u5f0f\u53ef\u5beb\u6210\u5982\u4e0b\u5206\u6bb5\u51fd\u6570\uff1a\n\n\n\n\n\\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n-log(s(h)) &\\ \\quad if\\ y = 1 \\\\\n-log(1 - s(h)) &\\ \\quad if\\ y = 0\n\\end{aligned}\n\\right.\n\n\n\n\n\n\u597d\u4e86\uff0c\u73b0\u5728\u7684\u76ee\u6807\u662f\u6700\u5c0f\u5316cost\u51fd\u6570\uff0c\u627e\u5230\u6700\u4f73\u7684\u53c2\u6570\n\\bf w\n\uff0c\u65b9\u6cd5\u662f\u68af\u5ea6\u4e0b\u964d\u6cd5\u3002\n\n\n\n\u68af\u5ea6\u4e0b\u964d\u6cd5\u6c42\u6a21\u578b\u53c2\u6570\n\\bf w\n\n\n\n\n\u5bf9l(w)\u51fd\u6570\u4e58\u4ee5\n-\\frac{1}{n}\n\uff0cn\u662f\u6837\u672c\u6570\u91cf, \u6240\u4ee5\uff0ccost\u51fd\u6570\u4e3a\uff1a\n\nJ(w) = -\\frac{1}{n}l(w)\n\n\u6b63\u56e0\u4e3a\u4e58\u4e86\u4e00\u4e2a\u8d1f\u7684\u7cfb\u6570\n-\\frac{1}{n}\n\uff0c\u6240\u4ee5J(w)\u53d6\u6700\u5c0f\u503c\u65f6\u7684w\u4e3a\u8981\u6c42\u7684\u6700\u4f73\u53c2\u6570\u3002\u6839\u636e\u68af\u5ea6\u4e0b\u964d\u6cd5\u53ef\u5f97\u5230\n\\bf w\n\u7684\u66f4\u65b0\u89c4\u5219\u5982\u4e0b\uff1a\n\n\\bf w_j: = w_j \\ + \\ \\Delta {\\bf w_j}\n\n\n\n\n\n\n\\Delta \\bf w_j = -\\eta \\nabla J(w)= -\\eta \\frac{\\partial J(w)}{\\partial w_j} = \\eta\\left(y^\\left(i\\right) - h_w\\left(x^{(i)}\\right) \\right)x_j^\\left(i\\right)\n\n\u5176\u4e2d\uff0c\nj = 1, 2, 3, \\cdots m \\ \n\u4ee3\u8868\u7684\u662f\u6837\u672c\u7684\u7b2cj\u7ef4\u7684\u7279\u5f81\uff0c\nx^{(i)}\n\u4ee3\u8868\u7684\u662fn\u500b\u6a23\u672c\u4e2d\u7684\u7b2ci\u500b\u6a23\u672c\uff0c\n\\eta\n\u662f\u5b66\u4e60\u7387\uff0c\u662f0~1\u4e4b\u95f4\u7684\u6570\uff0c\nh_w(x^{(i)})\n\u4e3a\u51c0\u8f93\u5165\uff0c\n\\frac{\\partial J(w)}{\\partial w_j}\n\u4e3acost\u51fd\u6570\nJ(w)\n\u7684\u68af\u5ea6\u3002\n\u5b8c\u6574\u7248\u7684\u68af\u5ea6\u4e0b\u964d\uff1a\n\n\\bf w_j: = w_j \\ - \\eta \\sum_{i=1}^n (h_w(x^{(i)}) - y^{(i)})x_j^{(i)} \\quad j = 1, 2, 3, \\cdots m\n\n\u68af\u5ea6\u4e0a\u5347\u6cd5\uff1a\n\n\n\n\n\\bf w_j: = w_j \\ + \\eta \\sum_{i=1}^n (y^{(i)} - h_w(x^{(i)})x_j^{(i)}  \\quad j = 1, 2, 3, \\cdots m\n\n\n\n\n\u56e0\u6b64\uff0c\u7ed9\u5b9a\u521d\u59cb\u7684\u6a21\u578b\u7cfb\u6570\n\\bf w\n\u540e\uff0c\u6a21\u578b\u5c31\u4f1a\u5229\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u81ea\u52a8\u5b66\u4e60\u5230\u5408\u9002\u7684\u6a21\u578b\u7cfb\u6570\n\\bf w\n\uff0c\u62ff\u5230\u6743\u91cd\uff08\u6a21\u578b\uff09\u7cfb\u6570\u540e\uff0c\u5c31\u53ef\u6839\u636e\u51b3\u7b56\u51fd\u6570\u7684\u8f93\u51fa\u5bf9\u6837\u672c\u6570\u636e\u8fdb\u884c\u5206\u7c7b\u5206\u6790\u4e86\u3002\n\n\n\u68af\u5ea6\u4e0b\u964d\u8fc7\u7a0b\u5411\u91cf\u5316\n\n\nvectorization\u540e\n\\bf w\n\u66f4\u65b0\u7684\u6b65\u9aa4\u5982\u4e0b\uff1a\n\n\uff081\uff09\u6c42\nA = \\bf X {\\bullet} {\\bf w}\n\uff1b\n\n\uff082\uff09\u6c42E = h(A) - y\uff1b\n\n\uff083\uff09\u6c42\nw: = w -\\eta {\\bullet} X' {\\bullet} E\n\uff0cX'\u8868\u793a\u77e9\u9635X\u7684\u8f6c\u7f6e\u3002\n\n\n\n\n\n\n\n\n\npython\u4ee3\u7801\u793a\u4f8b(sklearn)\n\n\n\u4e3a\u4e86\u7b80\u5316\u6d41\u7a0b\uff0c\u4ece\u56db\u4e2a\u7279\u5f81\u4e2d\u62bd\u53d6\u4e86\u4e24\u4e2a\u7279\u5f81\u7ec4\u6210\u7279\u5f81\u77e9\u9635\uff0c\u5373\u9009\u62e9\u4e86\u7b2c\u4e00\u5217\u82b1\u843c\u957f\u5ea6(sepal length) and \u7b2c\u4e09\u5217\u82b1\u74e3\u957f\u5ea6(petal length) as X\n\n\nX = df.iloc[:, [0,2]].values  # .values\u3000\u662f\u5c06pandas\u7684DataFrame\u6216Series\u6570\u636e\u7ed3\u6784\u53d8\u6210numpy\u7684array\u7684\u6570\u7ec4\u6216\u77e9\u9635\u7c7b\u578b\nX.shape\nX[-2:, :]\n\n\n\n\narray([[ 6.2,  5.4],\n       [ 5.9,  5.1]])\n\n\n\nfig, ax = plt.subplots(figsize=(7,7))\nax.scatter(X[:50, 0], X[:50, 1], marker=\no\n, label=\nsetosa\n, c=\nwhite\n, edgecolor=\npurple\n)\nax.scatter(X[50:100, 0], X[50:100, 1], c=\nblue\n, marker=\nx\n, label=\nversicolor\n)\nax.scatter(X[100:, 0], X[100:, 1], marker=\n^\n, label=\nvirginica\n, c=\nwhite\n, edgecolor=\nred\n)\nax.set_xlabel(\nsepal length [cm]\n)\nax.set_ylabel(\npetal length [cm]\n)\nax.legend(loc=\nupper left\n)\nax.grid(True)\n\n\n\n\n\n\nseaborn\u7ed8\u5236\u6563\u70b9\u56fe\n\n\n# sns.scatterplot(x=\npetal length\n, y=\nsepal length\n, data=df, hue=\niris\n,kind=\npoint\n)\ng = sns.FacetGrid(df, hue=\niris\n, size=7, legend_out=False, hue_kws=dict(marker=[\no\n, \nx\n, \n^\n]))\ng.map(plt.scatter, \nsepal length\n, \npetal length\n,  alpha=.7)\ng.add_legend();\n\n\n\n\n\n\ndf.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nsepal length\n\n      \nsepal width\n\n      \npetal length\n\n      \npetal width\n\n      \niris\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n5.1\n\n      \n3.5\n\n      \n1.4\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n    \n\n      \n1\n\n      \n4.9\n\n      \n3.0\n\n      \n1.4\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n    \n\n      \n2\n\n      \n4.7\n\n      \n3.2\n\n      \n1.3\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n  \n\n\n\n\n\n\n\ny = df.iloc[:, 4]\ny.unique()\n# \u5c06\u6570\u636e\u96c6\u7684\u5b57\u7b26\u7c7b\u578b\u7684\u6570\u636e\u8f6c\u53d8\u6210\u6570\u503c\u7c7b\u578b,Iris-setosa\u6807\u8bb0\u4e3a\uff10,Iris-Versicolor\u4e3a1\uff0c\n# Iris-virginica\u4e3a2\ny.replace(y.unique(), [0, 1, 2], inplace=True)\nY = y.values\n# Y = y.values.reshape(-1, 1)\nnp.shape(Y)\n# np.unique(Y)\n# [u'Iris-setosa', u'Iris-versicolor', u'Iris-virginica'][0, 1, 2] \n\n\n\n\n(150,)\n\n\n\nX = df.iloc[:, [0,2]].values  # .values\u3000\u662f\u5c06pandas\u7684DataFrame\u6216Series\u6570\u636e\u7ed3\u6784\u53d8\u6210numpy\u7684array\u7684\u6570\u7ec4\u6216\u77e9\u9635\u7c7b\u578b\n# X[-2:, :]\nnp.shape(X)\n\n\n\n\n(150, 2)\n\n\n\n\u8c03\u7528sklearn\u5e93\u7684\u7c7bLogisticRegression\uff0c\u5b9e\u73b0\u5bf9Iris\u8bad\u7ec3\u96c6\u7684\u5b66\u4e60\uff0c\u7528\u4ea4\u53c9\u9a8c\u8bc1\u68c0\u9a8c\u5206\u7c7b\u6548\u679c\uff0c\u6700\u7ec8\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5e94\u7528\u5728\u6d4b\u8bd5\u96c6\u8fdb\u884c\u9a8c\u8bc1\n\n\nfrom sklearn.model_selection import train_test_split    \nfrom sklearn.model_selection import cross_val_score \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\nsc = StandardScaler()\nsc.fit(X_train)\nX_train_std = sc.transform(X_train)\nX_test_std = sc.transform(X_test)\nX_combined_std = np.vstack((X_train_std, X_test_std))\ny_combined = np.hstack((y_train, y_test))\nlr = LogisticRegression(C=100, penalty=\nl2\n, random_state=0, tol=1e-6)\nlr.fit(X_train_std, y_train)\nlr.predict_proba(X_test_std[0, :].reshape(1, -1))\n# np.shape(X_test_std[0, :]),\u8981\u6574\u5f62\u4e3a\uff08\uff11\uff0c\u3000\uff0d\uff11\uff09\n# np.shape(y_train)\ny_pred = lr.predict(X_test_std)\nprint(\nMisclassified samples: %d\n % (y_test != y_pred).sum())\nprint(\nAccuracy: %.2f\n % accuracy_score(y_test,y_pred))\nprint(\ncross validation score: %s\n % cross_val_score(lr, X_train_std, y_train, cv=5))\nprint(\nmean cross validation score: %s\n % cross_val_score(lr, X_train_std, y_train, cv=5).mean())\n\n\n\n\nMisclassified samples: 1\nAccuracy: 0.98\ncross validation score: [ 0.95454545  1.          1.          0.9047619   0.94736842]\nmean cross validation score: 0.961335156072\n\n\n\n\u67e5\u770b\u6a21\u578b\u662f\u5426\u8fc7\u62df\u5408\u53ef\u4ee5\u7528learning curve\u6765\u67e5\u770b\uff0c\u8fc7\u62df\u5408\u73b0\u8c61\u8868\u73b0\u4e3a\uff0c\u5728\u8bad\u7ec3\u96c6\u4e0a\u51c6\u786e\u7387\u5f97\u5206\u6bd4\u8f83\u9ad8\uff0c\u4f46\u4ea4\u53c9\u9a8c\u8bc1\u96c6\u4e0a\u5f97\u5206\u8f83\u4f4e\uff0c\u4e2d\u95f4gap\u8f83\u5927\uff0c\u4e00\u822c\u662f\u6a21\u578b\u8fc7\u4e8e\u590d\u6742\u5bfc\u81f4\uff0c\u4f46\u4e00\u822c\u968f\u7740\u6837\u672c\u91cf\u589e\u52a0\uff0c\u8fc7\u62df\u5408\u4f1a\u51cf\u5f31\u3002\u4e0e\u4e4b\u76f8\u53cd\u7684\u8fd8\u6709\u6b20\u62df\u5408\uff0c\u5373\u6a21\u578b\u590d\u6742\u5ea6\u4e0d\u591f\uff0c\u8bad\u7ec3\u96c6\u548c\u4ea4\u53c9\u9a8c\u8bc1\u96c6\u7684\u5f97\u5206\u5747\u8f83\u4f4e\u3002\n\n\n\n\n\u6b20\u64ec\u5408\n\u6700\u4f73\u64ec\u5408\n\u904e\u64ec\u5408\n\u3000\n\n\nfrom sklearn.model_selection import learning_curve\n# \u7528sklearn\u7684learning_curve\u5f97\u5230training_score\u548ccv_score\uff0c\u4f7f\u7528matplotlib\u753b\u51falearning curve\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=5, n_jobs=1, \n                        train_sizes=np.linspace(.05, 1., 20), verbose=0, plot=True):\n    \n\n    \u753b\u51fadata\u5728\u67d0\u6a21\u578b\u4e0a\u7684learning curve.\n    \u53c2\u6570\u89e3\u91ca\n    ----------\n    estimator : \u4f7f\u7528\u7684\u5206\u7c7b\u5668\u3002\n    title : \u56fe\u7684\u6807\u9898\u3002\n    X : \u8f93\u5165\u7684feature\uff0cnumpy\u7c7b\u578b\n    y : \u8f93\u5165\u7684target vector\n    ylim : tuple\u683c\u5f0f\u7684(ymin, ymax), \u8bbe\u5b9a\u56fe\u50cf\u4e2d\u7eb5\u5750\u6807\u7684\u6700\u4f4e\u70b9\u548c\u6700\u9ad8\u70b9\n    cv : \u505across-validation\u7684\u65f6\u5019\uff0c\u6570\u636e\u5206\u6210\u7684\u4efd\u6570\uff0c\u5176\u4e2d\u4e00\u4efd\u4f5c\u4e3acv\u96c6\uff0c\u5176\u4f59n-1\u4efd\u4f5c\u4e3atraining(\u9ed8\u8ba4\u4e3a3\u4efd)\n    n_jobs : \u5e76\u884c\u7684\u7684\u4efb\u52a1\u6570(\u9ed8\u8ba41)\n    \n\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n\n    train_scores_mean = np.mean(train_scores, axis=1)  # train_scores\u662f\u4e00\u4e2a\uff12\uff10\u884c\uff15\u5217\u7684ndarry,20\u4e3a\u4ece\u6837\u672c\u53d6\u7684\u4e0d\u540c\u6bd4\u4f8b\u7684\u6837\u672c\u6570\u636e\u4f5c\u4e3aX, \u800c\uff15\u8868\u793a\uff15\u6b21\u4ea4\u53c9\u9a8c\u8bc1\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    if plot:\n        plt.figure(figsize=(7,7))\n        plt.title(title)\n        if ylim is not None:\n            plt.ylim(*ylim)\n        plt.xlabel(\nsamples\n)\n        plt.ylabel(\nscores\n)\n        # plt.gca().invert_yaxis() \u4f8b\u5982y\u8f74\u5750\u68073000-10000\uff0c\u8c03\u6574\u4e3a10000-3000\u6765\u663e\u793a\n        plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, \n                         alpha=0.2, color=\nb\n)\n        plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, \n                         alpha=0.2, color=\nr\n)\n        plt.plot(train_sizes, train_scores_mean, '^-', color=\nblue\n, label=\ntrain score\n)\n        plt.plot(train_sizes, test_scores_mean, 'v-', color=\nred\n, label=\ncross_validation score\n)\n        plt.legend(loc=\nbest\n)\n        plt.grid(True)\n        plt.show()                \nplot_learning_curve(lr, \nlearning curve\n, X_train_std, y_train)\n\n\n\n\n\u51b3\u7b56\u8fb9\u754c\u793a\u610f\u56fe\n\n\n\n\n\n\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\ndef plot_decision_regions(X, Y, classifier, test_idx=None, resolution=0.02):\n    # \u5bf9\u5e94\u5206\u7c7b\u6807\u7b7e\n    y_maps = {\n1\n:\nIris-versicolor\n, \n0\n:\nIris-setosa\n, \n2\n: \nIris-virginica\n}\n    # setup marker generator and color map\n    markers = (\n^\n, \nx\n, \ns\n, \no\n, \nv\n)\n    colors = (\npurple\n, \nred\n, \nblue\n, \ncyan\n, \nlightgreen\n, )  #\ngray\n\n    cmap = ListedColormap(colors[:len(np.unique(Y))])\n    # plot the decision surface    \n    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    plt.figure(figsize=(8,8))\n    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)          \n    plt.xlim(xx1.min(), xx1.max())\n    plt.ylim(xx2.min(), xx2.max())\n    # plot all samples\n    for idx, cl in enumerate(np.unique(Y)):        \n        plt.scatter(x=X[Y==cl, 0], y=X[Y==cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx],label=y_maps[str(cl)])        \n    # highlight test samples\n    if test_idx:\n        X_test, Y_test = X[test_idx, :], Y[test_idx]\n        X_test, Y_test = X[test_idx, :], Y[test_idx]\n        plt.scatter(X_test[:, 0], X_test[:, 1], c=\n, alpha=1.0, linewidth=1, marker=\no\n, s=55, label=\ntest set\n)\n\n\n\n\nplot_decision_regions(X=X_combined_std, Y=y_combined, classifier=lr, test_idx=None)\nplt.xlabel(\nsepal length [standardized] cm\n, fontsize=16)\nplt.ylabel(\npetal length [standardized] cm\n, fontsize=14)\nplt.legend(loc=\nupper left\n)\n\n\n\n\nmatplotlib.legend.Legend at 0x7fdd1fee2f50\n\n\n\n\n\n\n\u53c2\u8003\u6587\u732e\n\n\n\u3010\u673a\u5668\u5b66\u4e60\u7b14\u8bb01\u3011Logistic\u56de\u5f52\u603b\u7ed3 http://blog.csdn.net/dongtingzhizi/article/details/15962797\n\n\n\u3010\u673a\u5668\u5b66\u4e60\u7b14\u8bb02\u3011Linear Regression\u603b\u7ed3 http://blog.csdn.net/dongtingzhizi/article/details/16884215\n\n\nLogistic Regression \u6a21\u578b\u7b80\u4ecb\u3000https://tech.meituan.com/intro_to_logistic_regression.html\n\n\n\u903b\u8f91\u56de\u5f52\u7b97\u6cd5\u7684\u539f\u7406\u53ca\u5b9e\u73b0(LR) http://www.cnblogs.com/nxld/p/6124235.html\n\n\n\u903b\u8f91\u56de\u5f52\uff08Logistic regression\uff09\u8be6\u89e3-\u5e76\u7528scikit-learn\u8bad\u7ec3\u903b\u8f91\u56de\u5f52\u62df\u5408Iris\u6570\u636e\u96c6  http://blog.csdn.net/xlinsist/article/details/51289825\n\n\nSklearn-LogisticRegression\u903b\u8f91\u56de\u5f52 http://blog.csdn.net/cherdw/article/details/54891073\n\n\n\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4e0ePython\u5b9e\u8df5\u4e4b\uff08\u4e03\uff09\u903b\u8f91\u56de\u5f52\uff08Logistic Regression\uff09 http://blog.csdn.net/zouxy09/article/details/20319673\n\n\n\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4e0ePython\u5b9e\u8df5\u4e4b\uff08\u4e03\uff09\u903b\u8f91\u56de\u5f52\uff08Logistic Regression http://blog.csdn.net/wenyusuran/article/details/25824011\n\n\n\u6b63\u5219\u5316\u65b9\u6cd5\uff1aL1\u548cL2 regularization\u3001\u6570\u636e\u96c6\u6269\u589e\u3001dropout http://blog.csdn.net/u012162613/article/details/44261657\n\n\nLaTeX \u5404\u79cd\u547d\u4ee4\u7b26\u53f7 http://blog.csdn.net/anxiaoxi45/article/details/39449445", 
            "title": "Logistic_regression\u7684Python\u4ee3\u7801\u5b9e\u73b0"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#mathbbpython", 
            "text": "\u903b\u8f91\u56de\u5f52(Logistic Regression, LR)\u53c8\u79f0\u4e3a\u903b\u8f91\u56de\u5f52\u5206\u6790\uff0c\u662f\u5206\u7c7b\u548c\u9884\u6d4b\u7b97\u6cd5\u4e2d\u7684\u4e00\u79cd\u3002\u901a\u8fc7\u5386\u53f2\u6570\u636e\u7684\u8868\u73b0\u5bf9\u672a\u6765\u7ed3\u679c\u53d1\u751f\u7684\u6982\u7387\u8fdb\u884c\u9884\u6d4b\u3002  \u4f8b\u5982\uff0c\u6211\u4eec\u53ef\u4ee5\u5c06\u5546\u54c1\u7684\u8d2d\u4e70\u6982\u7387\u8bbe\u7f6e\u4e3a\u56e0\u53d8\u91cf\uff0c\u5c06\u7528\u6237\u7684\u7279\u5f81\u5c5e\u6027\uff0c\u4f8b\u5982\u6027\u522b\uff0c\u5e74\u9f84\uff0c\u6ce8\u518c\u65f6\u95f4\u7b49\u8bbe\u7f6e\u4e3a\u81ea\u53d8\u91cf\u3002\u6839\u636e\u7279\u5f81\u5c5e\u6027\u9884\u6d4b\u8d2d\u4e70\u7684\u6982\u7387\u3002\u903b\u8f91\u56de\u5f52\u4e0e\u7ebf\u6027\u56de\u5f52\u5206\u6790\uff08Linear Regression\uff09\u6709\u5f88\u591a\u76f8\u4f3c\u4e4b\u5904\uff0c\u4e0b\u9762\u5148\u6765\u770b\u4e0b\u7ebf\u6027\u56de\u5f52\u5206\u6790", 
            "title": "\\mathbb{\u903b\u8f91\u56de\u5f52\u4e0epython \u4ee3\u7801\u5b9e\u73b0}"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#_1", 
            "text": "\u9996\u5148\uff0c\u6e29\u6545\u4e00\u4e0b\u76f4\u7ebf\u65b9\u7a0b    y = ax + b    \u81ea\u53d8\u91cfx\u4e58\u4ee5\u659c\u7387a\u518d\u52a0\u4e0a\u622a\u8dddb\u5c31\u5f97\u5230\u4e86\u56e0\u53d8\u91cfy  import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# from matplotlib.font_manager import FontProperties\nx = np.arange(-10, 10)\na, b = 2, 5\nfig, ax = plt.subplots(figsize=(8, 8))\n# \u9690\u85cf\u4e0a\u8fb9\u548c\u53f3\u8fb9\nax.spines[ top ].set_color( none ) \nax.spines[ right ].set_color( none ) \n# \u79fb\u52a8\u53e6\u5916\u4e24\u4e2a\u8f74\nax.xaxis.set_ticks_position( bottom )\nax.spines['bottom'].set_position(('data', 0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data', 0))\nax.plot(x, a*x+b, linewidth=2, label= y=2x+5 )\nax.legend()\nax.grid(True, linestyle= : , linewidth=1.5, alpha=0.8)   \u4e00\u5143\u4e00\u6b21\u65b9\u7a0b   \\quad y \\ = \\ ax \\ + \\ b \\quad \u4f8b\u5982\uff1a\\ y = 2x + 5   \u53ef\u4ee5\u5199\u6210\uff1a   \\quad y \\ = \\ w_0 \\times x_0 \\ + \\ w_1 \\times x_1 \\quad \u5176\u4e2dw_0 =5, \\ x_0=1, \\ w_1=2, \\ x_1=x   \u4e8c\u5143\u4e00\u6b21\u65b9\u7a0b   \\quad y \\ = \\ ax \\ + \\ bx \\ + \\ c    \u53ef\u4ee5\u5199\u6210\uff1a   \\quad y \\ = \\ w_0 \\times x_0 \\ + \\ w_1 \\times x_1 \\ + \\ w_2 \\times x_2 \\quad \u5176\u4e2dx_0=1, \\ w_0=c   n\u5143\u4e00\u6b21\u65b9\u7a0b\u8868\u8fbe\u5f0f\u53ca\u77e9\u9635\u8868\u793a\uff1a   y \\ = \\ w_0\\times x_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdot\\cdot\\cdot \\ w_n \\times x_n \\     =\\underbrace{\\begin{bmatrix} w_0 & w_1 & w_2 & \\cdots\\ &w_n \\end{bmatrix}}_{\u6743\u91cd\u7cfb\u6570\u5411\u91cf\\bf w} {\\ \\bullet}  \\underbrace{\\begin{bmatrix} x_{0} \\\\ x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_n \\end{bmatrix}}_{\u6837\u672c\u7279\u5f81\u77e9\u9635\\bf x}    =\\ {\\bf w^T x} \\quad {\u5176\u4e2dx_0=1}   \u56de\u5f52\u5206\u6790\u7528\u6765\u63cf\u8ff0\u81ea\u53d8\u91cfx\u548c\u56e0\u53d8\u91cfY\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6216\u8005\u8bf4\u81ea\u53d8\u91cfX\u5bf9\u56e0\u53d8\u91cfY\u7684\u5f71\u54cd\u7a0b\u5ea6\uff0c\u5e76\u5bf9\u56e0\u53d8\u91cfY\u8fdb\u884c\u9884\u6d4b\u3002  \n\u5176\u4e2d\u56e0\u53d8\u91cf(y)\u662f\u6211\u4eec\u5e0c\u671b\u83b7\u5f97\u7684\u7ed3\u679c\uff0c\u81ea\u53d8\u91cf(x)\u662f\u5f71\u54cd\u7ed3\u679c\u7684\u6f5c\u5728\u56e0\u7d20\uff0c\u81ea\u53d8\u91cf\u53ef\u4ee5\u6709\u4e00\u4e2a\uff0c\u4e5f\u53ef\u4ee5\u6709\u591a\u4e2a\u3002\u4e00\u4e2a\u81ea\u53d8\u91cf\u7684\u53eb\u505a\u4e00\u5143\u56de\u5f52\u5206\u6790\uff0c\u8d85\u8fc7\u4e00\u4e2a\u81ea\u53d8\u91cf\u7684\u53eb\u505a\u591a\u5143\u56de\u5f52\u5206\u6790\u3002  \u56de\u5f52\u5206\u6790\u5176\u5b9e\u5c31\u662f\u5bf9\u5df2\u77e5\u516c\u5f0f\u7684\u672a\u77e5\u53c2\u6570\u8fdb\u884c\u4f30\u8ba1\uff0c\u5728\u7ed9\u5b9a\u8bad\u7ec3\u6837\u672c\u70b9\u548c\u5df2\u77e5\u7684\u516c\u5f0f\u540e\uff0c\u53bb\u6c42\u89e3\u4e00\u4e2a\u6216\u591a\u4e2a\u672a\u77e5\u53c2\u6570\uff0c\u76f4\u5230\u627e\u5230\u90a3\u4e2a\u6700\u7b26\u5408\u6837\u672c\u70b9\u5206\u5e03\u7684\u53c2\u6570\uff08\u6216\u53c2\u6570\u7ec4\u5408\uff09\u3002\u6ce8\u610f\uff0c\u56de\u5f52\u7684\u524d\u63d0\u662f\u516c\u5f0f\u5df2\u77e5\uff0c\u5426\u5219\u56de\u5f52\u65e0\u6cd5\u8fdb\u884c\u3002\u6839\u636e\u516c\u5f0f\u7684\u4e0d\u540c\uff0c\u56de\u5f52\u5206\u4e3a\u7ebf\u6027\u56de\u5f52\u548c\u975e\u7ebf\u6027\u56de\u5f52\u3002\u7ebf\u6027\u56de\u5f52\u4e2d\u516c\u5f0f\u90fd\u662f\u201c\u4e00\u6b21\u201d\u7684\uff08\u4e00\u5143\u4e00\u6b21\u65b9\u7a0b\uff0c\u4e8c\u5143\u4e00\u6b21\u65b9\u7a0b...\uff09\uff0c\u800c\u975e\u7ebf\u6027\u5219\u53ef\u4ee5\u6709\u5404\u79cd\u5f62\u5f0f\uff08N\u5143N\u6b21\u65b9\u7a0b\uff0clog\u65b9\u7a0b...\uff09\u3002  \u4e0b\u9762\u662f\u4e00\u7ec4\u5e7f\u544a\u8d39\u7528\u548c\u66dd\u5149\u6b21\u6570\u7684\u6570\u636e\uff0c\u8d39\u7528\u548c\u66dd\u5149\u6b21\u6570\u4e00\u4e00\u5bf9\u5e94\u3002\u5176\u4e2d\u66dd\u5149\u6b21\u6570\u662f\u6211\u4eec\u5e0c\u671b\u77e5\u9053\u7684\u7ed3\u679c\uff0c\u8d39\u7528\u662f\u5f71\u54cd\u66dd\u5149\u6b21\u6570\u7684\u56e0\u7d20\uff0c\u6211\u4eec\u5c06\u8d39\u7528\u8bbe\u7f6e\u4e3a\u81ea\u53d8\u91cfX\uff0c\u5c06\u66dd\u5149\u6b21\u6570\u8bbe\u7f6e\u4e3a\u56e0\u53d8\u91cfY\uff0c\u901a\u8fc7\u4e00\u5143\u7ebf\u6027\u56de\u5f52\u65b9\u7a0b\u548c\u5224\u5b9a\u7cfb\u6570\u53ef\u4ee5\u53d1\u73b0\u8d39\u7528(X)\u5bf9\u66dd\u5149\u6b21\u6570(Y)\u7684\u5f71\u54cd\u3002   \u4ee5\u4e0b\u4e3a\u4e00\u5143\u56de\u5f52\u7ebf\u6027\u65b9\u5f0f\u8868\u8fbe\u5f62\u5f0f\uff0c \\hat{y} \\ = \\ w_0 \\ + \\ w_1 x_1   \u5176\u4e2d \\bf{\\hat{y}} \u662f\u9884\u6d4b\u7684\u56e0\u53d8\u91cf\uff0c \\bf{x_1} \u662f\u81ea\u53d8\u91cf \\bf{X} \u7684\u4e00\u4e2a\u5177\u4f53\u503c\uff0c\u6211\u4eec\u53ea\u9700\u6c42\u51fa\u622a\u8ddd w_0 \u548c\u659c\u7387 w_1 \u5c31\u53ef\u4ee5\u83b7\u5f97\u8d39\u7528\u548c\u66dd\u5149\u6b21\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u5c31\u53ef\u4ee5\u5bf9\u66dd\u5149\u6b21\u6570\u8fdb\u884c\u9884\u6d4b\u3002\u901a\u5e38\uff0c\u53ef\u4ee5\u7528\u7528\u6700\u5c0f\u4e8c\u4e58\u6cd5\u6765\u8ba1\u7b97\u622a\u8dddb0\u548c\u659c\u7387b1\u3002\u6700\u5c0f\u4e8c\u4e58\u6cd5\u901a\u8fc7\u6700\u5c0f\u5316\u8bef\u5dee\u7684\u5e73\u65b9\u548c\u5bfb\u627e\u6570\u636e\u7684\u6700\u4f73\u51fd\u6570\u5339\u914d\u3002   \u5173\u4e8e\u51e0\u4e2a\u5c0f\u4f8b\u5b50\u53ef\u4ee5\u70b9\u51fb \u8fd9\u91cc \u548c \u8fd9\u91cc", 
            "title": "\u7ebf\u6027\u56de\u5f52\u5206\u6790"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#logistic-regression", 
            "text": "Logistic Regression \u662f\u7ebf\u6027\u56de\u5f52\u7684\u4e00\u79cd\uff0c\u662f\u5de5\u4e1a\u754c\u6bd4\u8f83\u5e38\u7528\u7684\u6709\u76d1\u7763\u5f0f\u7684\u5206\u7c7b\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u67d0\u79cd\u4e8b\u7269\u7684\u53ef\u80fd\u6027\uff0c\u6bd4\u5982\uff0c\u7528\u4e8e\u5e7f\u544a\u9884\u6d4b\uff08ctr\u9884\u4f30\uff09\uff0c\u6839\u636e\u4e0d\u540c\u5e7f\u544a\u7684\u70b9\u51fb\u7684\u5386\u53f2\u6570\u636e\uff0c\u6765\u9884\u6d4b\u67d0\u5e7f\u544a\u7684\u70b9\u51fb\u7387\u7684\u53ef\u80fd\u6027\uff0c\u7136\u540e\uff0c\u628a\u6700\u53ef\u80fd\u88ab\u7528\u6237\u70b9\u51fb\u7684\u5e7f\u544a\u6446\u5728\u7528\u6237\u80fd\u770b\u5230\u7684\u5730\u65b9\uff0c\u5f53\u7528\u6237\u70b9\u51fb\u4e86\u8be5\u5e7f\u544a\uff0c\u7f51\u7ad9\u5c31\u6709\u94b1\u6536\u4e86\u3002  \u73b0\u5b9e\u751f\u6d3b\u4e2d\uff0c\u6211\u4eec\u4e0d\u4ec5\u9700\u8981\u56de\u5f52\u4ea7\u751f\u4e00\u4e2a\u53ef\u4ee5\u6709\u5f88\u591a\u53d8\u5316\u7684\u56e0\u53d8\u91cf\uff0c\u6709\u65f6\u8fd8\u9700\u8981\u4ea7\u751f\u7c7b\u4f3c\u6982\u7387\u503c\u76840~1\u4e4b\u95f4\u7684\u6570\u503c\uff08\u6bd4\u5982\u67d0\u4e00\u53cc\u978b\u5b50\u4eca\u5929\u80fd\u5426\u5356\u51fa\u53bb\uff1f\u6216\u8005\u67d0\u4e00\u4e2a\u5e7f\u544a\u80fd\u5426\u88ab\u7528\u6237\u70b9\u51fb? \u6211\u4eec\u5e0c\u671b\u5f97\u5230\u8fd9\u4e2a\u6570\u503c\u6765\u8f85\u52a9\u51b3\u7b56\u978b\u5b50\u4e0a\u4e0d\u4e0a\u67b6\uff0c\u4ee5\u53ca\u5e7f\u544a\u5c55\u4e0d\u5c55\u793a\uff09\u3002\u8fd9\u4e2a\u6570\u503c\u5fc5\u987b\u662f0~1\u4e4b\u95f4\uff0c\u4f46\u663e\u7136\u7ebf\u6027\u56de\u5f52\u4e0d\u6ee1\u8db3\u8fd9\u4e2a\u533a\u95f4\u8981\u6c42\u3002\u4e8e\u662f\u5f15\u5165\u4e86Logistic\u65b9\u7a0b\uff0c\u6765\u505a\u5f52\u4e00\u5316\uff0c\u5373\u4ea7\u751f\u4e86\u903b\u8f91\u56de\u5f52\u3002  \u5728\u4ecb\u7ecd\u903b\u8f91\u56de\u5f52\u4e4b\u524d\uff0c\u6211\u4eec\u5148\u770b\u770b\u4e00\u4e2a\u5c0f\u4f8b\u5b50\uff1a\n\u9e22\u5c3e\u82b1\u6570\u636e\u96c6\u5305\u62ec\u4e09\u79cd\u9e22\u5c3e\u82b1\uff0c\u5c71\u9e22\u5c3e\u82b1(Iris Setosa)\u3001\u53d8\u8272\u9e22\u5c3e\u82b1(Iris\u3000Versicolor)\u3001\u7ef4\u5409\u5c3c\u4e9a\u9e22\u5c3e\u82b1(Iris Virginica)  \u641e\u6e05\u51e0\u4e2a\u6982\u5ff5\uff1a  \n\u6837\u672c  \u7279\u5f81  \u5206\u7c7b\u6807\u7b7e  \u8bad\u7ec3\u96c6(train)  \u6d4b\u8bd5\u96c6(test)  \u83ba(dai)\u5c3e\u82b1\u6570\u636e\u96c6\uff1a 150\u884c\\ \\times \\ 5\u5217   \u7279\u5f81\uff1a4\u4e2a\uff0c\u5206\u522b\u662f\u82b1\u74e3\u957f\u5ea6\u548c\u5bbd\u5ea6\uff0c\u82b1\u843c\u957f\u5ea6\u548c\u5bbd\u5ea6\uff0c\u5355\u4f4dcm  \u5206\u7c7b\u6807\u7b7e\uff1a\u6700\u540e\u4e00\u5217\uff0c\u4e09\u79cd\u53d6\u503c\uff0c\u5206\u522b\u4ee3\u8868\u4e09\u79cd\u7c7b\u578b\u7684\u83ba\u5c3e\u82b1   import pandas as pd\ndf = pd.read_excel( ./Iris.xls , sheetname= Iris )\nprint(type(df))\nprint(df.shape)\ndf.head(4)\n#df.tail(4)\n#df.iloc[49:54, :]  class 'pandas.core.frame.DataFrame' \n(150, 5)   \n   \n     \n       \n       sepal length \n       sepal width \n       petal length \n       petal width \n       iris \n     \n   \n   \n     \n       0 \n       5.1 \n       3.5 \n       1.4 \n       0.2 \n       Iris-setosa \n     \n     \n       1 \n       4.9 \n       3.0 \n       1.4 \n       0.2 \n       Iris-setosa \n     \n     \n       2 \n       4.7 \n       3.2 \n       1.3 \n       0.2 \n       Iris-setosa \n     \n     \n       3 \n       4.6 \n       3.1 \n       1.5 \n       0.2 \n       Iris-setosa", 
            "title": "\u903b\u8f91\u56de\u5f52\uff08Logistic Regression\uff09"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#sigmoid", 
            "text": "sigmoid\u51fd\u6570\uff0c\u6570\u5b66\u8868\u8fbe\u5f0f\uff1a s\\left(h\\right) \\ = \\ \\frac{1}{1 \\ + \\ e^{-h}} \n\u6ce8\u610f\uff0ch\u5728\u8fd9\u4e0d\u4ec5\u4ec5\u4ee3\u8868\u6211\u4eec\u901a\u5e38\u610f\u4e49\u7684\u81ea\u53d8\u91cfx\uff0c\u8fd8\u53ef\u4ee3\u8868\u591a\u4e2a\u81ea\u53d8\u91cf\u7684\u7ec4\u5408\u3002  Logistic regression\u53ef\u4ee5\u7528\u6765\u505a\u56de\u5f52\uff0c\u4e5f\u53ef\u4ee5\u7528\u6765\u5206\u7c7b\uff08\u4e3b\u8981\u7528\u4e8e\u4e8c\u5206\u7c7b\uff09\u3002\u4ece\u4e0a\u56fe\u53ef\u4ee5\u770b\u5230sigmoid\u51fd\u6570\u662f\u4e00\u4e2as\u5f62\u7684\u66f2\u7ebf\uff0c s\\left(h\\right) \u7684\u53d6\u503c\u5728(0, 1)\u4e4b\u95f4\uff0c\u5f53h=0\u65f6\uff0c \\ s\\left(h\\right)=0.5\\  ,\u5728h\u8fdc\u79bb0\u7684\u5730\u65b9\u51fd\u6570\u7684\u503c\u4f1a\u5f88\u5feb\u63a5\u8fd10\u62161\u3002\u8fd9\u4e2a\u6027\u8d28\u4f7f\u6211\u4eec\u80fd\u591f\u4ee5\u6982\u7387\u7684\u65b9\u5f0f\u6765\u89e3\u91ca\u3002", 
            "title": "sigmoid\u51fd\u6570"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#sigmoid_1", 
            "text": "\u5176\u5b9e\uff0c\u76f8\u6bd4\u7ebf\u6027\u56de\u5f52\u65b9\u7a0b\uff0c\u903b\u8f91\u56de\u5f52\u662f\u5728\u7ebf\u6027\u56de\u5f52\u7684\u57fa\u7840\u4e0a\u589e\u52a0\u4e86\u4e00\u4e2a\u903b\u8f91\u51fd\u6570\uff0c\u5373\u5c06 \\ y \\ = \\ ax \\ + \\ b \\  \u4f5c\u4e3a\u81ea\u53d8\u91cf\u5e26\u5165\u4e86sigmoid\u51fd\u6570\u91cc\uff08\u6b64\u65f6 h=y= ax \\ + \\ b  \uff09\u3002\n\u4ece\u4e00\u4e2a\u4f8b\u5b50\u8bf4\u8d77,\u6211\u4eec\u901a\u8fc7\u7528\u6237\u7684\u5c5e\u6027\u548c\u7279\u5f81\u6765\u5224\u65ad\u7528\u6237\u6700\u7ec8\u662f\u5426\u4f1a\u8fdb\u884c\u8d2d\u4e70\u4e00\u79cd\u5546\u54c1\u3002\u5176\u4e2d\u8d2d\u4e70\u7684\u6982\u7387\u662f\u56e0\u53d8\u91cfy\uff0c\u7528\u6237\u7684\u5c5e\u6027\u548c\u7279\u5f81\u662f\u81ea\u53d8\u91cfX\u3002y\u503c\u8d8a\u5927\u8bf4\u660e\u7528\u6237\u8d2d\u4e70\u7684\u53ef\u80fd\u6027\u8d8a\u5927\u3002\u8fd9\u91cc\u6211\u4eec\u4f7f\u7528InOdds(E)\u8868\u793a\u8fd9\u4e2a\u8d2d\u4e70\u4e8b\u4ef6\uff0c\u8be5\u4e8b\u4ef6\u53d1\u751f\u7684\u53ef\u80fd\u6027\uff08odds\uff09\u6765\u8868\u793a\u8d2d\u4e70\uff08P(E)  =  P\uff09\u4e0e\u672a\u8d2d\u4e70\uff08P(E')\uff09\u7684\u53ef\u80fd\u6027\u6bd4\u503c\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a InOdds\\left(E\\right)=W_0 + W_1 \\times X_1 + W_2 \\times X_2 + \\cdots + W_n \\times X_n +  \\epsilon  Odds\\left(E\\right) = \\frac{P \\left(E \\right)}{P \\left(E' \\right)} = \\frac{P \\left(E \\right)}{1 - P \\left(E \\right)} = \\frac{P}{1 - P}   Odds\u662f\u4e00\u4e2a\u4ece0\u5230\u65e0\u7a77\u7684\u6570\u5b57\uff0cOdds\u7684\u503c\u8d8a\u5927\uff0c\u8868\u660e\u4e8b\u4ef6\u53d1\u751f\u7684\u53ef\u80fd\u6027\u8d8a\u5927\u3002\u4e0b\u9762\u6211\u4eec\u8981\u5c06Odds\u8f6c\u5316\u4e3a0-1\u4e4b\u95f4\u7684\u6982\u7387\u51fd\u6570\u3002\u9996\u5148\u5bf9Odds\u53d6\u81ea\u7136\u5bf9\u6570\uff0c\u5f97\u5230logit\u65b9\u7a0b\uff0clogit\u662f\u4e00\u4e2a\u8303\u56f4\u5728\u8d1f\u65e0\u7a77\u5230\u6b63\u65e0\u7a77\u7684\u503c\u3002   logit(p) = lnOdds(p) = ln \\frac{p}{1 - p} = lnp - ln(1-p)    \u57fa\u4e8e\u4e0a\u9762\u7684logit\u65b9\u7a0b\uff0c\u83b7\u5f97\u4ee5\u4e0b\u516c\u5f0f\uff1a   logit(\\pi) = lnOdds(\\pi) = ln\\frac{P(E)}{P(1-E)} = W_0 + W_1 \\times X_1 + W_2 \\times X_2 + \\cdots + W_n \\times X_n +  \\epsilon   \u5176\u4e2d\u4f7f\u7528\u4e86 \\pi \u66ff\u6362\u4e86\u516c\u5f0f\u4e2d\u7684P(E)\uff0c\u5373 \\pi = P(E) \u3002\u6839\u636e\u6307\u6570\u51fd\u6570\u548c\u5bf9\u6570\u51fd\u6570\u89c4\u5219\u5f97\u5230\u4ee5\u4e0b\u516c\u5f0f\uff1a   \\frac{P(E)}{1 - P(E)} = Odds(E) = e^{W_0 + W_1 \\times X_1 + W_2 \\times X_2 + \\cdots + W_n \\times X_n +  \\epsilon}   \u79fb\u9879\uff0c\u5316\u7b80\u5f97\u5230\u903b\u8f91\u56de\u5f52\u65b9\u7a0b\uff1a    p = P(E) = \\frac{e^{w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n}}{1 + e^{w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n}} = \\frac{1}{1 + e^{-(w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n)}}", 
            "title": "sigmoid\u51fd\u6570\u63a8\u5bfc"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#_2", 
            "text": "\u903b\u8f91\u56de\u5f52\u51fd\u6570\uff1a   \\quad s\\left(h\\right) \\ = \\ \\frac{1}{1 \\ + \\ e^{-h}}\\quad  \u3000 \u5176\u4e2d,  h = w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n     \u5047\u8bbe\u6709n\u4e2a\u6837\u672c{ \\bf X , y}\uff0cy\u662f\u5206\u7c7b\u6807\u8bb0\uff0c\u53d6\u503c\u662f0\u62161\uff0c\u8868\u793a\u8d1f\u7c7b\u8fd8\u662f\u6b63\u7c7b\uff0c \\bf X \u662fm\u7ef4\u7684\u6837\u672c\u7279\u5f81\u5411\u91cf\uff0c\u90a3\u4e48\u8fd9\u4e2a\u6837\u672c \\bf X \u5c5e\u4e8e\u6b63\u7c7b\uff0c\u4e5f\u5c31\u662fy=1\u7684\u201c\u6982\u7387\u201d\u53ef\u4ee5\u901a\u8fc7\u4e0b\u9762\u7684\u903b\u8f91\u51fd\u6570\u6765\u8868\u793a\uff1a   p(y=1 \\mid x; w) = s(w^T x) = \\frac{1}{1 + e^{- w^T x}} \n\u8fd9\u91cc\u7684 \\bf w \u662f\u6a21\u578b\u53c2\u6570\uff0c\u4e5f\u79f0\u56de\u5f52\u7cfb\u6570\uff0c \\ s \u662fsigmoid\u51fd\u6570\u3002  \u51b3\u7b56\u51fd\u6570\u662f\uff1a  \\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n1 &\\ \\quad if\\ p(y=1 \\mid x)\\geq 0.5 \\\\\n0 &\\ \\quad otherwise.\n\\end{aligned}\n\\right. \n\u901a\u5e38\uff0c\u6211\u4eec\u9009\u62e90.5\u4f5c\u4e3a\u9608\u503c\uff0c\u5f53\u6709\u7279\u5b9a\u7684\u9700\u6c42\u65f6\u53ef\u4ee5\u9009\u62e9\u4e0d\u540c\u9608\u503c\uff0c\u5982\u679c\u5bf9\u6b63\u4f8b\u7684\u5224\u522b\u51c6\u786e\u6027\u8981\u6c42\u9ad8\uff0c\u53ef\u4ee5\u9009\u62e9\u9608\u503c\u5927\u4e00\u4e9b\uff0c\u5bf9\u6b63\u4f8b\u7684\u53ec\u56de\u8981\u6c42\u9ad8\uff0c\u5219\u53ef\u4ee5\u9009\u62e9\u9608\u503c\u5c0f\u4e00\u4e9b\u3002  \u6a21\u578b\u53c2\u6570\u6c42\u89e3  \u6700\u5927\u4f3c\u7136\u4f30\u8ba1  \n\u6211\u4eec\u8981\u7528\u903b\u8f91\u56de\u5f52\u51fd\u6570\u53bb\u505a\u5206\u7c7b\uff0c\u5fc5\u987b\u8981\u6c42\u51fa\u6a21\u578b\u7cfb\u6570 \\bf w \uff0c\u90a3\u4e48\u5982\u4f55\u6c42\u89e3 \\bf w \u5462\uff1f\n\u7b54\u6848\u662f\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\uff08maximum likelihood\uff09+ \u68af\u5ea6\u4e0b\u964d\uff08gradient descent\uff09\u3002  \u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u7684\u672c\u8d28\u662f\uff0c\u9009\u62e9\u6700\u4f73\u7684\u53c2\u6570 \\bf w ,\u6765\u6700\u5927\u5316\u6837\u672c\u6570\u636e\u7684\u53ef\u80fd\u6027\u3002\u5047\u8bbe\u7ed9\u5b9a\u6837\u672c X_1, X_2 \\cdots X_n , \u90a3\u4e48\u5173\u4e8e\u53c2\u6570 \\bf w \u7684\u53ef\u80fd\u6027\u51fd\u6570(\u53ef\u80fd\u6027\u51fd\u6570\u5c31\u662f\u6837\u672c\u6570\u636e\u4f5c\u4e3a\u53c2\u6570w\u7684\u51fd\u6570\u7684\u6982\u7387)\uff1a lik(w) = f(X_1, X_2, X_3, \\cdots X_n \\mid w) \n\u5982\u679c X_1, X_2, X_3, \\cdots X_n \u4e4b\u95f4\u662f\u76f8\u4e92\u72ec\u7acb\u7684\uff0c\u53ef\u80fd\u6027\u51fd\u6570\u53ef\u4ee5\u7b80\u5199\u4e3a\u5982\u4e0b\uff1a lik(w) = \\prod_{i=1}^n f(X_i \\mid w) \\quad likelihood \\ function   \u4e00\u822c\u60c5\u51b5\uff0c\u6211\u4eec\u8981\u4f7f\u7528log\u53ef\u80fd\u6027\u51fd\u6570\uff0c\u539f\u56e0\uff1a  1.\u5bf9\u4e0a\u9762\u7684likelihood function\u4e24\u8fb9\u540c\u65f6\u53d6\u5bf9\u6570\uff0c\u5c31\u5f97\u5230\u4e86log likelihood function\uff0c\u8fd9\u6837\u4e58\u79ef\u8f6c\u6362\u4e3a\u6c42\u548c\uff0c\u4ece\u800c\u4f7f\u5f97\u51fd\u6570\u7684\u6c42\u5bfc\u66f4\u5bb9\u6613\uff1b  2.\u5982\u679c\u6211\u4eec\u6709\u5f88\u591a\u7684\u6837\u672c\u6570\u636e\uff0c\u82e5\u76f4\u63a5\u7528likelihood function\uff0c\u8be5\u51fd\u6570\u662f\u8fde\u4e58\u7684\uff0c\u800c\u4e14\u901a\u5e38\u8fd9\u4e9b\u9879\u90fd\u8f83\u5c0f\uff0c\u6545\u53ef\u80fd\u6027\u51fd\u6570\u5c31\u4f1a\u53d8\u5f97\u5f88\u5c0f\u3002\u6240\u4ee5\uff0c\u5e94\u8be5\u91c7\u7528log\u53ef\u80fd\u6027\u51fd\u6570\uff0c\u53ef\u4ee5\u9632\u6b62\u5f53\u6837\u672c\u53ef\u80fd\u6027\u5f88\u5c0f\u65f6\uff0c\u53ef\u80fd\u51fa\u73b0\u7684\u6570\u503c\u4e0b\u6ea2;  3.log\u51fd\u6570\u662f\u5355\u8c03\u7684\uff0c\u6700\u5927\u5316\u53ef\u80fd\u6027\u51fd\u6570\u7684\u503c\u4e5f\u5c31\u662f\u6700\u5927\u5316log\u53ef\u80fd\u6027\u51fd\u6570\u7684\u503c\u3002log\u53ef\u80fd\u6027\u51fd\u6570\u516c\u5f0f\u5982\u4e0b\uff1a l(w) = log(\\ lik(w)\\ ) = \\sum_{i=1}^n log(\\ f(X_i \\mid w)\\ )   \u7528\u53ef\u80fd\u6027\u51fd\u6570\u6765\u5b9a\u4e49\u4e0a\u9762\u7684\u6a21\u578b\u7cfb\u6570w\uff0c\u8981\u5229\u7528\u4e8c\u9879\u5206\u5e03\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\uff0c\u516c\u5f0f\u5982\u4e0b\uff1a L(w) = \\prod_{i=1}^n p(y^{(i)} \\mid x^{(i)};w) = \n\\prod_{i=1}^n (s(h^{(i)})^{y^{(i)}} (1 - s(h^{(i)}))^{1 - y^{(i)}} \n\u5176\u4e2d\uff0c y^{(i)} \u8868\u793a\u7b2ci\u4e2a\u6837\u672c\u5bf9\u5e94\u7684\u5206\u7c7b\u6807\u8bb0\u503c\uff0c x^{(i)} \u8868\u793a\u7b2ci\u4e2a\u6837\u672c\u7684\u7279\u5f81\uff0c h^{(i)} \u4e3a\u7b2ci\u4e2a\u6837\u672c\u5bf9\u5e94\u7684\u5047\u8bbe\u51fd\u6570\u7684\u503c\uff0c h = h(w) = w_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdots + w_n \\times x_n\\  \u4e0a\u9762\u5f0f\u5b50\u4e24\u8fb9\u540c\u65f6\u6c42log\uff0c\u5f97\u5230\u6700\u7ec8\u7684log\u53ef\u80fd\u6027\u51fd\u6570\uff1a l(w) = log(L(w)) = \\sum_{i=1}^n y^{(i)} log(s(h^{(i)})) + (1 - y^{(i)}) log(1 - s(h^{(i)}))  \u903b\u8f91\u56de\u5f52\u7684cost\u51fd\u6570  \n\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u5c31\u662f\u8981\u6c42\u5f97\u4f7fl(w)\u53d6\u6700\u5927\u503c\u65f6\u7684w\uff0c\u8fd9\u91cc\u53ef\u4ee5\u4f7f\u7528\u68af\u5ea6\u4e0a\u5347\u6cd5\u6c42\u89e3\uff0c\u82e5\u8981\u7528\u68af\u5ea6\u4e0b\u964d\u6cd5\uff0c\u5c31\u8981\u4e58\u4ee5\u4e00\u4e2a\u8d1f\u6570\uff0c\u5728\u8fd9\uff0c\u6211\u4eec\u53ef\u4ee5\u5148\u76f4\u63a5\u4e58\u4ee5-1\u5f97\u5230\u5982\u4e0b\u516c\u5f0f\uff1a J(w) = -l(w) = -log(L(w)) = \\sum_{i=1}^n -y^{(i)} log(s(h^{(i)})) - (1 - y^{(i)}) log(1 - s(h^{(i)})) \n\u73b0\u5728\uff0c\u6211\u4eec\u5c31\u5206\u6790\u4e00\u4e2a\u6837\u672c\uff0c\u90a3\u4e48\u53ef\u4ee5\u628a\u4e0a\u9762\u7684cost\u51fd\u6570\u5199\u6210\u5982\u4e0b\u5f62\u5f0f\uff1a   J(w) = -ylog(s(h)) - (1 - y)log(1 - s(h))   \u7576y=0\u6642\uff0c\u4e0a\u5f0f\u7684\u524d\u9762\u4e00\u9805 -ylog(s(h)) = 0 \uff0c\u800c\u7576y=1\u6642\uff0c\u5f8c\u9762\u4e00\u9805 (1 - y)log(1 - s(h)) = 0 \uff0c\u6545\u4e0a\u5f0f\u53ef\u5beb\u6210\u5982\u4e0b\u5206\u6bb5\u51fd\u6570\uff1a   \\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n-log(s(h)) &\\ \\quad if\\ y = 1 \\\\\n-log(1 - s(h)) &\\ \\quad if\\ y = 0\n\\end{aligned}\n\\right.   \u597d\u4e86\uff0c\u73b0\u5728\u7684\u76ee\u6807\u662f\u6700\u5c0f\u5316cost\u51fd\u6570\uff0c\u627e\u5230\u6700\u4f73\u7684\u53c2\u6570 \\bf w \uff0c\u65b9\u6cd5\u662f\u68af\u5ea6\u4e0b\u964d\u6cd5\u3002  \u68af\u5ea6\u4e0b\u964d\u6cd5\u6c42\u6a21\u578b\u53c2\u6570 \\bf w   \u5bf9l(w)\u51fd\u6570\u4e58\u4ee5 -\\frac{1}{n} \uff0cn\u662f\u6837\u672c\u6570\u91cf, \u6240\u4ee5\uff0ccost\u51fd\u6570\u4e3a\uff1a J(w) = -\\frac{1}{n}l(w) \n\u6b63\u56e0\u4e3a\u4e58\u4e86\u4e00\u4e2a\u8d1f\u7684\u7cfb\u6570 -\\frac{1}{n} \uff0c\u6240\u4ee5J(w)\u53d6\u6700\u5c0f\u503c\u65f6\u7684w\u4e3a\u8981\u6c42\u7684\u6700\u4f73\u53c2\u6570\u3002\u6839\u636e\u68af\u5ea6\u4e0b\u964d\u6cd5\u53ef\u5f97\u5230 \\bf w \u7684\u66f4\u65b0\u89c4\u5219\u5982\u4e0b\uff1a \\bf w_j: = w_j \\ + \\ \\Delta {\\bf w_j}    \\Delta \\bf w_j = -\\eta \\nabla J(w)= -\\eta \\frac{\\partial J(w)}{\\partial w_j} = \\eta\\left(y^\\left(i\\right) - h_w\\left(x^{(i)}\\right) \\right)x_j^\\left(i\\right) \n\u5176\u4e2d\uff0c j = 1, 2, 3, \\cdots m \\  \u4ee3\u8868\u7684\u662f\u6837\u672c\u7684\u7b2cj\u7ef4\u7684\u7279\u5f81\uff0c x^{(i)} \u4ee3\u8868\u7684\u662fn\u500b\u6a23\u672c\u4e2d\u7684\u7b2ci\u500b\u6a23\u672c\uff0c \\eta \u662f\u5b66\u4e60\u7387\uff0c\u662f0~1\u4e4b\u95f4\u7684\u6570\uff0c h_w(x^{(i)}) \u4e3a\u51c0\u8f93\u5165\uff0c \\frac{\\partial J(w)}{\\partial w_j} \u4e3acost\u51fd\u6570 J(w) \u7684\u68af\u5ea6\u3002\n\u5b8c\u6574\u7248\u7684\u68af\u5ea6\u4e0b\u964d\uff1a \\bf w_j: = w_j \\ - \\eta \\sum_{i=1}^n (h_w(x^{(i)}) - y^{(i)})x_j^{(i)} \\quad j = 1, 2, 3, \\cdots m \n\u68af\u5ea6\u4e0a\u5347\u6cd5\uff1a   \\bf w_j: = w_j \\ + \\eta \\sum_{i=1}^n (y^{(i)} - h_w(x^{(i)})x_j^{(i)}  \\quad j = 1, 2, 3, \\cdots m   \u56e0\u6b64\uff0c\u7ed9\u5b9a\u521d\u59cb\u7684\u6a21\u578b\u7cfb\u6570 \\bf w \u540e\uff0c\u6a21\u578b\u5c31\u4f1a\u5229\u7528\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\u81ea\u52a8\u5b66\u4e60\u5230\u5408\u9002\u7684\u6a21\u578b\u7cfb\u6570 \\bf w \uff0c\u62ff\u5230\u6743\u91cd\uff08\u6a21\u578b\uff09\u7cfb\u6570\u540e\uff0c\u5c31\u53ef\u6839\u636e\u51b3\u7b56\u51fd\u6570\u7684\u8f93\u51fa\u5bf9\u6837\u672c\u6570\u636e\u8fdb\u884c\u5206\u7c7b\u5206\u6790\u4e86\u3002  \u68af\u5ea6\u4e0b\u964d\u8fc7\u7a0b\u5411\u91cf\u5316  vectorization\u540e \\bf w \u66f4\u65b0\u7684\u6b65\u9aa4\u5982\u4e0b\uff1a \n\uff081\uff09\u6c42 A = \\bf X {\\bullet} {\\bf w} \uff1b \n\uff082\uff09\u6c42E = h(A) - y\uff1b \n\uff083\uff09\u6c42 w: = w -\\eta {\\bullet} X' {\\bullet} E \uff0cX'\u8868\u793a\u77e9\u9635X\u7684\u8f6c\u7f6e\u3002", 
            "title": "\u903b\u8f91\u56de\u5f52\u6a21\u578b\u89e3\u8bfb"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#pythonsklearn", 
            "text": "", 
            "title": "python\u4ee3\u7801\u793a\u4f8b(sklearn)"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#sepal-length-and-petal-length-as-x", 
            "text": "X = df.iloc[:, [0,2]].values  # .values\u3000\u662f\u5c06pandas\u7684DataFrame\u6216Series\u6570\u636e\u7ed3\u6784\u53d8\u6210numpy\u7684array\u7684\u6570\u7ec4\u6216\u77e9\u9635\u7c7b\u578b\nX.shape\nX[-2:, :]  array([[ 6.2,  5.4],\n       [ 5.9,  5.1]])  fig, ax = plt.subplots(figsize=(7,7))\nax.scatter(X[:50, 0], X[:50, 1], marker= o , label= setosa , c= white , edgecolor= purple )\nax.scatter(X[50:100, 0], X[50:100, 1], c= blue , marker= x , label= versicolor )\nax.scatter(X[100:, 0], X[100:, 1], marker= ^ , label= virginica , c= white , edgecolor= red )\nax.set_xlabel( sepal length [cm] )\nax.set_ylabel( petal length [cm] )\nax.legend(loc= upper left )\nax.grid(True)   seaborn\u7ed8\u5236\u6563\u70b9\u56fe  # sns.scatterplot(x= petal length , y= sepal length , data=df, hue= iris ,kind= point )\ng = sns.FacetGrid(df, hue= iris , size=7, legend_out=False, hue_kws=dict(marker=[ o ,  x ,  ^ ]))\ng.map(plt.scatter,  sepal length ,  petal length ,  alpha=.7)\ng.add_legend();   df.head(3)   \n   \n     \n       \n       sepal length \n       sepal width \n       petal length \n       petal width \n       iris \n     \n   \n   \n     \n       0 \n       5.1 \n       3.5 \n       1.4 \n       0.2 \n       Iris-setosa \n     \n     \n       1 \n       4.9 \n       3.0 \n       1.4 \n       0.2 \n       Iris-setosa \n     \n     \n       2 \n       4.7 \n       3.2 \n       1.3 \n       0.2 \n       Iris-setosa \n     \n      y = df.iloc[:, 4]\ny.unique()\n# \u5c06\u6570\u636e\u96c6\u7684\u5b57\u7b26\u7c7b\u578b\u7684\u6570\u636e\u8f6c\u53d8\u6210\u6570\u503c\u7c7b\u578b,Iris-setosa\u6807\u8bb0\u4e3a\uff10,Iris-Versicolor\u4e3a1\uff0c\n# Iris-virginica\u4e3a2\ny.replace(y.unique(), [0, 1, 2], inplace=True)\nY = y.values\n# Y = y.values.reshape(-1, 1)\nnp.shape(Y)\n# np.unique(Y)\n# [u'Iris-setosa', u'Iris-versicolor', u'Iris-virginica'][0, 1, 2]   (150,)  X = df.iloc[:, [0,2]].values  # .values\u3000\u662f\u5c06pandas\u7684DataFrame\u6216Series\u6570\u636e\u7ed3\u6784\u53d8\u6210numpy\u7684array\u7684\u6570\u7ec4\u6216\u77e9\u9635\u7c7b\u578b\n# X[-2:, :]\nnp.shape(X)  (150, 2)", 
            "title": "\u4e3a\u4e86\u7b80\u5316\u6d41\u7a0b\uff0c\u4ece\u56db\u4e2a\u7279\u5f81\u4e2d\u62bd\u53d6\u4e86\u4e24\u4e2a\u7279\u5f81\u7ec4\u6210\u7279\u5f81\u77e9\u9635\uff0c\u5373\u9009\u62e9\u4e86\u7b2c\u4e00\u5217\u82b1\u843c\u957f\u5ea6(sepal length) and \u7b2c\u4e09\u5217\u82b1\u74e3\u957f\u5ea6(petal length) as X"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#sklearnlogisticregressioniris", 
            "text": "from sklearn.model_selection import train_test_split    \nfrom sklearn.model_selection import cross_val_score \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\nsc = StandardScaler()\nsc.fit(X_train)\nX_train_std = sc.transform(X_train)\nX_test_std = sc.transform(X_test)\nX_combined_std = np.vstack((X_train_std, X_test_std))\ny_combined = np.hstack((y_train, y_test))\nlr = LogisticRegression(C=100, penalty= l2 , random_state=0, tol=1e-6)\nlr.fit(X_train_std, y_train)\nlr.predict_proba(X_test_std[0, :].reshape(1, -1))\n# np.shape(X_test_std[0, :]),\u8981\u6574\u5f62\u4e3a\uff08\uff11\uff0c\u3000\uff0d\uff11\uff09\n# np.shape(y_train)\ny_pred = lr.predict(X_test_std)\nprint( Misclassified samples: %d  % (y_test != y_pred).sum())\nprint( Accuracy: %.2f  % accuracy_score(y_test,y_pred))\nprint( cross validation score: %s  % cross_val_score(lr, X_train_std, y_train, cv=5))\nprint( mean cross validation score: %s  % cross_val_score(lr, X_train_std, y_train, cv=5).mean())  Misclassified samples: 1\nAccuracy: 0.98\ncross validation score: [ 0.95454545  1.          1.          0.9047619   0.94736842]\nmean cross validation score: 0.961335156072  \u67e5\u770b\u6a21\u578b\u662f\u5426\u8fc7\u62df\u5408\u53ef\u4ee5\u7528learning curve\u6765\u67e5\u770b\uff0c\u8fc7\u62df\u5408\u73b0\u8c61\u8868\u73b0\u4e3a\uff0c\u5728\u8bad\u7ec3\u96c6\u4e0a\u51c6\u786e\u7387\u5f97\u5206\u6bd4\u8f83\u9ad8\uff0c\u4f46\u4ea4\u53c9\u9a8c\u8bc1\u96c6\u4e0a\u5f97\u5206\u8f83\u4f4e\uff0c\u4e2d\u95f4gap\u8f83\u5927\uff0c\u4e00\u822c\u662f\u6a21\u578b\u8fc7\u4e8e\u590d\u6742\u5bfc\u81f4\uff0c\u4f46\u4e00\u822c\u968f\u7740\u6837\u672c\u91cf\u589e\u52a0\uff0c\u8fc7\u62df\u5408\u4f1a\u51cf\u5f31\u3002\u4e0e\u4e4b\u76f8\u53cd\u7684\u8fd8\u6709\u6b20\u62df\u5408\uff0c\u5373\u6a21\u578b\u590d\u6742\u5ea6\u4e0d\u591f\uff0c\u8bad\u7ec3\u96c6\u548c\u4ea4\u53c9\u9a8c\u8bc1\u96c6\u7684\u5f97\u5206\u5747\u8f83\u4f4e\u3002   \u6b20\u64ec\u5408 \u6700\u4f73\u64ec\u5408 \u904e\u64ec\u5408 \u3000  from sklearn.model_selection import learning_curve\n# \u7528sklearn\u7684learning_curve\u5f97\u5230training_score\u548ccv_score\uff0c\u4f7f\u7528matplotlib\u753b\u51falearning curve\ndef plot_learning_curve(estimator, title, X, y, ylim=None, cv=5, n_jobs=1, \n                        train_sizes=np.linspace(.05, 1., 20), verbose=0, plot=True):\n     \n    \u753b\u51fadata\u5728\u67d0\u6a21\u578b\u4e0a\u7684learning curve.\n    \u53c2\u6570\u89e3\u91ca\n    ----------\n    estimator : \u4f7f\u7528\u7684\u5206\u7c7b\u5668\u3002\n    title : \u56fe\u7684\u6807\u9898\u3002\n    X : \u8f93\u5165\u7684feature\uff0cnumpy\u7c7b\u578b\n    y : \u8f93\u5165\u7684target vector\n    ylim : tuple\u683c\u5f0f\u7684(ymin, ymax), \u8bbe\u5b9a\u56fe\u50cf\u4e2d\u7eb5\u5750\u6807\u7684\u6700\u4f4e\u70b9\u548c\u6700\u9ad8\u70b9\n    cv : \u505across-validation\u7684\u65f6\u5019\uff0c\u6570\u636e\u5206\u6210\u7684\u4efd\u6570\uff0c\u5176\u4e2d\u4e00\u4efd\u4f5c\u4e3acv\u96c6\uff0c\u5176\u4f59n-1\u4efd\u4f5c\u4e3atraining(\u9ed8\u8ba4\u4e3a3\u4efd)\n    n_jobs : \u5e76\u884c\u7684\u7684\u4efb\u52a1\u6570(\u9ed8\u8ba41)\n     \n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, verbose=verbose)\n\n    train_scores_mean = np.mean(train_scores, axis=1)  # train_scores\u662f\u4e00\u4e2a\uff12\uff10\u884c\uff15\u5217\u7684ndarry,20\u4e3a\u4ece\u6837\u672c\u53d6\u7684\u4e0d\u540c\u6bd4\u4f8b\u7684\u6837\u672c\u6570\u636e\u4f5c\u4e3aX, \u800c\uff15\u8868\u793a\uff15\u6b21\u4ea4\u53c9\u9a8c\u8bc1\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    if plot:\n        plt.figure(figsize=(7,7))\n        plt.title(title)\n        if ylim is not None:\n            plt.ylim(*ylim)\n        plt.xlabel( samples )\n        plt.ylabel( scores )\n        # plt.gca().invert_yaxis() \u4f8b\u5982y\u8f74\u5750\u68073000-10000\uff0c\u8c03\u6574\u4e3a10000-3000\u6765\u663e\u793a\n        plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, \n                         alpha=0.2, color= b )\n        plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, \n                         alpha=0.2, color= r )\n        plt.plot(train_sizes, train_scores_mean, '^-', color= blue , label= train score )\n        plt.plot(train_sizes, test_scores_mean, 'v-', color= red , label= cross_validation score )\n        plt.legend(loc= best )\n        plt.grid(True)\n        plt.show()                \nplot_learning_curve(lr,  learning curve , X_train_std, y_train)", 
            "title": "\u8c03\u7528sklearn\u5e93\u7684\u7c7bLogisticRegression\uff0c\u5b9e\u73b0\u5bf9Iris\u8bad\u7ec3\u96c6\u7684\u5b66\u4e60\uff0c\u7528\u4ea4\u53c9\u9a8c\u8bc1\u68c0\u9a8c\u5206\u7c7b\u6548\u679c\uff0c\u6700\u7ec8\u5c06\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u5e94\u7528\u5728\u6d4b\u8bd5\u96c6\u8fdb\u884c\u9a8c\u8bc1"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#_3", 
            "text": "from matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\ndef plot_decision_regions(X, Y, classifier, test_idx=None, resolution=0.02):\n    # \u5bf9\u5e94\u5206\u7c7b\u6807\u7b7e\n    y_maps = { 1 : Iris-versicolor ,  0 : Iris-setosa ,  2 :  Iris-virginica }\n    # setup marker generator and color map\n    markers = ( ^ ,  x ,  s ,  o ,  v )\n    colors = ( purple ,  red ,  blue ,  cyan ,  lightgreen , )  # gray \n    cmap = ListedColormap(colors[:len(np.unique(Y))])\n    # plot the decision surface    \n    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    plt.figure(figsize=(8,8))\n    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)          \n    plt.xlim(xx1.min(), xx1.max())\n    plt.ylim(xx2.min(), xx2.max())\n    # plot all samples\n    for idx, cl in enumerate(np.unique(Y)):        \n        plt.scatter(x=X[Y==cl, 0], y=X[Y==cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx],label=y_maps[str(cl)])        \n    # highlight test samples\n    if test_idx:\n        X_test, Y_test = X[test_idx, :], Y[test_idx]\n        X_test, Y_test = X[test_idx, :], Y[test_idx]\n        plt.scatter(X_test[:, 0], X_test[:, 1], c= , alpha=1.0, linewidth=1, marker= o , s=55, label= test set )  plot_decision_regions(X=X_combined_std, Y=y_combined, classifier=lr, test_idx=None)\nplt.xlabel( sepal length [standardized] cm , fontsize=16)\nplt.ylabel( petal length [standardized] cm , fontsize=14)\nplt.legend(loc= upper left )  matplotlib.legend.Legend at 0x7fdd1fee2f50", 
            "title": "\u51b3\u7b56\u8fb9\u754c\u793a\u610f\u56fe"
        }, 
        {
            "location": "/machine_learning/logistic_regression/logistic_regression_forshow/#_4", 
            "text": "\u3010\u673a\u5668\u5b66\u4e60\u7b14\u8bb01\u3011Logistic\u56de\u5f52\u603b\u7ed3 http://blog.csdn.net/dongtingzhizi/article/details/15962797  \u3010\u673a\u5668\u5b66\u4e60\u7b14\u8bb02\u3011Linear Regression\u603b\u7ed3 http://blog.csdn.net/dongtingzhizi/article/details/16884215  Logistic Regression \u6a21\u578b\u7b80\u4ecb\u3000https://tech.meituan.com/intro_to_logistic_regression.html  \u903b\u8f91\u56de\u5f52\u7b97\u6cd5\u7684\u539f\u7406\u53ca\u5b9e\u73b0(LR) http://www.cnblogs.com/nxld/p/6124235.html  \u903b\u8f91\u56de\u5f52\uff08Logistic regression\uff09\u8be6\u89e3-\u5e76\u7528scikit-learn\u8bad\u7ec3\u903b\u8f91\u56de\u5f52\u62df\u5408Iris\u6570\u636e\u96c6  http://blog.csdn.net/xlinsist/article/details/51289825  Sklearn-LogisticRegression\u903b\u8f91\u56de\u5f52 http://blog.csdn.net/cherdw/article/details/54891073  \u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4e0ePython\u5b9e\u8df5\u4e4b\uff08\u4e03\uff09\u903b\u8f91\u56de\u5f52\uff08Logistic Regression\uff09 http://blog.csdn.net/zouxy09/article/details/20319673  \u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u4e0ePython\u5b9e\u8df5\u4e4b\uff08\u4e03\uff09\u903b\u8f91\u56de\u5f52\uff08Logistic Regression http://blog.csdn.net/wenyusuran/article/details/25824011  \u6b63\u5219\u5316\u65b9\u6cd5\uff1aL1\u548cL2 regularization\u3001\u6570\u636e\u96c6\u6269\u589e\u3001dropout http://blog.csdn.net/u012162613/article/details/44261657  LaTeX \u5404\u79cd\u547d\u4ee4\u7b26\u53f7 http://blog.csdn.net/anxiaoxi45/article/details/39449445", 
            "title": "\u53c2\u8003\u6587\u732e"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/", 
            "text": "\u5355\u5c42\u611f\u77e5\u5668\u7b80\u4ecb\n\n\n\u611f\u77e5\u5668(perceptron)\u662f\u6a21\u4eff\u4eba\u8111\u795e\u7ecf\u5143\u7684\u7ebf\u6027\u5206\u7c7b\u7b97\u6cd5\n\n\n\u795e\u7ecf\u5143\u7684\u6784\u6210\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u5305\u62ec\u6811\u7a81(Dendrites)\uff0c\u7ec6\u80de\u6838(Cell Body)\u548c\u8f74\u7a81(Axon)\u3002\n\n\n\n\u611f\u77e5\u5668\u662f\u4e00\u79cd\u7814\u7a76\u5355\u4e2a\u8bad\u7ec3\u6837\u672c\u7684\u4e8c\u5143\u5206\u7c7b\u5668\u3002\n\n\n\n\u795e\u7ecf\u5143\u53ca\u5355\u5c42\u611f\u77e5\u5668\u793a\u610f\u56fe\n\n \n\n \n\n\n\u4e3a\u5565\u8981\u626f\u6de1\u611f\u77e5\u5668\n\n\n\u7406\u89e3\u611f\u77e5\u5668\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u662f\u5b66\u4e60\u4e24\u79cd\u8d85\u7ea7\u6b66\u5668\u7684\u57fa\u7840\uff0c\u5373\u652f\u6301\u5411\u91cf\u673a(support vector machines)\u548c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc(artificial neural networks)\u7684\u57fa\u7840\u4e4b\u4e00\n\n\n\u9996\u5148\uff0c\u6e29\u6545\u4e00\u4e0b\u76f4\u7ebf\u65b9\u7a0b\n\n\n\n\n\n y = ax + b \n\n\n\u81ea\u53d8\u91cfx\u4e58\u4ee5\u659c\u7387a\u518d\u52a0\u4e0a\u622a\u8dddb\u5c31\u5f97\u5230\u4e86\u56e0\u53d8\u91cfy\n\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\n\n\nx = np.arange(-10, 10)\na, b = 2, 5\nfig, ax = plt.subplots()\n# \u9690\u85cf\u4e0a\u8fb9\u548c\u53f3\u8fb9\nax.spines[\ntop\n].set_color(\nnone\n) \nax.spines[\nright\n].set_color(\nnone\n) \n# \u79fb\u52a8\u53e6\u5916\u4e24\u4e2a\u8f74\nax.xaxis.set_ticks_position(\nbottom\n)\nax.spines['bottom'].set_position(('data', 0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data', 0))\nax.plot(x, a*x+b, linewidth=2, label=\ny=2x+5\n)\nax.legend()\nax.grid(True, linestyle=\n:\n, linewidth=1, alpha=0.8)\n\n\n\n\n\n\nn\u5143\u4e00\u6b21\u65b9\u7a0b\n\n\n\n\u4e00\u5143\u4e00\u6b21\u65b9\u7a0b:\n\n\\quad y \\ = \\ ax \\ + \\ b \\quad \u4f8b\u5982\uff1a\\ y = 2x + 5\n\n\n\n\u53ef\u4ee5\u5199\u6210\uff1a\n\n\n\\quad y \\ = \\ w_0 \\times x_0 \\ + \\ w_1 \\times x_1 \\quad \u5176\u4e2dw_0 =5, \\ x_0=1, \\ w_1=2, \\ x_1=x \n\n\n\n\n\u4e8c\u5143\u4e00\u6b21\u65b9\u7a0b:\n\n\\quad y \\ = \\ ax \\ + \\ bx \\ + \\ c \n\n\n\n\u53ef\u4ee5\u5199\u6210\uff1a  \n\\quad y \\ = \\ w_0 \\times x_0 \\ + \\ w_1 \\times x_1 \\ + \\ w_2 \\times x_2 \\quad \u5176\u4e2dx_0=1, \\ w_0=c\n\n\n\n\nn\u5143\u4e00\u6b21\u65b9\u7a0b\u8868\u8fbe\u5f0f\u53ca\u77e9\u9635\u8868\u793a\uff1a\n\n\n\n\ny \\ = \\ w_0\\times x_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdot\\cdot\\cdot \\ w_n \\times x_n \\ \n\n\n\n\n\n\n=\\underbrace{\\begin{bmatrix} w_0 & w_1 & w_2 & \\cdots\\ &w_n \\end{bmatrix}}_{\u6743\u91cd\u7cfb\u6570\u5411\u91cf\\bf w} {\\ \\bullet}  \\underbrace{\\begin{bmatrix} x_{0} \\\\ x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_n \\end{bmatrix}}_{\u6837\u672c\u7279\u5f81\u77e9\u9635\\bf x}\n\n\n\n\n\n\n=\\ {\\bf w^T x} \\quad {\u5176\u4e2dx_0=1}\n\n\n\n\n\u611f\u77e5\u5668\u7684\u6982\u5ff5\u5256\u6790\n\n\n\u795e\u7ecf\u5143\u7684\u5de5\u4f5c\u539f\u7406:\n\n\n\n\u6811\u7a81\u4ece\u4e00\u4e2a\u6216\u591a\u4e2a\u5176\u4ed6\u795e\u7ecf\u5143\u63a5\u53d7\u7535\u4fe1\u53f7\uff0c\u4fe1\u53f7\u5728\u5176\u7ec6\u80de\u6838\u5904\u7406\u540e\u4ece\u8f74\u7a81\u8f93\u51fa\u3002\u4e00\u4e2a\u611f\u77e5\u5668\u5c31\u662f\u5c06\u4e00\u4e2a\u6216\u591a\u4e2a\u8f93\u5165\nx_0, x_1, x_2 \\cdot\\cdot\\cdot x_n \n\u5904\u7406\u5e76\u8f93\u51fa\u7684\u8ba1\u7b97\u5355\u5143\u3002\u6bcf\u4e2a\u8f93\u5165\u4ee3\u8868\u4e86\u4e00\u4e2a\u7279\u5f81\uff0c\u901a\u5e38\uff0c\u611f\u77e5\u5668\u7528\u4e00\u4e2a\u7279\u5b9a\u7684\u8f93\u5165\u5355\u5143\u4ee3\u8868\u8f93\u5165\u8bef\u5dee\u9879\uff0c\u5176\u8868\u8fbe\u5f0f\u662f  \n\\quad x_0\\times \\theta \\quad \u5176\u4e2dx_0=1,\\ \\theta\u4e3a\u9608\u503c\n\n\n\n\n\u51c0\u8f93\u5165:\n\n\u5c06\u6240\u6709\u7684\u8f93\u5165\u5355\u5143\u503c(\u5373\u6837\u672c\u7279\u5f81\u503c)\u4e58\u4ee5\u5bf9\u5e94\u7684\u6743\u91cd\u7cfb\u6570\u518d\u52a0\u4e0a\u8bef\u5dee\u9879\u5c31\u5f97\u5230\u4e86\u51c0\u8f93\u5165z\n\n\n\n\n\n z = \\underbrace{w_0x_0}_{=\\theta\\times1} + \\underbrace{w_1x_1 + w_2x_2 + \\cdots + w_nx_n}_{\u6837\u672c\u7279\u5f81\u503c\u4e0e\u6743\u91cd\u7cfb\u6570\u4e58\u79ef\u4e4b\u548c}= {\\bf w^T}{\\bf x}\n\n\n\n\n\u6fc0\u52b1\u51fd\u6570:\n\n\n\n\u5e38\u7528\u7684\u6fc0\u52b1\u51fd\u6570\u6709\u591a\u79cd\uff0c\u5982\u9636\u8dc3\u51fd\u6570(unit step function\u6216Heaviside step function)\u548c\u903b\u8f91S\u5f62\u51fd\u6570(logistic sigmoid)\u3002\n\n\n\u4ee5\u4e0b\u793a\u4f8b\u4f7f\u7528\u7684\u5747\u662f\u6700\u7b80\u5355\u7684\u9636\u8dc3\u51fd\u6570\u3002\n\n\\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n1 &\\ \\quad if\\ z\\geq \\theta \\\\\n-1 &\\ \\quad otherwise.\n\\end{aligned}\n\\right.\n\n\n\n\u9636\u8dc3\u51fd\u6570\n\\ \\theta=0 \n\n\n\u9636\u8dc3\u51fd\u6570\n\n\n\n\n\u611f\u77e5\u5668\u6267\u884c\u6d41\u7a0b:\n\n\n\n\u611f\u77e5\u5668\u662f\u4e00\u79cd\u9519\u8bef\u9a71\u52a8(error-drive)\u7684\u5b66\u4e60\u7b97\u6cd5\u3002\u611f\u77e5\u5668\u5b66\u4e60\u7b97\u6cd5\u9996\u5148\u8981\u5c06\u6743\u91cd\u7cfb\u6570 (\n\\bf w_i \n) \u8bbe\u7f6e\u6210\uff10\u6216\u5f88\u5c0f\u7684\u968f\u673a\u6570\uff0c\u7136\u540e\u9884\u6d4b\u8bad\u7ec3\u6837\u672c\u7684\u7c7b\u578b\u3002\u82e5\u611f\u77e5\u5668\u7684\u9884\u6d4b\u4e0e\u5b9e\u9645\u503c\u4e00\u81f4\uff0c\u5219\u6743\u91cd\u7cfb\u6570\u4e0d\u6539\u53d8\uff0c\u5982\u679c\u611f\u77e5\u5668\u9884\u6d4b\u9519\u8bef\uff0c\u7b97\u6cd5\u5c31\u66f4\u6539\u6743\u91cd\u7cfb\u6570\uff0c\u63a5\u7740\uff0c\u5c06\u6743\u91cd\u4f20\u9012\u7ed9\u4e0b\u4e00\u4e2a\u6837\u672c\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u6837\u672c\u7684\u521d\u59cb\u6743\u91cd\u5e76\u7ee7\u7eed\u5904\u7406\u4e0b\u4e00\u4e2a\u6837\u672c\uff1b\u5f53\u6837\u672c\u96c6\u4e2d\u7684\u6240\u6709\u6837\u672c\u5747\u88ab\u5b66\u4e60\u4e00\u904d\u540e\uff0c\u672c\u4e16\u4ee3\u5b66\u4e60\u7ed3\u675f\uff0c\u5e76\u5f00\u59cb\u4e0b\u4e00\u4e16\u4ee3\u7684\u5b66\u4e60\u548c\u8bad\u7ec3\uff0c\u5c31\u8fd9\u6837\u5faa\u73af\u6307\u5b9a\u7684\u4e16\u4ee3\u6570\u540e\uff0c\u5b66\u4e60\u7ed3\u675f\u3002\n\n\n\u6743\u91cd\u7cfb\u6570\u7684\u66f4\u65b0\u89c4\u5219\n:\n\n\\bf w_j:=w_j \\ + \\ \\Delta {\\bf w_j}\n\n\n\n\n\n\n\\Delta \\bf w_j=\\eta\\left(y^\\left(i\\right)-\\hat{y}^\\left(i\\right) \\right)x_j^\\left(i\\right)\n\n\n\n\n\u5176\u4e2d\uff0c\n\\bf w_j:\n\u662f\u6837\u672c\u96c6\u7b2cj\u7ef4\u7279\u5f81\u66f4\u65b0\u540e\u7684\u6743\u91cd\uff0c\n\\bf w_j\n\u662f\u5f53\u524d\u6837\u672c\u7684\u4e0a\u4e00\u4e2a\u6837\u672c\u8ba1\u7b97\u5f97\u5230\u7684\u6743\u91cd\uff0c\n\\Delta \\bf w_j\n\u662f\u6839\u636e\u5f53\u524d\u6837\u672c\u8ba1\u7b97\u7684\u6743\u91cd\u7684\u589e\u91cf\uff0c\n\\eta\n\u662f\u4eba\u4e3a\u6307\u5b9a\u7684\u8d85\u53c2\u6570\u2014\u2014\u5b66\u4e60\u7387(learning rate, a constant between 0.0 and 1.0)\uff0c\ny^\\left(i\\right)\n\u662f\u5f53\u524d\u6837\u672c\u7684\u5206\u7c7b\u6807\u7b7e\u503c\uff0c\n\\hat{y}^\\left(i\\right)\n\u662f\u9884\u6d4b\u7684\u5206\u7c7b\u6807\u7b7e\u7684\u503c\uff0c\nx_j^\\left(i\\right)\n\u662f\u7b2ci\u4e2a\u6837\u672c\u7684\u7b2cj\u7ef4\u7279\u5f81\u3002\n\n\n\n\n\\bf w\n\u7684\u66f4\u65b0\u89c4\u5219\u4e0e\u68af\u5ea6\u4e0b\u964d\u6cd5\u4e2d\u7684\u6743\u91cd\u66f4\u65b0\u89c4\u5219\u7c7b\u4f3c\uff0c\u90fd\u662f\u671d\u7740\u4f7f\u6837\u672c\u5f97\u5230\u6b63\u786e\u5206\u7c7b\u7684\u65b9\u5411\u66f4\u65b0\u6743\u91cd\uff0c\u4e14\u66f4\u65b0\u7684\u5e45\u5ea6\u662f\u7531\u5b66\u4e60\u901f\u7387(\n\\eta\n)\u63a7\u5236\u7684\u3002\u6bcf\u904d\u5386\u4e00\u6b21\u6837\u672c\u96c6\u7684\u6240\u6709\u6837\u672c\u79f0\u5b8c\u6210\u4e86\u4e00\u4e16\u4ee3(epoch)\u3002\u82e5\u5b66\u4e60\u5b8c\u4e00\u4e16\u4ee3\u540e\uff0c\u6240\u6709\u7684\u6837\u672c\u90fd\u5206\u7c7b\u6b63\u786e\uff0c\u90a3\u4e48\u7b97\u6cd5\u5c31\u4f1a\u6536\u655b(converge)\u3002\u8981\u6ce8\u610f\u7684\u662f\uff0c\u611f\u77e5\u5668\u7684\u5b66\u4e60\u7b97\u6cd5\u5e76\u4e0d\u4fdd\u8bc1\u7b97\u6cd5\u672c\u8eab\u7684\u6536\u655b\uff0c\u5f53\u6837\u672c\u662f\u7ebf\u6027\u4e0d\u53ef\u5206\u7684\u65f6\u5019\uff0c\u662f\u4e0d\u53ef\u80fd\u6536\u655b\u7684\u3002\u56e0\u6b64\uff0c\u8981\u6307\u5b9a\u4e00\u4e2a\u8d85\u53c2\u6570(\nn_{iter}\n)\u6765\u9650\u5236\u6743\u91cd\u66f4\u65b0\u7684\u6700\u5927\u4e16\u4ee3\u6570\u3002\n\n\n\u4e00\u4e2a\u5c0f\u6848\u4f8b:\n\n\n\n\u4ece\u4e00\u7a9d\u732b\u91cc\u5206\u8fa8\u5e7c\u732bor\u6210\u5e74\u732b\n\n\n\u641e\u6e05\u51e0\u4e2a\u6982\u5ff5\uff1a\n\n\n\n\n\n\u6837\u672c\n\n\n\u7279\u5f81\n\n\n\u5206\u7c7b\u6807\u7b7e\n\n\n\u8bad\u7ec3\u96c6(train)\n\n\n\u6d4b\u8bd5\u96c6(test)\n\n\n\n\n# \u521b\u5efa\u6837\u672c\u7279\u5f81\u77e9\u9635\nX = np.array([\n    [0.2, 0.1],\n    [0.4, 0.6],\n    [0.5, 0.6],\n    [0.7, 0.9]\n])\n# \u521b\u5efa\u5206\u7c7b\u6807\u7b7e\ny = [1, 1, 1, 0]\n# \u6563\u70b9\u56fe\nplt.grid(True, linestyle=\n:\n, linewidth=1, alpha=0.8)\nplt.scatter(X[:3, 0], X[:3, 1], marker=\no\n, c=\nwhite\n, edgecolor=\nred\n)\nplt.scatter(X[3:, 0], X[3:, 1], marker=\nx\n)\nplt.xlabel(\npro of sleep day\n, fontsize=16)\nplt.ylabel(\npro of crazy day\n, fontsize=16)\nplt.title(\ncharacter of kitten and adult cats\n, fontsize=14)\n\n\n\n\nmatplotlib.text.Text at 0x7f7920cb6190\n\n\n\n\n\n\n\u6743\u91cd\u66f4\u65b0\u8fc7\u7a0b\n\n\n\n\u4e16\u4ee3\uff11\uff0c\u5373\u7b2c\u4e00\u6b21\u5faa\u73af\uff0c\u5f00\u59cb\u7684\u65f6\u5019\uff0c\u6240\u6709\u7684\u6743\u91cd\u8bbe\u7f6e\u4e3a0,\nw_1=0,w_2=0,w_3=0\n\n\u7279\u5f81\u5206\u522b\u4e3a\nx_0=1, x_1=0.2, x_2=0.1\n\n\u6839\u636e\u51c0\u8f93\u5165\u548c\u6fc0\u52b1\u51fd\u6570\u51b3\u5b9a\u662f\u5426\u66f4\u6539\u6743\u91cd\u7cfb\u6570\n\n\n\u51c0\u8f93\u5165z\u548c\u6fc0\u52b1\u51fd\u6570 \\(\\phi\\left(x\\right)\\) \n\n\n\n\n\n z = \\underbrace{w_0x_0}_{=\\theta\\times1} + \\underbrace{w_1x_1 + w_2x_2 + \\cdot\\cdot\\cdot +w_nx_n}_{\u8f93\u5165\u5355\u5143\u503c\u4e0e\u6743\u91cd\u7cfb\u6570\u4e58\u79ef\u4e4b\u548c}= {\\bf w^T}{\\bf x}\\quad\n\n\n\\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n1 &\\ \\quad if\\ z\\gt \\theta \\\\\n0 &\\ \\quad otherwise.\n\\end{aligned}\n\\right. \n\n\n\n\n\u6743\u91cd\u66f4\u65b0\n\n\n\n\n\n\\bf w_j:=w_j \\ + \\ \\Delta \\bf w_j \\quad\n\n\n\\quad \\Delta \\bf w_j=\\eta\\left(y^\\left(i\\right)-\\hat{y}^\\left(i\\right) \\right)x_j^\\left(i\\right)\n\n\n\n\n\u521d\u59cb\u6743\u91cd\n\\ w_0 = \\left[0, 0, 0 \\right]\n\uff0c\u4e3a\u4e86\u7b80\u5316\u8ba1\u7b97\uff0c\u4ee4\n\\eta=1.0\n\u3000\n\n\u7b2c\u4e00\u4e16\u4ee3\uff0c\u611f\u77e5\u5668\u5b66\u4e60\u7b2c\u4e00\u4e2a\u6837\u672c\u5bf9\u6743\u91cd\u7cfb\u6570\u7684\u66f4\u65b0\u8fc7\u7a0b\n\n\n\u7b2c\u4e00\u4e2a\u6837\u672c\u7279\u5f81\u503c\u4e3a\uff1a\nx_0=\\left[1.0,0.2,0.1\\right]\n\n\u6839\u636e\u6743\u91cd\u66f4\u65b0\u7684\u516c\u5f0f\uff0c\u8ba1\u7b97w\u7684\u589e\u91cf\uff1a\n\n\n\n\n\\Delta \\bf w_j=\\eta\\left(y^\\left(i\\right)-\\hat{y}^\\left(i\\right) \\right)x_j^\\left(i\\right) \n\n\n\n\n\n\n= 1.0\\times \\left(\u5b9e\u9645\u6807\u7b7e\u503c\uff0d\u9884\u6d4b\u6807\u7b7e\u503c\\right) \\times \\underbrace{\u5411\u91cf\\bf x}_{\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u7279\u5f81\u5411\u91cf} \\quad \n\n\n\n\n\n\n= 1.0\\times \\left(1\uff0d0\\right) \\times \\left[1.0, 0.2, 0.1 \\right] \n\n\n\n\n\n\n= \\left[1.0, 0.2, 0.1 \\right]\n\n\n\n\n\u56e0\u6b64\uff0c\u7531\n\\bf w_j:=w_j \\ + \\ \\Delta \\bf w_j \n\u5f97\u66f4\u65b0\u540e\u7684\u6743\u91cd: \n\\bf w = \\left[0,0,0\\right] \\ + \\ \\left[1.0,0.2,0.1\\right] = \\left[1.0,0.2,0.1\\right]\n\n\n\n\n\u7b2c\u4e00\u4e16\u4ee3\u7684\u7b2c\u4e00\u4e2a\u6837\u672c\u5b66\u4e60\u5b8c\u6bd5\uff0c\u5c06\u4ece\u7b2c\u4e00\u4e2a\u6837\u672c\u5b66\u4e60\u5230\u7684\u6743\u91cd\n\\bf w=\\left[1.0,0.2,0.1\\right]\n\u4f20\u9012\u7ed9\u4e0b\u4e00\u4e2a\u6837\u672c\u4f5c\u4e3a\u521d\u59cb\u6743\u91cd\u63a5\u7740\u5b66\u4e60\u3002\u4e0b\u9762\u63a2\u8ba8\u7b2c\u4e8c\u4e2a\u6837\u672c\u6743\u91cd\u66f4\u65b0\u8fc7\u7a0b\uff1a\n\u521d\u59cb\u6743\u91cd\nw_1 = \\left[1.0,0.2,0.1\\right]\n\uff0c\n\\eta=1.0\n\n\n\u7b2c\u4e00\u4e16\u4ee3\uff0c\u611f\u77e5\u5668\u5b66\u4e60\u7b2c\u4e8c\u4e2a\u6837\u672c\u5bf9\u6743\u91cd\u7cfb\u6570\u7684\u66f4\u65b0\u8fc7\u7a0b\n\n\n\u7b2c\u4e8c\u4e2a\u6837\u672c\u7279\u5f81\u503c\u4e3a\uff1a\nx_\uff11=\\left[1.0,0.4,0.6\\right]\n\n\n\n\n\u51c0\u8f93\u5165\uff1a\nz={\\bf w^T}{\\bf x}=w_0x_0 + w_1x_1 + w_2x_2 + \\cdot\\cdot\\cdot +w_nx_n = 1.0\\times1.0 + 0.2\\times0.4 + 0.1\\times0.6 = 1.14 \\gt0 \n\n\n\n\n\u6839\u636e\u6fc0\u52b1\u51fd\u6570\n\\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n1 &\\ \\quad if\\ z\\geq \\theta \\\\\n0 &\\ \\quad otherwise.\n\\end{aligned}\n\\right.\n\n\n\u53ef\u77e5\u9884\u6d4b\u503c\u4e3a1,\u9884\u6d4b\u5206\u7c7b\u6807\u7b7e\u503c\u4e0e\u5b9e\u9645\u5206\u7c7b\u6807\u7b7e\u503c\u76f8\u540c\uff1b\n\n\n\u66f4\u65b0\u6743\u91cd\uff1a\n\\Delta \\bf w_j=\\eta\\left(y^\\left(i\\right)-\\hat{y}^\\left(i\\right) \\right)x_j^\\left(i\\right)\u3000\uff1d\u30001.0\\times \\left(1.0-1.0\\right)\\times \\left[1.0,0.4,0.6\\right] = \\left[0,0,0\\right]\n\n\n\n\n\n\n\\bf w_j:=w_j \\ + \\ \\Delta \\bf w_j = \\left[1.0,0.2,0.1\\right] + \\left[0,0,0\\right] = \\left[1.0,0.2,0.1\\right]\n\n\n\n\n\u5728\u5b66\u4e60\u7b2c\u4e8c\u4e2a\u6837\u672c\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u6b63\u786e\u5730\u9884\u6d4b\u4e86\u5206\u7c7b\u6807\u7b7e\uff0c\u6240\u4ee5\u6743\u91cd\u7cfb\u6570\u6ca1\u6709\u6539\u53d8\u3002\u81f3\u6b64\uff0c\u7b2c\u4e8c\u4e2a\u6837\u672c\u5b66\u4e60\u5b8c\u6bd5\uff0c\u5e76\u5c06\u6743\u91cd\nw_1=\\left[1.0,0.2,0.1\\right]\n\u4f20\u7ed9\u4e0b\u4e00\u4e2a\u6837\u672c\u4f5c\u4e3a\u521d\u59cb\u6743\u91cd\u3002\n\n\n\u7b2c\u4e00\u4e16\u4ee3\uff0c\u611f\u77e5\u5668\u5b66\u4e60\u5269\u4f59\u6837\u672c\u5bf9\u6743\u91cd\u7cfb\u6570\u7684\u66f4\u65b0\u8fc7\u7a0b\u540c\u4e0a\n\n\n\n\u5c31\u8fd9\u6837\u5bf9\u6bcf\u4e2a\u6837\u672c\u8fdb\u884c\u5b66\u4e60\u5f97\u5230\u6743\u91cd\u5e76\u4f9d\u6b21\u4f20\u9012\uff0c\u7531\u4e8e\u672c\u6848\u4f8b\u53ea\u67094\u4e2a\u6837\u672c\uff0c\u5728\u7b2c\u4e00\u4e16\u4ee3\u4e0b\uff0c\u8fd8\u9700\u8981\u5bf9\u7b2c\u4e09\u4e2a\u548c\u7b2c\u56db\u4e2a\u6837\u672c\u8fdb\u884c\u5b66\u4e60\u5f97\u5230\u76f8\u5e94\u7684\u6743\u91cd\uff0c\u8fd9\u6837\uff0c\u7b2c\u4e00\u4e16\u4ee3\u5b66\u4e60\u5b8c\u6bd5\uff0c\u63a5\u7740\u6267\u884c\u7b2c\u4e8c\u4e16\u4ee3\u7684\u5b66\u4e60\uff0c\u8fc7\u7a0b\u548c\u7b2c\u4e00\u4e16\u4ee3\u662f\u7c7b\u4f3c\u7684\uff0c\u5982\u6b64\u5faa\u73af\u76f4\u81f3\u8fbe\u5230\u8bbe\u7f6e\u7684\u6700\u5927\u4e16\u4ee3\u6570\uff0c\u6574\u4e2a\u8bad\u7ec3\u96c6\u7684\u5b66\u4e60\u8fc7\u7a0b\u5c31\u7ed3\u675f\u4e86\u3002\n\n\n\u8bad\u7ec3\u96c6\u5b66\u4e60\u5b8c\u6bd5\u540e\uff0c\u5c31\u53ef\u4ee5\u5bf9\u6d4b\u8bd5\u96c6\u8fdb\u884c\u9884\u6d4b\u3001\u8c03\u53c2\u7b49\u5de5\u4f5c\uff0c\u5728\u8fd9\uff0c\u4e3a\u4e86\u7b80\u5316\u6d41\u7a0b\uff0c\u8fd9\u91cc\u6ca1\u6709\u63d0\u53ca\u5728\u5bf9\u8bad\u7ec3\u96c6\u8fdb\u884c\u8bad\u7ec3\u4e4b\u524d\u7684\u6570\u636e\u6e05\u6d17\u3001\u7279\u5f81\u5de5\u7a0b\u7b49\u4e00\u7cfb\u5217\u5de5\u4f5c\uff0c\u5f53\u7136\u5bf9\u4e8e\u672c\u793a\u4f8b\u4e5f\u4e0d\u9700\u8981\uff0c\u56e0\u4e3a\u8be5\u6570\u636e\u96c6\u672c\u8eab\u5c31\u662f\u5e72\u51c0\u7684\u3002\n\n\n# \u6743\u91cd\u7cfb\u6570\u66f4\u65b0\u8fc7\u7a0b\ndisplay(Image('./image/cats_epoch.png'))\n\n\n\n\n\n\nnumpy\u8fdb\u884c\u77e9\u9635\u8fd0\u7b97\u5c0f\u793a\u4f8b\n\n\nimport numpy as np\na = np.array([2, -1, 3])\nb = np.array([1, 0, -1])\nprint(\n\u77e9\u9635\u52a0\u6cd5\uff1a{0} + {1} = {2}\n.format(a, b, a + b)) \nprint(\n\u77e9\u9635\u70b9\u4e58\uff1a{0} . {1} = {2}\n.format(a, b, np.dot(a, b)))\nprint(\n\u77e9\u9635\u5bf9\u5e94\u5143\u7d20\u76f8\u4e58\uff0cHadamard\u4e58\u79ef\uff1a{0} \u00d7 {1} = {2}\n.format(a, b, a*b))\nprint(\n\u77e9\u9635\u4e0e\u6807\u91cf\u76f8\u4e58\uff1a{0} \u00d7 {1} = {2}\n.format(2, a, 2*a))\n\n\n\n\n\u77e9\u9635\u52a0\u6cd5\uff1a[ 2 -1  3] + [ 1  0 -1] = [ 3 -1  2]\n\u77e9\u9635\u70b9\u4e58\uff1a[ 2 -1  3] . [ 1  0 -1] = -1\n\u77e9\u9635\u5bf9\u5e94\u5143\u7d20\u76f8\u4e58\uff0cHadamard\u4e58\u79ef\uff1a[ 2 -1  3] \u00d7 [ 1  0 -1] = [ 2  0 -3]\n\u77e9\u9635\u4e0e\u6807\u91cf\u76f8\u4e58\uff1a2 \u00d7 [ 2 -1  3] = [ 4 -2  6]\n\n\n\nHadamard\u4e58\u79ef\uff1a\n\n\u77e9\u9635\u4e0e\u77e9\u9635\u7684Hadamard\u79ef\u5c31\u662f\u4e24\u4e2a\u77e9\u9635\u5bf9\u5e94\u5143\u7d20\u7684\u4e58\u79ef\n\n\nKronecker\u4e58\u79ef\uff1a\n\nKronecker\u79ef\u662f\u4e24\u4e2a\u4efb\u610f\u5927\u5c0f\u7684\u77e9\u9635\u95f4\u7684\u8fd0\u7b97\uff0c\u514b\u7f57\u5185\u514b\u79ef\u4e5f\u6210\u4e3a\u76f4\u79ef\u6216\u5f20\u91cf\u79ef\uff0c\u4ee5\u5fb7\u56fd\u6570\u5b66\u5bb6\u5229\u5965\u6ce2\u5fb7\u00b7\u514b\u7f57\u5185\u514b\u547d\u540d\u3002\n\n\n\n\nimport numpy as np \nw3 = np.array([1, 0.2, 0.1])\nupdate = np.array([-1, -0.7, -0.9])\nw4 = w3 + update\nw4\n\n\n\n\narray([ 0. , -0.5, -0.8])\n\n\n\npython\u5b9e\u73b0\u7684\u5355\u5c42\u611f\u77e5\u5668\n\n\n\u83ba(dai)\u5c3e\u82b1\u6570\u636e\u96c6\u3000\n150\u884c\\ \\times \\ 5\u5217\n\n\n\n\n\u7279\u5f81\uff1a4\u4e2a\uff0c\u5206\u522b\u662f\u82b1\u74e3\u957f\u5ea6\u548c\u5bbd\u5ea6\uff0c\u82b1\u843c\u957f\u5ea6\u548c\u5bbd\u5ea6\uff0c\u5355\u4f4dcm\n\n\n\u5206\u7c7b\u6807\u7b7e\uff1a\u6700\u540e\u4e00\u5217\uff0c\u4e09\u79cd\u53d6\u503c\uff0c\u5206\u522b\u4ee3\u8868\u4e09\u79cd\u7c7b\u578b\u7684\u83ba\u5c3e\u82b1\n\n\ndf = pd.read_excel(\n./Iris.xls\n, sheetname=\nIris\n)\n\n\n\n\ndf.head(3)\n\n\n\n\n\n\n\n  \n\n    \n\n      \n\n      \nsepal length\n\n      \nsepal width\n\n      \npetal length\n\n      \npetal width\n\n      \niris\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n5.1\n\n      \n3.5\n\n      \n1.4\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n    \n\n      \n1\n\n      \n4.9\n\n      \n3.0\n\n      \n1.4\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n    \n\n      \n2\n\n      \n4.7\n\n      \n3.2\n\n      \n1.3\n\n      \n0.2\n\n      \nIris-setosa\n\n    \n\n  \n\n\n\n\n\n\n\n\u4e3a\u4e86\u53ef\u4ee5\u753b\uff12D\u56fe\uff0c\u53ea\u62bd\u53d6\u4e86\u524d100\u884c\u6570\u636e\uff0c\u5373\u4ec5\u4ec5\u5305\u542b50\u4e2a\u6837\u672c\u7684 Iris-Setosa and 50\u4e2a\u6837\u672c\u7684 Iris-Versicolor flowers\n\n\ny = df.iloc[0:100, 4].values  # get a 1-array, numpy.ndarray\ny[-5:]\n\n\n\n\narray([u'Iris-versicolor', u'Iris-versicolor', u'Iris-versicolor',\n       u'Iris-versicolor', u'Iris-versicolor'], dtype=object)\n\n\n\n# \u5c06\u6570\u636e\u96c6\u7684\u6240\u6709\u5b57\u7b26\u7c7b\u578b\u7684\u6570\u636e\u8f6c\u53d8\u6210\u6570\u503c\u7c7b\u578b\nY = np.where(y==\nIris-setosa\n, -1, 1)\nY[-5:]\n\n\n\n\narray([1, 1, 1, 1, 1])\n\n\n\n\u4e3a\u4e86\u7b80\u5316\u6d41\u7a0b\uff0c\u4ece\u56db\u4e2a\u7279\u5f81\u4e2d\u62bd\u53d6\u4e86\u4e24\u4e2a\u7279\u5f81\u7ec4\u6210\u7279\u5f81\u77e9\u9635\uff0c\u5373\u9009\u62e9\u4e86\u7b2c\u4e00\u5217(sepal length) and \u7b2c\u4e09\u5217(petal length) as X\n\n\nX = df.iloc[0:100, [0,2]].values  # .values\u3000\u662f\u5c06pandas\u7684DataFrame\u6216Series\u6570\u636e\u7ed3\u6784\u53d8\u6210numpy\u7684array\u7684\u6570\u7ec4\u6216\u77e9\u9635\u7c7b\u578b\nX.shape\nX[-2:, :]\n\n\n\n\narray([[ 5.1,  3. ],\n       [ 5.7,  4.1]])\n\n\n\n\u6837\u672c\u7279\u5f81\u7684\u6563\u70b9\u56fe\n\n\nplt.scatter(X[:50, 0], X[:50, 1], marker=\no\n, label=\nsetosa\n, c=\nwhite\n, edgecolor=\npurple\n)\nplt.scatter(X[50:100, 0], X[50:100, 1], c=\nblue\n, marker=\nx\n, label=\nversicolor\n)\nplt.xlabel(\npetal length [cm]\n)\nplt.ylabel(\nsepal length [cm]\n)\nplt.legend(loc=\nupper left\n)\nplt.show()\n\n\n\n\n\n\nPerceptron\u611f\u77e5\u5668\u5206\u7c7b\u5668\n\n\nclass Perceptron(object):\n    \nPerceptron classifier\u5355\u5c42\u611f\u77e5\u5668\n\n    def __init__(self, eta=0.01, n_iter=10):\n        self.eta = eta\n        self.n_iter = n_iter\n\n    #\u62df\u5408\n    def fit(self, X, Y):\n        self.w_ = np.zeros(1 + X.shape[1])\n        self.errors_ = []\n        print(\nlength of w_ : %i\n) % len(self.w_)\n        for i in range(self.n_iter):\n            errors = 0\n            for xi, target in zip(X, Y):\n                update = self.eta * (target - self.predict(xi)) # update\u662f\u4e00\u4e2a\u6570\u503c\u3000\n                self.w_[1:] += update * xi  # \u6570\u7ec4\u4e0a\u64cd\u4f5c\uff0c\u4e0d\u662f\u6570\u503c\u52a0\n                self.w_[0] += update\n                errors += int(update != 0.0)\n            self.errors_.append(errors)\n            print(\nepoch_\n+str(i + 1))\n            print(self.w_)\n        return self\n\n    #\u51c0\u8f93\u5165\n    def net_input(self, X):\n        return np.dot(X, self.w_[1:]) + self.w_[0]\n\n    #\u6fc0\u52b1\u51fd\u6570\u9884\u6d4b\n    def predict(self, X):\n        return np.where(self.net_input(X) \n= 0.0, 1, -1)\n\n# \u9884\u6d4b\u672a\u77e5\u6837\u672c \n#     def predict_real(self, X):\n#         y_real = {\n1\n:\nIris-versicolor\n, \n-1\n:\nIris-setosa\n}\n#         y_ = self.net_input(X)        \n#         return y_real[str(y_)]                \n\n\n\n\n\u611f\u77e5\u5668\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5206\u7c7b\u6807\u7b7e\u9884\u6d4b\u9519\u8bef\u7684\u60c5\u51b5\n\n\nppn = Perceptron(eta=0.1, n_iter=10)\nppn.fit(X, Y)\nplt.plot(range(1, len(ppn.errors_)+1), ppn.errors_, marker=\n.\n, color=\npurple\n)\nplt.xlabel(\nEpochs\n, fontsize=16)\nplt.ylabel(\nNumber of Misclassification\n, fontsize=14)\nplt.grid(True, linestyle=\n:\n, alpha=0.8)\nplt.show()\n\n\n\n\nlength of w_ : 3\nepoch_1\n[ 0.    0.38  0.66]\nepoch_2\n[ 0.    0.76  1.32]\nepoch_3\n[-0.2   0.22  1.68]\nepoch_4\n[-0.2   0.34  2.1 ]\nepoch_5\n[-0.4  -0.68  1.82]\nepoch_6\n[-0.4  -0.68  1.82]\nepoch_7\n[-0.4  -0.68  1.82]\nepoch_8\n[-0.4  -0.68  1.82]\nepoch_9\n[-0.4  -0.68  1.82]\nepoch_10\n[-0.4  -0.68  1.82]\n\n\n\n\n\n\u611f\u77e5\u5668\u5206\u7c7b\u51b3\u7b56\u8fb9\u754c\u793a\u610f\u56fe\n\n\nimplement a small convenience function to visualize the decision boundaries for 2D datasets\n\n\nnp.meshgrid\u662f\u751f\u6210\u7f51\u683c\u91c7\u6837\u70b9\u7684\u51fd\u6578\uff0c\u5b83\u63a5\u6536\u4e24\u4e2a\u4e00\u7ef4\u6570\u7ec4,\u4ea7\u751f\u4e24\u4e2a\u4e8c\u7ef4\u77e9\u9635\n\n\ncontour:\u8f6e\u5ed3,\u7b49\u9ad8\u7ebf,f\uff1afilled\uff0c\u4e5f\u5373\u5bf9\u7b49\u9ad8\u7ebf\u95f4\u7684\u586b\u5145\u533a\u57df\u8fdb\u884c\u586b\u5145\uff08\u4f7f\u7528\u4e0d\u540c\u7684\u989c\u8272\uff09\uff1b\n\n\ncontourf\uff1a\u5c06\u4e0d\u4f1a\u518d\u7ed8\u5236\u7b49\u9ad8\u7ebf\uff08\u663e\u7136\u4e0d\u540c\u7684\u989c\u8272\u5206\u754c\u5c31\u8868\u793a\u7b49\u9ad8\u7ebf\u672c\u8eab\uff09\n\n\nfrom matplotlib.colors import ListedColormap\ndef plot_decision_regions(X, Y, classifier, resolution=0.02):\n    # \u5bf9\u5e94\u5206\u7c7b\u6807\u7b7e\n    y_maps = {\n1\n:\nIris-versicolor\n, \n-1\n:\nIris-setosa\n}\n    # setup marker generator and color map\n    markers = (\n^\n, \nx\n, \ns\n, \no\n, \nv\n)\n    colors = (\npurple\n, \nred\n, \nblue\n, \ncyan\n, \nlightgreen\n, )  #\ngray\n\n    cmap = ListedColormap(colors[:len(np.unique(Y))])\n    # plot the decision surface\n    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)  \n\n    plt.xlim(xx1.min(), xx1.max())\n    plt.ylim(xx2.min(), xx2.max())\n    # plot class samples\n    for idx, cl in enumerate(np.unique(Y)):\n        plt.scatter(x=X[Y==cl, 0], y=X[Y==cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx],label=y_maps[str(cl)])\n\n\n\n\nplot_decision_regions(X, Y, classifier=ppn)\nplt.xlabel(\nsepal length [cm]\n, fontsize=18)\nplt.ylabel(\npetal length [cm]\n, fontsize=18)\nplt.legend(loc=\nupper left\n)\nplt.show()\n\n\n\n\n\n\nsklearn\u611f\u77e5\u5668\u4ee3\u7801\u5b9e\u73b0\n\n\nfrom sklearn.preprocessing import StandardScaler  # \u6807\u6ce8\u53d8\u6362\u4e4b\u6807\u51c6\u5316\nfrom sklearn.linear_model import Perceptron as percep\nfrom sklearn.cross_validation import train_test_split as ttsplit\nfrom sklearn.metrics import accuracy_score\nX_train, X_test, Y_train, Y_test = ttsplit(X, Y, test_size=0.2, random_state=0)\n\nsc = StandardScaler()\nsc.fit(X_train)  # \u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\nX_train_std = sc.transform(X_train)  # \u8fdb\u884c\u6807\u51c6\u53d8\u6362\uff0c\u53d8\u6210\u6807\u51c6\u6b63\u592a\u5206\u5e03\nX_test_std = sc.transform(X_test)\nppn_ = percep(n_iter=10, eta0=0.1, random_state=0)\nppn_.fit(X_train_std, Y_train)\nY_pred = ppn_.predict(X_test_std)\nprint(\nMisclassified samples: %d\n % (Y_test != Y_pred).sum())\nprint(\nAccuracy: %.2f\n % accuracy_score(Y_test,Y_pred))\n\n\n\n\nMisclassified samples: 1\nAccuracy: 0.95\n\n\n/home/darren/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)\n\n\n\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\ndef plot_decision_region(X, Y, classifier, test_idx=None, resolution=0.02):\n    # \u5bf9\u5e94\u5206\u7c7b\u6807\u7b7e\n    y_maps = {\n1\n:\nIris-versicolor\n, \n-1\n:\nIris-setosa\n}\n    # setup marker generator and color map\n    markers = (\n^\n, \nx\n, \ns\n, \no\n, \nv\n)\n    colors = (\npurple\n, \nred\n, \nblue\n, \ncyan\n, \nlightgreen\n, )  #\ngray\n\n    cmap = ListedColormap(colors[:len(np.unique(Y))])\n    # plot the decision surface    \n    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)      \n    plt.xlim(xx1.min(), xx1.max())\n    plt.ylim(xx2.min(), xx2.max())\n    # plot all samples\n    for idx, cl in enumerate(np.unique(Y)):\n        plt.scatter(x=X[Y==cl, 0], y=X[Y==cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx],label=y_maps[str(cl)])\n    # highlight test samples\n    if test_idx:\n        X_test, Y_test = X[test_idx, :], Y[test_idx]\n        X_test, Y_test = X[test_idx, :], Y[test_idx]\n        plt.scatter(X_test[:, 0], X_test[:, 1], c=\n, alpha=1.0, linewidth=1, marker=\no\n, s=55, label=\ntest set\n)\n\n\n\n\nX_combined_std = np.vstack((X_train_std, X_test_std))\nY_combined = np.hstack((Y_train, Y_test))\nplot_decision_region(X=X_combined_std, Y=Y_combined, classifier=ppn_, test_idx=None)\nplt.xlabel(\nsepal length [standardized] cm\n, fontsize=16)\nplt.ylabel(\npetal length [standardized] cm\n, fontsize=14)\nplt.legend(loc=\nupper left\n)\nplt.show()", 
            "title": "\u611f\u77e5\u5668python\u4ee3\u7801\u5b9e\u73b0"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#_1", 
            "text": "\u611f\u77e5\u5668(perceptron)\u662f\u6a21\u4eff\u4eba\u8111\u795e\u7ecf\u5143\u7684\u7ebf\u6027\u5206\u7c7b\u7b97\u6cd5  \u795e\u7ecf\u5143\u7684\u6784\u6210\u5982\u4e0b\u56fe\u6240\u793a\uff0c\u4e3b\u8981\u5305\u62ec\u6811\u7a81(Dendrites)\uff0c\u7ec6\u80de\u6838(Cell Body)\u548c\u8f74\u7a81(Axon)\u3002  \u611f\u77e5\u5668\u662f\u4e00\u79cd\u7814\u7a76\u5355\u4e2a\u8bad\u7ec3\u6837\u672c\u7684\u4e8c\u5143\u5206\u7c7b\u5668\u3002  \u795e\u7ecf\u5143\u53ca\u5355\u5c42\u611f\u77e5\u5668\u793a\u610f\u56fe", 
            "title": "\u5355\u5c42\u611f\u77e5\u5668\u7b80\u4ecb"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#_2", 
            "text": "\u7406\u89e3\u611f\u77e5\u5668\u7684\u5de5\u4f5c\u539f\u7406\uff0c\u662f\u5b66\u4e60\u4e24\u79cd\u8d85\u7ea7\u6b66\u5668\u7684\u57fa\u7840\uff0c\u5373\u652f\u6301\u5411\u91cf\u673a(support vector machines)\u548c\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc(artificial neural networks)\u7684\u57fa\u7840\u4e4b\u4e00  \u9996\u5148\uff0c\u6e29\u6545\u4e00\u4e0b\u76f4\u7ebf\u65b9\u7a0b    y = ax + b   \u81ea\u53d8\u91cfx\u4e58\u4ee5\u659c\u7387a\u518d\u52a0\u4e0a\u622a\u8dddb\u5c31\u5f97\u5230\u4e86\u56e0\u53d8\u91cfy  import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline  x = np.arange(-10, 10)\na, b = 2, 5\nfig, ax = plt.subplots()\n# \u9690\u85cf\u4e0a\u8fb9\u548c\u53f3\u8fb9\nax.spines[ top ].set_color( none ) \nax.spines[ right ].set_color( none ) \n# \u79fb\u52a8\u53e6\u5916\u4e24\u4e2a\u8f74\nax.xaxis.set_ticks_position( bottom )\nax.spines['bottom'].set_position(('data', 0))\nax.yaxis.set_ticks_position('left')\nax.spines['left'].set_position(('data', 0))\nax.plot(x, a*x+b, linewidth=2, label= y=2x+5 )\nax.legend()\nax.grid(True, linestyle= : , linewidth=1, alpha=0.8)   n\u5143\u4e00\u6b21\u65b9\u7a0b  \u4e00\u5143\u4e00\u6b21\u65b9\u7a0b: \\quad y \\ = \\ ax \\ + \\ b \\quad \u4f8b\u5982\uff1a\\ y = 2x + 5  \n\u53ef\u4ee5\u5199\u6210\uff1a  \\quad y \\ = \\ w_0 \\times x_0 \\ + \\ w_1 \\times x_1 \\quad \u5176\u4e2dw_0 =5, \\ x_0=1, \\ w_1=2, \\ x_1=x    \u4e8c\u5143\u4e00\u6b21\u65b9\u7a0b: \\quad y \\ = \\ ax \\ + \\ bx \\ + \\ c   \n\u53ef\u4ee5\u5199\u6210\uff1a   \\quad y \\ = \\ w_0 \\times x_0 \\ + \\ w_1 \\times x_1 \\ + \\ w_2 \\times x_2 \\quad \u5176\u4e2dx_0=1, \\ w_0=c   n\u5143\u4e00\u6b21\u65b9\u7a0b\u8868\u8fbe\u5f0f\u53ca\u77e9\u9635\u8868\u793a\uff1a   y \\ = \\ w_0\\times x_0 + w_1 \\times x_1 + w_2 \\times x_2 + \\cdot\\cdot\\cdot \\ w_n \\times x_n \\     =\\underbrace{\\begin{bmatrix} w_0 & w_1 & w_2 & \\cdots\\ &w_n \\end{bmatrix}}_{\u6743\u91cd\u7cfb\u6570\u5411\u91cf\\bf w} {\\ \\bullet}  \\underbrace{\\begin{bmatrix} x_{0} \\\\ x_{1} \\\\ x_{2} \\\\ \\vdots \\\\ x_n \\end{bmatrix}}_{\u6837\u672c\u7279\u5f81\u77e9\u9635\\bf x}    =\\ {\\bf w^T x} \\quad {\u5176\u4e2dx_0=1}", 
            "title": "\u4e3a\u5565\u8981\u626f\u6de1\u611f\u77e5\u5668"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#_3", 
            "text": "\u795e\u7ecf\u5143\u7684\u5de5\u4f5c\u539f\u7406:  \u6811\u7a81\u4ece\u4e00\u4e2a\u6216\u591a\u4e2a\u5176\u4ed6\u795e\u7ecf\u5143\u63a5\u53d7\u7535\u4fe1\u53f7\uff0c\u4fe1\u53f7\u5728\u5176\u7ec6\u80de\u6838\u5904\u7406\u540e\u4ece\u8f74\u7a81\u8f93\u51fa\u3002\u4e00\u4e2a\u611f\u77e5\u5668\u5c31\u662f\u5c06\u4e00\u4e2a\u6216\u591a\u4e2a\u8f93\u5165 x_0, x_1, x_2 \\cdot\\cdot\\cdot x_n  \u5904\u7406\u5e76\u8f93\u51fa\u7684\u8ba1\u7b97\u5355\u5143\u3002\u6bcf\u4e2a\u8f93\u5165\u4ee3\u8868\u4e86\u4e00\u4e2a\u7279\u5f81\uff0c\u901a\u5e38\uff0c\u611f\u77e5\u5668\u7528\u4e00\u4e2a\u7279\u5b9a\u7684\u8f93\u5165\u5355\u5143\u4ee3\u8868\u8f93\u5165\u8bef\u5dee\u9879\uff0c\u5176\u8868\u8fbe\u5f0f\u662f   \\quad x_0\\times \\theta \\quad \u5176\u4e2dx_0=1,\\ \\theta\u4e3a\u9608\u503c   \u51c0\u8f93\u5165: \u5c06\u6240\u6709\u7684\u8f93\u5165\u5355\u5143\u503c(\u5373\u6837\u672c\u7279\u5f81\u503c)\u4e58\u4ee5\u5bf9\u5e94\u7684\u6743\u91cd\u7cfb\u6570\u518d\u52a0\u4e0a\u8bef\u5dee\u9879\u5c31\u5f97\u5230\u4e86\u51c0\u8f93\u5165z    z = \\underbrace{w_0x_0}_{=\\theta\\times1} + \\underbrace{w_1x_1 + w_2x_2 + \\cdots + w_nx_n}_{\u6837\u672c\u7279\u5f81\u503c\u4e0e\u6743\u91cd\u7cfb\u6570\u4e58\u79ef\u4e4b\u548c}= {\\bf w^T}{\\bf x}   \u6fc0\u52b1\u51fd\u6570:  \u5e38\u7528\u7684\u6fc0\u52b1\u51fd\u6570\u6709\u591a\u79cd\uff0c\u5982\u9636\u8dc3\u51fd\u6570(unit step function\u6216Heaviside step function)\u548c\u903b\u8f91S\u5f62\u51fd\u6570(logistic sigmoid)\u3002  \u4ee5\u4e0b\u793a\u4f8b\u4f7f\u7528\u7684\u5747\u662f\u6700\u7b80\u5355\u7684\u9636\u8dc3\u51fd\u6570\u3002 \\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n1 &\\ \\quad if\\ z\\geq \\theta \\\\\n-1 &\\ \\quad otherwise.\n\\end{aligned}\n\\right.  \u9636\u8dc3\u51fd\u6570 \\ \\theta=0   \u9636\u8dc3\u51fd\u6570   \u611f\u77e5\u5668\u6267\u884c\u6d41\u7a0b:  \u611f\u77e5\u5668\u662f\u4e00\u79cd\u9519\u8bef\u9a71\u52a8(error-drive)\u7684\u5b66\u4e60\u7b97\u6cd5\u3002\u611f\u77e5\u5668\u5b66\u4e60\u7b97\u6cd5\u9996\u5148\u8981\u5c06\u6743\u91cd\u7cfb\u6570 ( \\bf w_i  ) \u8bbe\u7f6e\u6210\uff10\u6216\u5f88\u5c0f\u7684\u968f\u673a\u6570\uff0c\u7136\u540e\u9884\u6d4b\u8bad\u7ec3\u6837\u672c\u7684\u7c7b\u578b\u3002\u82e5\u611f\u77e5\u5668\u7684\u9884\u6d4b\u4e0e\u5b9e\u9645\u503c\u4e00\u81f4\uff0c\u5219\u6743\u91cd\u7cfb\u6570\u4e0d\u6539\u53d8\uff0c\u5982\u679c\u611f\u77e5\u5668\u9884\u6d4b\u9519\u8bef\uff0c\u7b97\u6cd5\u5c31\u66f4\u6539\u6743\u91cd\u7cfb\u6570\uff0c\u63a5\u7740\uff0c\u5c06\u6743\u91cd\u4f20\u9012\u7ed9\u4e0b\u4e00\u4e2a\u6837\u672c\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u6837\u672c\u7684\u521d\u59cb\u6743\u91cd\u5e76\u7ee7\u7eed\u5904\u7406\u4e0b\u4e00\u4e2a\u6837\u672c\uff1b\u5f53\u6837\u672c\u96c6\u4e2d\u7684\u6240\u6709\u6837\u672c\u5747\u88ab\u5b66\u4e60\u4e00\u904d\u540e\uff0c\u672c\u4e16\u4ee3\u5b66\u4e60\u7ed3\u675f\uff0c\u5e76\u5f00\u59cb\u4e0b\u4e00\u4e16\u4ee3\u7684\u5b66\u4e60\u548c\u8bad\u7ec3\uff0c\u5c31\u8fd9\u6837\u5faa\u73af\u6307\u5b9a\u7684\u4e16\u4ee3\u6570\u540e\uff0c\u5b66\u4e60\u7ed3\u675f\u3002  \u6743\u91cd\u7cfb\u6570\u7684\u66f4\u65b0\u89c4\u5219 : \\bf w_j:=w_j \\ + \\ \\Delta {\\bf w_j}    \\Delta \\bf w_j=\\eta\\left(y^\\left(i\\right)-\\hat{y}^\\left(i\\right) \\right)x_j^\\left(i\\right)   \u5176\u4e2d\uff0c \\bf w_j: \u662f\u6837\u672c\u96c6\u7b2cj\u7ef4\u7279\u5f81\u66f4\u65b0\u540e\u7684\u6743\u91cd\uff0c \\bf w_j \u662f\u5f53\u524d\u6837\u672c\u7684\u4e0a\u4e00\u4e2a\u6837\u672c\u8ba1\u7b97\u5f97\u5230\u7684\u6743\u91cd\uff0c \\Delta \\bf w_j \u662f\u6839\u636e\u5f53\u524d\u6837\u672c\u8ba1\u7b97\u7684\u6743\u91cd\u7684\u589e\u91cf\uff0c \\eta \u662f\u4eba\u4e3a\u6307\u5b9a\u7684\u8d85\u53c2\u6570\u2014\u2014\u5b66\u4e60\u7387(learning rate, a constant between 0.0 and 1.0)\uff0c y^\\left(i\\right) \u662f\u5f53\u524d\u6837\u672c\u7684\u5206\u7c7b\u6807\u7b7e\u503c\uff0c \\hat{y}^\\left(i\\right) \u662f\u9884\u6d4b\u7684\u5206\u7c7b\u6807\u7b7e\u7684\u503c\uff0c x_j^\\left(i\\right) \u662f\u7b2ci\u4e2a\u6837\u672c\u7684\u7b2cj\u7ef4\u7279\u5f81\u3002   \\bf w \u7684\u66f4\u65b0\u89c4\u5219\u4e0e\u68af\u5ea6\u4e0b\u964d\u6cd5\u4e2d\u7684\u6743\u91cd\u66f4\u65b0\u89c4\u5219\u7c7b\u4f3c\uff0c\u90fd\u662f\u671d\u7740\u4f7f\u6837\u672c\u5f97\u5230\u6b63\u786e\u5206\u7c7b\u7684\u65b9\u5411\u66f4\u65b0\u6743\u91cd\uff0c\u4e14\u66f4\u65b0\u7684\u5e45\u5ea6\u662f\u7531\u5b66\u4e60\u901f\u7387( \\eta )\u63a7\u5236\u7684\u3002\u6bcf\u904d\u5386\u4e00\u6b21\u6837\u672c\u96c6\u7684\u6240\u6709\u6837\u672c\u79f0\u5b8c\u6210\u4e86\u4e00\u4e16\u4ee3(epoch)\u3002\u82e5\u5b66\u4e60\u5b8c\u4e00\u4e16\u4ee3\u540e\uff0c\u6240\u6709\u7684\u6837\u672c\u90fd\u5206\u7c7b\u6b63\u786e\uff0c\u90a3\u4e48\u7b97\u6cd5\u5c31\u4f1a\u6536\u655b(converge)\u3002\u8981\u6ce8\u610f\u7684\u662f\uff0c\u611f\u77e5\u5668\u7684\u5b66\u4e60\u7b97\u6cd5\u5e76\u4e0d\u4fdd\u8bc1\u7b97\u6cd5\u672c\u8eab\u7684\u6536\u655b\uff0c\u5f53\u6837\u672c\u662f\u7ebf\u6027\u4e0d\u53ef\u5206\u7684\u65f6\u5019\uff0c\u662f\u4e0d\u53ef\u80fd\u6536\u655b\u7684\u3002\u56e0\u6b64\uff0c\u8981\u6307\u5b9a\u4e00\u4e2a\u8d85\u53c2\u6570( n_{iter} )\u6765\u9650\u5236\u6743\u91cd\u66f4\u65b0\u7684\u6700\u5927\u4e16\u4ee3\u6570\u3002  \u4e00\u4e2a\u5c0f\u6848\u4f8b:  \u4ece\u4e00\u7a9d\u732b\u91cc\u5206\u8fa8\u5e7c\u732bor\u6210\u5e74\u732b  \u641e\u6e05\u51e0\u4e2a\u6982\u5ff5\uff1a   \u6837\u672c  \u7279\u5f81  \u5206\u7c7b\u6807\u7b7e  \u8bad\u7ec3\u96c6(train)  \u6d4b\u8bd5\u96c6(test)   # \u521b\u5efa\u6837\u672c\u7279\u5f81\u77e9\u9635\nX = np.array([\n    [0.2, 0.1],\n    [0.4, 0.6],\n    [0.5, 0.6],\n    [0.7, 0.9]\n])\n# \u521b\u5efa\u5206\u7c7b\u6807\u7b7e\ny = [1, 1, 1, 0]\n# \u6563\u70b9\u56fe\nplt.grid(True, linestyle= : , linewidth=1, alpha=0.8)\nplt.scatter(X[:3, 0], X[:3, 1], marker= o , c= white , edgecolor= red )\nplt.scatter(X[3:, 0], X[3:, 1], marker= x )\nplt.xlabel( pro of sleep day , fontsize=16)\nplt.ylabel( pro of crazy day , fontsize=16)\nplt.title( character of kitten and adult cats , fontsize=14)  matplotlib.text.Text at 0x7f7920cb6190    \u6743\u91cd\u66f4\u65b0\u8fc7\u7a0b  \u4e16\u4ee3\uff11\uff0c\u5373\u7b2c\u4e00\u6b21\u5faa\u73af\uff0c\u5f00\u59cb\u7684\u65f6\u5019\uff0c\u6240\u6709\u7684\u6743\u91cd\u8bbe\u7f6e\u4e3a0, w_1=0,w_2=0,w_3=0 \n\u7279\u5f81\u5206\u522b\u4e3a x_0=1, x_1=0.2, x_2=0.1 \n\u6839\u636e\u51c0\u8f93\u5165\u548c\u6fc0\u52b1\u51fd\u6570\u51b3\u5b9a\u662f\u5426\u66f4\u6539\u6743\u91cd\u7cfb\u6570  \u51c0\u8f93\u5165z\u548c\u6fc0\u52b1\u51fd\u6570 \\(\\phi\\left(x\\right)\\)     z = \\underbrace{w_0x_0}_{=\\theta\\times1} + \\underbrace{w_1x_1 + w_2x_2 + \\cdot\\cdot\\cdot +w_nx_n}_{\u8f93\u5165\u5355\u5143\u503c\u4e0e\u6743\u91cd\u7cfb\u6570\u4e58\u79ef\u4e4b\u548c}= {\\bf w^T}{\\bf x}\\quad  \\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n1 &\\ \\quad if\\ z\\gt \\theta \\\\\n0 &\\ \\quad otherwise.\n\\end{aligned}\n\\right.    \u6743\u91cd\u66f4\u65b0   \\bf w_j:=w_j \\ + \\ \\Delta \\bf w_j \\quad  \\quad \\Delta \\bf w_j=\\eta\\left(y^\\left(i\\right)-\\hat{y}^\\left(i\\right) \\right)x_j^\\left(i\\right)   \u521d\u59cb\u6743\u91cd \\ w_0 = \\left[0, 0, 0 \\right] \uff0c\u4e3a\u4e86\u7b80\u5316\u8ba1\u7b97\uff0c\u4ee4 \\eta=1.0 \u3000 \u7b2c\u4e00\u4e16\u4ee3\uff0c\u611f\u77e5\u5668\u5b66\u4e60\u7b2c\u4e00\u4e2a\u6837\u672c\u5bf9\u6743\u91cd\u7cfb\u6570\u7684\u66f4\u65b0\u8fc7\u7a0b  \u7b2c\u4e00\u4e2a\u6837\u672c\u7279\u5f81\u503c\u4e3a\uff1a x_0=\\left[1.0,0.2,0.1\\right] \n\u6839\u636e\u6743\u91cd\u66f4\u65b0\u7684\u516c\u5f0f\uff0c\u8ba1\u7b97w\u7684\u589e\u91cf\uff1a   \\Delta \\bf w_j=\\eta\\left(y^\\left(i\\right)-\\hat{y}^\\left(i\\right) \\right)x_j^\\left(i\\right)     = 1.0\\times \\left(\u5b9e\u9645\u6807\u7b7e\u503c\uff0d\u9884\u6d4b\u6807\u7b7e\u503c\\right) \\times \\underbrace{\u5411\u91cf\\bf x}_{\u7b2c\u4e00\u4e2a\u6837\u672c\u7684\u7279\u5f81\u5411\u91cf} \\quad     = 1.0\\times \\left(1\uff0d0\\right) \\times \\left[1.0, 0.2, 0.1 \\right]     = \\left[1.0, 0.2, 0.1 \\right]   \u56e0\u6b64\uff0c\u7531 \\bf w_j:=w_j \\ + \\ \\Delta \\bf w_j  \u5f97\u66f4\u65b0\u540e\u7684\u6743\u91cd:  \\bf w = \\left[0,0,0\\right] \\ + \\ \\left[1.0,0.2,0.1\\right] = \\left[1.0,0.2,0.1\\right]   \u7b2c\u4e00\u4e16\u4ee3\u7684\u7b2c\u4e00\u4e2a\u6837\u672c\u5b66\u4e60\u5b8c\u6bd5\uff0c\u5c06\u4ece\u7b2c\u4e00\u4e2a\u6837\u672c\u5b66\u4e60\u5230\u7684\u6743\u91cd \\bf w=\\left[1.0,0.2,0.1\\right] \u4f20\u9012\u7ed9\u4e0b\u4e00\u4e2a\u6837\u672c\u4f5c\u4e3a\u521d\u59cb\u6743\u91cd\u63a5\u7740\u5b66\u4e60\u3002\u4e0b\u9762\u63a2\u8ba8\u7b2c\u4e8c\u4e2a\u6837\u672c\u6743\u91cd\u66f4\u65b0\u8fc7\u7a0b\uff1a\n\u521d\u59cb\u6743\u91cd w_1 = \\left[1.0,0.2,0.1\\right] \uff0c \\eta=1.0  \u7b2c\u4e00\u4e16\u4ee3\uff0c\u611f\u77e5\u5668\u5b66\u4e60\u7b2c\u4e8c\u4e2a\u6837\u672c\u5bf9\u6743\u91cd\u7cfb\u6570\u7684\u66f4\u65b0\u8fc7\u7a0b  \u7b2c\u4e8c\u4e2a\u6837\u672c\u7279\u5f81\u503c\u4e3a\uff1a x_\uff11=\\left[1.0,0.4,0.6\\right]   \u51c0\u8f93\u5165\uff1a z={\\bf w^T}{\\bf x}=w_0x_0 + w_1x_1 + w_2x_2 + \\cdot\\cdot\\cdot +w_nx_n = 1.0\\times1.0 + 0.2\\times0.4 + 0.1\\times0.6 = 1.14 \\gt0    \u6839\u636e\u6fc0\u52b1\u51fd\u6570 \\phi\\left(x\\right)=\\left\\{\n\\begin{aligned}\n1 &\\ \\quad if\\ z\\geq \\theta \\\\\n0 &\\ \\quad otherwise.\n\\end{aligned}\n\\right. \n\u53ef\u77e5\u9884\u6d4b\u503c\u4e3a1,\u9884\u6d4b\u5206\u7c7b\u6807\u7b7e\u503c\u4e0e\u5b9e\u9645\u5206\u7c7b\u6807\u7b7e\u503c\u76f8\u540c\uff1b  \u66f4\u65b0\u6743\u91cd\uff1a \\Delta \\bf w_j=\\eta\\left(y^\\left(i\\right)-\\hat{y}^\\left(i\\right) \\right)x_j^\\left(i\\right)\u3000\uff1d\u30001.0\\times \\left(1.0-1.0\\right)\\times \\left[1.0,0.4,0.6\\right] = \\left[0,0,0\\right]    \\bf w_j:=w_j \\ + \\ \\Delta \\bf w_j = \\left[1.0,0.2,0.1\\right] + \\left[0,0,0\\right] = \\left[1.0,0.2,0.1\\right]   \u5728\u5b66\u4e60\u7b2c\u4e8c\u4e2a\u6837\u672c\u7684\u65f6\u5019\uff0c\u7531\u4e8e\u6b63\u786e\u5730\u9884\u6d4b\u4e86\u5206\u7c7b\u6807\u7b7e\uff0c\u6240\u4ee5\u6743\u91cd\u7cfb\u6570\u6ca1\u6709\u6539\u53d8\u3002\u81f3\u6b64\uff0c\u7b2c\u4e8c\u4e2a\u6837\u672c\u5b66\u4e60\u5b8c\u6bd5\uff0c\u5e76\u5c06\u6743\u91cd w_1=\\left[1.0,0.2,0.1\\right] \u4f20\u7ed9\u4e0b\u4e00\u4e2a\u6837\u672c\u4f5c\u4e3a\u521d\u59cb\u6743\u91cd\u3002  \u7b2c\u4e00\u4e16\u4ee3\uff0c\u611f\u77e5\u5668\u5b66\u4e60\u5269\u4f59\u6837\u672c\u5bf9\u6743\u91cd\u7cfb\u6570\u7684\u66f4\u65b0\u8fc7\u7a0b\u540c\u4e0a  \u5c31\u8fd9\u6837\u5bf9\u6bcf\u4e2a\u6837\u672c\u8fdb\u884c\u5b66\u4e60\u5f97\u5230\u6743\u91cd\u5e76\u4f9d\u6b21\u4f20\u9012\uff0c\u7531\u4e8e\u672c\u6848\u4f8b\u53ea\u67094\u4e2a\u6837\u672c\uff0c\u5728\u7b2c\u4e00\u4e16\u4ee3\u4e0b\uff0c\u8fd8\u9700\u8981\u5bf9\u7b2c\u4e09\u4e2a\u548c\u7b2c\u56db\u4e2a\u6837\u672c\u8fdb\u884c\u5b66\u4e60\u5f97\u5230\u76f8\u5e94\u7684\u6743\u91cd\uff0c\u8fd9\u6837\uff0c\u7b2c\u4e00\u4e16\u4ee3\u5b66\u4e60\u5b8c\u6bd5\uff0c\u63a5\u7740\u6267\u884c\u7b2c\u4e8c\u4e16\u4ee3\u7684\u5b66\u4e60\uff0c\u8fc7\u7a0b\u548c\u7b2c\u4e00\u4e16\u4ee3\u662f\u7c7b\u4f3c\u7684\uff0c\u5982\u6b64\u5faa\u73af\u76f4\u81f3\u8fbe\u5230\u8bbe\u7f6e\u7684\u6700\u5927\u4e16\u4ee3\u6570\uff0c\u6574\u4e2a\u8bad\u7ec3\u96c6\u7684\u5b66\u4e60\u8fc7\u7a0b\u5c31\u7ed3\u675f\u4e86\u3002  \u8bad\u7ec3\u96c6\u5b66\u4e60\u5b8c\u6bd5\u540e\uff0c\u5c31\u53ef\u4ee5\u5bf9\u6d4b\u8bd5\u96c6\u8fdb\u884c\u9884\u6d4b\u3001\u8c03\u53c2\u7b49\u5de5\u4f5c\uff0c\u5728\u8fd9\uff0c\u4e3a\u4e86\u7b80\u5316\u6d41\u7a0b\uff0c\u8fd9\u91cc\u6ca1\u6709\u63d0\u53ca\u5728\u5bf9\u8bad\u7ec3\u96c6\u8fdb\u884c\u8bad\u7ec3\u4e4b\u524d\u7684\u6570\u636e\u6e05\u6d17\u3001\u7279\u5f81\u5de5\u7a0b\u7b49\u4e00\u7cfb\u5217\u5de5\u4f5c\uff0c\u5f53\u7136\u5bf9\u4e8e\u672c\u793a\u4f8b\u4e5f\u4e0d\u9700\u8981\uff0c\u56e0\u4e3a\u8be5\u6570\u636e\u96c6\u672c\u8eab\u5c31\u662f\u5e72\u51c0\u7684\u3002  # \u6743\u91cd\u7cfb\u6570\u66f4\u65b0\u8fc7\u7a0b\ndisplay(Image('./image/cats_epoch.png'))", 
            "title": "\u611f\u77e5\u5668\u7684\u6982\u5ff5\u5256\u6790"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#numpy", 
            "text": "import numpy as np\na = np.array([2, -1, 3])\nb = np.array([1, 0, -1])\nprint( \u77e9\u9635\u52a0\u6cd5\uff1a{0} + {1} = {2} .format(a, b, a + b)) \nprint( \u77e9\u9635\u70b9\u4e58\uff1a{0} . {1} = {2} .format(a, b, np.dot(a, b)))\nprint( \u77e9\u9635\u5bf9\u5e94\u5143\u7d20\u76f8\u4e58\uff0cHadamard\u4e58\u79ef\uff1a{0} \u00d7 {1} = {2} .format(a, b, a*b))\nprint( \u77e9\u9635\u4e0e\u6807\u91cf\u76f8\u4e58\uff1a{0} \u00d7 {1} = {2} .format(2, a, 2*a))  \u77e9\u9635\u52a0\u6cd5\uff1a[ 2 -1  3] + [ 1  0 -1] = [ 3 -1  2]\n\u77e9\u9635\u70b9\u4e58\uff1a[ 2 -1  3] . [ 1  0 -1] = -1\n\u77e9\u9635\u5bf9\u5e94\u5143\u7d20\u76f8\u4e58\uff0cHadamard\u4e58\u79ef\uff1a[ 2 -1  3] \u00d7 [ 1  0 -1] = [ 2  0 -3]\n\u77e9\u9635\u4e0e\u6807\u91cf\u76f8\u4e58\uff1a2 \u00d7 [ 2 -1  3] = [ 4 -2  6]  Hadamard\u4e58\u79ef\uff1a \n\u77e9\u9635\u4e0e\u77e9\u9635\u7684Hadamard\u79ef\u5c31\u662f\u4e24\u4e2a\u77e9\u9635\u5bf9\u5e94\u5143\u7d20\u7684\u4e58\u79ef  Kronecker\u4e58\u79ef\uff1a \nKronecker\u79ef\u662f\u4e24\u4e2a\u4efb\u610f\u5927\u5c0f\u7684\u77e9\u9635\u95f4\u7684\u8fd0\u7b97\uff0c\u514b\u7f57\u5185\u514b\u79ef\u4e5f\u6210\u4e3a\u76f4\u79ef\u6216\u5f20\u91cf\u79ef\uff0c\u4ee5\u5fb7\u56fd\u6570\u5b66\u5bb6\u5229\u5965\u6ce2\u5fb7\u00b7\u514b\u7f57\u5185\u514b\u547d\u540d\u3002   import numpy as np \nw3 = np.array([1, 0.2, 0.1])\nupdate = np.array([-1, -0.7, -0.9])\nw4 = w3 + update\nw4  array([ 0. , -0.5, -0.8])", 
            "title": "numpy\u8fdb\u884c\u77e9\u9635\u8fd0\u7b97\u5c0f\u793a\u4f8b"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#python", 
            "text": "\u83ba(dai)\u5c3e\u82b1\u6570\u636e\u96c6\u3000 150\u884c\\ \\times \\ 5\u5217   \u7279\u5f81\uff1a4\u4e2a\uff0c\u5206\u522b\u662f\u82b1\u74e3\u957f\u5ea6\u548c\u5bbd\u5ea6\uff0c\u82b1\u843c\u957f\u5ea6\u548c\u5bbd\u5ea6\uff0c\u5355\u4f4dcm  \u5206\u7c7b\u6807\u7b7e\uff1a\u6700\u540e\u4e00\u5217\uff0c\u4e09\u79cd\u53d6\u503c\uff0c\u5206\u522b\u4ee3\u8868\u4e09\u79cd\u7c7b\u578b\u7684\u83ba\u5c3e\u82b1  df = pd.read_excel( ./Iris.xls , sheetname= Iris )  df.head(3)   \n   \n     \n       \n       sepal length \n       sepal width \n       petal length \n       petal width \n       iris \n     \n   \n   \n     \n       0 \n       5.1 \n       3.5 \n       1.4 \n       0.2 \n       Iris-setosa \n     \n     \n       1 \n       4.9 \n       3.0 \n       1.4 \n       0.2 \n       Iris-setosa \n     \n     \n       2 \n       4.7 \n       3.2 \n       1.3 \n       0.2 \n       Iris-setosa \n     \n      \u4e3a\u4e86\u53ef\u4ee5\u753b\uff12D\u56fe\uff0c\u53ea\u62bd\u53d6\u4e86\u524d100\u884c\u6570\u636e\uff0c\u5373\u4ec5\u4ec5\u5305\u542b50\u4e2a\u6837\u672c\u7684 Iris-Setosa and 50\u4e2a\u6837\u672c\u7684 Iris-Versicolor flowers  y = df.iloc[0:100, 4].values  # get a 1-array, numpy.ndarray\ny[-5:]  array([u'Iris-versicolor', u'Iris-versicolor', u'Iris-versicolor',\n       u'Iris-versicolor', u'Iris-versicolor'], dtype=object)  # \u5c06\u6570\u636e\u96c6\u7684\u6240\u6709\u5b57\u7b26\u7c7b\u578b\u7684\u6570\u636e\u8f6c\u53d8\u6210\u6570\u503c\u7c7b\u578b\nY = np.where(y== Iris-setosa , -1, 1)\nY[-5:]  array([1, 1, 1, 1, 1])  \u4e3a\u4e86\u7b80\u5316\u6d41\u7a0b\uff0c\u4ece\u56db\u4e2a\u7279\u5f81\u4e2d\u62bd\u53d6\u4e86\u4e24\u4e2a\u7279\u5f81\u7ec4\u6210\u7279\u5f81\u77e9\u9635\uff0c\u5373\u9009\u62e9\u4e86\u7b2c\u4e00\u5217(sepal length) and \u7b2c\u4e09\u5217(petal length) as X  X = df.iloc[0:100, [0,2]].values  # .values\u3000\u662f\u5c06pandas\u7684DataFrame\u6216Series\u6570\u636e\u7ed3\u6784\u53d8\u6210numpy\u7684array\u7684\u6570\u7ec4\u6216\u77e9\u9635\u7c7b\u578b\nX.shape\nX[-2:, :]  array([[ 5.1,  3. ],\n       [ 5.7,  4.1]])", 
            "title": "python\u5b9e\u73b0\u7684\u5355\u5c42\u611f\u77e5\u5668"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#_4", 
            "text": "plt.scatter(X[:50, 0], X[:50, 1], marker= o , label= setosa , c= white , edgecolor= purple )\nplt.scatter(X[50:100, 0], X[50:100, 1], c= blue , marker= x , label= versicolor )\nplt.xlabel( petal length [cm] )\nplt.ylabel( sepal length [cm] )\nplt.legend(loc= upper left )\nplt.show()", 
            "title": "\u6837\u672c\u7279\u5f81\u7684\u6563\u70b9\u56fe"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#perceptron", 
            "text": "class Perceptron(object):\n     Perceptron classifier\u5355\u5c42\u611f\u77e5\u5668 \n    def __init__(self, eta=0.01, n_iter=10):\n        self.eta = eta\n        self.n_iter = n_iter\n\n    #\u62df\u5408\n    def fit(self, X, Y):\n        self.w_ = np.zeros(1 + X.shape[1])\n        self.errors_ = []\n        print( length of w_ : %i ) % len(self.w_)\n        for i in range(self.n_iter):\n            errors = 0\n            for xi, target in zip(X, Y):\n                update = self.eta * (target - self.predict(xi)) # update\u662f\u4e00\u4e2a\u6570\u503c\u3000\n                self.w_[1:] += update * xi  # \u6570\u7ec4\u4e0a\u64cd\u4f5c\uff0c\u4e0d\u662f\u6570\u503c\u52a0\n                self.w_[0] += update\n                errors += int(update != 0.0)\n            self.errors_.append(errors)\n            print( epoch_ +str(i + 1))\n            print(self.w_)\n        return self\n\n    #\u51c0\u8f93\u5165\n    def net_input(self, X):\n        return np.dot(X, self.w_[1:]) + self.w_[0]\n\n    #\u6fc0\u52b1\u51fd\u6570\u9884\u6d4b\n    def predict(self, X):\n        return np.where(self.net_input(X)  = 0.0, 1, -1)\n\n# \u9884\u6d4b\u672a\u77e5\u6837\u672c \n#     def predict_real(self, X):\n#         y_real = { 1 : Iris-versicolor ,  -1 : Iris-setosa }\n#         y_ = self.net_input(X)        \n#         return y_real[str(y_)]", 
            "title": "Perceptron\u611f\u77e5\u5668\u5206\u7c7b\u5668"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#_5", 
            "text": "ppn = Perceptron(eta=0.1, n_iter=10)\nppn.fit(X, Y)\nplt.plot(range(1, len(ppn.errors_)+1), ppn.errors_, marker= . , color= purple )\nplt.xlabel( Epochs , fontsize=16)\nplt.ylabel( Number of Misclassification , fontsize=14)\nplt.grid(True, linestyle= : , alpha=0.8)\nplt.show()  length of w_ : 3\nepoch_1\n[ 0.    0.38  0.66]\nepoch_2\n[ 0.    0.76  1.32]\nepoch_3\n[-0.2   0.22  1.68]\nepoch_4\n[-0.2   0.34  2.1 ]\nepoch_5\n[-0.4  -0.68  1.82]\nepoch_6\n[-0.4  -0.68  1.82]\nepoch_7\n[-0.4  -0.68  1.82]\nepoch_8\n[-0.4  -0.68  1.82]\nepoch_9\n[-0.4  -0.68  1.82]\nepoch_10\n[-0.4  -0.68  1.82]", 
            "title": "\u611f\u77e5\u5668\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u5206\u7c7b\u6807\u7b7e\u9884\u6d4b\u9519\u8bef\u7684\u60c5\u51b5"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#_6", 
            "text": "implement a small convenience function to visualize the decision boundaries for 2D datasets  np.meshgrid\u662f\u751f\u6210\u7f51\u683c\u91c7\u6837\u70b9\u7684\u51fd\u6578\uff0c\u5b83\u63a5\u6536\u4e24\u4e2a\u4e00\u7ef4\u6570\u7ec4,\u4ea7\u751f\u4e24\u4e2a\u4e8c\u7ef4\u77e9\u9635  contour:\u8f6e\u5ed3,\u7b49\u9ad8\u7ebf,f\uff1afilled\uff0c\u4e5f\u5373\u5bf9\u7b49\u9ad8\u7ebf\u95f4\u7684\u586b\u5145\u533a\u57df\u8fdb\u884c\u586b\u5145\uff08\u4f7f\u7528\u4e0d\u540c\u7684\u989c\u8272\uff09\uff1b  contourf\uff1a\u5c06\u4e0d\u4f1a\u518d\u7ed8\u5236\u7b49\u9ad8\u7ebf\uff08\u663e\u7136\u4e0d\u540c\u7684\u989c\u8272\u5206\u754c\u5c31\u8868\u793a\u7b49\u9ad8\u7ebf\u672c\u8eab\uff09  from matplotlib.colors import ListedColormap\ndef plot_decision_regions(X, Y, classifier, resolution=0.02):\n    # \u5bf9\u5e94\u5206\u7c7b\u6807\u7b7e\n    y_maps = { 1 : Iris-versicolor ,  -1 : Iris-setosa }\n    # setup marker generator and color map\n    markers = ( ^ ,  x ,  s ,  o ,  v )\n    colors = ( purple ,  red ,  blue ,  cyan ,  lightgreen , )  # gray \n    cmap = ListedColormap(colors[:len(np.unique(Y))])\n    # plot the decision surface\n    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)  \n\n    plt.xlim(xx1.min(), xx1.max())\n    plt.ylim(xx2.min(), xx2.max())\n    # plot class samples\n    for idx, cl in enumerate(np.unique(Y)):\n        plt.scatter(x=X[Y==cl, 0], y=X[Y==cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx],label=y_maps[str(cl)])  plot_decision_regions(X, Y, classifier=ppn)\nplt.xlabel( sepal length [cm] , fontsize=18)\nplt.ylabel( petal length [cm] , fontsize=18)\nplt.legend(loc= upper left )\nplt.show()", 
            "title": "\u611f\u77e5\u5668\u5206\u7c7b\u51b3\u7b56\u8fb9\u754c\u793a\u610f\u56fe"
        }, 
        {
            "location": "/machine_learning/perceptron_classifier/perceptron_classifier_blog/#sklearn", 
            "text": "from sklearn.preprocessing import StandardScaler  # \u6807\u6ce8\u53d8\u6362\u4e4b\u6807\u51c6\u5316\nfrom sklearn.linear_model import Perceptron as percep\nfrom sklearn.cross_validation import train_test_split as ttsplit\nfrom sklearn.metrics import accuracy_score\nX_train, X_test, Y_train, Y_test = ttsplit(X, Y, test_size=0.2, random_state=0)\n\nsc = StandardScaler()\nsc.fit(X_train)  # \u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\nX_train_std = sc.transform(X_train)  # \u8fdb\u884c\u6807\u51c6\u53d8\u6362\uff0c\u53d8\u6210\u6807\u51c6\u6b63\u592a\u5206\u5e03\nX_test_std = sc.transform(X_test)\nppn_ = percep(n_iter=10, eta0=0.1, random_state=0)\nppn_.fit(X_train_std, Y_train)\nY_pred = ppn_.predict(X_test_std)\nprint( Misclassified samples: %d  % (Y_test != Y_pred).sum())\nprint( Accuracy: %.2f  % accuracy_score(Y_test,Y_pred))  Misclassified samples: 1\nAccuracy: 0.95\n\n\n/home/darren/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n  \"This module will be removed in 0.20.\", DeprecationWarning)  from matplotlib.colors import ListedColormap\nimport matplotlib.pyplot as plt\ndef plot_decision_region(X, Y, classifier, test_idx=None, resolution=0.02):\n    # \u5bf9\u5e94\u5206\u7c7b\u6807\u7b7e\n    y_maps = { 1 : Iris-versicolor ,  -1 : Iris-setosa }\n    # setup marker generator and color map\n    markers = ( ^ ,  x ,  s ,  o ,  v )\n    colors = ( purple ,  red ,  blue ,  cyan ,  lightgreen , )  # gray \n    cmap = ListedColormap(colors[:len(np.unique(Y))])\n    # plot the decision surface    \n    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n    Z = Z.reshape(xx1.shape)\n    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)      \n    plt.xlim(xx1.min(), xx1.max())\n    plt.ylim(xx2.min(), xx2.max())\n    # plot all samples\n    for idx, cl in enumerate(np.unique(Y)):\n        plt.scatter(x=X[Y==cl, 0], y=X[Y==cl, 1], alpha=0.8, c=cmap(idx), marker=markers[idx],label=y_maps[str(cl)])\n    # highlight test samples\n    if test_idx:\n        X_test, Y_test = X[test_idx, :], Y[test_idx]\n        X_test, Y_test = X[test_idx, :], Y[test_idx]\n        plt.scatter(X_test[:, 0], X_test[:, 1], c= , alpha=1.0, linewidth=1, marker= o , s=55, label= test set )  X_combined_std = np.vstack((X_train_std, X_test_std))\nY_combined = np.hstack((Y_train, Y_test))\nplot_decision_region(X=X_combined_std, Y=Y_combined, classifier=ppn_, test_idx=None)\nplt.xlabel( sepal length [standardized] cm , fontsize=16)\nplt.ylabel( petal length [standardized] cm , fontsize=14)\nplt.legend(loc= upper left )\nplt.show()", 
            "title": "sklearn\u611f\u77e5\u5668\u4ee3\u7801\u5b9e\u73b0"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/", 
            "text": "\u6caa\u6df1300\u80a1\u6307\u6da8\u8dcc\u9884\u6d4b\n\n\n\u5229\u7528LogisticRegression\u3001RandomForest\u7b49\u673a\u5668\u5b66\u4e60\u7684\u5206\u7c7b\u6a21\u578b\u5bf9\u6caa\u6df1300\u80a1\u6307\u7684\u6da8\u8dcc\u60c5\u51b5\u8fdb\u884c\u9884\u6d4b\u3002\u80a1\u6307\u6570\u636e\u7531tushare\u63d0\u4f9b\u7684API\u83b7\u53d6\uff0c\u91c7\u96c6\u4e862009-2017\u5e74\u7684\u80a1\u6307\u6570\u636e\uff0c\u5305\u62ec\u80a1\u6307\u548c\u6210\u4ea4\u91cf\u3002\u91c7\u7528\u524d5\u5929\u7684\u80a1\u6307\u548c\u6210\u4ea4\u91cf\u6570\u636e\u9884\u6d4b\u660e\u65e5\u80a1\u6307\u7684\u6da8\u8dcc\u60c5\u51b5\uff0c\u6700\u7ec8\uff0c\u51c6\u786e\u7387\u4e3a56.8%\u3002\n\n\n\u6570\u636e\u91c7\u96c6\n\n\n\u4f7f\u7528tushare\u91c7\u96c6\u56fd\u5185\u80a1\u7968\u6570\u636e\uff0ctushare\u662fpython\u7684\u7b2c\u4e09\u65b9\u5e93\uff0c\u529f\u80fd\u7c7b\u4f3cpandas\u7684DataReader\uff0c\u4e0d\u8fc7\u76ee\u524d\u53ea\u652f\u6301\u5bf9\u56fd\u5185\u80a1\u7968\u53ca\u4e00\u4e9b\u7ecf\u6d4e\u6570\u636e\u7684\u83b7\u53d6\u3002\u4f7f\u7528pymyql\u4e0emysql\u8fdb\u884c\u4ea4\u4e92\uff0c\u7531\u4e8e\u6570\u636e\u91cf\u5c0f\uff0c\u4e5f\u5b58\u50a8\u4e3aCSV\u65b9\u4fbf\u4e2a\u4eba\u4f7f\u7528\u3002\n\n\n\u6570\u636e\u5206\u6790\u53ca\u6a21\u578b\u6784\u5efa\n\n\ntushare\u63d0\u4f9b\u7684\u6570\u636e\u8d28\u91cf\u8fd8\u53ef\u4ee5\uff0c\u57fa\u672c\u65e0\u7f3a\u5931\u503c\u3002\u4e0b\u9762\u4e3b\u8981\u4f7f\u7528python\u7684\u6570\u636e\u5206\u6790\u53ca\u5efa\u6a21\u7b2c\u4e09\u65b9\u5e93\u5305\u62ec\uff0cpandas\u3001numpy\u3001scipy\u3001sklearn\uff0c\u4ee5\u53ca\u53ef\u89c6\u5316\u7684matplotlib\u548cseaborn\u3002\n\n\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(style=\nwhitegrid\n, palette=\nmuted\n, font_scale=1.0, color_codes=True, context=\ntalk\n)\n%matplotlib inline\nfrom matplotlib.font_manager import FontProperties  \nfont = FontProperties(fname=r\n/usr/share/fonts/truetype/arphic/ukai.ttc\n)\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\nimport datetime\nfrom scipy import stats\n\n\n\n\n\u8bfb\u5165\u6570\u636e\n\n\nsi = pd.read_csv(\n../linear_regression_20171018/stock_index_all_2008_2017.csv\n, \n                 parse_dates=True, index_col=\nsdate\n)\n\n\n\n\nsi.head(3)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nsindex\n\n      \nopen\n\n      \nclose\n\n      \nhigh\n\n      \nlow\n\n      \nvolume\n\n      \nprice_change\n\n      \np_change\n\n    \n\n    \n\n      \nsdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2010-06-02\n\n      \ncyb\n\n      \n967.609\n\n      \n997.119\n\n      \n997.12\n\n      \n952.61\n\n      \n1074627.0\n\n      \nNaN\n\n      \nNaN\n\n    \n\n    \n\n      \n2010-06-03\n\n      \ncyb\n\n      \n1002.355\n\n      \n998.394\n\n      \n1026.70\n\n      \n997.77\n\n      \n1616805.0\n\n      \nNaN\n\n      \nNaN\n\n    \n\n    \n\n      \n2010-06-04\n\n      \ncyb\n\n      \n989.681\n\n      \n1027.681\n\n      \n1027.68\n\n      \n986.50\n\n      \n1500295.0\n\n      \nNaN\n\n      \nNaN\n\n    \n\n  \n\n\n\n\n\n\n\nsi_pv = si.pivot_table(index=si.index, columns=\nsindex\n)\nsi_close = si_pv[\nclose\n]\nsi_close.head(3)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \nsindex\n\n      \ncyb\n\n      \nhs300\n\n      \nsh\n\n      \nsz\n\n      \nsz50\n\n      \nzxb\n\n    \n\n    \n\n      \nsdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2008-01-02\n\n      \nNaN\n\n      \n5385.10\n\n      \n5272.81\n\n      \n17856.2\n\n      \n4219.69\n\n      \n6400.808\n\n    \n\n    \n\n      \n2008-01-03\n\n      \nNaN\n\n      \n5422.03\n\n      \n5319.86\n\n      \n17911.3\n\n      \n4230.42\n\n      \n6421.972\n\n    \n\n    \n\n      \n2008-01-04\n\n      \nNaN\n\n      \n5483.65\n\n      \n5361.57\n\n      \n18122.4\n\n      \n4282.69\n\n      \n6387.947\n\n    \n\n  \n\n\n\n\n\n\n\n2009-2017\u5404\u5927\u80a1\u6307\u7684\u8d70\u52bf\uff0c\u5176\u4e2dsh\u4ee3\u8868\u6caa\u5e02\uff0csz\u4ee3\u8868\u6df1\u5e02\uff0ccyb\u4ee3\u8868\u521b\u4e1a\u677f\uff0chs300\u662f\u6caa\u6df1300\uff0c\u5373\u5206\u6790\u7684\u5bf9\u8c61\u3002\n\n\nsi_close.plot(figsize=(10,8))\nplt.title(u\n2009-2017\u5404\u80a1\u6307\u53d8\u5316\n, fontsize=20, fontproperties=font)\n\n\n\n\nmatplotlib.text.Text at 0x7fe6dc647d50\n\n\n\n\n\n\n\u9009\u62e9\u6caa\u6df1300(hs300)\u4e3a\u9884\u6d4b\u5206\u6790\u5bf9\u8c61\n\n\nhs = si[si[\nsindex\n].str.contains(\nhs300\n, regex=True)]  # (1893, 8)\n\n\n\n\nhs.drop([\nprice_change\n, \np_change\n], axis=1, inplace=True)\nhs.head(3)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nsindex\n\n      \nopen\n\n      \nclose\n\n      \nhigh\n\n      \nlow\n\n      \nvolume\n\n    \n\n    \n\n      \nsdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2008-01-02\n\n      \nhs300\n\n      \n5349.76\n\n      \n5385.10\n\n      \n5404.93\n\n      \n5283.45\n\n      \n45668700.0\n\n    \n\n    \n\n      \n2008-01-03\n\n      \nhs300\n\n      \n5381.15\n\n      \n5422.03\n\n      \n5422.67\n\n      \n5315.95\n\n      \n64645900.0\n\n    \n\n    \n\n      \n2008-01-04\n\n      \nhs300\n\n      \n5430.63\n\n      \n5483.65\n\n      \n5499.08\n\n      \n5422.46\n\n      \n51746400.0\n\n    \n\n  \n\n\n\n\n\n\n\n2009-2017\u6caa\u6df1300\u7684\u6307\u6570\u53ca\u6210\u4ea4\u91cf\u4fe1\u606f\n\n\nfig, ax = plt.subplots(figsize=(15,12))\nhs[[\nopen\n, \nclose\n, \nhigh\n, \nlow\n]].plot(ax=ax)\nhs[\nvolume\n].plot(secondary_y=True, ax=ax, label=\nvolume\n, legend=True)\nplt.title(u\n2009-2017\u6caa\u6df1300\u6307\u6570\u4e0e\u6210\u4ea4\u91cf(\u53f3\u6d4by\u8f74)\n, fontsize=20, fontproperties=font)\n\n\n\n\nmatplotlib.text.Text at 0x7fe6dc387e50\n\n\n\n\n\n\n\u63d0\u53d6\u7279\u5f81\n\n\nfrom techFeature import StockFeature\nsf = StockFeature(hs)\nstock_tech_fea = sf.extract_stock_fea()\nstock_tech_fea.shape\n\n\n\n\n(2383, 59)\n\n\n\nstock_tech_fea.head(2)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nVolume\n\n      \npct_change\n\n      \nLag5\n\n      \nLag10\n\n      \nLag20\n\n      \nLag30\n\n      \nLag60\n\n      \nhigh_pctchange\n\n      \nlow_pctchange\n\n      \nvolume_pctchange\n\n      \n...\n\n      \nbbands_upper\n\n      \nbbands_lower\n\n      \nroc\n\n      \nmacd_dif\n\n      \nmacd_dea\n\n      \nkdj_k\n\n      \nkdj_d\n\n      \nrsi\n\n      \nobv\n\n      \nrsv9\n\n    \n\n    \n\n      \nsdate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2008-01-02\n\n      \n45668700.0\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \n...\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \n0.000000\n\n      \n0.00000\n\n      \n83.676325\n\n      \n83.676325\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n    \n\n    \n\n      \n2008-01-03\n\n      \n64645900.0\n\n      \n0.685781\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \n0.328219\n\n      \n0.615128\n\n      \n41.554062\n\n      \n...\n\n      \nNaN\n\n      \nNaN\n\n      \nNaN\n\n      \n0.828558\n\n      \n0.46031\n\n      \n93.194708\n\n      \n89.387355\n\n      \n100.0\n\n      \nNaN\n\n      \nNaN\n\n    \n\n  \n\n\n\n\n2 rows \u00d7 59 columns\n\n\n\n\n\n\u4f7f\u7528\u524d5\u65e5\u80a1\u6307\u6570\u636e\u9884\u6d4b\u4eca\u65e5\u80a1\u6307\u7684\u6da8\u8dcc\u60c5\u51b5\n\n\nrolling_window = 5\nroll_tack = stock_tech_fea.copy()\nroll_tack.drop([\npct_change\n], axis=1, inplace=True)\nrollfmean = roll_tack.rolling(rolling_window, min_periods=rolling_window).mean()\nrollfmean.columns = rollfmean.columns.map(lambda x: x + \n_mean{}\n.format(rolling_window))\nrollf = rollfmean\nrollf = rollf.shift(1)  # \u7b2c6\u5929\u7684\u7279\u5f81\u4e3a\u524d5\u5929\u7684\u5747\u503c\uff0c\u7528\u6b64\u5747\u503c\u9884\u6d4b\u7b2c6\u5929\u7684\u6307\u6570\nrollf[\nclose\n] = hs[\nclose\n]\nrollf[\ndirection\n] = hs[\nclose\n].diff() \n 0\nrollf[\ndirection\n] = rollf[\ndirection\n].astype(np.int)\nrollf[\npct_change\n] = rollf[\nclose\n].pct_change() * 100\nrollf.dropna(how=\nany\n, inplace=True)\nrollf.shape\n\n\n\n\n(2180, 61)\n\n\n\nstock_tar = rollf[[\ndirection\n, \nclose\n, \npct_change\n]]\nstock_fea = rollf.drop([\ndirection\n, \nclose\n], axis=1)\nstock_fea.shape\n\n\n\n\n(2180, 59)\n\n\n\n\u6570\u636e\u521d\u63a2\u7d22\n\n\nfig, ax = plt.subplots(figsize=(10,8))\nstock_tar[\npct_change\n].plot(ax=ax)\nplt.ylabel('pct_change [%]', fontsize=16)\nplt.xlabel('')\nplt.title(u\n2009-2017\u6caa\u6df1300\u6da8\u8dcc\u5e45(%)\n, fontsize=20, fontproperties=font)\n\n\n\n\nmatplotlib.text.Text at 0x7fe6dc1fab10\n\n\n\n\n\n\nplt.figure(figsize=(8,6))\nfig = sns.distplot(stock_tar[\npct_change\n],kde=True, vertical=False, color=\npurple\n)\nsns.despine(top=True)\nplt.yticks(fig.get_yticks(), fig.get_yticks() * 100)\nplt.ylabel('Distribution [%]', fontsize=16)\n# plt.xticks(range(0, 100, 10))\nplt.gca().yaxis.grid(True, linestyle = \n-.\n)\nplt.gca().xaxis.grid(True, linestyle = \n-.\n)\nplt.xlabel(u\npct_change %\n, fontsize=16, fontproperties=font)\nplt.title(u\n2009-2017\u6caa\u6df1300\u6da8\u8dcc\u5e45\u5206\u5e03\n, fontsize=20, fontproperties=font)\n\n\n\n\nmatplotlib.text.Text at 0x7fe6dc1247d0\n\n\n\n\n\n\nupdown = stock_tar[\ndirection\n].value_counts()\nupdown.rename({1: \nup\n, 0: \ndown\n}, inplace=True) \nupdown\n\n\n\n\nup      1153\ndown    1027\nName: direction, dtype: int64\n\n\n\nplt.figure(figsize=(8,6))\ng=sns.barplot(x=updown.index, y=updown)\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.ylabel(\n)\nplt.xlabel(\n)\nplt.title(u\n2009-2017\u6caa\u6df1300\u4e0a\u6da8\u4e0e\u4e0b\u8dcc\u6b21\u6570\n, fontsize=20, fontproperties=font)\nplt.gca().yaxis.grid(True, linestyle = \n--\n)\nplt.legend(loc=7,prop=font, fontsize=12)\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(10,8))\nstock_tar[\nclose\n].plot(ax=ax)\nplt.ylabel('close', fontsize=16)\nplt.xlabel('')\nplt.gca().yaxis.grid(True, linestyle = \n-.\n)\nplt.gca().xaxis.grid(True, linestyle = \n-.\n)\nplt.xticks(plt.gca().get_xticks(), fontproperties=font, fontsize=16, rotation=-10)\nplt.title(u\n2009-2017\u6caa\u6df1300\u6307\u6570(close)\n, fontsize=20, fontproperties=font)\n\n\n\n\nmatplotlib.text.Text at 0x7fe6d7e2ae10\n\n\n\n\n\n\n\u7279\u5f81\u7b5b\u9009\n\n\nstock_fea.describe()\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nVolume_mean5\n\n      \nLag5_mean5\n\n      \nLag10_mean5\n\n      \nLag20_mean5\n\n      \nLag30_mean5\n\n      \nLag60_mean5\n\n      \nhigh_pctchange_mean5\n\n      \nlow_pctchange_mean5\n\n      \nvolume_pctchange_mean5\n\n      \nclose_roll_5_max_mean5\n\n      \n...\n\n      \nbbands_lower_mean5\n\n      \nroc_mean5\n\n      \nmacd_dif_mean5\n\n      \nmacd_dea_mean5\n\n      \nkdj_k_mean5\n\n      \nkdj_d_mean5\n\n      \nrsi_mean5\n\n      \nobv_mean5\n\n      \nrsv9_mean5\n\n      \npct_change\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n2.180000e+03\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n...\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n      \n2180.000000\n\n    \n\n    \n\n      \nmean\n\n      \n1.051363e+08\n\n      \n0.047027\n\n      \n0.045278\n\n      \n0.040162\n\n      \n0.039932\n\n      \n0.025105\n\n      \n0.046647\n\n      \n0.051635\n\n      \n2.817522\n\n      \n3001.432072\n\n      \n...\n\n      \n2671.912434\n\n      \n0.002508\n\n      \n5.702102\n\n      \n5.458203\n\n      \n216.317641\n\n      \n215.893160\n\n      \n52.071582\n\n      \n0.098248\n\n      \n0.548319\n\n      \n0.052583\n\n    \n\n    \n\n      \nstd\n\n      \n9.073317e+07\n\n      \n0.739807\n\n      \n0.740489\n\n      \n0.749253\n\n      \n0.759714\n\n      \n0.773778\n\n      \n0.700605\n\n      \n0.745852\n\n      \n8.150535\n\n      \n625.057884\n\n      \n...\n\n      \n522.791151\n\n      \n0.030531\n\n      \n64.431823\n\n      \n61.520109\n\n      \n147.532372\n\n      \n134.627519\n\n      \n12.195386\n\n      \n0.474311\n\n      \n0.324709\n\n      \n1.616292\n\n    \n\n    \n\n      \nmin\n\n      \n2.183633e+07\n\n      \n-4.838902\n\n      \n-4.838902\n\n      \n-4.838902\n\n      \n-4.838902\n\n      \n-4.838902\n\n      \n-4.809132\n\n      \n-4.497514\n\n      \n-18.049664\n\n      \n1696.796000\n\n      \n...\n\n      \n1531.647649\n\n      \n-0.177860\n\n      \n-276.353443\n\n      \n-228.492467\n\n      \n35.838216\n\n      \n44.991503\n\n      \n20.020866\n\n      \n-1.205182\n\n      \n0.000000\n\n      \n-8.747918\n\n    \n\n    \n\n      \n25%\n\n      \n5.559608e+07\n\n      \n-0.349020\n\n      \n-0.354861\n\n      \n-0.364369\n\n      \n-0.365298\n\n      \n-0.385432\n\n      \n-0.322148\n\n      \n-0.336338\n\n      \n-2.603190\n\n      \n2468.555500\n\n      \n...\n\n      \n2232.523107\n\n      \n-0.013679\n\n      \n-26.673772\n\n      \n-24.789436\n\n      \n107.145448\n\n      \n116.632821\n\n      \n42.578688\n\n      \n-0.220874\n\n      \n0.246982\n\n      \n-0.642415\n\n    \n\n    \n\n      \n50%\n\n      \n7.885951e+07\n\n      \n0.058455\n\n      \n0.057390\n\n      \n0.057390\n\n      \n0.057687\n\n      \n0.047854\n\n      \n0.042348\n\n      \n0.077093\n\n      \n1.765310\n\n      \n3026.933000\n\n      \n...\n\n      \n2620.764469\n\n      \n0.002935\n\n      \n5.721931\n\n      \n6.163226\n\n      \n181.459137\n\n      \n186.569701\n\n      \n52.341211\n\n      \n0.143482\n\n      \n0.584226\n\n      \n0.070339\n\n    \n\n    \n\n      \n75%\n\n      \n1.128905e+08\n\n      \n0.462984\n\n      \n0.462984\n\n      \n0.464625\n\n      \n0.466388\n\n      \n0.466889\n\n      \n0.434130\n\n      \n0.484127\n\n      \n7.137630\n\n      \n3403.722300\n\n      \n...\n\n      \n3083.151534\n\n      \n0.019482\n\n      \n34.422847\n\n      \n31.596202\n\n      \n282.154487\n\n      \n276.511020\n\n      \n60.152680\n\n      \n0.407017\n\n      \n0.859472\n\n      \n0.789530\n\n    \n\n    \n\n      \nmax\n\n      \n5.827038e+08\n\n      \n3.024969\n\n      \n3.024969\n\n      \n3.024969\n\n      \n3.340340\n\n      \n3.340340\n\n      \n2.870094\n\n      \n3.103424\n\n      \n59.134120\n\n      \n5353.750000\n\n      \n...\n\n      \n4308.229635\n\n      \n0.114338\n\n      \n230.638543\n\n      \n219.278724\n\n      \n1147.655035\n\n      \n1084.400053\n\n      \n90.298874\n\n      \n1.416612\n\n      \n1.000000\n\n      \n7.380962\n\n    \n\n  \n\n\n\n\n8 rows \u00d7 59 columns\n\n\n\n\n\ndef corr_plot(dataframe, plot_title=None, method='pearson', figsize=(20, 15)):\n    si_corr = dataframe.corr(method=method)    \n    siname = si_corr.columns.values\n    plt.figure(figsize=figsize)\n    g = sns.heatmap(si_corr, cbar=True, annot=True, \n                square=True, fmt=\n.2f\n, \n                annot_kws={'size': 12}, \n               yticklabels=siname,xticklabels=siname)\n    plt.yticks(g.get_yticks(), fontproperties=font, fontsize=20)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=20)\n    plt.xlabel(\n)\n    plt.ylabel(\n)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=20, rotation=75)\n    plt.title(plot_title + \n_\n + method, fontproperties=font, fontsize=25)\n\n\n\n\ncorr_plot(stock_fea, plot_title=u\n\u6caa\u6df1300\u7279\u5f81\u95f4\u76f8\u5173\u5173\u7cfb\n)\n\n\n\n\n\n\ncorr_plot(stock_fea, plot_title=u\n\u6caa\u6df1300\u7279\u5f81\u95f4\u76f8\u5173\u5173\u7cfb\n, method=\nspearman\n)\n\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RandomizedLasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import RandomizedLogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn import svm\n\n\n\n\ntrain_num = int(len(stock_fea) * 0.9)\nif \npct_change\n in stock_fea.columns:\n    stock_fea.drop(\npct_change\n, inplace=True, axis=1)\nX = stock_fea.copy()\ny_classification = stock_tar[\ndirection\n]\ny_regression = stock_tar[\nclose\n]\nsc = StandardScaler()\nsc.fit(X)  # \u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\nX_std = sc.transform(X)  # \u8fdb\u884c\u6807\u51c6\u53d8\u6362\uff0c\u53d8\u6210\u6807\u51c6\u6b63\u6001\u5206\u5e03\n\n\n\n\ndef feature_select(X, y, X_std):\n    feature_name = X.columns.values    \n    estimator = LogisticRegression()\n    selector = RFE(estimator, n_features_to_select=1, step=1)  \n    selector = selector.fit(X_std, y) \n    bag = sorted(zip(feature_name, selector.ranking_, selector.support_),\n                 key=lambda x: x[1])\n    fea_importance = pd.DataFrame(bag)\n    fea_importance.set_index(0,inplace=True)\n    fea_importance.drop(2, axis=1, inplace=True)\n    fea_importance.rename(index=str, columns={1: \nRFE_Logistic\n}, inplace=True)\n\n    model_dict = dict(zip([\nRandomLR\n, \nExtraTree\n], [RandomizedLogisticRegression(),\n                                                      ExtraTreesClassifier(n_estimators=1000, random_state=1)]))\n    for i in [\nRandomLR\n, \nExtraTree\n]:\n        model = model_dict[i]\n        model.fit(X if i == \nExtraTree\n else X_std, y_classification)\n        df_fea = pd.DataFrame(sorted(zip(feature_name, \n                model.feature_importances_ if i == \nExtraTree\n else model.scores_),\n                 key=lambda x: x[1], reverse=True))\n        df_fea.set_index(0, inplace=True)\n        df_fea.rename(index=str, columns={1: i}, inplace=True)\n        fea_importance = fea_importance.join(df_fea)\n    return fea_importance\n\n\n\n\nfea_importance = feature_select(X, y_classification , X_std) \nfea_importance\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nRFE_Logistic\n\n      \nRandomLR\n\n      \nExtraTree\n\n    \n\n    \n\n      \n0\n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \nclose_roll_5_min_mean5\n\n      \n1\n\n      \n0.000\n\n      \n0.014992\n\n    \n\n    \n\n      \nclose_roll_20_min_mean5\n\n      \n2\n\n      \n0.000\n\n      \n0.012900\n\n    \n\n    \n\n      \nvolume_roll_30_pp_mean5\n\n      \n3\n\n      \n0.465\n\n      \n0.022894\n\n    \n\n    \n\n      \nvolume_roll_10_pp_mean5\n\n      \n4\n\n      \n0.005\n\n      \n0.022125\n\n    \n\n    \n\n      \nlow_pctchange_mean5\n\n      \n5\n\n      \n0.000\n\n      \n0.022189\n\n    \n\n    \n\n      \nhigh_pctchange_mean5\n\n      \n6\n\n      \n0.000\n\n      \n0.020495\n\n    \n\n    \n\n      \nbbands_upper_mean5\n\n      \n7\n\n      \n0.000\n\n      \n0.013378\n\n    \n\n    \n\n      \nclose_roll_30_max_mean5\n\n      \n8\n\n      \n0.000\n\n      \n0.011722\n\n    \n\n    \n\n      \nclose_roll_60_min_mean5\n\n      \n9\n\n      \n0.000\n\n      \n0.012344\n\n    \n\n    \n\n      \nbbands_lower_mean5\n\n      \n10\n\n      \n0.000\n\n      \n0.014522\n\n    \n\n    \n\n      \nclose_roll_30_min_mean5\n\n      \n11\n\n      \n0.000\n\n      \n0.012110\n\n    \n\n    \n\n      \nvolume_roll_20_min_mean5\n\n      \n12\n\n      \n0.000\n\n      \n0.013796\n\n    \n\n    \n\n      \nvolume_roll_10_min_mean5\n\n      \n13\n\n      \n0.000\n\n      \n0.015238\n\n    \n\n    \n\n      \nclose_roll_10_max_mean5\n\n      \n14\n\n      \n0.000\n\n      \n0.013887\n\n    \n\n    \n\n      \nsma_30_mean5\n\n      \n15\n\n      \n0.000\n\n      \n0.013732\n\n    \n\n    \n\n      \nclose_roll_10_min_mean5\n\n      \n16\n\n      \n0.000\n\n      \n0.014065\n\n    \n\n    \n\n      \nvolume_roll_60_max_mean5\n\n      \n17\n\n      \n0.020\n\n      \n0.011409\n\n    \n\n    \n\n      \nvolume_roll_20_max_mean5\n\n      \n18\n\n      \n0.000\n\n      \n0.013721\n\n    \n\n    \n\n      \nvolume_roll_5_min_mean5\n\n      \n19\n\n      \n0.005\n\n      \n0.016882\n\n    \n\n    \n\n      \nkdj_k_mean5\n\n      \n20\n\n      \n0.055\n\n      \n0.019311\n\n    \n\n    \n\n      \nkdj_d_mean5\n\n      \n21\n\n      \n0.075\n\n      \n0.018454\n\n    \n\n    \n\n      \nrsv9_mean5\n\n      \n22\n\n      \n0.000\n\n      \n0.019859\n\n    \n\n    \n\n      \nrsi_mean5\n\n      \n23\n\n      \n0.030\n\n      \n0.018308\n\n    \n\n    \n\n      \nclose_roll_20_max_mean5\n\n      \n24\n\n      \n0.000\n\n      \n0.012585\n\n    \n\n    \n\n      \nvolume_roll_30_min_mean5\n\n      \n25\n\n      \n0.000\n\n      \n0.012333\n\n    \n\n    \n\n      \nsma_20_mean5\n\n      \n26\n\n      \n0.000\n\n      \n0.014133\n\n    \n\n    \n\n      \nvolume_roll_30_max_mean5\n\n      \n27\n\n      \n0.000\n\n      \n0.013155\n\n    \n\n    \n\n      \nvolume_roll_20_pp_mean5\n\n      \n28\n\n      \n0.105\n\n      \n0.022286\n\n    \n\n    \n\n      \nsma_60_mean5\n\n      \n29\n\n      \n0.000\n\n      \n0.013465\n\n    \n\n    \n\n      \nclose_roll_20_pp_mean5\n\n      \n30\n\n      \n0.000\n\n      \n0.020728\n\n    \n\n    \n\n      \nclose_roll_60_pp_mean5\n\n      \n31\n\n      \n0.000\n\n      \n0.020377\n\n    \n\n    \n\n      \nclose_roll_5_max_mean5\n\n      \n32\n\n      \n0.000\n\n      \n0.014565\n\n    \n\n    \n\n      \newma_mean5\n\n      \n33\n\n      \n0.000\n\n      \n0.013391\n\n    \n\n    \n\n      \nLag60_mean5\n\n      \n34\n\n      \n0.000\n\n      \n0.022234\n\n    \n\n    \n\n      \nroc_mean5\n\n      \n35\n\n      \n0.000\n\n      \n0.020028\n\n    \n\n    \n\n      \nsma_5_mean5\n\n      \n36\n\n      \n0.000\n\n      \n0.014687\n\n    \n\n    \n\n      \ncci_mean5\n\n      \n37\n\n      \n0.000\n\n      \n0.018813\n\n    \n\n    \n\n      \nobv_mean5\n\n      \n38\n\n      \n0.000\n\n      \n0.023669\n\n    \n\n    \n\n      \nvolume_roll_60_min_mean5\n\n      \n39\n\n      \n0.000\n\n      \n0.012152\n\n    \n\n    \n\n      \nmacd_dea_mean5\n\n      \n40\n\n      \n0.000\n\n      \n0.016500\n\n    \n\n    \n\n      \nLag5_mean5\n\n      \n41\n\n      \n0.005\n\n      \n0.021485\n\n    \n\n    \n\n      \nmacd_dif_mean5\n\n      \n42\n\n      \n0.020\n\n      \n0.016610\n\n    \n\n    \n\n      \nLag10_mean5\n\n      \n43\n\n      \n0.000\n\n      \n0.021961\n\n    \n\n    \n\n      \nVolume_mean5\n\n      \n44\n\n      \n0.015\n\n      \n0.017822\n\n    \n\n    \n\n      \nvolume_roll_60_pp_mean5\n\n      \n45\n\n      \n0.355\n\n      \n0.022679\n\n    \n\n    \n\n      \nclose_roll_10_pp_mean5\n\n      \n46\n\n      \n0.000\n\n      \n0.020859\n\n    \n\n    \n\n      \nclose_roll_60_max_mean5\n\n      \n47\n\n      \n0.000\n\n      \n0.011358\n\n    \n\n    \n\n      \nemv_mean5\n\n      \n48\n\n      \n0.000\n\n      \n0.017818\n\n    \n\n    \n\n      \nvolume_roll_10_max_mean5\n\n      \n49\n\n      \n0.005\n\n      \n0.015913\n\n    \n\n    \n\n      \nLag20_mean5\n\n      \n50\n\n      \n0.000\n\n      \n0.022178\n\n    \n\n    \n\n      \nclose_roll_5_pp_mean5\n\n      \n51\n\n      \n0.000\n\n      \n0.020580\n\n    \n\n    \n\n      \nLag30_mean5\n\n      \n52\n\n      \n0.000\n\n      \n0.022674\n\n    \n\n    \n\n      \nfi_mean5\n\n      \n53\n\n      \n0.000\n\n      \n0.019666\n\n    \n\n    \n\n      \nvolume_roll_5_max_mean5\n\n      \n54\n\n      \n0.000\n\n      \n0.017331\n\n    \n\n    \n\n      \nvolume_pctchange_mean5\n\n      \n55\n\n      \n0.015\n\n      \n0.021926\n\n    \n\n    \n\n      \nclose_roll_30_pp_mean5\n\n      \n56\n\n      \n0.000\n\n      \n0.020302\n\n    \n\n    \n\n      \nvolume_roll_5_pp_mean5\n\n      \n57\n\n      \n0.000\n\n      \n0.020994\n\n    \n\n    \n\n      \nsma_10_mean5\n\n      \n58\n\n      \n0.000\n\n      \n0.014408\n\n    \n\n  \n\n\n\n\n\n\n\n\u57fa\u4e8eRFE\u548cRandomLogistic\u8fdb\u884c\u7279\u5f81\u9009\u62e9\n\n\nfrlr = set(fea_importance.loc[fea_importance[\nRandomLR\n] != 0, :].index.tolist())\nfrfe = set(fea_importance.loc[fea_importance[\nRFE_Logistic\n] \n=23, :].index.tolist())\n# \u6b64\u5904\u768423\u662f\u6d4b\u8bd5\u4e0d\u540c\u6570\u503c\u7684\u7279\u5f81\u4f7f\u7528logisticRegression\u8fdb\u884c\u5206\u7c7b\uff0c\u770b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u5f97\u5230\u7684\n# \u5bf9\u4e8e\u4f7f\u7528RandomLR\u9009\u62e9\u7684\u7279\u5f81\u4e5f\u7c7b\u4f3c\uff0c\u4e0d\u8fc7\u7531\u4e8e\u5176\u57280\u5904\u6709\u5212\u5206\uff0c\u6545\u9009\u62e9\n0\u7684\n# \u89c2\u5bdf\u4e24\u79cd\u9009\u62e9\u540e\u7684\u7279\u5f81\u7684logistic\u5206\u7c7b\u6df7\u6dc6\u77e9\u9635\uff0c\u53d1\u73b0\u4fe9\u8005\u6709\u4e92\u8865\u7684\u8d8b\u52bf\nchoosen_features = list(frlr | frfe)\nchoosen_features\n# len(choosen_feature)  # 31\n\n\n\n\n['low_pctchange_mean5',\n 'volume_roll_5_min_mean5',\n 'close_roll_5_min_mean5',\n 'high_pctchange_mean5',\n 'volume_roll_20_min_mean5',\n 'close_roll_30_max_mean5',\n 'close_roll_30_min_mean5',\n 'kdj_d_mean5',\n 'volume_roll_60_pp_mean5',\n 'sma_30_mean5',\n 'volume_pctchange_mean5',\n 'Lag5_mean5',\n 'volume_roll_10_min_mean5',\n 'rsv9_mean5',\n 'volume_roll_10_pp_mean5',\n 'close_roll_20_min_mean5',\n 'close_roll_60_min_mean5',\n 'kdj_k_mean5',\n 'volume_roll_20_pp_mean5',\n 'Volume_mean5',\n 'volume_roll_10_max_mean5',\n 'volume_roll_60_max_mean5',\n 'volume_roll_20_max_mean5',\n 'rsi_mean5',\n 'close_roll_10_min_mean5',\n 'volume_roll_30_pp_mean5',\n 'macd_dif_mean5',\n 'bbands_upper_mean5',\n 'close_roll_10_max_mean5',\n 'bbands_lower_mean5']\n\n\n\n\u6a21\u578b\u6784\u5efa\n\n\n\u7528\u9009\u51fa\u768431\u4e2a\u7279\u5f81\u6784\u9020\u7684\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3\n\n\nif \npct_change\n in stock_fea.columns:\n    stock_fea.drop(\npct_change\n, inplace=True, axis=1)\nX_temp = stock_fea[choosen_features]\nX_train = X_temp[:train_num]\nX_test = X_temp[train_num:]\ny_train = stock_tar[\ndirection\n][:train_num]\ny_test = stock_tar[\ndirection\n][train_num:]\nsc = StandardScaler()\nsc.fit(X_train)  \nX_train_std = sc.transform(X_train) \nX_test_std = sc.transform(X_test)\nX_train.shape\n\n\n\n\n(1962, 30)\n\n\n\ndef confusion_mplot(y_test, y_pred):\n    tick_labels = [u\n\u6da8\n,u\n\u8dcc\n]\n    confm = confusion_matrix(y_test, y_pred, labels=[1,0])\n    plt.figure(figsize=(4,3))\n    g = sns.heatmap(confm, cbar=True, annot=True, \n                square=True, fmt=\n.2f\n, \n                annot_kws={'size': 12}, \n               yticklabels=tick_labels,xticklabels=tick_labels)\n    plt.yticks(g.get_yticks(), fontproperties=font, fontsize=15)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=15)\n    plt.ylabel(u'\u5b9e\u9645', fontproperties=font, fontsize=20)\n    plt.xlabel(u'\u9884\u6d4b', fontproperties=font, fontsize=20)\n\n\n\n\nparameters = {'C':[150, 50, 10, 2, 1.5, 1, 0.8, 0.5, 0.3, 0.1, 0.01, 0.001, 0.0001]}\nlr = LogisticRegression(penalty=\nl2\n, random_state=1, tol=1e-6)\ngscv = GridSearchCV(lr, parameters)\ngscv.fit(X_train_std, y_train)\ngs = gscv.grid_scores_\nbp = gscv.best_params_\nbs = gscv.best_score_ \ngs\n\n\n\n\n[mean: 0.53109, std: 0.01380, params: {'C': 150},\n mean: 0.53007, std: 0.01243, params: {'C': 50},\n mean: 0.52803, std: 0.01158, params: {'C': 10},\n mean: 0.52905, std: 0.00909, params: {'C': 2},\n mean: 0.53058, std: 0.00921, params: {'C': 1.5},\n mean: 0.53007, std: 0.01112, params: {'C': 1},\n mean: 0.53058, std: 0.01003, params: {'C': 0.8},\n mean: 0.53160, std: 0.00537, params: {'C': 0.5},\n mean: 0.53007, std: 0.00716, params: {'C': 0.3},\n mean: 0.53262, std: 0.00529, params: {'C': 0.1},\n mean: 0.53211, std: 0.00920, params: {'C': 0.01},\n mean: 0.49949, std: 0.02314, params: {'C': 0.001},\n mean: 0.48777, std: 0.02197, params: {'C': 0.0001}]\n\n\n\nLogisticRegression\u5206\u7c7b\u6a21\u578b\n\n\nlrf = LogisticRegression(C = 0.01, penalty=\nl2\n, random_state=1, tol=1e-6)\nlrf.fit(X_train_std, y_train)\ny_pred = lrf.predict(X_test_std)\nconfusion_mplot(y_test, y_pred)\nclassification_report(y_test, y_pred)\n\n\n\n\nu'             precision    recall  f1-score   support\\n\\n          0       0.47      0.63      0.54       101\\n          1       0.54      0.38      0.44       117\\n\\navg / total       0.51      0.50      0.49       218\\n'\n\n\n\n\n\naccuracy_score(y_test, y_pred)\n# accuracy_score(y_train, lrf.predict(X_train_std))  # 0.5558\n\n\n\n\n0.49541284403669728\n\n\n\nRandomForest\u5206\u7c7b\u6a21\u578b\n\n\nrf = RandomForestClassifier(n_estimators=1000, random_state=24)\nrf.fit(X_train, y_train)\nrf_prediction_train = rf.predict(X_train)\nrf_prediction_test = rf.predict(X_test)\nrf_evaluate_result = classification_report(y_test, rf_prediction_test)\nconfusion_mplot(y_test, rf_prediction_test)\nrf_evaluate_result  \n\n\n\n\nu'             precision    recall  f1-score   support\\n\\n          0       0.46      0.31      0.37       101\\n          1       0.54      0.69      0.60       117\\n\\navg / total       0.50      0.51      0.50       218\\n'\n\n\n\n\n\naccuracy_score(y_test,rf_prediction_test)\n# accuracy_score(y_train, rf.predict(X_train_std))  # 0.5224\n\n\n\n\n0.51376146788990829\n\n\n\n\u51b3\u7b56\u6811\u5206\u7c7b\u6a21\u578b\n\n\n# \u51b3\u7b56\u6869\u5206\u7c7b\u5668\u6027\u80fd\ntree = DecisionTreeClassifier(max_depth=8)\ntree.fit(X_train, y_train)\ntree_pred_test = tree.predict(X_test)\ntree_pred_train = tree.predict(X_train)\ntree_evaluate_result = classification_report(y_test, tree_pred_test)\nconfusion_mplot(y_test, tree_pred_test)\ntree_evaluate_result\n\n\n\n\nu'             precision    recall  f1-score   support\\n\\n          0       0.53      0.69      0.60       101\\n          1       0.64      0.46      0.53       117\\n\\navg / total       0.58      0.57      0.56       218\\n'\n\n\n\n\n\naccuracy_score(y_test,tree_pred_test)\n# accuracy_score(y_train,tree_pred_train)  # 0.6671\n\n\n\n\n0.56880733944954132\n\n\n\nAdaBoost\n\n\n# Boosting\u5206\u7c7b\u5668\u6027\u80fd\nada = AdaBoostClassifier(base_estimator=tree,n_estimators=1000,learning_rate=0.1, random_state=24)\nada = ada.fit(X_train, y_train)\nada_test_pred = ada.predict(X_test)\nada_evaluate_result = classification_report(y_test, ada_test_pred)\nconfusion_mplot(y_test, ada_test_pred)\nada_evaluate_result\n\n\n\n\nu'             precision    recall  f1-score   support\\n\\n          0       0.46      0.28      0.35       101\\n          1       0.54      0.72      0.61       117\\n\\navg / total       0.50      0.51      0.49       218\\n'\n\n\n\n\n\naccuracy_score(y_test,ada_test_pred)\n# accuracy_score(y_train, ada.predict(X_train_std))  # 0.5127\n\n\n\n\n0.51376146788990829\n\n\n\n\u6a21\u578b\u878d\u5408-\u6295\u7968\n\n\neclf = VotingClassifier(estimators=[(\nlr\n, lrf), ('ada', ada), ('rf', rf), (\ntree\n,tree)], voting='soft',weights=[2,1,1,1])\neclf.fit(X_train, y_train)\neclf_pred_test = eclf.predict(X_test)\neclf_pred_train = eclf.predict(X_train)\neclf_train_accu = accuracy_score(y_train, eclf_pred_train)\neclf_test_accu = accuracy_score(y_test, eclf_pred_test)\neclf_train_f1 = f1_score(y_train, eclf_pred_train)\neclf_test_f1 = f1_score(y_test, eclf_pred_test)\nbase_result_eclf = \ntrain_accuracy:{1},test_accuracy:{2},train_f1:{0},test_f1:{3}\n.format(eclf_train_accu,eclf_test_accu,eclf_train_f1,eclf_test_f1)\neclf_evaluate_result = classification_report(y_test, eclf_pred_test)\nconfusion_mplot(y_test, eclf_pred_test)\neclf_evaluate_result\n\n\n\n\nu'             precision    recall  f1-score   support\\n\\n          0       0.56      0.34      0.42       101\\n          1       0.57      0.77      0.66       117\\n\\navg / total       0.57      0.57      0.55       218\\n'\n\n\n\n\n\naccuracy_score(y_test, eclf_pred_test)\n# accuracy_score(y_train, eclf.predict(X_train_std))  # 0.5224\n\n\n\n\n0.56880733944954132\n\n\n\neclf\n\n\n\n\nVotingClassifier(estimators=[('lr', LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=1, solver='liblinear', tol=1e-06,\n          verbose=0, warm_start=False)), ('ada', AdaBoostC...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best'))],\n         flatten_transform=None, n_jobs=1, voting='soft',\n         weights=[2, 1, 1, 1])\n\n\n\n\u7531LogisticRegression\u5206\u7c7b\u5668\u3001\u968f\u673a\u68ee\u6797\u3001Adaboost_tree\u3001\u51b3\u7b56\u6811\u6784\u5efa\u7684\u6700\u7ec8\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u4e3a56.8%\uff0c\u9ad8\u4e8e\u4efb\u4f55\u5355\u4e00\u5206\u7c7b\u6a21\u578b\u3002\n\u6700\u540e\uff0c\u7528eclf.predict()\u5c31\u53ef\u4ee5\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u9884\u6d4b\u4e86\u3002\n\n\n\u603b\u7ed3\n\n\n\u672c\u6587\u75282009-2017\u5e74\u7684\u6caa\u6df1300\u6307\u6570\u6784\u5efa\u5206\u7c7b\u6a21\u578b\u4ee5\u9884\u6d4b\u6caa\u6df1300\u80a1\u6307\u660e\u65e5\u662f\u6da8\u8fd8\u662f\u8dcc\uff0c\u6700\u7ec8\uff0c\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u4e3a56.8%\u3002\n\n\n\u7531\u4e8e\u8bad\u7ec3\u6a21\u578b\u53ea\u4f7f\u7528\u4e86\u6caa\u6df1300\u80a1\u6307\u6536\u5e02\u6307\u6570\u3001\u6210\u4ea4\u91cf\u3001\u4e00\u65e5\u7684\u6700\u9ad8\u548c\u6700\u4f4e\u503c\u4ee5\u53ca\u57fa\u4e8e\u8fd9\u4e9b\u8ba1\u7b97\u7684\u4e00\u4e9b\u5e38\u7528\u7684\u6280\u672f\u6307\u6807\uff0c\u5373\u6570\u636e\u6bd4\u8f83\u5355\u4e00\uff0c\u6ca1\u6709\u8003\u8651\u76d8\u5916\u7684\u5176\u4ed6\u4fe1\u606f\uff0c\u6bd4\u5982\u671f\u8d27\u4fe1\u606f\u3001\u5916\u5e02\u4fe1\u606f\u3001\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\u7b49\u7b49\uff0c\u540c\u65f6\uff0c\u4f7f\u7528\u7684\u6280\u672f\u6307\u6807\u4e5f\u4e0d\u5168\u9762\uff0c\u800c\u4e14\u4ec5\u4ec5\u4f7f\u7528\u4e865\u65e5\u4fe1\u606f\uff0c\u5e76\u6ca1\u6709\u8003\u8651\u66f4\u957f\u6216\u66f4\u77ed\u65f6\u95f4\u5c3a\u5ea6\u7684\u80a1\u6307\u4fe1\u606f\uff0c\u56e0\u6b64\uff0c\u6700\u7ec8\u7684\u5206\u7c7b\u6548\u679c\u4e0d\u548b\u5730\u4e5f\u662f\u9884\u6599\u4e4b\u4e2d\u7684\u4e8b\u3002", 
            "title": "\u6caa\u6df1300\u80a1\u6307\u6da8\u8dcc\u9884\u6d4b"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#300", 
            "text": "\u5229\u7528LogisticRegression\u3001RandomForest\u7b49\u673a\u5668\u5b66\u4e60\u7684\u5206\u7c7b\u6a21\u578b\u5bf9\u6caa\u6df1300\u80a1\u6307\u7684\u6da8\u8dcc\u60c5\u51b5\u8fdb\u884c\u9884\u6d4b\u3002\u80a1\u6307\u6570\u636e\u7531tushare\u63d0\u4f9b\u7684API\u83b7\u53d6\uff0c\u91c7\u96c6\u4e862009-2017\u5e74\u7684\u80a1\u6307\u6570\u636e\uff0c\u5305\u62ec\u80a1\u6307\u548c\u6210\u4ea4\u91cf\u3002\u91c7\u7528\u524d5\u5929\u7684\u80a1\u6307\u548c\u6210\u4ea4\u91cf\u6570\u636e\u9884\u6d4b\u660e\u65e5\u80a1\u6307\u7684\u6da8\u8dcc\u60c5\u51b5\uff0c\u6700\u7ec8\uff0c\u51c6\u786e\u7387\u4e3a56.8%\u3002", 
            "title": "\u6caa\u6df1300\u80a1\u6307\u6da8\u8dcc\u9884\u6d4b"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#_1", 
            "text": "\u4f7f\u7528tushare\u91c7\u96c6\u56fd\u5185\u80a1\u7968\u6570\u636e\uff0ctushare\u662fpython\u7684\u7b2c\u4e09\u65b9\u5e93\uff0c\u529f\u80fd\u7c7b\u4f3cpandas\u7684DataReader\uff0c\u4e0d\u8fc7\u76ee\u524d\u53ea\u652f\u6301\u5bf9\u56fd\u5185\u80a1\u7968\u53ca\u4e00\u4e9b\u7ecf\u6d4e\u6570\u636e\u7684\u83b7\u53d6\u3002\u4f7f\u7528pymyql\u4e0emysql\u8fdb\u884c\u4ea4\u4e92\uff0c\u7531\u4e8e\u6570\u636e\u91cf\u5c0f\uff0c\u4e5f\u5b58\u50a8\u4e3aCSV\u65b9\u4fbf\u4e2a\u4eba\u4f7f\u7528\u3002", 
            "title": "\u6570\u636e\u91c7\u96c6"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#_2", 
            "text": "tushare\u63d0\u4f9b\u7684\u6570\u636e\u8d28\u91cf\u8fd8\u53ef\u4ee5\uff0c\u57fa\u672c\u65e0\u7f3a\u5931\u503c\u3002\u4e0b\u9762\u4e3b\u8981\u4f7f\u7528python\u7684\u6570\u636e\u5206\u6790\u53ca\u5efa\u6a21\u7b2c\u4e09\u65b9\u5e93\u5305\u62ec\uff0cpandas\u3001numpy\u3001scipy\u3001sklearn\uff0c\u4ee5\u53ca\u53ef\u89c6\u5316\u7684matplotlib\u548cseaborn\u3002  import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(style= whitegrid , palette= muted , font_scale=1.0, color_codes=True, context= talk )\n%matplotlib inline\nfrom matplotlib.font_manager import FontProperties  \nfont = FontProperties(fname=r /usr/share/fonts/truetype/arphic/ukai.ttc )\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\nimport datetime\nfrom scipy import stats  \u8bfb\u5165\u6570\u636e  si = pd.read_csv( ../linear_regression_20171018/stock_index_all_2008_2017.csv , \n                 parse_dates=True, index_col= sdate )  si.head(3)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       sindex \n       open \n       close \n       high \n       low \n       volume \n       price_change \n       p_change \n     \n     \n       sdate \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2010-06-02 \n       cyb \n       967.609 \n       997.119 \n       997.12 \n       952.61 \n       1074627.0 \n       NaN \n       NaN \n     \n     \n       2010-06-03 \n       cyb \n       1002.355 \n       998.394 \n       1026.70 \n       997.77 \n       1616805.0 \n       NaN \n       NaN \n     \n     \n       2010-06-04 \n       cyb \n       989.681 \n       1027.681 \n       1027.68 \n       986.50 \n       1500295.0 \n       NaN \n       NaN \n     \n      si_pv = si.pivot_table(index=si.index, columns= sindex )\nsi_close = si_pv[ close ]\nsi_close.head(3)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       sindex \n       cyb \n       hs300 \n       sh \n       sz \n       sz50 \n       zxb \n     \n     \n       sdate \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2008-01-02 \n       NaN \n       5385.10 \n       5272.81 \n       17856.2 \n       4219.69 \n       6400.808 \n     \n     \n       2008-01-03 \n       NaN \n       5422.03 \n       5319.86 \n       17911.3 \n       4230.42 \n       6421.972 \n     \n     \n       2008-01-04 \n       NaN \n       5483.65 \n       5361.57 \n       18122.4 \n       4282.69 \n       6387.947 \n     \n      2009-2017\u5404\u5927\u80a1\u6307\u7684\u8d70\u52bf\uff0c\u5176\u4e2dsh\u4ee3\u8868\u6caa\u5e02\uff0csz\u4ee3\u8868\u6df1\u5e02\uff0ccyb\u4ee3\u8868\u521b\u4e1a\u677f\uff0chs300\u662f\u6caa\u6df1300\uff0c\u5373\u5206\u6790\u7684\u5bf9\u8c61\u3002  si_close.plot(figsize=(10,8))\nplt.title(u 2009-2017\u5404\u80a1\u6307\u53d8\u5316 , fontsize=20, fontproperties=font)  matplotlib.text.Text at 0x7fe6dc647d50    \u9009\u62e9\u6caa\u6df1300(hs300)\u4e3a\u9884\u6d4b\u5206\u6790\u5bf9\u8c61  hs = si[si[ sindex ].str.contains( hs300 , regex=True)]  # (1893, 8)  hs.drop([ price_change ,  p_change ], axis=1, inplace=True)\nhs.head(3)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       sindex \n       open \n       close \n       high \n       low \n       volume \n     \n     \n       sdate \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2008-01-02 \n       hs300 \n       5349.76 \n       5385.10 \n       5404.93 \n       5283.45 \n       45668700.0 \n     \n     \n       2008-01-03 \n       hs300 \n       5381.15 \n       5422.03 \n       5422.67 \n       5315.95 \n       64645900.0 \n     \n     \n       2008-01-04 \n       hs300 \n       5430.63 \n       5483.65 \n       5499.08 \n       5422.46 \n       51746400.0 \n     \n      2009-2017\u6caa\u6df1300\u7684\u6307\u6570\u53ca\u6210\u4ea4\u91cf\u4fe1\u606f  fig, ax = plt.subplots(figsize=(15,12))\nhs[[ open ,  close ,  high ,  low ]].plot(ax=ax)\nhs[ volume ].plot(secondary_y=True, ax=ax, label= volume , legend=True)\nplt.title(u 2009-2017\u6caa\u6df1300\u6307\u6570\u4e0e\u6210\u4ea4\u91cf(\u53f3\u6d4by\u8f74) , fontsize=20, fontproperties=font)  matplotlib.text.Text at 0x7fe6dc387e50", 
            "title": "\u6570\u636e\u5206\u6790\u53ca\u6a21\u578b\u6784\u5efa"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#_3", 
            "text": "from techFeature import StockFeature\nsf = StockFeature(hs)\nstock_tech_fea = sf.extract_stock_fea()\nstock_tech_fea.shape  (2383, 59)  stock_tech_fea.head(2)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       Volume \n       pct_change \n       Lag5 \n       Lag10 \n       Lag20 \n       Lag30 \n       Lag60 \n       high_pctchange \n       low_pctchange \n       volume_pctchange \n       ... \n       bbands_upper \n       bbands_lower \n       roc \n       macd_dif \n       macd_dea \n       kdj_k \n       kdj_d \n       rsi \n       obv \n       rsv9 \n     \n     \n       sdate \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2008-01-02 \n       45668700.0 \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       ... \n       NaN \n       NaN \n       NaN \n       0.000000 \n       0.00000 \n       83.676325 \n       83.676325 \n       NaN \n       NaN \n       NaN \n     \n     \n       2008-01-03 \n       64645900.0 \n       0.685781 \n       NaN \n       NaN \n       NaN \n       NaN \n       NaN \n       0.328219 \n       0.615128 \n       41.554062 \n       ... \n       NaN \n       NaN \n       NaN \n       0.828558 \n       0.46031 \n       93.194708 \n       89.387355 \n       100.0 \n       NaN \n       NaN \n     \n     2 rows \u00d7 59 columns   \u4f7f\u7528\u524d5\u65e5\u80a1\u6307\u6570\u636e\u9884\u6d4b\u4eca\u65e5\u80a1\u6307\u7684\u6da8\u8dcc\u60c5\u51b5  rolling_window = 5\nroll_tack = stock_tech_fea.copy()\nroll_tack.drop([ pct_change ], axis=1, inplace=True)\nrollfmean = roll_tack.rolling(rolling_window, min_periods=rolling_window).mean()\nrollfmean.columns = rollfmean.columns.map(lambda x: x +  _mean{} .format(rolling_window))\nrollf = rollfmean\nrollf = rollf.shift(1)  # \u7b2c6\u5929\u7684\u7279\u5f81\u4e3a\u524d5\u5929\u7684\u5747\u503c\uff0c\u7528\u6b64\u5747\u503c\u9884\u6d4b\u7b2c6\u5929\u7684\u6307\u6570\nrollf[ close ] = hs[ close ]\nrollf[ direction ] = hs[ close ].diff()   0\nrollf[ direction ] = rollf[ direction ].astype(np.int)\nrollf[ pct_change ] = rollf[ close ].pct_change() * 100\nrollf.dropna(how= any , inplace=True)\nrollf.shape  (2180, 61)  stock_tar = rollf[[ direction ,  close ,  pct_change ]]\nstock_fea = rollf.drop([ direction ,  close ], axis=1)\nstock_fea.shape  (2180, 59)", 
            "title": "\u63d0\u53d6\u7279\u5f81"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#_4", 
            "text": "fig, ax = plt.subplots(figsize=(10,8))\nstock_tar[ pct_change ].plot(ax=ax)\nplt.ylabel('pct_change [%]', fontsize=16)\nplt.xlabel('')\nplt.title(u 2009-2017\u6caa\u6df1300\u6da8\u8dcc\u5e45(%) , fontsize=20, fontproperties=font)  matplotlib.text.Text at 0x7fe6dc1fab10    plt.figure(figsize=(8,6))\nfig = sns.distplot(stock_tar[ pct_change ],kde=True, vertical=False, color= purple )\nsns.despine(top=True)\nplt.yticks(fig.get_yticks(), fig.get_yticks() * 100)\nplt.ylabel('Distribution [%]', fontsize=16)\n# plt.xticks(range(0, 100, 10))\nplt.gca().yaxis.grid(True, linestyle =  -. )\nplt.gca().xaxis.grid(True, linestyle =  -. )\nplt.xlabel(u pct_change % , fontsize=16, fontproperties=font)\nplt.title(u 2009-2017\u6caa\u6df1300\u6da8\u8dcc\u5e45\u5206\u5e03 , fontsize=20, fontproperties=font)  matplotlib.text.Text at 0x7fe6dc1247d0    updown = stock_tar[ direction ].value_counts()\nupdown.rename({1:  up , 0:  down }, inplace=True) \nupdown  up      1153\ndown    1027\nName: direction, dtype: int64  plt.figure(figsize=(8,6))\ng=sns.barplot(x=updown.index, y=updown)\nplt.yticks(g.get_yticks(), fontproperties=font, fontsize=16)\nplt.ylabel( )\nplt.xlabel( )\nplt.title(u 2009-2017\u6caa\u6df1300\u4e0a\u6da8\u4e0e\u4e0b\u8dcc\u6b21\u6570 , fontsize=20, fontproperties=font)\nplt.gca().yaxis.grid(True, linestyle =  -- )\nplt.legend(loc=7,prop=font, fontsize=12)   fig, ax = plt.subplots(figsize=(10,8))\nstock_tar[ close ].plot(ax=ax)\nplt.ylabel('close', fontsize=16)\nplt.xlabel('')\nplt.gca().yaxis.grid(True, linestyle =  -. )\nplt.gca().xaxis.grid(True, linestyle =  -. )\nplt.xticks(plt.gca().get_xticks(), fontproperties=font, fontsize=16, rotation=-10)\nplt.title(u 2009-2017\u6caa\u6df1300\u6307\u6570(close) , fontsize=20, fontproperties=font)  matplotlib.text.Text at 0x7fe6d7e2ae10", 
            "title": "\u6570\u636e\u521d\u63a2\u7d22"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#_5", 
            "text": "stock_fea.describe()   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       Volume_mean5 \n       Lag5_mean5 \n       Lag10_mean5 \n       Lag20_mean5 \n       Lag30_mean5 \n       Lag60_mean5 \n       high_pctchange_mean5 \n       low_pctchange_mean5 \n       volume_pctchange_mean5 \n       close_roll_5_max_mean5 \n       ... \n       bbands_lower_mean5 \n       roc_mean5 \n       macd_dif_mean5 \n       macd_dea_mean5 \n       kdj_k_mean5 \n       kdj_d_mean5 \n       rsi_mean5 \n       obv_mean5 \n       rsv9_mean5 \n       pct_change \n     \n   \n   \n     \n       count \n       2.180000e+03 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       ... \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n       2180.000000 \n     \n     \n       mean \n       1.051363e+08 \n       0.047027 \n       0.045278 \n       0.040162 \n       0.039932 \n       0.025105 \n       0.046647 \n       0.051635 \n       2.817522 \n       3001.432072 \n       ... \n       2671.912434 \n       0.002508 \n       5.702102 \n       5.458203 \n       216.317641 \n       215.893160 \n       52.071582 \n       0.098248 \n       0.548319 \n       0.052583 \n     \n     \n       std \n       9.073317e+07 \n       0.739807 \n       0.740489 \n       0.749253 \n       0.759714 \n       0.773778 \n       0.700605 \n       0.745852 \n       8.150535 \n       625.057884 \n       ... \n       522.791151 \n       0.030531 \n       64.431823 \n       61.520109 \n       147.532372 \n       134.627519 \n       12.195386 \n       0.474311 \n       0.324709 \n       1.616292 \n     \n     \n       min \n       2.183633e+07 \n       -4.838902 \n       -4.838902 \n       -4.838902 \n       -4.838902 \n       -4.838902 \n       -4.809132 \n       -4.497514 \n       -18.049664 \n       1696.796000 \n       ... \n       1531.647649 \n       -0.177860 \n       -276.353443 \n       -228.492467 \n       35.838216 \n       44.991503 \n       20.020866 \n       -1.205182 \n       0.000000 \n       -8.747918 \n     \n     \n       25% \n       5.559608e+07 \n       -0.349020 \n       -0.354861 \n       -0.364369 \n       -0.365298 \n       -0.385432 \n       -0.322148 \n       -0.336338 \n       -2.603190 \n       2468.555500 \n       ... \n       2232.523107 \n       -0.013679 \n       -26.673772 \n       -24.789436 \n       107.145448 \n       116.632821 \n       42.578688 \n       -0.220874 \n       0.246982 \n       -0.642415 \n     \n     \n       50% \n       7.885951e+07 \n       0.058455 \n       0.057390 \n       0.057390 \n       0.057687 \n       0.047854 \n       0.042348 \n       0.077093 \n       1.765310 \n       3026.933000 \n       ... \n       2620.764469 \n       0.002935 \n       5.721931 \n       6.163226 \n       181.459137 \n       186.569701 \n       52.341211 \n       0.143482 \n       0.584226 \n       0.070339 \n     \n     \n       75% \n       1.128905e+08 \n       0.462984 \n       0.462984 \n       0.464625 \n       0.466388 \n       0.466889 \n       0.434130 \n       0.484127 \n       7.137630 \n       3403.722300 \n       ... \n       3083.151534 \n       0.019482 \n       34.422847 \n       31.596202 \n       282.154487 \n       276.511020 \n       60.152680 \n       0.407017 \n       0.859472 \n       0.789530 \n     \n     \n       max \n       5.827038e+08 \n       3.024969 \n       3.024969 \n       3.024969 \n       3.340340 \n       3.340340 \n       2.870094 \n       3.103424 \n       59.134120 \n       5353.750000 \n       ... \n       4308.229635 \n       0.114338 \n       230.638543 \n       219.278724 \n       1147.655035 \n       1084.400053 \n       90.298874 \n       1.416612 \n       1.000000 \n       7.380962 \n     \n     8 rows \u00d7 59 columns   def corr_plot(dataframe, plot_title=None, method='pearson', figsize=(20, 15)):\n    si_corr = dataframe.corr(method=method)    \n    siname = si_corr.columns.values\n    plt.figure(figsize=figsize)\n    g = sns.heatmap(si_corr, cbar=True, annot=True, \n                square=True, fmt= .2f , \n                annot_kws={'size': 12}, \n               yticklabels=siname,xticklabels=siname)\n    plt.yticks(g.get_yticks(), fontproperties=font, fontsize=20)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=20)\n    plt.xlabel( )\n    plt.ylabel( )\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=20, rotation=75)\n    plt.title(plot_title +  _  + method, fontproperties=font, fontsize=25)  corr_plot(stock_fea, plot_title=u \u6caa\u6df1300\u7279\u5f81\u95f4\u76f8\u5173\u5173\u7cfb )   corr_plot(stock_fea, plot_title=u \u6caa\u6df1300\u7279\u5f81\u95f4\u76f8\u5173\u5173\u7cfb , method= spearman )   from sklearn.preprocessing import StandardScaler \nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RandomizedLasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import RandomizedLogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn import svm  train_num = int(len(stock_fea) * 0.9)\nif  pct_change  in stock_fea.columns:\n    stock_fea.drop( pct_change , inplace=True, axis=1)\nX = stock_fea.copy()\ny_classification = stock_tar[ direction ]\ny_regression = stock_tar[ close ]\nsc = StandardScaler()\nsc.fit(X)  # \u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\nX_std = sc.transform(X)  # \u8fdb\u884c\u6807\u51c6\u53d8\u6362\uff0c\u53d8\u6210\u6807\u51c6\u6b63\u6001\u5206\u5e03  def feature_select(X, y, X_std):\n    feature_name = X.columns.values    \n    estimator = LogisticRegression()\n    selector = RFE(estimator, n_features_to_select=1, step=1)  \n    selector = selector.fit(X_std, y) \n    bag = sorted(zip(feature_name, selector.ranking_, selector.support_),\n                 key=lambda x: x[1])\n    fea_importance = pd.DataFrame(bag)\n    fea_importance.set_index(0,inplace=True)\n    fea_importance.drop(2, axis=1, inplace=True)\n    fea_importance.rename(index=str, columns={1:  RFE_Logistic }, inplace=True)\n\n    model_dict = dict(zip([ RandomLR ,  ExtraTree ], [RandomizedLogisticRegression(),\n                                                      ExtraTreesClassifier(n_estimators=1000, random_state=1)]))\n    for i in [ RandomLR ,  ExtraTree ]:\n        model = model_dict[i]\n        model.fit(X if i ==  ExtraTree  else X_std, y_classification)\n        df_fea = pd.DataFrame(sorted(zip(feature_name, \n                model.feature_importances_ if i ==  ExtraTree  else model.scores_),\n                 key=lambda x: x[1], reverse=True))\n        df_fea.set_index(0, inplace=True)\n        df_fea.rename(index=str, columns={1: i}, inplace=True)\n        fea_importance = fea_importance.join(df_fea)\n    return fea_importance  fea_importance = feature_select(X, y_classification , X_std) \nfea_importance   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       RFE_Logistic \n       RandomLR \n       ExtraTree \n     \n     \n       0 \n       \n       \n       \n     \n   \n   \n     \n       close_roll_5_min_mean5 \n       1 \n       0.000 \n       0.014992 \n     \n     \n       close_roll_20_min_mean5 \n       2 \n       0.000 \n       0.012900 \n     \n     \n       volume_roll_30_pp_mean5 \n       3 \n       0.465 \n       0.022894 \n     \n     \n       volume_roll_10_pp_mean5 \n       4 \n       0.005 \n       0.022125 \n     \n     \n       low_pctchange_mean5 \n       5 \n       0.000 \n       0.022189 \n     \n     \n       high_pctchange_mean5 \n       6 \n       0.000 \n       0.020495 \n     \n     \n       bbands_upper_mean5 \n       7 \n       0.000 \n       0.013378 \n     \n     \n       close_roll_30_max_mean5 \n       8 \n       0.000 \n       0.011722 \n     \n     \n       close_roll_60_min_mean5 \n       9 \n       0.000 \n       0.012344 \n     \n     \n       bbands_lower_mean5 \n       10 \n       0.000 \n       0.014522 \n     \n     \n       close_roll_30_min_mean5 \n       11 \n       0.000 \n       0.012110 \n     \n     \n       volume_roll_20_min_mean5 \n       12 \n       0.000 \n       0.013796 \n     \n     \n       volume_roll_10_min_mean5 \n       13 \n       0.000 \n       0.015238 \n     \n     \n       close_roll_10_max_mean5 \n       14 \n       0.000 \n       0.013887 \n     \n     \n       sma_30_mean5 \n       15 \n       0.000 \n       0.013732 \n     \n     \n       close_roll_10_min_mean5 \n       16 \n       0.000 \n       0.014065 \n     \n     \n       volume_roll_60_max_mean5 \n       17 \n       0.020 \n       0.011409 \n     \n     \n       volume_roll_20_max_mean5 \n       18 \n       0.000 \n       0.013721 \n     \n     \n       volume_roll_5_min_mean5 \n       19 \n       0.005 \n       0.016882 \n     \n     \n       kdj_k_mean5 \n       20 \n       0.055 \n       0.019311 \n     \n     \n       kdj_d_mean5 \n       21 \n       0.075 \n       0.018454 \n     \n     \n       rsv9_mean5 \n       22 \n       0.000 \n       0.019859 \n     \n     \n       rsi_mean5 \n       23 \n       0.030 \n       0.018308 \n     \n     \n       close_roll_20_max_mean5 \n       24 \n       0.000 \n       0.012585 \n     \n     \n       volume_roll_30_min_mean5 \n       25 \n       0.000 \n       0.012333 \n     \n     \n       sma_20_mean5 \n       26 \n       0.000 \n       0.014133 \n     \n     \n       volume_roll_30_max_mean5 \n       27 \n       0.000 \n       0.013155 \n     \n     \n       volume_roll_20_pp_mean5 \n       28 \n       0.105 \n       0.022286 \n     \n     \n       sma_60_mean5 \n       29 \n       0.000 \n       0.013465 \n     \n     \n       close_roll_20_pp_mean5 \n       30 \n       0.000 \n       0.020728 \n     \n     \n       close_roll_60_pp_mean5 \n       31 \n       0.000 \n       0.020377 \n     \n     \n       close_roll_5_max_mean5 \n       32 \n       0.000 \n       0.014565 \n     \n     \n       ewma_mean5 \n       33 \n       0.000 \n       0.013391 \n     \n     \n       Lag60_mean5 \n       34 \n       0.000 \n       0.022234 \n     \n     \n       roc_mean5 \n       35 \n       0.000 \n       0.020028 \n     \n     \n       sma_5_mean5 \n       36 \n       0.000 \n       0.014687 \n     \n     \n       cci_mean5 \n       37 \n       0.000 \n       0.018813 \n     \n     \n       obv_mean5 \n       38 \n       0.000 \n       0.023669 \n     \n     \n       volume_roll_60_min_mean5 \n       39 \n       0.000 \n       0.012152 \n     \n     \n       macd_dea_mean5 \n       40 \n       0.000 \n       0.016500 \n     \n     \n       Lag5_mean5 \n       41 \n       0.005 \n       0.021485 \n     \n     \n       macd_dif_mean5 \n       42 \n       0.020 \n       0.016610 \n     \n     \n       Lag10_mean5 \n       43 \n       0.000 \n       0.021961 \n     \n     \n       Volume_mean5 \n       44 \n       0.015 \n       0.017822 \n     \n     \n       volume_roll_60_pp_mean5 \n       45 \n       0.355 \n       0.022679 \n     \n     \n       close_roll_10_pp_mean5 \n       46 \n       0.000 \n       0.020859 \n     \n     \n       close_roll_60_max_mean5 \n       47 \n       0.000 \n       0.011358 \n     \n     \n       emv_mean5 \n       48 \n       0.000 \n       0.017818 \n     \n     \n       volume_roll_10_max_mean5 \n       49 \n       0.005 \n       0.015913 \n     \n     \n       Lag20_mean5 \n       50 \n       0.000 \n       0.022178 \n     \n     \n       close_roll_5_pp_mean5 \n       51 \n       0.000 \n       0.020580 \n     \n     \n       Lag30_mean5 \n       52 \n       0.000 \n       0.022674 \n     \n     \n       fi_mean5 \n       53 \n       0.000 \n       0.019666 \n     \n     \n       volume_roll_5_max_mean5 \n       54 \n       0.000 \n       0.017331 \n     \n     \n       volume_pctchange_mean5 \n       55 \n       0.015 \n       0.021926 \n     \n     \n       close_roll_30_pp_mean5 \n       56 \n       0.000 \n       0.020302 \n     \n     \n       volume_roll_5_pp_mean5 \n       57 \n       0.000 \n       0.020994 \n     \n     \n       sma_10_mean5 \n       58 \n       0.000 \n       0.014408 \n     \n      \u57fa\u4e8eRFE\u548cRandomLogistic\u8fdb\u884c\u7279\u5f81\u9009\u62e9  frlr = set(fea_importance.loc[fea_importance[ RandomLR ] != 0, :].index.tolist())\nfrfe = set(fea_importance.loc[fea_importance[ RFE_Logistic ]  =23, :].index.tolist())\n# \u6b64\u5904\u768423\u662f\u6d4b\u8bd5\u4e0d\u540c\u6570\u503c\u7684\u7279\u5f81\u4f7f\u7528logisticRegression\u8fdb\u884c\u5206\u7c7b\uff0c\u770b\u8bad\u7ec3\u548c\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u5f97\u5230\u7684\n# \u5bf9\u4e8e\u4f7f\u7528RandomLR\u9009\u62e9\u7684\u7279\u5f81\u4e5f\u7c7b\u4f3c\uff0c\u4e0d\u8fc7\u7531\u4e8e\u5176\u57280\u5904\u6709\u5212\u5206\uff0c\u6545\u9009\u62e9 0\u7684\n# \u89c2\u5bdf\u4e24\u79cd\u9009\u62e9\u540e\u7684\u7279\u5f81\u7684logistic\u5206\u7c7b\u6df7\u6dc6\u77e9\u9635\uff0c\u53d1\u73b0\u4fe9\u8005\u6709\u4e92\u8865\u7684\u8d8b\u52bf\nchoosen_features = list(frlr | frfe)\nchoosen_features\n# len(choosen_feature)  # 31  ['low_pctchange_mean5',\n 'volume_roll_5_min_mean5',\n 'close_roll_5_min_mean5',\n 'high_pctchange_mean5',\n 'volume_roll_20_min_mean5',\n 'close_roll_30_max_mean5',\n 'close_roll_30_min_mean5',\n 'kdj_d_mean5',\n 'volume_roll_60_pp_mean5',\n 'sma_30_mean5',\n 'volume_pctchange_mean5',\n 'Lag5_mean5',\n 'volume_roll_10_min_mean5',\n 'rsv9_mean5',\n 'volume_roll_10_pp_mean5',\n 'close_roll_20_min_mean5',\n 'close_roll_60_min_mean5',\n 'kdj_k_mean5',\n 'volume_roll_20_pp_mean5',\n 'Volume_mean5',\n 'volume_roll_10_max_mean5',\n 'volume_roll_60_max_mean5',\n 'volume_roll_20_max_mean5',\n 'rsi_mean5',\n 'close_roll_10_min_mean5',\n 'volume_roll_30_pp_mean5',\n 'macd_dif_mean5',\n 'bbands_upper_mean5',\n 'close_roll_10_max_mean5',\n 'bbands_lower_mean5']", 
            "title": "\u7279\u5f81\u7b5b\u9009"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#_6", 
            "text": "\u7528\u9009\u51fa\u768431\u4e2a\u7279\u5f81\u6784\u9020\u7684\u6570\u636e\u96c6\u8fdb\u884c\u6a21\u578b\u8bad\u7ec3  if  pct_change  in stock_fea.columns:\n    stock_fea.drop( pct_change , inplace=True, axis=1)\nX_temp = stock_fea[choosen_features]\nX_train = X_temp[:train_num]\nX_test = X_temp[train_num:]\ny_train = stock_tar[ direction ][:train_num]\ny_test = stock_tar[ direction ][train_num:]\nsc = StandardScaler()\nsc.fit(X_train)  \nX_train_std = sc.transform(X_train) \nX_test_std = sc.transform(X_test)\nX_train.shape  (1962, 30)  def confusion_mplot(y_test, y_pred):\n    tick_labels = [u \u6da8 ,u \u8dcc ]\n    confm = confusion_matrix(y_test, y_pred, labels=[1,0])\n    plt.figure(figsize=(4,3))\n    g = sns.heatmap(confm, cbar=True, annot=True, \n                square=True, fmt= .2f , \n                annot_kws={'size': 12}, \n               yticklabels=tick_labels,xticklabels=tick_labels)\n    plt.yticks(g.get_yticks(), fontproperties=font, fontsize=15)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=15)\n    plt.ylabel(u'\u5b9e\u9645', fontproperties=font, fontsize=20)\n    plt.xlabel(u'\u9884\u6d4b', fontproperties=font, fontsize=20)  parameters = {'C':[150, 50, 10, 2, 1.5, 1, 0.8, 0.5, 0.3, 0.1, 0.01, 0.001, 0.0001]}\nlr = LogisticRegression(penalty= l2 , random_state=1, tol=1e-6)\ngscv = GridSearchCV(lr, parameters)\ngscv.fit(X_train_std, y_train)\ngs = gscv.grid_scores_\nbp = gscv.best_params_\nbs = gscv.best_score_ \ngs  [mean: 0.53109, std: 0.01380, params: {'C': 150},\n mean: 0.53007, std: 0.01243, params: {'C': 50},\n mean: 0.52803, std: 0.01158, params: {'C': 10},\n mean: 0.52905, std: 0.00909, params: {'C': 2},\n mean: 0.53058, std: 0.00921, params: {'C': 1.5},\n mean: 0.53007, std: 0.01112, params: {'C': 1},\n mean: 0.53058, std: 0.01003, params: {'C': 0.8},\n mean: 0.53160, std: 0.00537, params: {'C': 0.5},\n mean: 0.53007, std: 0.00716, params: {'C': 0.3},\n mean: 0.53262, std: 0.00529, params: {'C': 0.1},\n mean: 0.53211, std: 0.00920, params: {'C': 0.01},\n mean: 0.49949, std: 0.02314, params: {'C': 0.001},\n mean: 0.48777, std: 0.02197, params: {'C': 0.0001}]", 
            "title": "\u6a21\u578b\u6784\u5efa"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#logisticregression", 
            "text": "lrf = LogisticRegression(C = 0.01, penalty= l2 , random_state=1, tol=1e-6)\nlrf.fit(X_train_std, y_train)\ny_pred = lrf.predict(X_test_std)\nconfusion_mplot(y_test, y_pred)\nclassification_report(y_test, y_pred)  u'             precision    recall  f1-score   support\\n\\n          0       0.47      0.63      0.54       101\\n          1       0.54      0.38      0.44       117\\n\\navg / total       0.51      0.50      0.49       218\\n'   accuracy_score(y_test, y_pred)\n# accuracy_score(y_train, lrf.predict(X_train_std))  # 0.5558  0.49541284403669728", 
            "title": "LogisticRegression\u5206\u7c7b\u6a21\u578b"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#randomforest", 
            "text": "rf = RandomForestClassifier(n_estimators=1000, random_state=24)\nrf.fit(X_train, y_train)\nrf_prediction_train = rf.predict(X_train)\nrf_prediction_test = rf.predict(X_test)\nrf_evaluate_result = classification_report(y_test, rf_prediction_test)\nconfusion_mplot(y_test, rf_prediction_test)\nrf_evaluate_result    u'             precision    recall  f1-score   support\\n\\n          0       0.46      0.31      0.37       101\\n          1       0.54      0.69      0.60       117\\n\\navg / total       0.50      0.51      0.50       218\\n'   accuracy_score(y_test,rf_prediction_test)\n# accuracy_score(y_train, rf.predict(X_train_std))  # 0.5224  0.51376146788990829", 
            "title": "RandomForest\u5206\u7c7b\u6a21\u578b"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#_7", 
            "text": "# \u51b3\u7b56\u6869\u5206\u7c7b\u5668\u6027\u80fd\ntree = DecisionTreeClassifier(max_depth=8)\ntree.fit(X_train, y_train)\ntree_pred_test = tree.predict(X_test)\ntree_pred_train = tree.predict(X_train)\ntree_evaluate_result = classification_report(y_test, tree_pred_test)\nconfusion_mplot(y_test, tree_pred_test)\ntree_evaluate_result  u'             precision    recall  f1-score   support\\n\\n          0       0.53      0.69      0.60       101\\n          1       0.64      0.46      0.53       117\\n\\navg / total       0.58      0.57      0.56       218\\n'   accuracy_score(y_test,tree_pred_test)\n# accuracy_score(y_train,tree_pred_train)  # 0.6671  0.56880733944954132", 
            "title": "\u51b3\u7b56\u6811\u5206\u7c7b\u6a21\u578b"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#adaboost", 
            "text": "# Boosting\u5206\u7c7b\u5668\u6027\u80fd\nada = AdaBoostClassifier(base_estimator=tree,n_estimators=1000,learning_rate=0.1, random_state=24)\nada = ada.fit(X_train, y_train)\nada_test_pred = ada.predict(X_test)\nada_evaluate_result = classification_report(y_test, ada_test_pred)\nconfusion_mplot(y_test, ada_test_pred)\nada_evaluate_result  u'             precision    recall  f1-score   support\\n\\n          0       0.46      0.28      0.35       101\\n          1       0.54      0.72      0.61       117\\n\\navg / total       0.50      0.51      0.49       218\\n'   accuracy_score(y_test,ada_test_pred)\n# accuracy_score(y_train, ada.predict(X_train_std))  # 0.5127  0.51376146788990829", 
            "title": "AdaBoost"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#-", 
            "text": "eclf = VotingClassifier(estimators=[( lr , lrf), ('ada', ada), ('rf', rf), ( tree ,tree)], voting='soft',weights=[2,1,1,1])\neclf.fit(X_train, y_train)\neclf_pred_test = eclf.predict(X_test)\neclf_pred_train = eclf.predict(X_train)\neclf_train_accu = accuracy_score(y_train, eclf_pred_train)\neclf_test_accu = accuracy_score(y_test, eclf_pred_test)\neclf_train_f1 = f1_score(y_train, eclf_pred_train)\neclf_test_f1 = f1_score(y_test, eclf_pred_test)\nbase_result_eclf =  train_accuracy:{1},test_accuracy:{2},train_f1:{0},test_f1:{3} .format(eclf_train_accu,eclf_test_accu,eclf_train_f1,eclf_test_f1)\neclf_evaluate_result = classification_report(y_test, eclf_pred_test)\nconfusion_mplot(y_test, eclf_pred_test)\neclf_evaluate_result  u'             precision    recall  f1-score   support\\n\\n          0       0.56      0.34      0.42       101\\n          1       0.57      0.77      0.66       117\\n\\navg / total       0.57      0.57      0.55       218\\n'   accuracy_score(y_test, eclf_pred_test)\n# accuracy_score(y_train, eclf.predict(X_train_std))  # 0.5224  0.56880733944954132  eclf  VotingClassifier(estimators=[('lr', LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l2', random_state=1, solver='liblinear', tol=1e-06,\n          verbose=0, warm_start=False)), ('ada', AdaBoostC...      min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n            splitter='best'))],\n         flatten_transform=None, n_jobs=1, voting='soft',\n         weights=[2, 1, 1, 1])  \u7531LogisticRegression\u5206\u7c7b\u5668\u3001\u968f\u673a\u68ee\u6797\u3001Adaboost_tree\u3001\u51b3\u7b56\u6811\u6784\u5efa\u7684\u6700\u7ec8\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u4e3a56.8%\uff0c\u9ad8\u4e8e\u4efb\u4f55\u5355\u4e00\u5206\u7c7b\u6a21\u578b\u3002\n\u6700\u540e\uff0c\u7528eclf.predict()\u5c31\u53ef\u4ee5\u5bf9\u65b0\u6570\u636e\u8fdb\u884c\u9884\u6d4b\u4e86\u3002", 
            "title": "\u6a21\u578b\u878d\u5408-\u6295\u7968"
        }, 
        {
            "location": "/machine_learning/stock_index_classification/stock_index_classification/#_8", 
            "text": "\u672c\u6587\u75282009-2017\u5e74\u7684\u6caa\u6df1300\u6307\u6570\u6784\u5efa\u5206\u7c7b\u6a21\u578b\u4ee5\u9884\u6d4b\u6caa\u6df1300\u80a1\u6307\u660e\u65e5\u662f\u6da8\u8fd8\u662f\u8dcc\uff0c\u6700\u7ec8\uff0c\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u4e3a56.8%\u3002  \u7531\u4e8e\u8bad\u7ec3\u6a21\u578b\u53ea\u4f7f\u7528\u4e86\u6caa\u6df1300\u80a1\u6307\u6536\u5e02\u6307\u6570\u3001\u6210\u4ea4\u91cf\u3001\u4e00\u65e5\u7684\u6700\u9ad8\u548c\u6700\u4f4e\u503c\u4ee5\u53ca\u57fa\u4e8e\u8fd9\u4e9b\u8ba1\u7b97\u7684\u4e00\u4e9b\u5e38\u7528\u7684\u6280\u672f\u6307\u6807\uff0c\u5373\u6570\u636e\u6bd4\u8f83\u5355\u4e00\uff0c\u6ca1\u6709\u8003\u8651\u76d8\u5916\u7684\u5176\u4ed6\u4fe1\u606f\uff0c\u6bd4\u5982\u671f\u8d27\u4fe1\u606f\u3001\u5916\u5e02\u4fe1\u606f\u3001\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\u7b49\u7b49\uff0c\u540c\u65f6\uff0c\u4f7f\u7528\u7684\u6280\u672f\u6307\u6807\u4e5f\u4e0d\u5168\u9762\uff0c\u800c\u4e14\u4ec5\u4ec5\u4f7f\u7528\u4e865\u65e5\u4fe1\u606f\uff0c\u5e76\u6ca1\u6709\u8003\u8651\u66f4\u957f\u6216\u66f4\u77ed\u65f6\u95f4\u5c3a\u5ea6\u7684\u80a1\u6307\u4fe1\u606f\uff0c\u56e0\u6b64\uff0c\u6700\u7ec8\u7684\u5206\u7c7b\u6548\u679c\u4e0d\u548b\u5730\u4e5f\u662f\u9884\u6599\u4e4b\u4e2d\u7684\u4e8b\u3002", 
            "title": "\u603b\u7ed3"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/", 
            "text": "\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6caa\u6df1300\u80a1\u7968\u6da8\u8dcc\n\n\n\u8fd1\u51e0\u5e74\u4eba\u5de5\u667a\u80fd\u5927\u70ed\uff0c\u5176\u4f7f\u7528\u7684\u7b97\u6cd5\u5305\u62ec\u673a\u5668\u5b66\u4e60\u5c24\u5176\u662f\u6df1\u5ea6\u5b66\u4e60\uff0c\u8fd9\u4fe9\u8005\u662f\u76ee\u524d\u6700\u706b\u70ed\u7684\u804c\u4e1a\u4e4b\u4e00\u3002\u5728\u4eba\u4eec\u751f\u6d3b\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u4e5f\u5728\u9010\u6e10\u8d70\u5982\u4eba\u4eec\u7684\u751f\u6d3b\uff0c\u6bd4\u5982Alphago\u3001\u4eba\u8138\u8bc6\u522b\u3001\u65e0\u4eba\u9a7e\u9a76\u90fd\u7528\u5230\u4e86\u673a\u5668\u5b66\u4e60\u6216\u6df1\u5ea6\u5b66\u4e60\u7684\u4e00\u4e9b\u7b97\u6cd5\uff0c\u8ba9\u4eba\u5207\u5b9e\u611f\u53d7\u5230\u79d1\u6280\u7684\u529b\u91cf\u6b63\u663e\u8457\u5730\u6539\u53d8\u7740\u4eba\u7c7b\u4e16\u754c\u3002\u800c\u8fd0\u7528\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u91cf\u5316\u4ea4\u6613\uff0c\u4e5f\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u5927\u5e94\u7528\u9886\u57df\u3002\u672c\u6587\u91c7\u7528python\u7b2c\u4e09\u65b9\u5e93sklearn\u63d0\u4f9b\u7684\u51e0\u79cd\u5206\u7c7b\u7b97\u6cd5\u5bf9\u6caa\u6df1300\u7684\u90e8\u5206\u80a1\u7968\u8fdb\u884c\u8bad\u7ec3\u548c\u5b66\u4e60\uff0c\u4ee5\u671f\u80fd\u591f\u9884\u6d4b\u80a1\u7968\u7684\u6da8\u8dcc\u60c5\u51b5\u3002\n\n\n\u6570\u636e\u91c7\u96c6\n\n\n\u4f7f\u7528tushare\u63d0\u4f9b\u7684API\u91c7\u96c62012-2017\u5e74\u6caa\u6df1300\u7684\u80a1\u7968\u4ea4\u6613\u6570\u636e\uff0c\u6caa\u5e02\u3001\u6df1\u5e02\u3001\u521b\u4e1a\u677f\u7b49\u80a1\u6307\u6570\u636e\uff0c\u80a1\u7968\u7684\u57fa\u672c\u9762\u6570\u636e\u4ee5\u53ca\u5176\u4ed6\u7684\u7ecf\u6d4e\u6307\u6807\u6570\u636e\uff0c\u7531\u4e8e\u6570\u636e\u91cf\u4e0d\u5927\uff0c\u76f4\u63a5\u4fdd\u5b58\u4e3aCSV\u683c\u5f0f\u7684\u6587\u4ef6\u3002\n\n\n\u6570\u636e\u5206\u6790\n\n\n\u6570\u636e\u5904\u7406\u53ca\u6e05\u6d17\n\n\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(style=\nwhitegrid\n, palette=\nmuted\n, font_scale=1, color_codes=True, context=\ntalk\n)\n%matplotlib inline\nfrom matplotlib.font_manager import FontProperties  \nfont = FontProperties(fname=r\n/usr/share/fonts/truetype/arphic/ukai.ttc\n)\n# font = FontProperties(fname=r\nC:\\Windows\\Fonts\\msyh.ttc\n)\nimport datetime\nimport re\nfrom techFeature import StockFeature\nimport os\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RandomizedLasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import RandomizedLogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn import svm\n\n\n\n\n\u6caa\u6df1300\u80a1\u7968\u4e2d\u6709\u8fd150\u652f\u80a1\u7968\u7f3a\u5931\u6570\u636e\u8f83\u591a(\u8d85\u8fc720%\uff09\uff0c\u6545\u4f7f\u7528\u5904\u7406\u540e\u7684251\u652f\u80a1\u7968\u8fdb\u884c\u521d\u6b65\u7edf\u8ba1\u5206\u6790\n\n\n# \u8bfb\u53d6\u5df2\u7ecf\u5220\u9664\u8fc7\u90e8\u5206\u80a1\u7968\u7684\u6570\u636e\nst = pd.read_csv(\n./datas/hs300_dropleft_251.csv\n, encoding=\nutf-8\n, dtype={\ncode\n: str})\nst[\ndate\n] = pd.to_datetime(st[\ndate\n])\n#\u7531\u4e8e600688\u548c600871\u7684pct_change\u6709\u5f02\u5e38\uff0c\u6545\u4e0d\u4f7f\u7528\u8be5\u4e24\u652f\u80a1\u7968\u7684\u4fe1\u606f\nst = st[st[\ncode\n] != \n600688\n]\nst = st[st[\ncode\n] != \n600871\n]\nst.head(2)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \ndate\n\n      \ncode\n\n      \nclose\n\n      \nhigh\n\n      \nlow\n\n      \nopen\n\n      \nvolume\n\n    \n\n  \n\n  \n\n    \n\n      \n0\n\n      \n2012-01-04\n\n      \n000001\n\n      \n5.120\n\n      \n5.265\n\n      \n5.116\n\n      \n5.265\n\n      \n147910.0\n\n    \n\n    \n\n      \n1\n\n      \n2012-01-04\n\n      \n000002\n\n      \n6.052\n\n      \n6.316\n\n      \n6.044\n\n      \n6.168\n\n      \n474329.0\n\n    \n\n  \n\n\n\n\n\n\n\nst.shape\n\n\n\n\n(335285, 7)\n\n\n\nst_pv = st.pivot_table(index=\ndate\n, columns=\ncode\n)\nst_pv.head(3)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nclose\n\n      \n...\n\n      \nvolume\n\n    \n\n    \n\n      \ncode\n\n      \n000001\n\n      \n000002\n\n      \n000008\n\n      \n000009\n\n      \n000060\n\n      \n000063\n\n      \n000069\n\n      \n000100\n\n      \n000156\n\n      \n000157\n\n      \n...\n\n      \n601901\n\n      \n601919\n\n      \n601933\n\n      \n601939\n\n      \n601958\n\n      \n601988\n\n      \n601989\n\n      \n601992\n\n      \n601998\n\n      \n603993\n\n    \n\n    \n\n      \ndate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2012-01-04\n\n      \n5.120\n\n      \n6.052\n\n      \n0.760\n\n      \n5.344\n\n      \n7.802\n\n      \n13.371\n\n      \n5.013\n\n      \n1.607\n\n      \nNaN\n\n      \n6.362\n\n      \n...\n\n      \n606942.0\n\n      \n258238.0\n\n      \n11334.0\n\n      \n414369.0\n\n      \n52481.0\n\n      \n183288.0\n\n      \n222003.0\n\n      \n63765.0\n\n      \n160450.0\n\n      \nNaN\n\n    \n\n    \n\n      \n2012-01-05\n\n      \n5.197\n\n      \n5.986\n\n      \n0.729\n\n      \n5.048\n\n      \n7.675\n\n      \n13.292\n\n      \n4.782\n\n      \n1.652\n\n      \nNaN\n\n      \n6.151\n\n      \n...\n\n      \n533317.0\n\n      \n320893.0\n\n      \n15274.0\n\n      \n804582.0\n\n      \n48201.0\n\n      \n389570.0\n\n      \n276832.0\n\n      \n58840.0\n\n      \n863501.0\n\n      \nNaN\n\n    \n\n    \n\n      \n2012-01-06\n\n      \n5.184\n\n      \n5.912\n\n      \n0.734\n\n      \n5.350\n\n      \n7.763\n\n      \n12.950\n\n      \n4.790\n\n      \n1.661\n\n      \nNaN\n\n      \n6.143\n\n      \n...\n\n      \n867634.0\n\n      \n304644.0\n\n      \n14070.0\n\n      \n662240.0\n\n      \n43909.0\n\n      \nNaN\n\n      \n215748.0\n\n      \n62473.0\n\n      \n383847.0\n\n      \nNaN\n\n    \n\n  \n\n\n\n\n3 rows \u00d7 1245 columns\n\n\n\n\n\nst_pv_ = st_pv.copy()\nst_pv_.columns = st_pv.columns.reorder_levels([1,0])\nst_pv_.head(3)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \ncode\n\n      \n000001\n\n      \n000002\n\n      \n000008\n\n      \n000009\n\n      \n000060\n\n      \n000063\n\n      \n000069\n\n      \n000100\n\n      \n000156\n\n      \n000157\n\n      \n...\n\n      \n601901\n\n      \n601919\n\n      \n601933\n\n      \n601939\n\n      \n601958\n\n      \n601988\n\n      \n601989\n\n      \n601992\n\n      \n601998\n\n      \n603993\n\n    \n\n    \n\n      \n\n      \nclose\n\n      \nclose\n\n      \nclose\n\n      \nclose\n\n      \nclose\n\n      \nclose\n\n      \nclose\n\n      \nclose\n\n      \nclose\n\n      \nclose\n\n      \n...\n\n      \nvolume\n\n      \nvolume\n\n      \nvolume\n\n      \nvolume\n\n      \nvolume\n\n      \nvolume\n\n      \nvolume\n\n      \nvolume\n\n      \nvolume\n\n      \nvolume\n\n    \n\n    \n\n      \ndate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2012-01-04\n\n      \n5.120\n\n      \n6.052\n\n      \n0.760\n\n      \n5.344\n\n      \n7.802\n\n      \n13.371\n\n      \n5.013\n\n      \n1.607\n\n      \nNaN\n\n      \n6.362\n\n      \n...\n\n      \n606942.0\n\n      \n258238.0\n\n      \n11334.0\n\n      \n414369.0\n\n      \n52481.0\n\n      \n183288.0\n\n      \n222003.0\n\n      \n63765.0\n\n      \n160450.0\n\n      \nNaN\n\n    \n\n    \n\n      \n2012-01-05\n\n      \n5.197\n\n      \n5.986\n\n      \n0.729\n\n      \n5.048\n\n      \n7.675\n\n      \n13.292\n\n      \n4.782\n\n      \n1.652\n\n      \nNaN\n\n      \n6.151\n\n      \n...\n\n      \n533317.0\n\n      \n320893.0\n\n      \n15274.0\n\n      \n804582.0\n\n      \n48201.0\n\n      \n389570.0\n\n      \n276832.0\n\n      \n58840.0\n\n      \n863501.0\n\n      \nNaN\n\n    \n\n    \n\n      \n2012-01-06\n\n      \n5.184\n\n      \n5.912\n\n      \n0.734\n\n      \n5.350\n\n      \n7.763\n\n      \n12.950\n\n      \n4.790\n\n      \n1.661\n\n      \nNaN\n\n      \n6.143\n\n      \n...\n\n      \n867634.0\n\n      \n304644.0\n\n      \n14070.0\n\n      \n662240.0\n\n      \n43909.0\n\n      \nNaN\n\n      \n215748.0\n\n      \n62473.0\n\n      \n383847.0\n\n      \nNaN\n\n    \n\n  \n\n\n\n\n3 rows \u00d7 1245 columns\n\n\n\n\n\n\u901a\u8fc7\u8ba1\u7b97pct_change\u68c0\u67e5\u6570\u636e\u6709\u65e0\u5f02\u5e38\u60c5\u51b5\n\n\npctchanges = st_pv[\nclose\n].pct_change() * 100.0\npctchanges.dropna(how=\nall\n, inplace=True)\npp = pctchanges.apply(lambda x: np.abs(x) \n 11.0)\nppsum = pp.sum().sort_values(ascending=False)\nproblem_stock_index = ppsum[ppsum \n 0].index.tolist()  # [u'600153', u'600871', u'600688']\nproblem_stock = st_pv_[problem_stock_index]\nproblem_stock.head(3)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \ncode\n\n      \n600153\n\n    \n\n    \n\n      \n\n      \nclose\n\n      \nhigh\n\n      \nlow\n\n      \nopen\n\n      \nvolume\n\n    \n\n    \n\n      \ndate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2012-01-04\n\n      \n5.177\n\n      \n5.396\n\n      \n5.161\n\n      \n5.380\n\n      \n82566.0\n\n    \n\n    \n\n      \n2012-01-05\n\n      \n5.161\n\n      \n5.203\n\n      \n5.144\n\n      \n5.161\n\n      \n86409.0\n\n    \n\n    \n\n      \n2012-01-06\n\n      \n5.152\n\n      \n5.186\n\n      \n5.085\n\n      \n5.177\n\n      \n69581.0\n\n    \n\n  \n\n\n\n\n\n\n\nproblem_stock.tail(3)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \ncode\n\n      \n600153\n\n    \n\n    \n\n      \n\n      \nclose\n\n      \nhigh\n\n      \nlow\n\n      \nopen\n\n      \nvolume\n\n    \n\n    \n\n      \ndate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2017-10-19\n\n      \n11.89\n\n      \n11.92\n\n      \n11.73\n\n      \n11.80\n\n      \n170555.0\n\n    \n\n    \n\n      \n2017-10-20\n\n      \n12.00\n\n      \n12.08\n\n      \n11.92\n\n      \n11.95\n\n      \n201325.0\n\n    \n\n    \n\n      \n2017-10-23\n\n      \n12.00\n\n      \n12.09\n\n      \n11.89\n\n      \n12.04\n\n      \n140262.0\n\n    \n\n  \n\n\n\n\n\n\n\npctchanges[problem_stock_index].plot(figsize=(8,6), legend=True)\n\n\n\n\nmatplotlib.axes._subplots.AxesSubplot at 0x7ff7d4cf5750\n\n\n\n\n\n\n# \u5404\u7edf\u8ba1\u91cf\u7684\u5747\u503c\u3001\u4e2d\u4f4d\u6570\u3001\u767e\u5206\u4f4d\u6570\u3001\u6700\u5927\u548c\u6700\u5c0f\u503c\u4e00\u89c8\nhs_all_info = st_pv.describe()\nhs_all_info\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nclose\n\n      \n...\n\n      \nvolume\n\n    \n\n    \n\n      \ncode\n\n      \n000001\n\n      \n000002\n\n      \n000008\n\n      \n000009\n\n      \n000060\n\n      \n000063\n\n      \n000069\n\n      \n000100\n\n      \n000156\n\n      \n000157\n\n      \n...\n\n      \n601901\n\n      \n601919\n\n      \n601933\n\n      \n601939\n\n      \n601958\n\n      \n601988\n\n      \n601989\n\n      \n601992\n\n      \n601998\n\n      \n603993\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n1397.000000\n\n      \n1258.000000\n\n      \n1195.000000\n\n      \n1311.000000\n\n      \n1396.000000\n\n      \n1367.000000\n\n      \n1364.000000\n\n      \n1214.000000\n\n      \n1173.000000\n\n      \n1401.000000\n\n      \n...\n\n      \n1.291000e+03\n\n      \n1.261000e+03\n\n      \n1.394000e+03\n\n      \n1.407000e+03\n\n      \n1.408000e+03\n\n      \n1.407000e+03\n\n      \n1.206000e+03\n\n      \n1.381000e+03\n\n      \n1.405000e+03\n\n      \n1.204000e+03\n\n    \n\n    \n\n      \nmean\n\n      \n7.895441\n\n      \n12.305227\n\n      \n5.456906\n\n      \n8.294201\n\n      \n9.930986\n\n      \n14.259742\n\n      \n6.607823\n\n      \n3.015196\n\n      \n23.784151\n\n      \n5.537340\n\n      \n...\n\n      \n1.095797e+06\n\n      \n5.011430e+05\n\n      \n3.265446e+05\n\n      \n9.733053e+05\n\n      \n1.990064e+05\n\n      \n2.778726e+06\n\n      \n2.198017e+06\n\n      \n4.599039e+05\n\n      \n6.741906e+05\n\n      \n6.512692e+05\n\n    \n\n    \n\n      \nstd\n\n      \n2.113651\n\n      \n6.182167\n\n      \n3.846793\n\n      \n2.731044\n\n      \n3.188618\n\n      \n4.655476\n\n      \n1.644207\n\n      \n1.156071\n\n      \n9.296279\n\n      \n1.504979\n\n      \n...\n\n      \n9.993168e+05\n\n      \n7.407939e+05\n\n      \n3.802748e+05\n\n      \n1.459887e+06\n\n      \n2.193792e+05\n\n      \n5.595141e+06\n\n      \n2.890371e+06\n\n      \n9.062799e+05\n\n      \n8.444628e+05\n\n      \n9.123304e+05\n\n    \n\n    \n\n      \nmin\n\n      \n4.269000\n\n      \n5.592000\n\n      \n0.729000\n\n      \n3.958000\n\n      \n5.344000\n\n      \n6.190000\n\n      \n4.144000\n\n      \n1.607000\n\n      \n7.685000\n\n      \n3.751000\n\n      \n...\n\n      \n7.093400e+04\n\n      \n2.760100e+04\n\n      \n3.177000e+03\n\n      \n8.230200e+04\n\n      \n1.672500e+04\n\n      \n5.679500e+04\n\n      \n2.705100e+04\n\n      \n2.710800e+04\n\n      \n4.250900e+04\n\n      \n1.422600e+04\n\n    \n\n    \n\n      \n25%\n\n      \n6.190000\n\n      \n7.439000\n\n      \n1.720500\n\n      \n6.004000\n\n      \n7.720000\n\n      \n10.852500\n\n      \n5.373000\n\n      \n2.112000\n\n      \n17.268000\n\n      \n4.397000\n\n      \n...\n\n      \n4.283485e+05\n\n      \n1.087420e+05\n\n      \n5.740900e+04\n\n      \n2.672415e+05\n\n      \n6.349275e+04\n\n      \n2.768075e+05\n\n      \n4.695140e+05\n\n      \n1.243880e+05\n\n      \n2.062040e+05\n\n      \n1.110132e+05\n\n    \n\n    \n\n      \n50%\n\n      \n8.016000\n\n      \n9.398000\n\n      \n5.283000\n\n      \n8.351000\n\n      \n9.682500\n\n      \n13.660000\n\n      \n6.317000\n\n      \n2.589000\n\n      \n20.969000\n\n      \n4.780000\n\n      \n...\n\n      \n7.909860e+05\n\n      \n2.291660e+05\n\n      \n2.132770e+05\n\n      \n5.010900e+05\n\n      \n1.210935e+05\n\n      \n7.675750e+05\n\n      \n1.006596e+06\n\n      \n2.145180e+05\n\n      \n3.466360e+05\n\n      \n2.936680e+05\n\n    \n\n    \n\n      \n75%\n\n      \n9.224000\n\n      \n16.605750\n\n      \n9.001000\n\n      \n10.037500\n\n      \n11.390250\n\n      \n16.361000\n\n      \n7.371000\n\n      \n3.624000\n\n      \n28.892000\n\n      \n6.896000\n\n      \n...\n\n      \n1.394280e+06\n\n      \n5.246280e+05\n\n      \n4.610060e+05\n\n      \n9.291410e+05\n\n      \n2.398298e+05\n\n      \n1.930524e+06\n\n      \n2.492684e+06\n\n      \n4.556470e+05\n\n      \n7.663030e+05\n\n      \n7.521080e+05\n\n    \n\n    \n\n      \nmax\n\n      \n13.986000\n\n      \n29.300000\n\n      \n13.721000\n\n      \n17.548000\n\n      \n28.849000\n\n      \n30.630000\n\n      \n13.448000\n\n      \n7.147000\n\n      \n59.297000\n\n      \n9.635000\n\n      \n...\n\n      \n7.081835e+06\n\n      \n6.846566e+06\n\n      \n3.915401e+06\n\n      \n1.805440e+07\n\n      \n2.213357e+06\n\n      \n5.109897e+07\n\n      \n2.107839e+07\n\n      \n1.693063e+07\n\n      \n7.545412e+06\n\n      \n6.340851e+06\n\n    \n\n  \n\n\n\n\n8 rows \u00d7 1245 columns\n\n\n\n\n\nstock_null = (hs_all_info.loc[\ncount\n, \nclose\n] / st_pv.shape[0]) * 100\nstock_null = stock_null.map(lambda x: np.int(x))\nstock_null = stock_null.value_counts().sort_index()\nplt.figure(figsize=(8,6))\nstock_null.plot(kind=\nbar\n, grid=False)\nplt.ylabel(u\n\u6837\u672c\u6570\u91cf\n, fontsize=16, fontproperties=font)\nplt.xlabel(u\n\u975e\u7f3a\u5931\u6570\u636e\u767e\u5206\u6bd4 %\n, fontsize=16, fontproperties=font)\nplt.title(u\n\u6570\u636e\u96c6\u6570\u636e\u975e\u7f3a\u5931\u60c5\u51b5\n, fontproperties=font, fontsize=20)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n,)\nplt.gca().xaxis.grid(False)\n\n\n\n\n\n\n\u7531\u4e8e\u91c7\u96c6\u6570\u636e\u662f12-17\u5e74\u7684\uff0c\u65f6\u95f4\u8de8\u5ea6\u6709\u4e9b\u5927\uff0c\u6545\u57fa\u672c\u6240\u6709\u7684\u80a1\u7968\u90fd\u6709\u7f3a\u5931\u7684\u6570\u636e\uff0c\u8fd9\u662f\u56e0\u4e3a\u80a1\u5e02\u7ecf\u5e38\u51fa\u73b0\u7531\u4e8e\u5404\u79cd\u539f\u56e0\u505c\u6b62\u4ea4\u6613\u7684\u80a1\u7968\uff0c\u5728\u6b64\u9009\u62e9\u7f3a\u5931\u6570\u636e\u572820%\u4ee5\u5185\u7684\u80a1\u7968\u4e3a\u521d\u6b65\u7814\u7a76\u5bf9\u8c61\u3002\n\n\n\u6caa\u6df1300\u5404\u80a1\u7968\u7684\u4ef7\u683c\u533a\u95f4\u5206\u5e03\n\n\ngroup_name = [u'\u4fbf\u5b9c', u'\u9002\u4e2d', u'\u7a0d\u8d35', u'\u8d35']\nbins = [2, 10, 30, 100, 300]\nstock_kind_tuple = pd.cut(hs_all_info[\nclose\n].loc[\nmean\n, :], bins,\n                           labels=group_name, retbins=True)\nst_kind = pd.DataFrame(stock_kind_tuple[0].value_counts())\nst_kind[\nindex_name\n] = [u\n\u4fbf\u5b9c(2-10]\n, u\n\u9002\u4e2d(10-30]\n, u\n\u7a0d\u8d35(30-100]\n, u\n\u8d35(100-300]\n]\nplt.figure(figsize=(8,6))\ng = sns.barplot(x=\nindex_name\n, y=\nmean\n, data=st_kind)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\nplt.ylabel(u\n\u6570\u91cf\n, fontsize=16, fontproperties=font)\nplt.xlabel(u\n\u80a1\u7968\u4ef7\u683c\u533a\u95f4 \uffe5\n, fontsize=16, fontproperties=font)\nplt.title(u\n\u6caa\u6df1300\u80a1\u7968(251\u652f)\u4ef7\u683c\u533a\u95f4\n, fontproperties=font, fontsize=20)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n,)\nplt.legend(loc=7,prop=font, fontsize=12)\n\n\n\n\n\n\n\u4ece\u56fe\u4e2d\u660e\u663e\u770b\u51fa\u6caa\u6df1300\u80a1\u7968\u4e2d\u7edd\u5927\u90e8\u5206\u80a1\u7968\u7684\u4ef7\u683c(\u5747\u4ef7)\u572830\u5143\u4ee5\u5185\uff0c\u540e\u7eed\u7814\u7a76\u9009\u62e9\u4ef7\u683c\u572810-30\u5143\u7684\u80a1\u7968\u4e3a\u7814\u7a76\u5bf9\u8c61\uff0c\u5171\u8ba1114\u652f\u3002\n\n\n\u6caa\u6df1300\u80a1\u79682012-2017\u6536\u5e02\u4ef7\u683c\u7684\u6ce2\u52a8\u60c5\u51b5\u7edf\u8ba1\n\n\nstock_std = hs_all_info.loc[\nstd\n, \nclose\n].sort_values(ascending=False)\nstock_std = stock_std.map(lambda x: np.round(x, 2))\nplt.figure(figsize=(8,6))\nfig = sns.distplot(stock_std, bins=80, kde=True, vertical=False, color=\ngreen\n)\nsns.despine(top=True)\nplt.yticks(fig.get_yticks(), fig.get_yticks() * 100)\nplt.ylabel('Distribution [%]', fontsize=16)\n# plt.xticks(range(0, 100, 10))\nplt.gca().yaxis.grid(True, linestyle = \n-.\n)\nplt.gca().xaxis.grid(True, linestyle = \n-.\n)\nplt.xlabel(u\n\u6caa\u6df1300\u5404\u80a1\u7968\u6536\u5e02\u4ef7\u683cstd\n, fontsize=16, fontproperties=font)\nplt.title(u\n\u6caa\u6df1300\u5404\u80a1\u7968\u6536\u5e02\u4ef7\u683c\u6ce2\u52a8\n, fontsize=20, fontproperties=font)\n\n\n\n\nText(0.5,1,'\u6caa\u6df1300\u5404\u80a1\u7968\u6536\u5e02\u4ef7\u683c\u6ce2\u52a8')\n\n\n\n\n\n\u5c06251\u652f\u80a1\u7968\u7684\u6536\u5e02\u4ef7\u683c\u7684\u6807\u6ce8\u5dee\u8fdb\u884c\u6c47\u603b\u7edf\u8ba1\uff0c\u7ed3\u679c\u5982\u4e0b\uff0c\u5927\u90e8\u5206\u80a1\u7968\u7684\u6536\u5e02\u4ef7\u683c\u6ce2\u52a8\u5747\u8f83\u5c0f\uff0c\u5c11\u6570\u80a1\u7968\u6709\u8f83\u5927\u7684\u6ce2\u52a8\uff0c\u5982\uff0c\u8d35\u5dde\u8305\u53f0\u7684std\u8fbe\u5230106\uff0c\u4ece2012-01-04\u7684134.60\u6da8\u5230\u4e86\n2017-10-23\u7684573.41\u3002\u53ef\u4ee5\u62ff\u80a1\u4ef7std\u8f83\u5927\u7684\u80a1\u7968\u505a\u6587\u7ae0\u3002\n\n\nbins = [0, 5, 10, 20, 100, 200]\nstock_std_cut = pd.cut(stock_std, bins, labels=False)\nstock_std_stat = stock_std.groupby(stock_std_cut).agg([np.min, np.max, np.mean, np.median, np.std, np.size])\nstock_std_stat[\nstock_std_cut_range\n] = [\n(0, 5]\n, \n(5, 10]\n, \n(10, 20]\n, \n(20, 100]\n, \n(100, 200]\n]\nstock_std_stat.set_index(\nstock_std_cut_range\n, inplace=True)\nstock_std_stat\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \namin\n\n      \namax\n\n      \nmean\n\n      \nmedian\n\n      \nstd\n\n      \nsize\n\n    \n\n    \n\n      \nstock_std_cut_range\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n(0, 5]\n\n      \n0.58\n\n      \n5.00\n\n      \n2.756818\n\n      \n2.710\n\n      \n1.217010\n\n      \n154.0\n\n    \n\n    \n\n      \n(5, 10]\n\n      \n5.04\n\n      \n9.67\n\n      \n6.982667\n\n      \n6.865\n\n      \n1.377019\n\n      \n60.0\n\n    \n\n    \n\n      \n(10, 20]\n\n      \n10.29\n\n      \n19.54\n\n      \n12.872258\n\n      \n12.490\n\n      \n2.421688\n\n      \n31.0\n\n    \n\n    \n\n      \n(20, 100]\n\n      \n25.95\n\n      \n32.31\n\n      \n29.096667\n\n      \n29.030\n\n      \n3.180524\n\n      \n3.0\n\n    \n\n    \n\n      \n(100, 200]\n\n      \n106.09\n\n      \n106.09\n\n      \n106.090000\n\n      \n106.090\n\n      \nNaN\n\n      \n1.0\n\n    \n\n  \n\n\n\n\n\n\n\ndef stock_indicator_plot(stock_data, stock_index):\n    particular = stock_data[stock_index]\n    if \n600519\n in stock_index:\n        maotai = stock_data[\n600519\n]\n    if \n600519\n in particular.columns:\n        particular.drop(\n600519\n, axis=1, inplace=True)\n    particular.columns = particular.columns.reorder_levels([1,0])\n    fig, ax = plt.subplots(figsize=(16,12)) \n    particular[\nclose\n].plot(ax=ax, legend=False if len(stock_index)\n30 else True, alpha=0.7)\n    if \n600519\n in stock_index:    \n        maotai[\nclose\n].plot(secondary_y=True, ax=ax, linewidth=4, legend=True, label=u\nmaotai\n)\n    ax.set_ylabel(u\nclose price \uffe5\n, fontsize=15, fontproperties=font)\n    ax.set_xlabel(\n)\n    plt.gca().yaxis.grid(True, linestyle = \n-.\n)    \n    plt.title(u\n\u6caa\u6df1300\u7684\u80a1\u7968\u4ef7\u683c\u8d8b\u52bf\n, fontproperties=font, fontsize=20)\n\n\n\n\ndef stock_pctchange_plot(stock_data, stock_index):\n    if \n600688\n in stock_index:\n        stock_index.remove(\n600688\n)\n    if \n600871\n in stock_index:\n        stock_index.remove(\n600871\n)\n    particular = stock_data[stock_index]\n    particular.columns = particular.columns.reorder_levels([1,0])    \n    pctchange = particular[\nclose\n].pct_change() * 100.0\n    fig, ax = plt.subplots(figsize=(16,12))\n    pctchange.plot(ax=ax, legend=False if len(stock_index)\n30 else True, alpha=0.7)\n    plt.ylabel('pct_change [%]', fontsize=16)\n    plt.xlabel('')\n    plt.title(u\n\u6caa\u6df1300\u80a1\u7968\u6da8\u8dcc\u5e45(%)\n, fontsize=20, fontproperties=font)\n\n\n\n\nstd \n 20\u7684\u80a1\u7968\n\n\nlarge_index = stock_std_cut[stock_std_cut \n 2].index.tolist()\nstock_indicator_plot(st_pv_, large_index)\nstock_pctchange_plot(st_pv_, large_index)\n\n\n\n\n\n\n\n\n10 \n std \n 20 \u7684\u80a1\u7968\n\n\nmiddle_index = stock_std_cut[stock_std_cut == 2].index.tolist()\nstock_indicator_plot(st_pv_, middle_index)\nstock_pctchange_plot(st_pv_, middle_index)\n\n\n\n\n\n\n\n\n5 \n std \n 10 \u7684\u80a1\u7968\n\n\nminor_index = stock_std_cut[stock_std_cut == 1].index.tolist()\nstock_indicator_plot(st_pv_, minor_index)\nstock_pctchange_plot(st_pv_, minor_index)\n\n\n\n\n\n\n\n\n0 \n std \n 5 \u7684\u80a1\u7968\n\n\npoor_index = stock_std_cut[stock_std_cut == 0].index.tolist()\nstock_indicator_plot(st_pv_, poor_index)\nstock_pctchange_plot(st_pv_, poor_index)\n\n\n\n\n\n\n\n\n\u5206\u7c7b\u6a21\u578b\u5efa\u7acb\n\n\n\u9996\u5148\uff0c\u9009\u62e9\u80a1\u7968\u4ef7\u683c(\u5747\u4ef7\uff09\u572810-30\u5143\u4e4b\u95f4\u7684\u80a1\u7968\u4e3a\u6700\u7ec8\u7814\u7a76\u5bf9\u8c61\uff0c\u5171114\u652f\u80a1\u7968\uff0c\u4ee5\u5f53\u65e5\u6536\u5e02\u80a1\u7968\u6da8\u8dcc\u5e45(pct_change)\u5927\u4e8e0\u7684\u4e3a\u6da8\uff0c\u5c0f\u4e8e0\u7684\u4e3a\u8dcc\u4e3a\u8bc4\u5224\u6807\u51c6\uff0c\u6839\u636e\u524d1\u65e5\u30015\u65e5\u300130\u65e5\u300190\u65e5\u7684\u80a1\u7968\u4fe1\u606f\u4e3a\u4f9d\u636e\u9884\u6d4b\u4eca\u65e5\u80a1\u7968\u7684\u6da8\u8dcc\u60c5\u51b5\u3002\n\n\n\u5176\u6b21\uff0c\u9009\u62e9\u80a1\u7968\u6536\u5e02\u4ef7\u683c\u3001\u6210\u4ea4\u91cf\u3001\u65e5\u6700\u9ad8\u548c\u6700\u4f4e\u4ef7\u683c\u548c\u5176\u4ed6\u7684tech_features\u59825\u65e5\u5747\u503c\u7b49\u5176\u4ed6\u6839\u636e\u80a1\u7968\u4ef7\u683c\u6210\u4ea4\u91cf\u4fe1\u606f\u8ba1\u7b97\u51fa\u7684\u6307\u6807\uff0c\u5e76\u4e14\u6dfb\u52a0\u4e86\u80a1\u7968\u7684\u57fa\u672c\u9762\u6570\u636e\u3001\u4e2d\u56fd\u80a1\u5e02\u7684\u80a1\u6307\u6570\u636e\u3001\u4e00\u4e9b\u7ecf\u6d4e\u6570\u636e\u7b49\u4fe1\u606f\u6784\u6210\u7279\u5f81\u96c6\u5408\u3002\u7136\u540e\u4f7f\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664\u6cd5\u7b49\u7279\u5f81\u9009\u53d6\u65b9\u6cd5\u8fdb\u884c\u7279\u5f81\u62bd\u53d6\uff0c\u9009\u62e9\u51fa\u7528\u4e8e\u6784\u5efa\u5206\u7c7b\u6a21\u578b\u7684\u7279\u5f81\u96c6\u3002\n\n\n\u968f\u4e4b\u662f\u6784\u5efa\u5206\u7c7b\u6a21\u578b\uff0c\u91c7\u7528sklearn\u63d0\u4f9b\u7684\u968f\u673a\u68ee\u6797\u3001LogisticRegression\u3001\u51b3\u7b56\u6811\u3001Adaboost\u5206\u7c7b\u7b97\u6cd5\u5206\u522b\u6784\u5efa\u5bf9\u5e94\u7684\u5206\u7c7b\u5668\uff0c\u7136\u540e\u91c7\u7528softVoting\u8fdb\u884c\u6a21\u578b\u878d\u5408\u5f97\u5230\u6700\u7ec8\u7684\u5206\u7c7b\u5668\u3002\n\n\n\u6839\u636e\u7b2c\u4e00\u6b21\u6784\u5efa\u7684\u5206\u7c7b\u6a21\u578b\uff0c\u5bf9\u90a3\u4e9b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u80a1\u7968\u7528\u7279\u5b9a\u7684\u7279\u5f81\u91cd\u65b0\u5efa\u6a21\u8fdb\u884c\u8bc4\u4f30\u3002\n\n\n\u80a1\u7968\u7279\u5f81\u6570\u636e\u5904\u7406\n\n\n# \u9009\u62e9\u80a1\u7968\u4ef7\u683c(12-17\u5e74\u5747\u503c\uff09\u572810-30\u5143\u4e4b\u95f4\u7684\u80a1\u7968\nstocks_ = st_pv.copy()\nstocks_.columns = st_pv.columns.reorder_levels([1,0])\nst_mean_price = st_pv[\nclose\n].mean()\nstt = st_mean_price[st_mean_price \n 10.0]\nlarge = set(stt.index)\nsmall = set(stt[stt \n 30.0].index)\nstockid_list = list(large \n small)\n# len(stockid)  # 114\nstocks= stocks_[stockid_list]\nstocks.shape  # (1409, 570)\nstocks.head(2)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \ncode\n\n      \n000002\n\n      \n600066\n\n      \n...\n\n      \n000826\n\n      \n000728\n\n    \n\n    \n\n      \n\n      \nclose\n\n      \nhigh\n\n      \nlow\n\n      \nopen\n\n      \nvolume\n\n      \nclose\n\n      \nhigh\n\n      \nlow\n\n      \nopen\n\n      \nvolume\n\n      \n...\n\n      \nclose\n\n      \nhigh\n\n      \nlow\n\n      \nopen\n\n      \nvolume\n\n      \nclose\n\n      \nhigh\n\n      \nlow\n\n      \nopen\n\n      \nvolume\n\n    \n\n    \n\n      \ndate\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n2012-01-04\n\n      \n6.052\n\n      \n6.316\n\n      \n6.044\n\n      \n6.168\n\n      \n474329.0\n\n      \n6.282\n\n      \n6.501\n\n      \n6.179\n\n      \n6.487\n\n      \n39311.0\n\n      \n...\n\n      \n13.505\n\n      \n14.387\n\n      \n13.505\n\n      \n14.269\n\n      \n27417.0\n\n      \n5.249\n\n      \n5.354\n\n      \n5.249\n\n      \n5.354\n\n      \n51205.0\n\n    \n\n    \n\n      \n2012-01-05\n\n      \n5.986\n\n      \n6.126\n\n      \n5.937\n\n      \n6.036\n\n      \n528117.0\n\n      \n6.228\n\n      \n6.406\n\n      \n6.193\n\n      \n6.217\n\n      \n54086.0\n\n      \n...\n\n      \n12.622\n\n      \n13.634\n\n      \n12.510\n\n      \n13.375\n\n      \n65717.0\n\n      \n5.174\n\n      \n5.305\n\n      \n5.155\n\n      \n5.230\n\n      \n61228.0\n\n    \n\n  \n\n\n\n\n2 rows \u00d7 570 columns\n\n\n\n\n\n\u5904\u7406\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\n\n\ndef stock_economy_tackle():\n    stock_en_list = []\n    # \u901a\u8fc7pandas\u5c06csv\u6587\u4ef6\u5185\u5bb9append\u5230\u5217\u8868\u91cc\u7136\u540e\u751f\u6210\u5b57\u5178\u4fbf\u4e8e\u540e\u7eed\u6570\u636e\u5904\u7406\n    for stcok_en in os.listdir(\n./datas/stock_economy/\n):\n        st_en_path = os.path.join(\n./datas/stock_economy\n, stcok_en) \n        stock_en_list.append(pd.read_csv(st_en_path, encoding=\nutf-8\n)) \n    stock_en_dict = dict(zip([i[:-9] for i in os.listdir(\n./datas/stock_economy/\n)], stock_en_list))\n    # \u4e0d\u540c\u6587\u4ef6\u5185\u5bb9\u5206\u522b\u5904\u7406\n    for stock_en in [i[:-9] for i in os.listdir(\n./datas/stock_economy/\n)]:\n        if stock_en == \nshibor\n:\n            stock_en_dict[stock_en].set_index(pd.to_datetime(stock_en_dict[stock_en][\ndate\n]), inplace=True)\n            shibor = stock_en_dict[stock_en].drop([\n6M\n, \n9M\n, \n1Y\n, \ndate\n], axis=1)\n            shibor.columns = shibor.columns.map(lambda x: \nshibor_\n + x)\n        elif stock_en == \nmoney\n:\n            stock_en_dict[stock_en].sort_index(ascending=False, inplace=True)\n            num = len(stock_en_dict[stock_en].columns) - 1\n            stock_en_dict[stock_en] = stock_en_dict[stock_en].append(pd.Series([\n2017.11\n]+[np.nan]*num, index=stock_en_dict[stock_en].columns.values), ignore_index=True)\n            stock_en_dict[stock_en][\nmonth\n] = stock_en_dict[stock_en][\nmonth\n].astype(str)\n            stock_en_dict[stock_en][\nmonth\n] = stock_en_dict[stock_en][\nmonth\n].str.replace(r\n\\.\n, \n-\n)\n            stock_en_dict[stock_en].set_index(pd.to_datetime(stock_en_dict[stock_en][\nmonth\n]), inplace=True)\n            stock_en_dict[stock_en].drop(\nmonth\n, axis=1, inplace=True)\n            cols = stock_en_dict[stock_en].columns.map(lambda x: x if len(x) \n 6 else \n).values\n            cols = [i for i in cols if len(i) \n 1]\n            money = stock_en_dict[stock_en][cols]\n            money = money[\n2013-01-01\n:]\n            money = money.astype(np.float)\n            # \u4ece\u6708\u4efd\u6570\u636e\u5347\u91c7\u6837\u5230\u5929\n            money = money .resample(\n1D\n).mean()\n            money.fillna(method=\nffill\n, inplace=True)\n            money.columns = money.columns.map(lambda x: \nmoney_\n + x)\n        elif stock_en == \nlpr\n:\n            stock_en_dict[stock_en][\ndate\n] = pd.to_datetime(stock_en_dict[stock_en][\ndate\n])\n            stock_en_dict[stock_en].set_index(stock_en_dict[stock_en][\ndate\n], inplace=True)\n            stock_en_dict[stock_en].drop(\ndate\n, axis=1, inplace=True)\n            stock_en_dict[stock_en].sort_index(ascending=False, inplace=True)\n            stock_en_dict[stock_en].columns = stock_en_dict[stock_en].columns.map(lambda x: \nlpr_\n + x)\n            ts_a = pd.Series([None]*297, index=pd.date_range(start=\n2013-01-01\n, end=\n2013-10-24\n, freq=\nD\n))\n            ts_a.sort_index(ascending=False, inplace=True)\n            lpr = pd.concat([stock_en_dict[stock_en], ts_a], axis=0)\n            lpr.drop(0, axis=1, inplace=True)\n            lpr.fillna(method=\nffill\n, inplace=True)\n        elif stock_en == \ncpi\n:\n            stock_en_dict[stock_en].sort_index(ascending=False, inplace=True)\n            cpi = stock_en_dict[stock_en].append(pd.Series([2017.11, None], index=stock_en_dict[stock_en].columns), ignore_index=True)\n            cpi[\nmonth\n] = cpi[\nmonth\n].astype(str)\n            cpi[\nmonth\n] = cpi[\nmonth\n].str.replace(r\n\\.\n, \n-\n)\n            cpi[\ndate\n] = pd.to_datetime(cpi[\nmonth\n])\n            cpi.set_index(cpi[\ndate\n], inplace=True)\n            cpi.drop([\nmonth\n, \ndate\n], inplace=True, axis=1)\n            # \u4ece\u6708\u4efd\u6570\u636e\u5347\u91c7\u6837\u5230\u5929\n            cpi = cpi.resample(\n1D\n).mean()\n            cpi.fillna(method=\nffill\n, inplace=True)\n            cpi = cpi[\n2013-01-01\n:]\n    return pd.concat([shibor, money, lpr, cpi], axis=1, join=\ninner\n)\n\n\n\n\n\u5904\u7406\u80a1\u7968\u7684\u57fa\u672c\u9762\u6570\u636e\n\n\ndef stock_basics_tackle(stockid, stock_basicd, stock_basic_file_name):\n    stock_basics_df = pd.DataFrame()\n    for skind in stock_basic_file_name:\n        df = stock_basicd[skind]\n        onestock = df[df[u\ncode\n] == stockid]        \n        # \u8fd9\u51e0\u4e2a\u6587\u4ef6\u4e2d\u53ea\u6709debt\u6587\u4ef6\u6709\u7279\u6b8a\u7684\u7f3a\u5931\u503c\u201c--\u201d\u6545\u8981\u7279\u6b8a\u5904\u7406\n        if skind == u\ndebt\n:\n            debt_col = onestock.columns.tolist()        \n            for col in debt_col:\n                onestock[col] = onestock[col].replace(\n--\n, np.nan)\n            debt_col.remove(u\ncode\n)\n            debt_col.remove(u\nname\n)\n            debt_col.remove(u\ntime_q\n)\n            # \u66f4\u6539DataFrame\u7684\u5217\u7c7b\u578b\n            debt = onestock[debt_col].astype(np.float)\n            debt[u\ntime_q\n] = onestock[u\ntime_q\n]\n            onestock = debt\n        if skind == u'report':\n            report_col = onestock.columns.tolist() \n            report_col.remove(u\ncode\n)\n            report_col.remove(u\nname\n)\n            report_col.remove(u\ntime_q\n)\n            report_col.remove(u\ndistrib\n)\n            report_col.remove(u\nreport_date\n)            \n            # \u66f4\u6539DataFrame\u7684\u5217\u7c7b\u578b\n            report = onestock[report_col].astype(np.float)\n            report[\ntime_q\n] = onestock[\ntime_q\n]\n            onestock = report           \n        temp = onestock[\ntime_q\n]\n        col_type = onestock.dtypes\n        onestock.drop(col_type[col_type == object].index.values, axis=1, inplace=True)\n        onestock = onestock.astype(np.float)        \n        onestock[\ntime_q\n] = temp\n        num = len(onestock.columns)\n        onestock[\ndate\n] = pd.to_datetime(onestock[\ntime_q\n])\n        onestock = onestock.append(pd.Series([None]*num+[\n2017-11-01\n], index=onestock.columns), ignore_index=True)\n        onestock[\ndate\n] = pd.to_datetime(onestock[\ndate\n])\n        onestock.set_index(onestock[\ndate\n], inplace=True, drop=True)\n        onestock.drop([\ndate\n, \ntime_q\n], axis=1, inplace=True)        \n        # \u4ece\u6708\u4efd\u6570\u636e\u5347\u91c7\u6837\u5230\u5929\n        onestock_dropna = onestock.dropna()\n        if len(onestock_dropna) \n 1:  # \u53bb\u9664\u4e00\u4e9b\u5168\u4e3a\u7a7a\u7684\u7279\u5f81\uff0c\u8fd9\u6837\u4f1a\u5bfc\u81f4\u4e0d\u540c\u7684\u80a1\u7968\u7684\u7279\u5f81\u6570\u91cf\u4e0d\u4e00\u6837\n            continue\n        onestock.columns = onestock.columns.map(lambda x: skind + \n_\n + x)\n        onestock = onestock.resample(\n1D\n).mean()\n        onestock.fillna(method=\nffill\n, inplace=True)\n        temp_df = onestock[\n2013-01-01\n:]\n        onestock_ = temp_df.dropna()\n        if onestock_.shape[0] \n= 1:\n            if onestock_.iloc[0, :].name \n pd.Timestamp(\n2013-01-01\n):\n                temp_df.fillna(method=\nbfill\n, inplace=True)\n        if stock_basics_df.empty:\n            stock_basics_df = temp_df\n        else:\n            stock_basics_df = stock_basics_df.join(temp_df)            \n    return stock_basics_df\n\n\n\n\n\u5904\u7406\u80a1\u6307\u6570\u636e\n\n\ndef stock_index_tackle():\n    si = pd.read_csv(\n./datas/stockindex_2012_2017.csv\n, parse_dates=True, index_col=\ndate\n, encoding=\nutf-8\n)    \n    stock_indexes = pd.DataFrame()    \n    for i in si[\ncode\n].unique()[:3]:\n        index_single = si[si[\ncode\n] == i]\n        index_single.drop([\nopen\n, \ncode\n], axis=1, inplace=True)\n        index_single.columns = index_single.columns.map(lambda x: str(i) + \n_\n + x)\n        if stock_indexes.empty:        \n            stock_indexes = index_single\n        else:\n            stock_indexes = stock_indexes.join(index_single)\n    return stock_indexes\n\n\n\n\n\u8bfb\u53d6\u80a1\u7968\u57fa\u672c\u9762\u6570\u636e\n\n\ndef read_stock_basics():\n    file_cont = []\n    for j in os.listdir(\n./datas/stock_basic/\n):\n        file_path = os.path.join(\n./datas/stock_basic/\n, j)\n        file_cont.append(pd.read_csv(file_path, encoding=\nutf-8\n, dtype={\ncode\n: str}))\n    stock_basics = dict(zip([j[:-9] for j in os.listdir(\n./datas/stock_basic/\n)], file_cont))\n    return stock_basics\n\n\n\n\n\u80a1\u7968\u6da8\u8dcc\u5e45\u5212\u5206\u533a\u95f4\n\n\ndef num_cut(x):\n    if x \n0:\n        x = 1\n    elif x \n= 0:\n        x = 0\n    return x\n\n\n\n\n\u8ba1\u7b97\u79fb\u52a8\u5e73\u5747\n\n\ndef stock_roll_mean(df):\n    df_temp = pd.DataFrame()\n    for k in [1,5,30,90]:\n        rolling_window = k\n        if \npct_change\n in df.columns:\n            df.drop([\npct_change\n], axis=1, inplace=True)\n        min_per = int(np.ceil(rolling_window-rolling_window*0.6)) if rolling_window \n 1 else rolling_window\n        stock_roll = df.rolling(rolling_window, min_periods=min_per).mean()\n        stock_roll.columns = stock_roll.columns.map(lambda x: x + \nmean{}\n.format(rolling_window))\n        if df_temp.empty:\n            df_temp = stock_roll\n        else:\n            df_temp = df_temp.join(stock_roll)            \n    return df_temp\n\n\n\n\n\u5206\u7c7b\u6a21\u578b\u7279\u5f81\u9009\u62e9\n\n\n# \u80a1\u7968\u7279\u5f81\u9009\u62e9\ndef feature_select(stock_):\n    if \npct_change\n in stock_.columns:\n        stock_.drop(\npct_change\n, inplace=True, axis=1)\n    if \nclose\n in stock_.columns:\n        stock_.drop(\nclose\n, inplace=True, axis=1)\n    y = stock_[\ndirection\n]\n    stock_.drop(\ndirection\n, axis=1, inplace=True)\n    X = stock_\n    sc = StandardScaler()\n    X_std = sc.fit_transform(X)  \n    feature_name = X.columns.values \n    # \u4f7f\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664(RFE)\u8fdb\u884c\u7279\u5f81\u9009\u62e9\n    estimator = LogisticRegression()\n    selector = RFE(estimator, n_features_to_select=1, step=1)  \n    selector = selector.fit(X_std, y) \n    bag = sorted(zip(feature_name, selector.ranking_, selector.support_),\n                 key=lambda x: x[1])\n    fea_importance = pd.DataFrame(bag)\n    fea_importance.set_index(0,inplace=True)\n    fea_importance.drop(2, axis=1, inplace=True)\n    fea_importance.rename(index=str, columns={1: \nRFE_Logistic\n}, inplace=True)\n    # \u4f7f\u7528\u7ec4\u5408\u51b3\u7b56\u6811(ExtraTrees)\u548c\u7a33\u5b9a\u6027\u9009\u62e9(RandomizedLogisticRegression )\u8fdb\u884c\u7279\u5f81\u9009\u62e9    \n    model_dict = dict(zip([\nRandomLR\n, \nExtraTree\n], [RandomizedLogisticRegression(),\n                                                      ExtraTreesClassifier(n_estimators=1000, random_state=1)]))\n    for i in [\nRandomLR\n, \nExtraTree\n]:\n        model = model_dict[i]\n        model.fit(X if i == \nExtraTree\n else X_std, y)\n        df_fea = pd.DataFrame(sorted(zip(feature_name, \n                model.feature_importances_ if i == \nExtraTree\n else model.scores_),\n                 key=lambda x: x[1], reverse=True))\n        df_fea.set_index(0, inplace=True)\n        df_fea.rename(index=str, columns={1: i}, inplace=True)\n        fea_importance = fea_importance.join(df_fea)\n    RandomLR_list = fea_importance[fea_importance[\nRandomLR\n] \n 0].index.tolist()\n    RFELR_list = fea_importance[fea_importance[\nRFE_Logistic\n] \n 150].index.tolist()\n    ExtraTree_list = fea_importance[fea_importance[\nExtraTree\n] \n 0.003].index.tolist()\n    # \u4e09\u79cdfeature\u9009\u62e9\u7684\u4ea4\u96c6\n    fea_two = set(RandomLR_list) \n set(RFELR_list)\n    fea_thr = fea_two \n set(ExtraTree_list)\n    feature_selected = list(fea_thr)\n    return feature_selected\n\n\n\n\n\u6a21\u578b\u8bad\u7ec3\n\n\n\u5206\u7c7b\u6a21\u578b\u7684\u5206\u7c7b\u6548\u679c\u7684\u6df7\u6dc6\u77e9\u9635\u53ef\u89c6\u5316\n\n\n# \u6df7\u6dc6\u77e9\u9635\u56fe\ndef confusion_group_plot(randomforest_result, logisticR_result, \n                         merge_result,tree_result,ada_result,close_price,pct_change,stockid):\n    # \u8ba1\u7b97\u5404\u4e2a\u5206\u7c7b\u7b97\u6cd5\u6240\u5f97\u7ed3\u679c\u7684\u6df7\u6dc6\u77e9\u9635\n    con_rf = confusion_matrix(randomforest_result[0], randomforest_result[1], labels=[1, 0])    \n    con_lr = confusion_matrix(logisticR_result[0], logisticR_result[1], labels=[1, 0])    \n    con_merge = confusion_matrix(merge_result[0], merge_result[1], labels=[1, 0])    \n    con_tree = confusion_matrix(tree_result[0], tree_result[1], labels=[1, 0])    \n    con_ada = confusion_matrix(ada_result[0], ada_result[1], labels=[1, 0])    \n    # \u6df7\u6dc6\u77e9\u9635\u53ef\u89c6\u5316\n    tick_labels = [u\n\u6da8\n, u\n\u8dcc\n]    \n    fig, axes = plt.subplots(3,2, figsize=(8,12))        \n    ax1 = axes[0][0]\n    ax2 = axes[0][1]\n    ax3 = axes[1][0]        \n    ax4 = axes[1][1]\n    ax5 = axes[2][0]\n    ax6 = axes[2][1]\n    # g1-g5\u662f\u7528seaborn\u7ed8\u5236\u5404\u5206\u7c7b\u7b97\u6cd5\u7684\u6df7\u6dc6\u77e9\u9635\n    g1 = sns.heatmap(con_rf, ax=ax1, cbar=True, annot=True, square=True, fmt=\n.2f\n, \n                annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    g2 = sns.heatmap(con_lr, ax=ax2, cbar=True, annot=True, square=True, fmt=\n.2f\n, \n                annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    g4 = sns.heatmap(con_ada, ax=ax4, cbar=True, annot=True, square=True, fmt=\n.2f\n, \n                annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    g3 = sns.heatmap(con_tree, ax=ax3, cbar=True, annot=True, square=True, \n                     fmt=\n.2f\n, annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    g5 = sns.heatmap(con_merge, ax=ax5, cbar=True, annot=True, square=True, \n                     fmt=\n.2f\n, annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    # ax6\u548cax7\u662f\u53ccy\u8f74\u56fe\uff0c\u7528\u4e8e\u80a1\u7968\u7684\u6da8\u8dcc\u5e45\u548c\u4ef7\u683c\u7684\u53ef\u89c6\u5316\u8f93\u51fa\n    pct_change.plot(ax=ax6, legend=False, alpha=0.8)\n    ax7 = ax6.twinx()\n    close_price.plot(ax=ax7, legend=True, color=\nr\n,alpha=0.6)\n    # \u4ee5\u4e0b\u4e3atitle\u3001x_axis\u3001x_label\u3001y_axis\u3001y_label\u7684\u8bbe\u7f6e\n    ax7.set_ylabel(u\n\u80a1\u7968\u4ef7\u683c \uffe5\n, fontsize=14, fontproperties=font)\n    ax6.set_ylabel(\npct_change\n, fontsize=17, fontproperties=font)\n    ax6.set_xlabel(\n)    \n    ax6.set_title(\n{} pct_chage \n close_price\n.format(stockid),fontsize=14)\n    ax5.set_title(u\nMerge-Softvote\n, fontsize=15, fontproperties=font)    \n    ax1.set_title(u\nRandomForest\n, fontsize=15, fontproperties=font)\n    ax2.set_title(u\nLogisticRegression\n, fontsize=15, fontproperties=font)    \n    ax3.set_title(u\nTree\n, fontsize=15, fontproperties=font)    \n    ax4.set_title(u\nAdaboosgt\n, fontsize=15, fontproperties=font) \n    ax5.set_title(u\nMerge-Softvote\n, fontsize=15, fontproperties=font)    \n    # \u6587\u672c\u6807\u6ce8\n    ax1.text(0.3,-0.23,s=randomforest_result[2],fontsize=12,va=\nbottom\n,ha=\nleft\n,fontproperties=font,color='green')\n    ax2.text(0.3,-0.23,s=logisticR_result[2],fontsize=12,va=\nbottom\n,ha=\nleft\n,fontproperties=font,color='red')\n    ax4.text(0.3,-0.23,s=ada_result[2],fontsize=12,va=\nbottom\n,ha=\nleft\n,fontproperties=font,color='blue')\n    ax3.text(0.3,-0.23,s=tree_result[2],fontsize=12,va=\nbottom\n,ha=\nleft\n,fontproperties=font,color='purple')\n    ax5.text(0.3,-0.23,s=merge_result[2],fontsize=12,va=\nbottom\n,ha=\nleft\n,fontproperties=font,color='k')\n    # x\u3001y\u8f74\u8bbe\u7f6e\n    ax1.set_yticklabels(g1.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax1.set_xticklabels(g1.get_xticklabels(), fontproperties=font, fontsize=12)\n    ax2.set_yticklabels(g2.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax2.set_xticklabels(g2.get_xticklabels(), fontproperties=font, fontsize=12)\n    ax3.set_yticklabels(g3.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax3.set_xticklabels(g3.get_xticklabels(), fontproperties=font, fontsize=12)\n    ax4.set_yticklabels(g4.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax4.set_xticklabels(g4.get_xticklabels(), fontproperties=font, fontsize=12)        \n    ax5.set_yticklabels(g5.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax5.set_xticklabels(g5.get_xticklabels(), fontproperties=font, fontsize=12)        \n    #\u8f74\u6807\u7b7e\u8bbe\u7f6e\n    ax1.set_ylabel(u\n\u5b9e\u9645\n, fontsize=15, fontproperties=font)\n    ax1.set_xlabel(u\n\u9884\u6d4b\n, fontsize=15, fontproperties=font)\n    ax2.set_ylabel(u\n\u5b9e\u9645\n, fontsize=15, fontproperties=font)\n    ax2.set_xlabel(u\n\u9884\u6d4b\n, fontsize=15, fontproperties=font)\n    ax3.set_ylabel(u\n\u5b9e\u9645\n, fontsize=15, fontproperties=font)\n    ax3.set_xlabel(u\n\u9884\u6d4b\n, fontsize=15, fontproperties=font)\n    ax4.set_ylabel(u\n\u5b9e\u9645\n, fontsize=15, fontproperties=font)\n    ax4.set_xlabel(u\n\u9884\u6d4b\n, fontsize=15, fontproperties=font)\n    ax5.set_ylabel(u\n\u5b9e\u9645\n, fontsize=15, fontproperties=font)\n    ax5.set_xlabel(u\n\u9884\u6d4b\n, fontsize=15, fontproperties=font)\n    plt.tight_layout() \n    plt.show()  \n    # \u4fdd\u5b58\u56fe\u7247\n    fig.savefig(\n./classificationResult/reasses/{}_classification_result.png\n.format(stockid))\n\n\n\n\n\u5206\u7c7b\u5668\u8bad\u7ec3\n\n\n# \u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\ndef random_forest(stock_, stock_y, feature_selected):\n    train_num = int(stock_.shape[0] * 0.85)\n    if \npct_change\n in stock_.columns:\n        stock_.drop(\npct_change\n, inplace=True, axis=1)\n    if \nclose\n in stock_.columns:\n        stock_.drop(\nclose\n, inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    random_forest = RandomForestClassifier(max_features=\nauto\n,n_estimators=3000, class_weight=\nbalanced\n,random_state=24)\n    parameters = {'max_depth':[6,7,8]}\n    gs = GridSearchCV(estimator=random_forest, param_grid=parameters, \n                        scoring=\naccuracy\n, cv=3, n_jobs=3)\n    gs.fit(X_train, y_train)\n    rf = gs.best_estimator_\n    rf.fit(X_train, y_train)\n    rf_prediction_train = rf.predict(X_train)\n    rf_prediction_test = rf.predict(X_test)\n    rf_evaluate_result = classification_report(y_test, rf_prediction_test)\n    train_accuracy = np.round(accuracy_score(y_train, rf_prediction_train),4)\n    test_accuracy = np.round(accuracy_score(y_test, rf_prediction_test),4) \n    train_f = np.round(f1_score(y_train, rf_prediction_train),4)\n    test_f = np.round(f1_score(y_test, rf_prediction_test),4)\n    cls_accuracy = \ntrain:{0},test:{1}\n.format(train_accuracy, test_accuracy)\n    cls_f = \ntrain:{0},test:{1}\n.format(train_f, test_f)  \n    cls_report = \nclassifationReport:{}\n.format(rf_evaluate_result)    \n    print(\nrf,{}\n.format(cls_report))\n    return [y_test, rf_prediction_test,cls_accuracy,cls_f,rf]    \n\n\n\n\n# Logistic \u5206\u7c7b\u5668\ndef logistic(stock_, stock_y, feature_selected):\n    # \u4f7f\u7528\u9009\u62e9\u7684\u7279\u5f81\u8bad\u7ec3LogisticRegression\u5206\u7c7b\u5668\n    train_num = int(stock_.shape[0] * 0.85)\n    if \npct_change\n in stock_.columns:\n        stock_.drop(\npct_change\n, inplace=True, axis=1)\n    if \nclose\n in stock_.columns:\n        stock_.drop(\nclose\n, inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    sc = StandardScaler()\n    sc.fit(X_train)  # \u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\n    X_train_std = sc.transform(X_train)  # \u8fdb\u884c\u6807\u51c6\u53d8\u6362\uff0c\u53d8\u6210\u6807\u51c6\u6b63\u6001\u5206\u5e03\n    X_test_std = sc.transform(X_test)\n    parameters = {'C':[0.04, 0.05, 0.06]}\n    logistic = LogisticRegression(penalty=\nl2\n, random_state=24, tol=1e-6)\n    gs = GridSearchCV(estimator=logistic, param_grid=parameters, \n                        scoring=\naccuracy\n, cv=3, n_jobs=3)\n    gs.fit(X_train_std, y_train)\n    lr = gs.best_estimator_\n    lr.fit(X_train_std, y_train)\n    y_pred_test = lr.predict(X_test_std)\n    y_pred_train = lr.predict(X_train_std)    \n    lr_evaluate_result = classification_report(y_test, y_pred_test)\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)\n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4) \n    train_f = np.round(f1_score(y_train, y_pred_train),4)\n    test_f = np.round(f1_score(y_test, y_pred_test),4)\n    lr_accuracy = \ntrain:{0},test:{1}\n.format(train_accuracy, test_accuracy) \n    lr_f = \ntrain:{0},test:{1}\n.format(train_f, test_f) \n    lr_report = \nclassifationReport:{}\n.format(lr_evaluate_result)    \n    print(\nlr,{}\n.format(lr_report))\n    return [y_test, y_pred_test, lr_accuracy, lr_f, lr]\n\n\n\n\n# \u6a21\u578b\u878d\u5408\u2014\u2014softVoting\ndef merge(stock_, stock_y, feature_selected, models):\n    train_num = int(stock_.shape[0] * 0.85)\n    if \npct_change\n in stock_.columns:\n        stock_.drop(\npct_change\n, inplace=True, axis=1)\n    if \nclose\n in stock_.columns:\n        stock_.drop(\nclose\n, inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    sc = StandardScaler()\n    sc.fit(X_train)  \n    X_train_std = sc.transform(X_train)  \n    X_test_std = sc.transform(X_test)\n    lr = models.get(\nlr\n)\n    rf = models.get(\nrf\n)\n    tree = models.get(\ntree\n)\n    ada = models.get(\nada\n)    \n    eclf = VotingClassifier(estimators=[(\nlr\n, lr),('rf', rf),('ada', ada),('tree', tree),], voting='soft',weights=[1.2,1.2,1.1,0.8]) \n    eclf.fit(X_train_std, y_train)\n    eclf_pred_test = eclf.predict(X_test_std)\n    eclf_pred_train = eclf.predict(X_train_std)\n    eclf_train_accu = np.round(accuracy_score(y_train, eclf_pred_train),4)\n    eclf_test_accu = np.round(accuracy_score(y_test, eclf_pred_test),4)\n    eclf_train_f = np.round(f1_score(y_train, eclf_pred_train),4)\n    eclf_test_f = np.round(f1_score(y_test, eclf_pred_test),4)\n    eclf_evaluate_result = classification_report(y_test, eclf_pred_test)\n    merge_result = \ntrain:{0}, test:{1}\n.format(eclf_train_accu, eclf_test_accu)\n    merge_result_f = \ntrain:{0}, test:{1}\n.format(eclf_train_f, eclf_test_f)\n    print(\nmerge,{}\n.format(eclf_evaluate_result))\n    return [y_test, eclf_pred_test, merge_result, merge_result_f]\n\n\n\n\n# \u51b3\u7b56\u6811\u5206\u7c7b\u5668\ndef tree(stock_, stock_y, feature_selected):\n    train_num = int(stock_.shape[0] * 0.85)\n    if \npct_change\n in stock_.columns:\n        stock_.drop(\npct_change\n, inplace=True, axis=1)\n    if \nclose\n in stock_.columns:\n        stock_.drop(\nclose\n, inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    decision_tree = DecisionTreeClassifier(random_state=24)\n    parameters = {'max_depth':[9,10,11]}\n    gs = GridSearchCV(estimator=decision_tree, param_grid=parameters, \n                        scoring=\naccuracy\n, cv=3, n_jobs=3)\n    gs.fit(X_train, y_train)\n    tree = gs.best_estimator_\n    tree.fit(X_train, y_train)\n    tree_pred_test = tree.predict(X_test)\n    tree_evaluate_result = classification_report(y_test, tree_pred_test)\n    tree_pred_train = tree.predict(X_train)    \n    train_accuracy = np.round(accuracy_score(y_train, tree_pred_train),4)\n    test_accuracy = np.round(accuracy_score(y_test, tree_pred_test),4) \n    train_f = np.round(f1_score(y_train, tree_pred_train),4)\n    test_f = np.round(f1_score(y_test, tree_pred_test),4)\n    tree_accuracy = \ntrain:{0},test:{1}\n.format(train_accuracy, test_accuracy) \n    tree_f = \ntrain:{0},test:{1}\n.format(train_f, test_f)  \n    tree_report = \nclassifationReport:{}\n.format(tree_evaluate_result)    \n    print(\ntree,{}\n.format(tree_report))\n    return [y_test, tree_pred_test, tree_accuracy,tree_f,tree]\n\n\n\n\n# Boosting\u5206\u7c7b\u5668\ndef adaboost(stock_, stock_y, feature_selected):\n    train_num = int(stock_.shape[0] * 0.85)\n    if \npct_change\n in stock_.columns:\n        stock_.drop(\npct_change\n, inplace=True, axis=1)\n    if \nclose\n in stock_.columns:\n        stock_.drop(\nclose\n, inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    sc = StandardScaler()\n    sc.fit(X_train)  \n    X_train_std = sc.transform(X_train)  \n    X_test_std = sc.transform(X_test)\n    tree = DecisionTreeClassifier(max_depth=5, random_state=24)    \n    adaboost = AdaBoostClassifier(base_estimator=tree, random_state=24)\n    parameters = [{'n_estimators':[1000,2000]}, {\nlearning_rate\n:[0.05,0.08,0.11]}]\n    gs = GridSearchCV(estimator=adaboost, param_grid=parameters, \n                        scoring=\naccuracy\n, cv=3, n_jobs=3)\n    gs.fit(X_train_std, y_train)\n    ada = gs.best_estimator_\n    ada = ada.fit(X_train_std, y_train)\n    ada_test_pred = ada.predict(X_test_std)\n    ada_train_pred = ada.predict(X_train_std)    \n    ada_evaluate_result = classification_report(y_test, ada_test_pred)\n    test_f = np.round(f1_score(y_test, ada_test_pred),4)    \n    train_f = np.round(f1_score(y_train, ada_train_pred),4)\n    train_accuracy = np.round(accuracy_score(y_train, ada_train_pred),4)\n    test_accuracy = np.round(accuracy_score(y_test, ada_test_pred),4)    \n    ada_accuracy = \ntrain:{0},test:{1}\n.format(train_accuracy, test_accuracy)\n    ada_f = \ntrain:{0},test:{1}\n.format(train_f, test_f)  \n    ada_report = \nclassifationReport:{}\n.format(ada_evaluate_result) \n    print(\nada,{}\n.format(ada_report))\n    return [y_test, ada_test_pred, ada_accuracy, ada_f, ada]\n\n\n\n\ndef stock_tackle(stockid_list, stocks, features=None, feature_select=1):\n    sf = StockFeature()  \n    clf_result = \n./classificationResult/reasses/ClassificationResultAccuracy.csv\n\n    clf_result_ = \n./classificationResult/reasses/ClassificationResultReport.csv\n\n    feature_result = \n./classificationResult/reasses/FeatureResult.csv\n    \n    stock_basic_file_name = [i[:-9] for i in os.listdir(\n./datas/stock_basic/\n)]    \n    stock_basics = read_stock_basics()\n    stock_index = stock_index_tackle()\n    stock_eco = stock_economy_tackle()    \n    # \u53d6\u51fa\u6bcf\u4e00\u652f\u80a1\u7968\u8fdb\u884c\u7279\u5f81\u62bd\u53d6\u548c\u6a21\u578b\u8bad\u7ec3\u7684\u5904\u7406\n    for i, stid in enumerate(stockid_list):        \n        models = {}  # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570\u7528\u4e8e\u6700\u540e\u7684\u6a21\u578b\u878d\u5408        \n        tar_st = stocks[stid]\n        tar_st[\npct_change\n] = tar_st[\nclose\n].pct_change() * 100\n        tar_st.drop(tar_st[tar_st[\npct_change\n] \n 11.0].index, inplace=True)\n        tar_st.drop(tar_st[tar_st[\npct_change\n] \n -11.0].index, inplace=True)\n        tar_st.drop([\npct_change\n, \nopen\n], inplace=True, axis=1)\n        # \u63d0\u53d6\u80a1\u7968\u7684tech_features\n        stock_tech_fea = sf.extract_stock_fea(tar_st)\n        stock_roll = stock_roll_mean(stock_tech_fea)       \n        # \u589e\u52a0\u80a1\u6307\u6570\u636e\n        stock_roll = stock_roll.join(stock_index)\n        # \u589e\u52a0\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\n        stock_roll = stock_roll.join(stock_eco)\n        # \u589e\u52a0\u80a1\u7968\u57fa\u672c\u9762\u6570\u636e\n        stock_basic_one = stock_basics_tackle(stid, stock_basics, stock_basic_file_name)\n        stock_roll = stock_roll.join(stock_basic_one)\n        stock_roll = stock_roll.shift(1)\n        # \u589e\u52a0\u5206\u7c7b\u6807\u7b7e\n        tar_close = pd.DataFrame(index=tar_st.index)\n        tar_close[\nclose\n] = tar_st[\nclose\n]         \n        tar_close[\npct_change\n] = tar_st[\nclose\n].pct_change() * 100 \n        tar_close[\ndirection\n] = tar_close[\npct_change\n].apply(num_cut)\n        close_price = tar_close[\nclose\n]\n        pct_change = tar_close[\npct_change\n]        \n        tar_close.drop([\npct_change\n], axis=1, inplace=True)\n        tar_close.drop([\nclose\n], axis=1, inplace=True)\n        stock_roll = stock_roll.join(tar_close)\n        stock_roll.dropna(inplace=True)\n        Y = stock_roll[\ndirection\n]\n        # \u6a21\u578b\u7279\u5f81\u9009\u62e9\n        if feature_select == 1:\n            feature_selected = feature_select(stock_roll)\n        else:\n            feature_selected = features\n        # \u6a21\u578b\u8bad\u7ec3\n        if \ndirection\n in stock_roll.columns:\n            stock_roll.drop(\ndirection\n, axis=1, inplace=True)\n        randomforest_result = random_forest(stock_roll, Y, feature_selected)\n        logisticR_result = logistic(stock_roll, Y, feature_selected)\n        tree_result = tree(stock_roll, Y, feature_selected)\n        ada_result = adaboost(stock_roll, Y, feature_selected)\n        models[\nrf\n] = randomforest_result[4]\n        models[\nlr\n] = logisticR_result[4]\n        models[\ntree\n] = tree_result[4]\n        models[\nada\n] = ada_result[4]\n        merge_result = merge(stock_roll, Y, feature_selected, models)        \n        # \u6df7\u6dc6\u77e9\u9635\u53ef\u89c6\u5316\n        confusion_group_plot(randomforest_result, logisticR_result,\n                             merge_result,tree_result,ada_result,\n                             close_price, pct_change,stid)\n        # \u5206\u7c7b\u7279\u5f81\u4fdd\u5b58\n        if feature_select == 1:\n            feature_selected.insert(0, stid)\n            feature_str = \n,\n.join(feature_selected)\n            with open(feature_result, \na\n) as f:\n                f.write( feature_str + \n\\n\n)\n        # \u5206\u7c7b\u7ed3\u679c\u4fdd\u5b58\n        classification_accuracy = \n,\n.join([stid,randomforest_result[2],logisticR_result[2],tree_result[2],ada_result[2],merge_result[2]]) + \n\\n\n \n        classification_reportf1 = \n,\n.join([stid,randomforest_result[3],logisticR_result[3],tree_result[3],ada_result[3],merge_result[3]]) + str(stock_roll.shape) + \n\\n\n \n        with open(clf_result, \na\n) as f:\n            f.write(classification_accuracy)\n        with open(clf_result_, \na\n) as f:\n            f.write(classification_reportf1)\n\n\n\n\n\u5206\u7c7b\u6a21\u578b\u7ed3\u679c\u8f93\u51fa\n\n\n# \u5206\u7c7b\u7ed3\u679c\u8f93\u51fa\uff0c\u7ed3\u679c\u592a\u957f,\u7565...\nstock_tackle(stockid_list, stocks)\n\n\n\n\n\u5206\u7c7b\u7ed3\u679c\u5206\u6790\n\n\n# \u5206\u7c7b\u51c6\u786e\u7387\naccuracy = pd.read_csv(\n./classification_result_accuracy.csv\n,encoding=\nutf-8\n, dtype=str)\naccuracy.set_index(\nstockid\n, inplace=True)\naccuracy.head(2)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nrf_train_accuracy\n\n      \nrf_test_accuracy\n\n      \nlr_train_accuracy\n\n      \nlr_test_accuracy\n\n      \ntree_train_accuracy\n\n      \ntree_test_accuracy\n\n      \nada_train_accuracy\n\n      \nada_test_accuracy\n\n      \nmerge_train_accuracy\n\n      \nmerge_test_accuracy\n\n    \n\n    \n\n      \nstockid\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n002450\n\n      \n0.9032\n\n      \n0.5833\n\n      \n0.5874\n\n      \n0.5476\n\n      \n0.9179\n\n      \n0.5595\n\n      \n0.9979\n\n      \n0.5952\n\n      \n0.9874\n\n      \n0.5357\n\n    \n\n    \n\n      \n600999\n\n      \n0.8713\n\n      \n0.5038\n\n      \n0.5528\n\n      \n0.458\n\n      \n0.8496\n\n      \n0.4733\n\n      \n1.0\n\n      \n0.5191\n\n      \n1.0\n\n      \n0.4733\n\n    \n\n  \n\n\n\n\n\n\n\n# \u5206\u7c7bf1scrore\nfscore = pd.read_csv(\n./classification_result_fscore.csv\n,encoding=\nutf-8\n, dtype=str)\nfscore.set_index(\nstockid\n, inplace=True)\nfscore.head(2)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nrf_train_fscore\n\n      \nrf_test_fscore\n\n      \nlr_train_fscore\n\n      \nlr_test_fscore\n\n      \ntree_train_fscore\n\n      \ntree_test_fscore\n\n      \nada_train_fscore\n\n      \nada_test_fscore\n\n      \nmerge_train_fscore\n\n      \nmerge_test_fscore\n\n    \n\n    \n\n      \nstockid\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n002450\n\n      \n0.9112\n\n      \n0.6535\n\n      \n0.6423\n\n      \n0.4242\n\n      \n0.9234\n\n      \n0.5934\n\n      \n0.998\n\n      \n0.66\n\n      \n0.9882\n\n      \n0.5979\n\n    \n\n    \n\n      \n600999\n\n      \n0.8633\n\n      \n0.4037\n\n      \n0.5352\n\n      \n0.4409\n\n      \n0.8326\n\n      \n0.3429\n\n      \n1.0\n\n      \n0.496\n\n      \n1.0\n\n      \n0.3784\n\n    \n\n  \n\n\n\n\n\n\n\n# \u5404\u80a1\u7968\u5206\u7c7b\u6a21\u578b\u6784\u5efa\u4f7f\u7528\u7684\u7279\u5f81\nstock_feature_selected_file = \n./feature_selected.csv\n\nfeature_selected = pd.read_csv(stock_feature_selected_file,header=None,encoding=\nutf-8\n, dtype=str)\nfeature_selected.set_index(0, inplace=True)\nfeature_selected.index.rename(\nstockid\n, inplace=True)\nfeature_selected.columns = [\nfea_num\n, \nfea_name\n]\nfeature_selected.head(2)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nfea_num\n\n      \nfea_name\n\n    \n\n    \n\n      \nstockid\n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n002450\n\n      \n14\n\n      \nvolume_roll_20_maxmean90::volume_roll_5_ppmean...\n\n    \n\n    \n\n      \n600999\n\n      \n9\n\n      \nLag60mean30::macd_deamean30::volume_roll_20_pp...\n\n    \n\n  \n\n\n\n\n\n\n\n# \u5408\u5e76\u6587\u4ef6\nresult = pd.concat([feature_selected, accuracy, fscore], axis=1)\nresult.head(2)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nfea_num\n\n      \nfea_name\n\n      \nrf_train_accuracy\n\n      \nrf_test_accuracy\n\n      \nlr_train_accuracy\n\n      \nlr_test_accuracy\n\n      \ntree_train_accuracy\n\n      \ntree_test_accuracy\n\n      \nada_train_accuracy\n\n      \nada_test_accuracy\n\n      \n...\n\n      \nrf_train_fscore\n\n      \nrf_test_fscore\n\n      \nlr_train_fscore\n\n      \nlr_test_fscore\n\n      \ntree_train_fscore\n\n      \ntree_test_fscore\n\n      \nada_train_fscore\n\n      \nada_test_fscore\n\n      \nmerge_train_fscore\n\n      \nmerge_test_fscore\n\n    \n\n    \n\n      \nstockid\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n002450\n\n      \n14\n\n      \nvolume_roll_20_maxmean90::volume_roll_5_ppmean...\n\n      \n0.9032\n\n      \n0.5833\n\n      \n0.5874\n\n      \n0.5476\n\n      \n0.9179\n\n      \n0.5595\n\n      \n0.9979\n\n      \n0.5952\n\n      \n...\n\n      \n0.9112\n\n      \n0.6535\n\n      \n0.6423\n\n      \n0.4242\n\n      \n0.9234\n\n      \n0.5934\n\n      \n0.998\n\n      \n0.66\n\n      \n0.9882\n\n      \n0.5979\n\n    \n\n    \n\n      \n600999\n\n      \n9\n\n      \nLag60mean30::macd_deamean30::volume_roll_20_pp...\n\n      \n0.8713\n\n      \n0.5038\n\n      \n0.5528\n\n      \n0.458\n\n      \n0.8496\n\n      \n0.4733\n\n      \n1.0\n\n      \n0.5191\n\n      \n...\n\n      \n0.8633\n\n      \n0.4037\n\n      \n0.5352\n\n      \n0.4409\n\n      \n0.8326\n\n      \n0.3429\n\n      \n1.0\n\n      \n0.496\n\n      \n1.0\n\n      \n0.3784\n\n    \n\n  \n\n\n\n\n2 rows \u00d7 22 columns\n\n\n\n\n\nfea_name = result[\nfea_name\n]\nresult.drop(\nfea_name\n, axis=1, inplace=True)\nresult = result.astype(np.float)\nresult[\nfea_name\n] = fea_name\nresult.describe()\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nfea_num\n\n      \nrf_train_accuracy\n\n      \nrf_test_accuracy\n\n      \nlr_train_accuracy\n\n      \nlr_test_accuracy\n\n      \ntree_train_accuracy\n\n      \ntree_test_accuracy\n\n      \nada_train_accuracy\n\n      \nada_test_accuracy\n\n      \nmerge_train_accuracy\n\n      \n...\n\n      \nrf_train_fscore\n\n      \nrf_test_fscore\n\n      \nlr_train_fscore\n\n      \nlr_test_fscore\n\n      \ntree_train_fscore\n\n      \ntree_test_fscore\n\n      \nada_train_fscore\n\n      \nada_test_fscore\n\n      \nmerge_train_fscore\n\n      \nmerge_test_fscore\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n...\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n      \n114.000000\n\n    \n\n    \n\n      \nmean\n\n      \n14.736842\n\n      \n0.931375\n\n      \n0.535332\n\n      \n0.576775\n\n      \n0.539644\n\n      \n0.848904\n\n      \n0.518705\n\n      \n0.997176\n\n      \n0.513425\n\n      \n0.987729\n\n      \n...\n\n      \n0.931418\n\n      \n0.505799\n\n      \n0.591576\n\n      \n0.516610\n\n      \n0.848570\n\n      \n0.504644\n\n      \n0.997196\n\n      \n0.508587\n\n      \n0.987868\n\n      \n0.509133\n\n    \n\n    \n\n      \nstd\n\n      \n5.507923\n\n      \n0.047039\n\n      \n0.044155\n\n      \n0.020905\n\n      \n0.044296\n\n      \n0.076324\n\n      \n0.046297\n\n      \n0.008231\n\n      \n0.044125\n\n      \n0.016967\n\n      \n...\n\n      \n0.048054\n\n      \n0.117307\n\n      \n0.062980\n\n      \n0.144329\n\n      \n0.085231\n\n      \n0.102104\n\n      \n0.008179\n\n      \n0.085687\n\n      \n0.016824\n\n      \n0.098467\n\n    \n\n    \n\n      \nmin\n\n      \n2.000000\n\n      \n0.780500\n\n      \n0.429600\n\n      \n0.521500\n\n      \n0.451100\n\n      \n0.644100\n\n      \n0.373200\n\n      \n0.952500\n\n      \n0.392400\n\n      \n0.923600\n\n      \n...\n\n      \n0.779500\n\n      \n0.038500\n\n      \n0.165300\n\n      \n0.000000\n\n      \n0.400000\n\n      \n0.140400\n\n      \n0.952200\n\n      \n0.228600\n\n      \n0.918200\n\n      \n0.140400\n\n    \n\n    \n\n      \n25%\n\n      \n11.250000\n\n      \n0.897700\n\n      \n0.508825\n\n      \n0.563525\n\n      \n0.508925\n\n      \n0.797925\n\n      \n0.493250\n\n      \n0.999250\n\n      \n0.486125\n\n      \n0.982825\n\n      \n...\n\n      \n0.896425\n\n      \n0.447150\n\n      \n0.564025\n\n      \n0.473550\n\n      \n0.799850\n\n      \n0.449125\n\n      \n0.999250\n\n      \n0.474700\n\n      \n0.983400\n\n      \n0.471225\n\n    \n\n    \n\n      \n50%\n\n      \n14.000000\n\n      \n0.937250\n\n      \n0.536100\n\n      \n0.575250\n\n      \n0.537850\n\n      \n0.851200\n\n      \n0.520500\n\n      \n1.000000\n\n      \n0.517500\n\n      \n0.995250\n\n      \n...\n\n      \n0.938100\n\n      \n0.518300\n\n      \n0.600450\n\n      \n0.541600\n\n      \n0.855050\n\n      \n0.522850\n\n      \n1.000000\n\n      \n0.515050\n\n      \n0.995550\n\n      \n0.525050\n\n    \n\n    \n\n      \n75%\n\n      \n18.750000\n\n      \n0.971250\n\n      \n0.564900\n\n      \n0.590150\n\n      \n0.569000\n\n      \n0.913475\n\n      \n0.543225\n\n      \n1.000000\n\n      \n0.534675\n\n      \n1.000000\n\n      \n...\n\n      \n0.971650\n\n      \n0.591875\n\n      \n0.625400\n\n      \n0.616650\n\n      \n0.914700\n\n      \n0.571400\n\n      \n1.000000\n\n      \n0.571025\n\n      \n1.000000\n\n      \n0.577725\n\n    \n\n    \n\n      \nmax\n\n      \n30.000000\n\n      \n1.000000\n\n      \n0.695700\n\n      \n0.640100\n\n      \n0.658500\n\n      \n0.992800\n\n      \n0.634900\n\n      \n1.000000\n\n      \n0.615400\n\n      \n1.000000\n\n      \n...\n\n      \n1.000000\n\n      \n0.704200\n\n      \n0.704700\n\n      \n0.708700\n\n      \n0.992900\n\n      \n0.691900\n\n      \n1.000000\n\n      \n0.700600\n\n      \n1.000000\n\n      \n0.695700\n\n    \n\n  \n\n\n\n\n8 rows \u00d7 21 columns\n\n\n\n\n\nresult.head(3)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nfea_num\n\n      \nrf_train_accuracy\n\n      \nrf_test_accuracy\n\n      \nlr_train_accuracy\n\n      \nlr_test_accuracy\n\n      \ntree_train_accuracy\n\n      \ntree_test_accuracy\n\n      \nada_train_accuracy\n\n      \nada_test_accuracy\n\n      \nmerge_train_accuracy\n\n      \n...\n\n      \nrf_test_fscore\n\n      \nlr_train_fscore\n\n      \nlr_test_fscore\n\n      \ntree_train_fscore\n\n      \ntree_test_fscore\n\n      \nada_train_fscore\n\n      \nada_test_fscore\n\n      \nmerge_train_fscore\n\n      \nmerge_test_fscore\n\n      \nfea_name\n\n    \n\n    \n\n      \nstockid\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n002450\n\n      \n14.0\n\n      \n0.9032\n\n      \n0.5833\n\n      \n0.5874\n\n      \n0.5476\n\n      \n0.9179\n\n      \n0.5595\n\n      \n0.9979\n\n      \n0.5952\n\n      \n0.9874\n\n      \n...\n\n      \n0.6535\n\n      \n0.6423\n\n      \n0.4242\n\n      \n0.9234\n\n      \n0.5934\n\n      \n0.998\n\n      \n0.6600\n\n      \n0.9882\n\n      \n0.5979\n\n      \nvolume_roll_20_maxmean90::volume_roll_5_ppmean...\n\n    \n\n    \n\n      \n600999\n\n      \n9.0\n\n      \n0.8713\n\n      \n0.5038\n\n      \n0.5528\n\n      \n0.4580\n\n      \n0.8496\n\n      \n0.4733\n\n      \n1.0000\n\n      \n0.5191\n\n      \n1.0000\n\n      \n...\n\n      \n0.4037\n\n      \n0.5352\n\n      \n0.4409\n\n      \n0.8326\n\n      \n0.3429\n\n      \n1.000\n\n      \n0.4960\n\n      \n1.0000\n\n      \n0.3784\n\n      \nLag60mean30::macd_deamean30::volume_roll_20_pp...\n\n    \n\n    \n\n      \n601633\n\n      \n28.0\n\n      \n0.9153\n\n      \n0.5435\n\n      \n0.6072\n\n      \n0.5145\n\n      \n0.9037\n\n      \n0.5435\n\n      \n1.0000\n\n      \n0.5507\n\n      \n0.9884\n\n      \n...\n\n      \n0.2588\n\n      \n0.5854\n\n      \n0.1299\n\n      \n0.9007\n\n      \n0.5828\n\n      \n1.000\n\n      \n0.3111\n\n      \n0.9880\n\n      \n0.2444\n\n      \nLag60mean30::sz_low::volume_roll_10_minmean5::...\n\n    \n\n  \n\n\n\n\n3 rows \u00d7 22 columns\n\n\n\n\n\n5\u79cd\u4e0d\u540c\u5206\u7c7b\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u7684\u8868\u73b0\n\n\ndef test_score_plot(df, regex, score_type):\n    score = result.filter(regex=regex)\n    score.columns = score.columns.map(lambda x: re.match(r\n(.*?)_.*\n, x).group(1))\n    score.sort_values(\nmerge\n, ascending=False, inplace=True)\n    score.columns = [\nrandomForest\n, \nLogisiticRegression\n, \ndecisionTree\n, \nAdaboost\n, \nmerge-softvoting\n]\n    merge_ = score[\nmerge-softvoting\n]\n    score.drop(\nmerge-softvoting\n, axis=1, inplace=True)\n    fig, ax = plt.subplots(figsize=(12,9))\n    score.plot(legend=True, ax=ax, grid=False, alpha=0.9)\n    merge_.plot(ax=ax, lw=4, legend=True, grid=False)\n    plt.gca().yaxis.grid(True, linestyle = \n-.\n)\n    plt.xlabel(\n)\n    plt.ylabel(u\n{}\n.format(score_type), fontsize=16, fontproperties=font)\n    plt.title(u\n\u4e94\u79cd\u5206\u7c7b\u6a21\u578b\u6d4b\u8bd5\u96c6{}\n.format(score_type), fontsize=20, fontproperties=font)\n\n\n\n\naccuracy_regex=\n.*?_test_accuracy\n\ntest_score_plot(result, accuracy_regex, u\n\u51c6\u786e\u7387\n)\n\n\n\n\n\n\nfscore_regex=\n.*?_test_fscore\n\ntest_score_plot(result, fscore_regex, \nf1_score\n)\n\n\n\n\n\n\n# \u5206\u7c7bf1 score\u4e0d\u9ad8\u4e8e50%\u7684\u6bd4\u4f8b\nmerge_test = result[[\nmerge_test_accuracy\n, \nmerge_test_fscore\n]]\nfscore_low_num = merge_test.loc[merge_test[\nmerge_test_fscore\n] \n= 0.501, :].shape[0]  # (46,2)\nnp.float(fscore_low_num) / merge_test.shape[0] * 100\n\n\n\n\n37.719298245614034\n\n\n\n# \u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u6bd4\u4f8b\naccuracy_low_num = merge_test.loc[merge_test[\nmerge_test_accuracy\n] \n= 0.501, :].shape[0]  # (46,2)\nnp.float(accuracy_low_num) / merge_test.shape[0] * 100\n\n\n\n\n30.701754385964914\n\n\n\n# \u627e\u51fa\u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u80a1\u7968\naccuracy_low_index = merge_test.loc[merge_test[\nmerge_test_accuracy\n] \n= 0.501, :].index.tolist()\nlen(result.loc[accuracy_low_index, \nmerge_test_accuracy\n])  # 35\naccuracy_low_index[:2]\n\n\n\n\n[u'600999', u'002352']\n\n\n\n\u6240\u6709\u80a1\u7968\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u4e8e50%\u548c\u4e0d\u9ad8\u4e8e50%\u7684\u6570\u91cf\n\n\ndef test_score_count(df, index_name, score_name):\n    group_name = [u\n\u51c6\u786e\u7387\n0.50\n, u\n\u51c6\u786e\u7387\n=0.50\n]\n    bins = [0.1, 0.5, 0.7]\n    score_bins = pd.cut(df, bins,labels=index_name, retbins=True)\n    score_bin_kind = pd.DataFrame(score_bins[0].value_counts())\n    score_bin_kind[\nindex_name\n] = index_name\n    score_bin_kind.columns = [\nscore\n, \nindex_name\n]\n    plt.figure(figsize=(4,3)) \n    g = sns.barplot(x=\nindex_name\n, y=\nscore\n, data=score_bin_kind)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n    plt.ylabel(u\n\u6570\u91cf\n, fontsize=16, fontproperties=font)\n    plt.xlabel(\n)\n    plt.title(u\n\u80a1\u7968\u6570\u91cf\u5bf9\u6bd4\u2014{}\n.format(score_name), fontproperties=font, fontsize=18)\n    plt.gca().yaxis.grid(True, linestyle = \n-.\n,)\n    text_loc = zip(g.get_xticks(), score_bin_kind[\nscore\n].values)    \n    plt.text(text_loc[0][0],text_loc[0][1],s=str(score_bin_kind[\nscore\n].values[0]), fontsize=16,va=\nbottom\n,ha=\ncenter\n,fontproperties=font)\n    plt.text(text_loc[1][0],text_loc[1][1],s=str(score_bin_kind[\nscore\n].values[1]), fontsize=16,va=\nbottom\n,ha=\ncenter\n,fontproperties=font)    \n    if \nress\n not in score_name:\n        plt.ylim(0,90)\n    else:\n        plt.ylim(0,25)\n\n\n\n\ntest_score_count(merge_test[\nmerge_test_accuracy\n], [u\n\u51c6\u786e\u7387\n0.50\n,u\n\u51c6\u786e\u7387\n=0.50\n],u\n\u51c6\u786e\u7387\n)\n\n\n\n\n\n\ntest_score_count(merge_test[\nmerge_test_fscore\n], [u\nf1_score\n0.50\n,u\nf1_score\n=0.50\n],u\nf1_score\n)\n\n\n\n\n\n\n\u65e0\u8bba\u662f\u51c6\u786e\u7387\u8fd8\u662ff1\uff0c\u5927\u4e8e50%\u7684\u80a1\u7968\u6570\u91cf\u8d85\u8fc760%\n\n\n# accuracy\u4e0ef1_score\u5bf9\u6bd4\nmerge_test_sorted = merge_test.sort_index()\nmerge_test_sorted.columns = [\naccuracy\n, \nf1_score\n]\nmerge_test_sorted.plot(figsize=(8,6), grid=False)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n)\nplt.xlabel(\n)\nplt.ylabel(u\naccuracy \n f1_score\n, fontsize=16)\nplt.title(u\n\u5404\u80a1\u7968\u5728\u6d4b\u8bd5\u96c6\u7684accuracy\u4e0ef1_score\u5bf9\u6bd4\n, fontsize=20, fontproperties=font)\n\n\n\n\nmatplotlib.text.Text at 0x7f8509327990\n\n\n\n\n\n\nfscore_low_index = merge_test.loc[merge_test[\nmerge_test_fscore\n] \n= 0.501, :].index.tolist()\nfscore_low_index\n\n\n\n\nfscore_low = result.loc[merge_test[\nmerge_test_fscore\n] \n= 0.501, :]\nfscore_low[\nfea_num\n].describe()\n\n\n\n\ncount    43.000000\nmean     14.558140\nstd       5.607403\nmin       2.000000\n25%      11.500000\n50%      14.000000\n75%      19.000000\nmax      28.000000\nName: fea_num, dtype: float64\n\n\n\nfscore_large = result.loc[merge_test[\nmerge_test_fscore\n] \n 0.501, :]\nfscore_large[\nfea_num\n].describe()\n\n\n\n\ncount    71.000000\nmean     14.845070\nstd       5.484127\nmin       2.000000\n25%      11.500000\n50%      14.000000\n75%      18.000000\nmax      30.000000\nName: fea_num, dtype: float64\n\n\n\naccuracy_large = result.loc[merge_test[\nmerge_test_accuracy\n] \n 0.501, :]\naccuracy_large[\nfea_num\n].describe()\n\n\n\n\ncount    79.000000\nmean     15.518987\nstd       5.322571\nmin       2.000000\n25%      12.000000\n50%      15.000000\n75%      19.500000\nmax      28.000000\nName: fea_num, dtype: float64\n\n\n\naccuracy_low = result.loc[merge_test[\nmerge_test_accuracy\n] \n= 0.501, :]\naccuracy_low[\nfea_num\n].describe()\n\n\n\n\ncount    35.000000\nmean     12.971429\nstd       5.586147\nmin       2.000000\n25%       9.500000\n50%      13.000000\n75%      15.000000\nmax      30.000000\nName: fea_num, dtype: float64\n\n\n\n\u5206\u522b\u5bf9\u6bd4\u51c6\u786e\u7387\u548cf1 score\u7684\u7edf\u8ba1\u7ed3\u679c\uff0c\u5373\u9ad8\u4e8e50%\u548c\u4f4e\u4e8e50%\u7684\u4e24\u7c7b\u5bf9\u6bd4\u7ed3\u679c\uff0c\u611f\u811a\u51c6\u786e\u7387\u9ad8\u7684\u7279\u5f81\u6570\u4e5f\u591a\uff01\n\n\ndef score_lowandhigh(df, accu_kind):\n    first_test = df.filter(regex=\nfea_num|merge_test.*\n)\n    first_test.sort_values(\nfea_num\n, inplace=True)\n    first_test.columns = [\nfea_num\n, \naccuracy\n, \nf1_score\n]\n    feature_num = first_test[\nfea_num\n]\n    first_test.drop(\nfea_num\n, axis=1, inplace=True)\n    fig, ax1 = plt.subplots(figsize=(8,6))\n    first_test.plot(ax=ax1, grid=False)\n    ax2 = ax1.twinx()\n    feature_num.plot(ax=ax2, grid=False, label=\nfeature_number(right_axis)\n, legend=True, color=\npurple\n, alpha=0.7)\n    ax1.set_ylabel(\naccuracy \n f1_score\n, fontsize=16, fontproperties=font)\n    ax2.set_ylabel(\nfeature_number\n, fontsize=16, fontproperties=font)\n    ax2.legend(loc=1, fontsize=12)\n    ax1.legend(loc=2, fontsize=12)\n    # merge_test_sorted.plot(figsize=(8,6), grid=False)\n    ax1.yaxis.grid(True, linestyle = \n-.\n)\n    ax1.set_xlabel(\n)\n    plt.title(u\n\u51c6\u786e\u7387{}\u7684\u80a1\u7968\u7684accuracy\u3001f1_score\u4e0efeature_num\n.format(accu_kind), fontsize=17, fontproperties=font)\n\n\n\n\n# \u770b\u770b\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u4e8e0.50\u7684\u90a3\u4e9bstocks\u7684\u51c6\u786e\u7387\u548cf1 score\nscore_lowandhigh(accuracy_large, u\n\u9ad8\u4e8e0.50\n)\n\n\n\n\n\n\n# \u770b\u770b\u5206\u7c7b\u51c6\u786e\u7387\u4f4e\u4e8e0.50\u7684\u90a3\u4e9bstocks\u7684\u51c6\u786e\u7387\u548cf1 score\nscore_lowandhigh(accuracy_low, u\n\u4f4e\u4e8e0.50\n)\n\n\n\n\n\n\naccuracy_top = result.loc[merge_test[\nmerge_test_accuracy\n] \n 0.55, :]\n# \u770b\u770b\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u4e8e0.55\u7684\u90a3\u4e9bstocks\u7684\u51c6\u786e\u7387\u548cf1 score\nscore_lowandhigh(accuracy_top, u\n\u9ad8\u4e8e0.55\n)\n\n\n\n\n\n\n\u4e0d\u540c\u7684\u51c6\u786e\u7387\u4e0b\u80a1\u7968\u7279\u5f81\u4e0eaccuracy\u548cf1_score\u7684\u5173\u7cfb\u53ef\u770b\u51fa\uff0c\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u5bf9\u5e94\u7740\u8f83\u9ad8\u7684f1_score\uff0c\u540c\u65f6\uff0c\u7279\u5f81\u4e5f\u8f83\u591a\u3002\n\n\n\u770b\u770b\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u4e8e55%\u7684\u90a3\u4e9bstocks\u7684\u7279\u5f81\u90fd\u662f\u5565\n\n\naccuracy_top_list = result.loc[merge_test[\nmerge_test_accuracy\n] \n 0.55, :].index.tolist()\nfscore_top_list = result.loc[result[\nmerge_test_fscore\n] \n 0.55, :].index.tolist()\ntarget_index = list(set(accuracy_top_list) \n set(fscore_top_list))\n# len(target_index)  # 20\ntarget_stock = result.loc[target_index, :]\ntarget_stock.head(2)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nfea_num\n\n      \nrf_train_accuracy\n\n      \nrf_test_accuracy\n\n      \nlr_train_accuracy\n\n      \nlr_test_accuracy\n\n      \ntree_train_accuracy\n\n      \ntree_test_accuracy\n\n      \nada_train_accuracy\n\n      \nada_test_accuracy\n\n      \nmerge_train_accuracy\n\n      \n...\n\n      \nrf_test_fscore\n\n      \nlr_train_fscore\n\n      \nlr_test_fscore\n\n      \ntree_train_fscore\n\n      \ntree_test_fscore\n\n      \nada_train_fscore\n\n      \nada_test_fscore\n\n      \nmerge_train_fscore\n\n      \nmerge_test_fscore\n\n      \nfea_name\n\n    \n\n    \n\n      \nstockid\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n601877\n\n      \n14.0\n\n      \n0.8831\n\n      \n0.5556\n\n      \n0.5831\n\n      \n0.5556\n\n      \n0.8085\n\n      \n0.6349\n\n      \n1.0\n\n      \n0.5476\n\n      \n1.0000\n\n      \n...\n\n      \n0.6585\n\n      \n0.5647\n\n      \n0.6818\n\n      \n0.7994\n\n      \n0.6714\n\n      \n1.0\n\n      \n0.6275\n\n      \n1.000\n\n      \n0.6667\n\n      \nsz_volume::rocmean1::fimean5::Lag5mean5::hs300...\n\n    \n\n    \n\n      \n600332\n\n      \n19.0\n\n      \n0.9942\n\n      \n0.5435\n\n      \n0.5792\n\n      \n0.5870\n\n      \n0.8533\n\n      \n0.5652\n\n      \n1.0\n\n      \n0.4783\n\n      \n0.9981\n\n      \n...\n\n      \n0.5962\n\n      \n0.5381\n\n      \n0.5000\n\n      \n0.8538\n\n      \n0.6078\n\n      \n1.0\n\n      \n0.5000\n\n      \n0.998\n\n      \n0.5859\n\n      \nclose_roll_20_ppmean90::fimean5::high_pctchang...\n\n    \n\n  \n\n\n\n\n2 rows \u00d7 22 columns\n\n\n\n\n\ntarget_stock.describe()\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nfea_num\n\n      \nrf_train_accuracy\n\n      \nrf_test_accuracy\n\n      \nlr_train_accuracy\n\n      \nlr_test_accuracy\n\n      \ntree_train_accuracy\n\n      \ntree_test_accuracy\n\n      \nada_train_accuracy\n\n      \nada_test_accuracy\n\n      \nmerge_train_accuracy\n\n      \n...\n\n      \nrf_train_fscore\n\n      \nrf_test_fscore\n\n      \nlr_train_fscore\n\n      \nlr_test_fscore\n\n      \ntree_train_fscore\n\n      \ntree_test_fscore\n\n      \nada_train_fscore\n\n      \nada_test_fscore\n\n      \nmerge_train_fscore\n\n      \nmerge_test_fscore\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n...\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n      \n20.000000\n\n    \n\n    \n\n      \nmean\n\n      \n15.950000\n\n      \n0.940980\n\n      \n0.559530\n\n      \n0.583380\n\n      \n0.553630\n\n      \n0.856590\n\n      \n0.565900\n\n      \n0.999245\n\n      \n0.527110\n\n      \n0.989585\n\n      \n...\n\n      \n0.941895\n\n      \n0.584980\n\n      \n0.599625\n\n      \n0.573735\n\n      \n0.868400\n\n      \n0.614970\n\n      \n0.999255\n\n      \n0.553925\n\n      \n0.989940\n\n      \n0.615905\n\n    \n\n    \n\n      \nstd\n\n      \n3.872644\n\n      \n0.045878\n\n      \n0.038063\n\n      \n0.016712\n\n      \n0.049804\n\n      \n0.080882\n\n      \n0.038997\n\n      \n0.001889\n\n      \n0.045610\n\n      \n0.017169\n\n      \n...\n\n      \n0.045279\n\n      \n0.085217\n\n      \n0.044295\n\n      \n0.093469\n\n      \n0.067407\n\n      \n0.051002\n\n      \n0.001867\n\n      \n0.077192\n\n      \n0.016303\n\n      \n0.036228\n\n    \n\n    \n\n      \nmin\n\n      \n10.000000\n\n      \n0.838000\n\n      \n0.493400\n\n      \n0.555800\n\n      \n0.457400\n\n      \n0.709500\n\n      \n0.503600\n\n      \n0.992200\n\n      \n0.428600\n\n      \n0.933300\n\n      \n...\n\n      \n0.842600\n\n      \n0.384000\n\n      \n0.510100\n\n      \n0.333300\n\n      \n0.768900\n\n      \n0.527500\n\n      \n0.992300\n\n      \n0.371400\n\n      \n0.938100\n\n      \n0.552200\n\n    \n\n    \n\n      \n25%\n\n      \n13.000000\n\n      \n0.924775\n\n      \n0.537600\n\n      \n0.567525\n\n      \n0.511600\n\n      \n0.795325\n\n      \n0.527800\n\n      \n1.000000\n\n      \n0.481425\n\n      \n0.987825\n\n      \n...\n\n      \n0.923500\n\n      \n0.557475\n\n      \n0.579100\n\n      \n0.510925\n\n      \n0.810450\n\n      \n0.571400\n\n      \n1.000000\n\n      \n0.497575\n\n      \n0.988250\n\n      \n0.589375\n\n    \n\n    \n\n      \n50%\n\n      \n14.500000\n\n      \n0.948400\n\n      \n0.562050\n\n      \n0.584250\n\n      \n0.555600\n\n      \n0.859800\n\n      \n0.565450\n\n      \n1.000000\n\n      \n0.528300\n\n      \n0.997700\n\n      \n...\n\n      \n0.948750\n\n      \n0.601850\n\n      \n0.601500\n\n      \n0.570900\n\n      \n0.861700\n\n      \n0.610650\n\n      \n1.000000\n\n      \n0.566200\n\n      \n0.997700\n\n      \n0.610000\n\n    \n\n    \n\n      \n75%\n\n      \n19.000000\n\n      \n0.983525\n\n      \n0.578025\n\n      \n0.593950\n\n      \n0.586400\n\n      \n0.933800\n\n      \n0.596350\n\n      \n1.000000\n\n      \n0.563975\n\n      \n1.000000\n\n      \n...\n\n      \n0.983925\n\n      \n0.654000\n\n      \n0.621475\n\n      \n0.666700\n\n      \n0.933250\n\n      \n0.664450\n\n      \n1.000000\n\n      \n0.604250\n\n      \n1.000000\n\n      \n0.639975\n\n    \n\n    \n\n      \nmax\n\n      \n23.000000\n\n      \n0.995500\n\n      \n0.641000\n\n      \n0.627600\n\n      \n0.642900\n\n      \n0.992800\n\n      \n0.634900\n\n      \n1.000000\n\n      \n0.594800\n\n      \n1.000000\n\n      \n...\n\n      \n0.995500\n\n      \n0.681800\n\n      \n0.677200\n\n      \n0.681800\n\n      \n0.992900\n\n      \n0.691900\n\n      \n1.000000\n\n      \n0.700600\n\n      \n1.000000\n\n      \n0.695700\n\n    \n\n  \n\n\n\n\n8 rows \u00d7 21 columns\n\n\n\n\n\ntarget_stock\u7684\u7279\u5f81\u6570\u76ee\u6700\u5c11\u768410\u4e2a\uff0c\u6700\u591a\u768423\u4e2a\uff0c\u5e73\u574715\u4e2a\u5de6\u53f3\uff0c\u5373\u5206\u7c7b\u6548\u679c\u8f83\u597d\u7684stocks\u7684\u7279\u5f81\u6570\u76ee\u65e2\u4e0d\u592a\u5c11\u4e5f\u4e0d\u592a\u591a\uff0c\u90a3\u8fd9\u4e9b\u80a1\u7968\u90fd\u4f7f\u7528\u4e86\u54ea\u4e9b\u7279\u5f81\u5462\uff0c\u53ef\u5426\u7528\u8fd9\u4e9b\u7279\u5f81\u4f5c\u4e3a\u6240\u6709\u80a1\u7968\u7684\u6700\u7ec8\u7684\u5206\u7c7b\u7279\u5f81\u5462\uff1f\n\n\ntarget_stock[\nfea_name\n].head(2)\n\n\n\n\nstockid\n002241    volume_roll_5_ppmean90::rocmean1::close_roll_3...\n600703    Lag20mean90::rocmean1::ccimean1::rsv9mean1::vo...\nName: fea_name, dtype: object\n\n\n\ntop_fea_name = target_stock[\nfea_name\n].str.split(\n::\n)\ntop_fea_name.head(2)\n\n\n\n\nstockid\n601877    [sz_volume, rocmean1, fimean5, Lag5mean5, hs30...\n600332    [close_roll_20_ppmean90, fimean5, high_pctchan...\nName: fea_name, dtype: object\n\n\n\n\u53d6\u572820\u652f\u80a1\u7968\u4e2d\u516c\u5171\u7279\u5f81\u6b21\u6570\u8d85\u8fc73\u6b21\u7684\u90a3\u4e9b\u7279\u5f81\n\n\ntip_fea_list = []\nfor i in range(len(top_fea_name)):\n    tip_fea_list.extend(top_fea_name[i])\nfname, fcount = np.unique(tip_fea_list, return_counts=True)\nfea_sorted = sorted(zip(fname, fcount), key=lambda x: x[1], reverse=True)\nfea_sorted = filter(lambda x: x[1]\n3, fea_sorted)\n# len(fea_sorted)  # 25\nfeature_final = [i[0] for i in fea_sorted]\nfeature_final[:3]\n\n\n\n\n[u'rsimean1', u'rocmean1', u'obvmean5']\n\n\n\n\u4f7f\u7528\u9009\u5b9a\u7279\u5f81\u91cd\u65b0\u5efa\u6a21\n\n\n\u4f7f\u7528\u9009\u62e9\u768425\u4e2a\u7279\u5f81\u5bf9\u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684stocks\u91cd\u65b0\u8fdb\u884c\u5206\u7c7b\u8bad\u7ec3\n\n\nstock_tackle(accuracy_low_index, stocks, feature_final, 0)\n# \u5206\u7c7b\u7ed3\u679c\u5728\u6b64\u7565\u8fc7...\n\n\n\n\n\u4f7f\u7528\u9009\u5b9a\u768425\u4e2a\u7279\u5f81\u5bf9\u7b2c\u4e00\u6b21\u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u80a1\u7968\u91cd\u65b0\u8fdb\u884c\u5206\u7c7b\u8bc4\u4f30\uff0c\u7ed3\u679c\u5982\u4e0b\uff1a\n\n\n# \u8bfb\u5165\u6587\u4ef6\naccuracy_ress = pd.read_csv(\n./classification_result_ress_accuracy.csv\n,encoding=\nutf-8\n, dtype=str)\naccuracy_ress.set_index(\nstockid\n, inplace=True)\nfscore_ress = pd.read_csv(\n./classification_result_ress_fscore.csv\n,encoding=\nutf-8\n, dtype=str)\nfscore_ress.set_index(\nstockid\n, inplace=True)\nresult_ress = pd.concat([accuracy_ress, fscore_ress], axis=1)\nresult_ress.drop(\ndata_shape\n, axis=1, inplace=True)\nresult_ress = result_ress.astype(np.float)\nresult_ress.head(2)\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nrf_train_accuracy\n\n      \nrf_test_accuracy\n\n      \nlr_train_accuracy\n\n      \nlr_test_accuracy\n\n      \ntree_train_accuracy\n\n      \ntree_test_accuracy\n\n      \nada_train_accuracy\n\n      \nada_test_accuracy\n\n      \nmerge_train_accuracy\n\n      \nmerge_test_accuracy\n\n      \nrf_train_fscore\n\n      \nrf_test_fscore\n\n      \nlr_train_fscore\n\n      \nlr_test_fscore\n\n      \ntree_train_fscore\n\n      \ntree_test_fscore\n\n      \nada_train_fscore\n\n      \nada_test_fscore\n\n      \nmerge_train_fscore\n\n      \nmerge_test_fscore\n\n    \n\n    \n\n      \nstockid\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n600999\n\n      \n0.9892\n\n      \n0.5573\n\n      \n0.5732\n\n      \n0.4351\n\n      \n0.8889\n\n      \n0.5496\n\n      \n1.0\n\n      \n0.5038\n\n      \n1.0000\n\n      \n0.5191\n\n      \n0.9888\n\n      \n0.4314\n\n      \n0.5428\n\n      \n0.1778\n\n      \n0.8898\n\n      \n0.5124\n\n      \n1.0\n\n      \n0.3299\n\n      \n1.0000\n\n      \n0.3762\n\n    \n\n    \n\n      \n002352\n\n      \n0.9925\n\n      \n0.5141\n\n      \n0.5593\n\n      \n0.5634\n\n      \n0.7878\n\n      \n0.4366\n\n      \n1.0\n\n      \n0.4789\n\n      \n0.9925\n\n      \n0.4859\n\n      \n0.9931\n\n      \n0.6057\n\n      \n0.6728\n\n      \n0.6265\n\n      \n0.8265\n\n      \n0.4872\n\n      \n1.0\n\n      \n0.5432\n\n      \n0.9932\n\n      \n0.5576\n\n    \n\n  \n\n\n\n\n\n\n\nresult_ress.describe()\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nrf_train_accuracy\n\n      \nrf_test_accuracy\n\n      \nlr_train_accuracy\n\n      \nlr_test_accuracy\n\n      \ntree_train_accuracy\n\n      \ntree_test_accuracy\n\n      \nada_train_accuracy\n\n      \nada_test_accuracy\n\n      \nmerge_train_accuracy\n\n      \nmerge_test_accuracy\n\n      \nrf_train_fscore\n\n      \nrf_test_fscore\n\n      \nlr_train_fscore\n\n      \nlr_test_fscore\n\n      \ntree_train_fscore\n\n      \ntree_test_fscore\n\n      \nada_train_fscore\n\n      \nada_test_fscore\n\n      \nmerge_train_fscore\n\n      \nmerge_test_fscore\n\n    \n\n  \n\n  \n\n    \n\n      \ncount\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n      \n35.000000\n\n    \n\n    \n\n      \nmean\n\n      \n0.966860\n\n      \n0.505991\n\n      \n0.574640\n\n      \n0.502557\n\n      \n0.845254\n\n      \n0.507454\n\n      \n0.997851\n\n      \n0.498680\n\n      \n0.991723\n\n      \n0.506531\n\n      \n0.967537\n\n      \n0.484546\n\n      \n0.588957\n\n      \n0.504066\n\n      \n0.841951\n\n      \n0.490154\n\n      \n0.997880\n\n      \n0.495414\n\n      \n0.991934\n\n      \n0.502054\n\n    \n\n    \n\n      \nstd\n\n      \n0.030945\n\n      \n0.049303\n\n      \n0.024525\n\n      \n0.039650\n\n      \n0.081260\n\n      \n0.054788\n\n      \n0.006110\n\n      \n0.043482\n\n      \n0.013401\n\n      \n0.038681\n\n      \n0.029980\n\n      \n0.107487\n\n      \n0.061700\n\n      \n0.125887\n\n      \n0.087532\n\n      \n0.092912\n\n      \n0.006022\n\n      \n0.078563\n\n      \n0.012882\n\n      \n0.084782\n\n    \n\n    \n\n      \nmin\n\n      \n0.890700\n\n      \n0.417500\n\n      \n0.541000\n\n      \n0.435100\n\n      \n0.661800\n\n      \n0.418900\n\n      \n0.967500\n\n      \n0.421100\n\n      \n0.939400\n\n      \n0.426400\n\n      \n0.896300\n\n      \n0.256400\n\n      \n0.349100\n\n      \n0.177800\n\n      \n0.586700\n\n      \n0.335900\n\n      \n0.968000\n\n      \n0.329900\n\n      \n0.942100\n\n      \n0.273500\n\n    \n\n    \n\n      \n25%\n\n      \n0.948100\n\n      \n0.467400\n\n      \n0.558850\n\n      \n0.472950\n\n      \n0.793450\n\n      \n0.459600\n\n      \n1.000000\n\n      \n0.466000\n\n      \n0.991750\n\n      \n0.474700\n\n      \n0.950150\n\n      \n0.406200\n\n      \n0.553900\n\n      \n0.425550\n\n      \n0.795500\n\n      \n0.408250\n\n      \n1.000000\n\n      \n0.451400\n\n      \n0.992150\n\n      \n0.449500\n\n    \n\n    \n\n      \n50%\n\n      \n0.976000\n\n      \n0.506200\n\n      \n0.572800\n\n      \n0.503100\n\n      \n0.860200\n\n      \n0.500000\n\n      \n1.000000\n\n      \n0.500000\n\n      \n0.997000\n\n      \n0.506300\n\n      \n0.976100\n\n      \n0.493500\n\n      \n0.602300\n\n      \n0.528700\n\n      \n0.858100\n\n      \n0.493000\n\n      \n1.000000\n\n      \n0.500000\n\n      \n0.997100\n\n      \n0.490300\n\n    \n\n    \n\n      \n75%\n\n      \n0.991400\n\n      \n0.548750\n\n      \n0.583850\n\n      \n0.531150\n\n      \n0.892400\n\n      \n0.538950\n\n      \n1.000000\n\n      \n0.524000\n\n      \n1.000000\n\n      \n0.523550\n\n      \n0.991400\n\n      \n0.565150\n\n      \n0.633400\n\n      \n0.604150\n\n      \n0.891800\n\n      \n0.565350\n\n      \n1.000000\n\n      \n0.551500\n\n      \n1.000000\n\n      \n0.578650\n\n    \n\n    \n\n      \nmax\n\n      \n1.000000\n\n      \n0.611100\n\n      \n0.665100\n\n      \n0.610000\n\n      \n0.954200\n\n      \n0.638900\n\n      \n1.000000\n\n      \n0.638900\n\n      \n1.000000\n\n      \n0.629600\n\n      \n1.000000\n\n      \n0.679200\n\n      \n0.684800\n\n      \n0.678000\n\n      \n0.955100\n\n      \n0.681600\n\n      \n1.000000\n\n      \n0.682900\n\n      \n1.000000\n\n      \n0.661000\n\n    \n\n  \n\n\n\n\n\n\n\n# \u5206\u7c7b\u51c6\u786e\u7387\u4f4e\u4e8e50%\u7684\u6bd4\u4f8b\naccuracy_low_num_ress = merge_test_ress.loc[merge_test_ress[\nmerge_test_accuracy\n] \n= 0.501, :].shape[0]\nnp.float(accuracy_low_num_ress) / merge_test_ress.shape[0] * 100\n\n\n\n\n40.0\n\n\n\n# \u5206\u7c7bf1_score\u4f4e\u4e8e50%\u7684\u6bd4\u4f8b\nmerge_test_ress = result_ress[[\nmerge_test_accuracy\n, \nmerge_test_fscore\n]]\nfscore_low_num_ress = merge_test_ress.loc[merge_test_ress[\nmerge_test_fscore\n] \n= 0.501, :].shape[0]\nnp.float(fscore_low_num_ress) / merge_test_ress.shape[0] * 100\n\n\n\n\n57.14285714285714\n\n\n\ntest_score_count(merge_test_ress[\nmerge_test_accuracy\n], [u\n\u51c6\u786e\u7387\n0.50\n,u\n\u51c6\u786e\u7387\n=0.50\n],u\n\u51c6\u786e\u7387_ress\n)\n\n\n\n\n\n\ntest_score_count(merge_test_ress[\nmerge_test_fscore\n], [u\nf1_score\n=0.50\n,u\nf1_score\n0.50\n],u\nf1_score_ress\n)\n\n\n\n\n\n\n# \u4f7f\u7528\u7279\u5b9a\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u8bc4\u4f30\u4e0e\u4e4b\u524d\u7684\u5206\u7c7b\u51c6\u786e\u7387\u5bf9\u6bd4\nfig, ax = plt.subplots(figsize=(8,6))\nmerge_test_ress_sorted = merge_test_ress.sort_index()\nmerge_test_ress_sorted.columns = [\naccuracy\n, \nf1_score\n]\nmerge_test_ress_sorted[\naccuracy\n].plot(ax=ax, grid=False, linewidth=2, label=\naccuracy_ress\n, legend=True, color=\nred\n, style=\n-.\n,alpha=0.7)\n# merge_test_ress_sorted[\nf1_score\n].plot(ax=ax, grid=False, label=\nf1_score_ress\n, legend=True,linewidth=4, color=\npurple\n,style=\n-.\n,alpha=0.8)\nmerge_low_sorted = merge_test_sorted.loc[merge_test_sorted[\naccuracy\n] \n 0.501, :]\nmerge_low_sorted  = merge_low_sorted .sort_index()\nmerge_low_sorted[\naccuracy\n].plot(ax=ax,grid=False,linewidth=2,alpha=0.9,legend=True, label=\naccuracy\n)\n# merge_low_sorted[\nf1_score\n].plot(ax=ax,grid=False,linewidth=2,alpha=0.9,legend=True, label=\nfscore\n)\nplt.gca().yaxis.grid(True, linestyle = \n-.\n)\nplt.xlabel(\n)\nplt.ylabel(u\naccuracy\n, fontsize=16)\nplt.title(u\n\u4f7f\u7528\u7279\u5b9a\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u8bc4\u4f30\u4e0e\u4e4b\u524d\u7684\u5206\u7c7b\u5bf9\u6bd4\n, fontsize=20, fontproperties=font)\n\n\n\n\nmatplotlib.text.Text at 0x7f8502d89ed0\n\n\n\n\n\n\n\u5404\u79cd\u5206\u7c7b\u5668\u5728\u4f7f\u7528\u7279\u5b9a\u7279\u5f81\u91cd\u65b0\u5206\u7c7b\u7684\u7684\u8868\u73b0\n\n\ntest_score_plot(result_ress, accuracy_regex, u\n\u51c6\u786e\u7387_ress\n)\n\n\n\n\n\n\ntest_score_plot(result_ress, fscore_regex, u\nf1_score_ress\n)\n\n\n\n\n\n\n\u5728\u4f7f\u7528\u9009\u5b9a\u768425\u4e2a\u7279\u5f81\u5bf9\u7b2c\u4e00\u6b21\u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u90a3\u4e9b\u80a1\u7968\u8fdb\u884c\u91cd\u5206\u7c7b\u6a21\u578b\u6784\u5efa\uff0c\u6574\u4f53\u51c6\u786e\u7387\u6709\u63d0\u9ad8\uff0c\u8bf4\u660e\u7279\u5f81\u9009\u62e9\u5f88\u91cd\u8981\uff01\uff01\uff01\n\n\n\u5bf9114\u652f\u80a1\u7968\u5206\u522b\u5efa\u7acb\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u80a1\u4ef7\u6da8\u8dcc\uff0c\u5206\u7c7b\u7ed3\u679c\u8be6\u60c5\u5c31\u4e0d\u5217\u51fa\u4e86\uff0c\u5728\u8fd9\u4e3e\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5c31\u62ff\u5728\u7b2c\u4e8c\u6b21\u91cd\u65b0\u5206\u7c7b\u51c6\u786e\u7387\u6700\u9ad8\u7684000063\u8fd9\u652f\u80a1\u7968\u4e3a\u4f8b\uff1a\n\n\nresult_ress_sorted_ = result_ress.sort_values(\nmerge_test_accuracy\n, ascending=False)\nresult_ress_sorted_.head()\n\n\n\n\n\n\n\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n\n\n\n  \n\n    \n\n      \n\n      \nrf_train_accuracy\n\n      \nrf_test_accuracy\n\n      \nlr_train_accuracy\n\n      \nlr_test_accuracy\n\n      \ntree_train_accuracy\n\n      \ntree_test_accuracy\n\n      \nada_train_accuracy\n\n      \nada_test_accuracy\n\n      \nmerge_train_accuracy\n\n      \nmerge_test_accuracy\n\n      \nrf_train_fscore\n\n      \nrf_test_fscore\n\n      \nlr_train_fscore\n\n      \nlr_test_fscore\n\n      \ntree_train_fscore\n\n      \ntree_test_fscore\n\n      \nada_train_fscore\n\n      \nada_test_fscore\n\n      \nmerge_train_fscore\n\n      \nmerge_test_fscore\n\n    \n\n    \n\n      \nstockid\n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n      \n\n    \n\n  \n\n  \n\n    \n\n      \n000063\n\n      \n0.9984\n\n      \n0.6111\n\n      \n0.5698\n\n      \n0.5370\n\n      \n0.9524\n\n      \n0.6389\n\n      \n1.0000\n\n      \n0.6389\n\n      \n1.0000\n\n      \n0.6296\n\n      \n0.9984\n\n      \n0.6719\n\n      \n0.6147\n\n      \n0.6377\n\n      \n0.9532\n\n      \n0.6422\n\n      \n1.0000\n\n      \n0.6829\n\n      \n1.0000\n\n      \n0.6610\n\n    \n\n    \n\n      \n300070\n\n      \n0.9728\n\n      \n0.4898\n\n      \n0.5725\n\n      \n0.5204\n\n      \n0.8297\n\n      \n0.5000\n\n      \n0.9982\n\n      \n0.5714\n\n      \n0.9783\n\n      \n0.5816\n\n      \n0.9731\n\n      \n0.3902\n\n      \n0.5986\n\n      \n0.3896\n\n      \n0.8058\n\n      \n0.3951\n\n      \n0.9982\n\n      \n0.6182\n\n      \n0.9783\n\n      \n0.6019\n\n    \n\n    \n\n      \n600741\n\n      \n0.8914\n\n      \n0.5414\n\n      \n0.5837\n\n      \n0.5541\n\n      \n0.7862\n\n      \n0.4904\n\n      \n0.9966\n\n      \n0.5350\n\n      \n0.9593\n\n      \n0.5478\n\n      \n0.8963\n\n      \n0.5862\n\n      \n0.6175\n\n      \n0.6196\n\n      \n0.8000\n\n      \n0.5699\n\n      \n0.9967\n\n      \n0.5922\n\n      \n0.9605\n\n      \n0.6162\n\n    \n\n    \n\n      \n601601\n\n      \n0.9414\n\n      \n0.4914\n\n      \n0.5566\n\n      \n0.5143\n\n      \n0.8879\n\n      \n0.5257\n\n      \n1.0000\n\n      \n0.5429\n\n      \n0.9970\n\n      \n0.5429\n\n      \n0.9428\n\n      \n0.5389\n\n      \n0.6049\n\n      \n0.6222\n\n      \n0.8917\n\n      \n0.5608\n\n      \n1.0000\n\n      \n0.5876\n\n      \n0.9971\n\n      \n0.5876\n\n    \n\n    \n\n      \n300133\n\n      \n0.9936\n\n      \n0.5904\n\n      \n0.5906\n\n      \n0.5422\n\n      \n0.9424\n\n      \n0.6024\n\n      \n1.0000\n\n      \n0.4578\n\n      \n1.0000\n\n      \n0.5422\n\n      \n0.9937\n\n      \n0.6792\n\n      \n0.6082\n\n      \n0.6780\n\n      \n0.9434\n\n      \n0.6118\n\n      \n1.0000\n\n      \n0.5455\n\n      \n1.0000\n\n      \n0.6275\n\n    \n\n  \n\n\n\n\n\n\n\nresult_ress_sorted_.loc[\n000063\n, \nmerge_test_accuracy\n]\n\n\n\n\n0.62960000000000005\n\n\n\nresult.loc[\n000063\n, \nmerge_test_accuracy\n]\n\n\n\n\n0.46300000000000002\n\n\n\n000063\u80a1\u7968\u5728\u7b2c\u4e00\u6b21\u6784\u5efa\u5206\u7c7b\u6a21\u578b\u7684\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u4e3a0.463\uff0c\u800c\u5728\u7b2c\u4e8c\u6b21\u4f7f\u7528\u9009\u5b9a\u7684\u7279\u5f81\u8fdb\u884c\u7684\u5206\u7c7b\u6a21\u578b\u6784\u5efa\u7684\u51c6\u786e\u7387\u4e3a0.629\uff0c\u7cbe\u786e\u7387\uff0c\u53ec\u56de\u7387\u53caf1_score\u5c31\u4e0d\u4e00\u4e00\u5217\u51fa\u6765\u4e86\uff0c\u4e0d\u540c\u5206\u7c7b\u5668\u7684\u5206\u7c7b\u6548\u679c\u53ef\u53c2\u8003\u89c1\u4e0b\u9762\u7684\u6df7\u6dc6\u77e9\u9635\u56fe\uff0c\u5176\u4e2d\uff0c\u524d5\u526f\u56fe\u4e3a\u6df7\u6dc6\u77e9\u9635\uff0c\u540e\u4e00\u5f20\u4e3a\u8be5\u80a1\u7968\u7684close_price\u548cpct_change\u3002\n\n\n000063\u6df7\u6dc6\u77e9\u9635\u56fe\n\n \n\n\n\u603b\u7ed3\n\n\n\u672c\u9879\u76ee\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5206\u7c7b\u7b97\u6cd5\u9884\u6d4b\u90e8\u5206\u6caa\u6df1300\u80a1\u7968\u7684\u6da8\u8dcc\u60c5\u51b5\u3002\u6570\u636e\u662f\u4f7f\u7528tushare\u63d0\u4f9b\u7684API\u91c7\u96c62012-2017\u5e74\u6caa\u6df1300\u80a1\u7968\u7684\u4fe1\u606f\uff0c\u540c\u65f6\uff0c\u4e5f\u6536\u96c6\u4e86\u540c\u65f6\u671f\u7684\u5404\u80a1\u6307\u3001\u80a1\u7968\u57fa\u672c\u9762\u3001\u7ecf\u6d4e\u6570\u636e\u7b49\u76f8\u5173\u4fe1\u606f\uff0c\u91c7\u7528sklearn\u7684\u5206\u7c7b\u6a21\u578b\uff0c\u5982\u968f\u673a\u68ee\u6797\u3001LogisticRegression\u7b49\u5206\u7c7b\u5668\u5bf9\u90e8\u5206\u6caa\u6df1300\u80a1\u7968\u7684\u6da8\u8dcc\u60c5\u51b5\u8fdb\u884c\u9884\u6d4b\u3002\n\n\n\u5206\u7c7b\u5efa\u6a21\u4f7f\u7528\u7684\u80a1\u7968\u6570\u636e\u662f\u6e90\u81ea\u662f\u6caa\u6df1300\u4e2d\u5747\u4ef7\u572810-30\u5143\u4e4b\u95f4\u5e76\u4e14\u7f3a\u5931\u6570\u636e\u5c11\u4e8e20%\u7684114\u652f\u80a1\u7968\u4fe1\u606f\uff0c\u7279\u5f81\u5de5\u7a0b\u9009\u62e9\u7684\u7279\u5f81\u5305\u62ec\u4e86\u80a1\u7968\u4ef7\u683c\u3001\u6210\u4ea4\u91cf\u4fe1\u606f\uff0c\u57fa\u4e8e\u80a1\u7968\u4ef7\u683c\u548c\u6210\u4ea4\u91cf\u8ba1\u7b97\u7684\u5176\u4ed6\u80a1\u7968\u6307\u6807\uff0c\u56fd\u5185\u540c\u65f6\u671f\u80a1\u6307\u3001\u7ecf\u6d4e\u4ee5\u53ca\u80a1\u7968\u7684\u57fa\u672c\u9762\u4fe1\u606f\u7b49\u3002\u4f7f\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664(RFE)\u7b49\u4e09\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u9009\u51fa\u91cd\u8981\u7684\u7279\u5f81\uff0c\u7136\u540e\u7b80\u5355\u7c97\u66b4\u5730\u7528\u4e09\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u9009\u62e9\u7684\u7279\u5f81\u7684\u4ea4\u96c6\u4e3a\u5206\u7c7b\u6a21\u578b\u7684\u8bad\u7ec3\u7279\u5f81\u3002\u4f7f\u7528sklearn\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u7684\u6784\u5efa\uff0c\u5177\u4f53\u800c\u8a00\u662f\u91c7\u7528\u4e86\u968f\u673a\u68ee\u6797\u3001LogisticRegression\u3001\u51b3\u7b56\u6811\u3001Adaboost\u56db\u79cd\u5206\u7c7b\u5668\u5206\u522b\u6784\u5efa\u76f8\u5e94\u7684\u5206\u7c7b\u6a21\u578b\uff0c\u6700\u540e\u4f7f\u7528softVoting\u5bf9\u4e0a\u8ff0\u56db\u7c7b\u5206\u7c7b\u5668\u8fdb\u884c\u6a21\u578b\u878d\u5408\uff0c\u4ece\u800c\u5b8c\u6210\u5206\u7c7b\u6a21\u578b\u7684\u6784\u5efa\u3002\n\n\n\u5206\u7c7b\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u7684\u8868\u73b0\u4e3a\uff0c\u670940%\u5de6\u53f3\u7684\u80a1\u7968\u7684\u5206\u7c7b\u9884\u6d4b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\uff0c\u5206\u6790\u5206\u7c7b\u7ed3\u679c\u80fd\u53d1\u73b0\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u8f83\u9ad8\u7684stocks\u7684\u7279\u5f81\u6570\u91cf\u8f83\u591a\uff0c\u4e3a\u6b64\uff0c\u4f7f\u7528\u5206\u7c7b\u7ed3\u679c\u4e2d\u51c6\u786e\u7387\u9ad8\u4e8e55%\u7684\u80a1\u7968\u7684\u7279\u5f81\u4e3a\u7279\u5b9a\u7684\u7279\u5f81\u5bf9\u90a340%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u4f4e\u7684\u80a1\u7968\u91cd\u65b0\u8fdb\u884c\u5206\u7c7b\u8bad\u7ec3\uff0c\u7ed3\u679c\u4e3a\u670940%\u7684\u80a1\u7968\u7684\u5206\u7c7b\u51c6\u786e\u7387\u4ecd\u65e7\u4e0d\u9ad8\u4e8e50%\uff0c\u670960%\u7684\u5728\u7b2c\u4e00\u6b21\u5206\u7c7b\u4e2d\u7684\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\uff0c\u5728\u7b2c\u4e8c\u6b21\u4f7f\u7528\u9009\u5b9a\u7684\u7279\u5f81\u8bad\u7ec3\u540e\u5176\u51c6\u786e\u7387\u8d85\u8fc750%\uff0c\u8bf4\u660e\u9009\u5b9a\u7684\u7279\u5f81\u5bf9\u5206\u7c7b\u6a21\u578b\u6784\u5efa\u662f\u6709\u6548\u7684\u3002\n\n\n\u76ee\u524d\uff0c\u5728\u91cf\u5316\u6295\u8d44\u9886\u57df\u6709\u5f88\u591a\u4eba\u5728\u7528\u4e00\u4e9b\u673a\u5668\u5b66\u4e60\u7684\u7b97\u6cd5\u8fdb\u884cresearch\uff0c\u5982\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6765\u9009\u80a1\uff0c\u7ebf\u6027\u56de\u5f52\u7684\u03b2\u7cfb\u6570\u3001\u5206\u7c7b\u9884\u6d4b\u7b49\u7b49\uff0c\u672c\u9879\u76ee\u5c31\u662f\u5229\u7528sklearn\u5c01\u88c5\u7684\u5206\u7c7b\u7b97\u6cd5\u5bf9\u80a1\u7968\u6da8\u8dcc\u8fdb\u884c\u9884\u6d4b\uff0c\u672c\u8d28\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5206\u7c7b\u95ee\u9898\u3002\u4e3a\u4e86\u7b80\u5316\u6d41\u7a0b\uff0c\u5728\u6784\u5efa\u7684\u5206\u7c7b\u6a21\u578b\u7684\u65f6\u5019\u91c7\u7528\u7684\u662f\u4e8c\u5206\u7c7b\uff0c\u540c\u65f6\u7531\u4e8e\u6700\u7ec8\u5206\u7c7b\u6548\u679c\u8f83\u5dee\uff0c\u56e0\u6b64\u4e0d\u5177\u5907\u5b9e\u9645\u610f\u4e49\u3002\u540e\u7eed\uff0c\u53ef\u8fdb\u884c\u591a\u5206\u7c7b\u6a21\u578b\u6784\u5efa\uff0c\u540c\u65f6\u5e94\u91c7\u7528\u66f4\u591a\u6709\u6548\u7684\u7279\u5f81\uff0c\u7ed3\u5408\u5176\u4ed6\u65b9\u6cd5\u6bd4\u5982\u52a0\u5165\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u624b\u6bb5\u5bf9\u80a1\u7968\u7684\u65b0\u95fb\u7c7b\u4fe1\u606f\u8fdb\u884c\u91c7\u96c6\u548c\u5206\u6790\u5e76\u52a0\u5165\u5230\u6a21\u578b\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u9884\u6d4b\u7cbe\u51c6\u6027\u3002", 
            "title": "\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6caa\u6df1300\u80a1\u7968\u6da8\u8dcc"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#300", 
            "text": "\u8fd1\u51e0\u5e74\u4eba\u5de5\u667a\u80fd\u5927\u70ed\uff0c\u5176\u4f7f\u7528\u7684\u7b97\u6cd5\u5305\u62ec\u673a\u5668\u5b66\u4e60\u5c24\u5176\u662f\u6df1\u5ea6\u5b66\u4e60\uff0c\u8fd9\u4fe9\u8005\u662f\u76ee\u524d\u6700\u706b\u70ed\u7684\u804c\u4e1a\u4e4b\u4e00\u3002\u5728\u4eba\u4eec\u751f\u6d3b\u4e2d\uff0c\u673a\u5668\u5b66\u4e60\u548c\u6df1\u5ea6\u5b66\u4e60\u4e5f\u5728\u9010\u6e10\u8d70\u5982\u4eba\u4eec\u7684\u751f\u6d3b\uff0c\u6bd4\u5982Alphago\u3001\u4eba\u8138\u8bc6\u522b\u3001\u65e0\u4eba\u9a7e\u9a76\u90fd\u7528\u5230\u4e86\u673a\u5668\u5b66\u4e60\u6216\u6df1\u5ea6\u5b66\u4e60\u7684\u4e00\u4e9b\u7b97\u6cd5\uff0c\u8ba9\u4eba\u5207\u5b9e\u611f\u53d7\u5230\u79d1\u6280\u7684\u529b\u91cf\u6b63\u663e\u8457\u5730\u6539\u53d8\u7740\u4eba\u7c7b\u4e16\u754c\u3002\u800c\u8fd0\u7528\u673a\u5668\u5b66\u4e60\u8fdb\u884c\u91cf\u5316\u4ea4\u6613\uff0c\u4e5f\u662f\u673a\u5668\u5b66\u4e60\u7684\u4e00\u5927\u5e94\u7528\u9886\u57df\u3002\u672c\u6587\u91c7\u7528python\u7b2c\u4e09\u65b9\u5e93sklearn\u63d0\u4f9b\u7684\u51e0\u79cd\u5206\u7c7b\u7b97\u6cd5\u5bf9\u6caa\u6df1300\u7684\u90e8\u5206\u80a1\u7968\u8fdb\u884c\u8bad\u7ec3\u548c\u5b66\u4e60\uff0c\u4ee5\u671f\u80fd\u591f\u9884\u6d4b\u80a1\u7968\u7684\u6da8\u8dcc\u60c5\u51b5\u3002", 
            "title": "\u673a\u5668\u5b66\u4e60\u9884\u6d4b\u6caa\u6df1300\u80a1\u7968\u6da8\u8dcc"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_1", 
            "text": "\u4f7f\u7528tushare\u63d0\u4f9b\u7684API\u91c7\u96c62012-2017\u5e74\u6caa\u6df1300\u7684\u80a1\u7968\u4ea4\u6613\u6570\u636e\uff0c\u6caa\u5e02\u3001\u6df1\u5e02\u3001\u521b\u4e1a\u677f\u7b49\u80a1\u6307\u6570\u636e\uff0c\u80a1\u7968\u7684\u57fa\u672c\u9762\u6570\u636e\u4ee5\u53ca\u5176\u4ed6\u7684\u7ecf\u6d4e\u6307\u6807\u6570\u636e\uff0c\u7531\u4e8e\u6570\u636e\u91cf\u4e0d\u5927\uff0c\u76f4\u63a5\u4fdd\u5b58\u4e3aCSV\u683c\u5f0f\u7684\u6587\u4ef6\u3002", 
            "title": "\u6570\u636e\u91c7\u96c6"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_2", 
            "text": "", 
            "title": "\u6570\u636e\u5206\u6790"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_3", 
            "text": "import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nsns.set(style= whitegrid , palette= muted , font_scale=1, color_codes=True, context= talk )\n%matplotlib inline\nfrom matplotlib.font_manager import FontProperties  \nfont = FontProperties(fname=r /usr/share/fonts/truetype/arphic/ukai.ttc )\n# font = FontProperties(fname=r C:\\Windows\\Fonts\\msyh.ttc )\nimport datetime\nimport re\nfrom techFeature import StockFeature\nimport os\nimport sys\nreload(sys)\nsys.setdefaultencoding('utf-8')\nfrom sklearn.preprocessing import StandardScaler \nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import learning_curve\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import RandomizedLasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import RandomizedLogisticRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn import svm  \u6caa\u6df1300\u80a1\u7968\u4e2d\u6709\u8fd150\u652f\u80a1\u7968\u7f3a\u5931\u6570\u636e\u8f83\u591a(\u8d85\u8fc720%\uff09\uff0c\u6545\u4f7f\u7528\u5904\u7406\u540e\u7684251\u652f\u80a1\u7968\u8fdb\u884c\u521d\u6b65\u7edf\u8ba1\u5206\u6790  # \u8bfb\u53d6\u5df2\u7ecf\u5220\u9664\u8fc7\u90e8\u5206\u80a1\u7968\u7684\u6570\u636e\nst = pd.read_csv( ./datas/hs300_dropleft_251.csv , encoding= utf-8 , dtype={ code : str})\nst[ date ] = pd.to_datetime(st[ date ])\n#\u7531\u4e8e600688\u548c600871\u7684pct_change\u6709\u5f02\u5e38\uff0c\u6545\u4e0d\u4f7f\u7528\u8be5\u4e24\u652f\u80a1\u7968\u7684\u4fe1\u606f\nst = st[st[ code ] !=  600688 ]\nst = st[st[ code ] !=  600871 ]\nst.head(2)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       date \n       code \n       close \n       high \n       low \n       open \n       volume \n     \n   \n   \n     \n       0 \n       2012-01-04 \n       000001 \n       5.120 \n       5.265 \n       5.116 \n       5.265 \n       147910.0 \n     \n     \n       1 \n       2012-01-04 \n       000002 \n       6.052 \n       6.316 \n       6.044 \n       6.168 \n       474329.0 \n     \n      st.shape  (335285, 7)  st_pv = st.pivot_table(index= date , columns= code )\nst_pv.head(3)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       close \n       ... \n       volume \n     \n     \n       code \n       000001 \n       000002 \n       000008 \n       000009 \n       000060 \n       000063 \n       000069 \n       000100 \n       000156 \n       000157 \n       ... \n       601901 \n       601919 \n       601933 \n       601939 \n       601958 \n       601988 \n       601989 \n       601992 \n       601998 \n       603993 \n     \n     \n       date \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2012-01-04 \n       5.120 \n       6.052 \n       0.760 \n       5.344 \n       7.802 \n       13.371 \n       5.013 \n       1.607 \n       NaN \n       6.362 \n       ... \n       606942.0 \n       258238.0 \n       11334.0 \n       414369.0 \n       52481.0 \n       183288.0 \n       222003.0 \n       63765.0 \n       160450.0 \n       NaN \n     \n     \n       2012-01-05 \n       5.197 \n       5.986 \n       0.729 \n       5.048 \n       7.675 \n       13.292 \n       4.782 \n       1.652 \n       NaN \n       6.151 \n       ... \n       533317.0 \n       320893.0 \n       15274.0 \n       804582.0 \n       48201.0 \n       389570.0 \n       276832.0 \n       58840.0 \n       863501.0 \n       NaN \n     \n     \n       2012-01-06 \n       5.184 \n       5.912 \n       0.734 \n       5.350 \n       7.763 \n       12.950 \n       4.790 \n       1.661 \n       NaN \n       6.143 \n       ... \n       867634.0 \n       304644.0 \n       14070.0 \n       662240.0 \n       43909.0 \n       NaN \n       215748.0 \n       62473.0 \n       383847.0 \n       NaN \n     \n     3 rows \u00d7 1245 columns   st_pv_ = st_pv.copy()\nst_pv_.columns = st_pv.columns.reorder_levels([1,0])\nst_pv_.head(3)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       code \n       000001 \n       000002 \n       000008 \n       000009 \n       000060 \n       000063 \n       000069 \n       000100 \n       000156 \n       000157 \n       ... \n       601901 \n       601919 \n       601933 \n       601939 \n       601958 \n       601988 \n       601989 \n       601992 \n       601998 \n       603993 \n     \n     \n       \n       close \n       close \n       close \n       close \n       close \n       close \n       close \n       close \n       close \n       close \n       ... \n       volume \n       volume \n       volume \n       volume \n       volume \n       volume \n       volume \n       volume \n       volume \n       volume \n     \n     \n       date \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2012-01-04 \n       5.120 \n       6.052 \n       0.760 \n       5.344 \n       7.802 \n       13.371 \n       5.013 \n       1.607 \n       NaN \n       6.362 \n       ... \n       606942.0 \n       258238.0 \n       11334.0 \n       414369.0 \n       52481.0 \n       183288.0 \n       222003.0 \n       63765.0 \n       160450.0 \n       NaN \n     \n     \n       2012-01-05 \n       5.197 \n       5.986 \n       0.729 \n       5.048 \n       7.675 \n       13.292 \n       4.782 \n       1.652 \n       NaN \n       6.151 \n       ... \n       533317.0 \n       320893.0 \n       15274.0 \n       804582.0 \n       48201.0 \n       389570.0 \n       276832.0 \n       58840.0 \n       863501.0 \n       NaN \n     \n     \n       2012-01-06 \n       5.184 \n       5.912 \n       0.734 \n       5.350 \n       7.763 \n       12.950 \n       4.790 \n       1.661 \n       NaN \n       6.143 \n       ... \n       867634.0 \n       304644.0 \n       14070.0 \n       662240.0 \n       43909.0 \n       NaN \n       215748.0 \n       62473.0 \n       383847.0 \n       NaN \n     \n     3 rows \u00d7 1245 columns   \u901a\u8fc7\u8ba1\u7b97pct_change\u68c0\u67e5\u6570\u636e\u6709\u65e0\u5f02\u5e38\u60c5\u51b5  pctchanges = st_pv[ close ].pct_change() * 100.0\npctchanges.dropna(how= all , inplace=True)\npp = pctchanges.apply(lambda x: np.abs(x)   11.0)\nppsum = pp.sum().sort_values(ascending=False)\nproblem_stock_index = ppsum[ppsum   0].index.tolist()  # [u'600153', u'600871', u'600688']\nproblem_stock = st_pv_[problem_stock_index]\nproblem_stock.head(3)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       code \n       600153 \n     \n     \n       \n       close \n       high \n       low \n       open \n       volume \n     \n     \n       date \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2012-01-04 \n       5.177 \n       5.396 \n       5.161 \n       5.380 \n       82566.0 \n     \n     \n       2012-01-05 \n       5.161 \n       5.203 \n       5.144 \n       5.161 \n       86409.0 \n     \n     \n       2012-01-06 \n       5.152 \n       5.186 \n       5.085 \n       5.177 \n       69581.0 \n     \n      problem_stock.tail(3)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       code \n       600153 \n     \n     \n       \n       close \n       high \n       low \n       open \n       volume \n     \n     \n       date \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2017-10-19 \n       11.89 \n       11.92 \n       11.73 \n       11.80 \n       170555.0 \n     \n     \n       2017-10-20 \n       12.00 \n       12.08 \n       11.92 \n       11.95 \n       201325.0 \n     \n     \n       2017-10-23 \n       12.00 \n       12.09 \n       11.89 \n       12.04 \n       140262.0 \n     \n      pctchanges[problem_stock_index].plot(figsize=(8,6), legend=True)  matplotlib.axes._subplots.AxesSubplot at 0x7ff7d4cf5750    # \u5404\u7edf\u8ba1\u91cf\u7684\u5747\u503c\u3001\u4e2d\u4f4d\u6570\u3001\u767e\u5206\u4f4d\u6570\u3001\u6700\u5927\u548c\u6700\u5c0f\u503c\u4e00\u89c8\nhs_all_info = st_pv.describe()\nhs_all_info   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       close \n       ... \n       volume \n     \n     \n       code \n       000001 \n       000002 \n       000008 \n       000009 \n       000060 \n       000063 \n       000069 \n       000100 \n       000156 \n       000157 \n       ... \n       601901 \n       601919 \n       601933 \n       601939 \n       601958 \n       601988 \n       601989 \n       601992 \n       601998 \n       603993 \n     \n   \n   \n     \n       count \n       1397.000000 \n       1258.000000 \n       1195.000000 \n       1311.000000 \n       1396.000000 \n       1367.000000 \n       1364.000000 \n       1214.000000 \n       1173.000000 \n       1401.000000 \n       ... \n       1.291000e+03 \n       1.261000e+03 \n       1.394000e+03 \n       1.407000e+03 \n       1.408000e+03 \n       1.407000e+03 \n       1.206000e+03 \n       1.381000e+03 \n       1.405000e+03 \n       1.204000e+03 \n     \n     \n       mean \n       7.895441 \n       12.305227 \n       5.456906 \n       8.294201 \n       9.930986 \n       14.259742 \n       6.607823 \n       3.015196 \n       23.784151 \n       5.537340 \n       ... \n       1.095797e+06 \n       5.011430e+05 \n       3.265446e+05 \n       9.733053e+05 \n       1.990064e+05 \n       2.778726e+06 \n       2.198017e+06 \n       4.599039e+05 \n       6.741906e+05 \n       6.512692e+05 \n     \n     \n       std \n       2.113651 \n       6.182167 \n       3.846793 \n       2.731044 \n       3.188618 \n       4.655476 \n       1.644207 \n       1.156071 \n       9.296279 \n       1.504979 \n       ... \n       9.993168e+05 \n       7.407939e+05 \n       3.802748e+05 \n       1.459887e+06 \n       2.193792e+05 \n       5.595141e+06 \n       2.890371e+06 \n       9.062799e+05 \n       8.444628e+05 \n       9.123304e+05 \n     \n     \n       min \n       4.269000 \n       5.592000 \n       0.729000 \n       3.958000 \n       5.344000 \n       6.190000 \n       4.144000 \n       1.607000 \n       7.685000 \n       3.751000 \n       ... \n       7.093400e+04 \n       2.760100e+04 \n       3.177000e+03 \n       8.230200e+04 \n       1.672500e+04 \n       5.679500e+04 \n       2.705100e+04 \n       2.710800e+04 \n       4.250900e+04 \n       1.422600e+04 \n     \n     \n       25% \n       6.190000 \n       7.439000 \n       1.720500 \n       6.004000 \n       7.720000 \n       10.852500 \n       5.373000 \n       2.112000 \n       17.268000 \n       4.397000 \n       ... \n       4.283485e+05 \n       1.087420e+05 \n       5.740900e+04 \n       2.672415e+05 \n       6.349275e+04 \n       2.768075e+05 \n       4.695140e+05 \n       1.243880e+05 \n       2.062040e+05 \n       1.110132e+05 \n     \n     \n       50% \n       8.016000 \n       9.398000 \n       5.283000 \n       8.351000 \n       9.682500 \n       13.660000 \n       6.317000 \n       2.589000 \n       20.969000 \n       4.780000 \n       ... \n       7.909860e+05 \n       2.291660e+05 \n       2.132770e+05 \n       5.010900e+05 \n       1.210935e+05 \n       7.675750e+05 \n       1.006596e+06 \n       2.145180e+05 \n       3.466360e+05 \n       2.936680e+05 \n     \n     \n       75% \n       9.224000 \n       16.605750 \n       9.001000 \n       10.037500 \n       11.390250 \n       16.361000 \n       7.371000 \n       3.624000 \n       28.892000 \n       6.896000 \n       ... \n       1.394280e+06 \n       5.246280e+05 \n       4.610060e+05 \n       9.291410e+05 \n       2.398298e+05 \n       1.930524e+06 \n       2.492684e+06 \n       4.556470e+05 \n       7.663030e+05 \n       7.521080e+05 \n     \n     \n       max \n       13.986000 \n       29.300000 \n       13.721000 \n       17.548000 \n       28.849000 \n       30.630000 \n       13.448000 \n       7.147000 \n       59.297000 \n       9.635000 \n       ... \n       7.081835e+06 \n       6.846566e+06 \n       3.915401e+06 \n       1.805440e+07 \n       2.213357e+06 \n       5.109897e+07 \n       2.107839e+07 \n       1.693063e+07 \n       7.545412e+06 \n       6.340851e+06 \n     \n     8 rows \u00d7 1245 columns   stock_null = (hs_all_info.loc[ count ,  close ] / st_pv.shape[0]) * 100\nstock_null = stock_null.map(lambda x: np.int(x))\nstock_null = stock_null.value_counts().sort_index()\nplt.figure(figsize=(8,6))\nstock_null.plot(kind= bar , grid=False)\nplt.ylabel(u \u6837\u672c\u6570\u91cf , fontsize=16, fontproperties=font)\nplt.xlabel(u \u975e\u7f3a\u5931\u6570\u636e\u767e\u5206\u6bd4 % , fontsize=16, fontproperties=font)\nplt.title(u \u6570\u636e\u96c6\u6570\u636e\u975e\u7f3a\u5931\u60c5\u51b5 , fontproperties=font, fontsize=20)\nplt.gca().yaxis.grid(True, linestyle =  -. ,)\nplt.gca().xaxis.grid(False)   \u7531\u4e8e\u91c7\u96c6\u6570\u636e\u662f12-17\u5e74\u7684\uff0c\u65f6\u95f4\u8de8\u5ea6\u6709\u4e9b\u5927\uff0c\u6545\u57fa\u672c\u6240\u6709\u7684\u80a1\u7968\u90fd\u6709\u7f3a\u5931\u7684\u6570\u636e\uff0c\u8fd9\u662f\u56e0\u4e3a\u80a1\u5e02\u7ecf\u5e38\u51fa\u73b0\u7531\u4e8e\u5404\u79cd\u539f\u56e0\u505c\u6b62\u4ea4\u6613\u7684\u80a1\u7968\uff0c\u5728\u6b64\u9009\u62e9\u7f3a\u5931\u6570\u636e\u572820%\u4ee5\u5185\u7684\u80a1\u7968\u4e3a\u521d\u6b65\u7814\u7a76\u5bf9\u8c61\u3002", 
            "title": "\u6570\u636e\u5904\u7406\u53ca\u6e05\u6d17"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#300_1", 
            "text": "group_name = [u'\u4fbf\u5b9c', u'\u9002\u4e2d', u'\u7a0d\u8d35', u'\u8d35']\nbins = [2, 10, 30, 100, 300]\nstock_kind_tuple = pd.cut(hs_all_info[ close ].loc[ mean , :], bins,\n                           labels=group_name, retbins=True)\nst_kind = pd.DataFrame(stock_kind_tuple[0].value_counts())\nst_kind[ index_name ] = [u \u4fbf\u5b9c(2-10] , u \u9002\u4e2d(10-30] , u \u7a0d\u8d35(30-100] , u \u8d35(100-300] ]\nplt.figure(figsize=(8,6))\ng = sns.barplot(x= index_name , y= mean , data=st_kind)\nplt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\nplt.ylabel(u \u6570\u91cf , fontsize=16, fontproperties=font)\nplt.xlabel(u \u80a1\u7968\u4ef7\u683c\u533a\u95f4 \uffe5 , fontsize=16, fontproperties=font)\nplt.title(u \u6caa\u6df1300\u80a1\u7968(251\u652f)\u4ef7\u683c\u533a\u95f4 , fontproperties=font, fontsize=20)\nplt.gca().yaxis.grid(True, linestyle =  -. ,)\nplt.legend(loc=7,prop=font, fontsize=12)   \u4ece\u56fe\u4e2d\u660e\u663e\u770b\u51fa\u6caa\u6df1300\u80a1\u7968\u4e2d\u7edd\u5927\u90e8\u5206\u80a1\u7968\u7684\u4ef7\u683c(\u5747\u4ef7)\u572830\u5143\u4ee5\u5185\uff0c\u540e\u7eed\u7814\u7a76\u9009\u62e9\u4ef7\u683c\u572810-30\u5143\u7684\u80a1\u7968\u4e3a\u7814\u7a76\u5bf9\u8c61\uff0c\u5171\u8ba1114\u652f\u3002", 
            "title": "\u6caa\u6df1300\u5404\u80a1\u7968\u7684\u4ef7\u683c\u533a\u95f4\u5206\u5e03"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#3002012-2017", 
            "text": "stock_std = hs_all_info.loc[ std ,  close ].sort_values(ascending=False)\nstock_std = stock_std.map(lambda x: np.round(x, 2))\nplt.figure(figsize=(8,6))\nfig = sns.distplot(stock_std, bins=80, kde=True, vertical=False, color= green )\nsns.despine(top=True)\nplt.yticks(fig.get_yticks(), fig.get_yticks() * 100)\nplt.ylabel('Distribution [%]', fontsize=16)\n# plt.xticks(range(0, 100, 10))\nplt.gca().yaxis.grid(True, linestyle =  -. )\nplt.gca().xaxis.grid(True, linestyle =  -. )\nplt.xlabel(u \u6caa\u6df1300\u5404\u80a1\u7968\u6536\u5e02\u4ef7\u683cstd , fontsize=16, fontproperties=font)\nplt.title(u \u6caa\u6df1300\u5404\u80a1\u7968\u6536\u5e02\u4ef7\u683c\u6ce2\u52a8 , fontsize=20, fontproperties=font)  Text(0.5,1,'\u6caa\u6df1300\u5404\u80a1\u7968\u6536\u5e02\u4ef7\u683c\u6ce2\u52a8')   \u5c06251\u652f\u80a1\u7968\u7684\u6536\u5e02\u4ef7\u683c\u7684\u6807\u6ce8\u5dee\u8fdb\u884c\u6c47\u603b\u7edf\u8ba1\uff0c\u7ed3\u679c\u5982\u4e0b\uff0c\u5927\u90e8\u5206\u80a1\u7968\u7684\u6536\u5e02\u4ef7\u683c\u6ce2\u52a8\u5747\u8f83\u5c0f\uff0c\u5c11\u6570\u80a1\u7968\u6709\u8f83\u5927\u7684\u6ce2\u52a8\uff0c\u5982\uff0c\u8d35\u5dde\u8305\u53f0\u7684std\u8fbe\u5230106\uff0c\u4ece2012-01-04\u7684134.60\u6da8\u5230\u4e86\n2017-10-23\u7684573.41\u3002\u53ef\u4ee5\u62ff\u80a1\u4ef7std\u8f83\u5927\u7684\u80a1\u7968\u505a\u6587\u7ae0\u3002  bins = [0, 5, 10, 20, 100, 200]\nstock_std_cut = pd.cut(stock_std, bins, labels=False)\nstock_std_stat = stock_std.groupby(stock_std_cut).agg([np.min, np.max, np.mean, np.median, np.std, np.size])\nstock_std_stat[ stock_std_cut_range ] = [ (0, 5] ,  (5, 10] ,  (10, 20] ,  (20, 100] ,  (100, 200] ]\nstock_std_stat.set_index( stock_std_cut_range , inplace=True)\nstock_std_stat   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       amin \n       amax \n       mean \n       median \n       std \n       size \n     \n     \n       stock_std_cut_range \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       (0, 5] \n       0.58 \n       5.00 \n       2.756818 \n       2.710 \n       1.217010 \n       154.0 \n     \n     \n       (5, 10] \n       5.04 \n       9.67 \n       6.982667 \n       6.865 \n       1.377019 \n       60.0 \n     \n     \n       (10, 20] \n       10.29 \n       19.54 \n       12.872258 \n       12.490 \n       2.421688 \n       31.0 \n     \n     \n       (20, 100] \n       25.95 \n       32.31 \n       29.096667 \n       29.030 \n       3.180524 \n       3.0 \n     \n     \n       (100, 200] \n       106.09 \n       106.09 \n       106.090000 \n       106.090 \n       NaN \n       1.0 \n     \n      def stock_indicator_plot(stock_data, stock_index):\n    particular = stock_data[stock_index]\n    if  600519  in stock_index:\n        maotai = stock_data[ 600519 ]\n    if  600519  in particular.columns:\n        particular.drop( 600519 , axis=1, inplace=True)\n    particular.columns = particular.columns.reorder_levels([1,0])\n    fig, ax = plt.subplots(figsize=(16,12)) \n    particular[ close ].plot(ax=ax, legend=False if len(stock_index) 30 else True, alpha=0.7)\n    if  600519  in stock_index:    \n        maotai[ close ].plot(secondary_y=True, ax=ax, linewidth=4, legend=True, label=u maotai )\n    ax.set_ylabel(u close price \uffe5 , fontsize=15, fontproperties=font)\n    ax.set_xlabel( )\n    plt.gca().yaxis.grid(True, linestyle =  -. )    \n    plt.title(u \u6caa\u6df1300\u7684\u80a1\u7968\u4ef7\u683c\u8d8b\u52bf , fontproperties=font, fontsize=20)  def stock_pctchange_plot(stock_data, stock_index):\n    if  600688  in stock_index:\n        stock_index.remove( 600688 )\n    if  600871  in stock_index:\n        stock_index.remove( 600871 )\n    particular = stock_data[stock_index]\n    particular.columns = particular.columns.reorder_levels([1,0])    \n    pctchange = particular[ close ].pct_change() * 100.0\n    fig, ax = plt.subplots(figsize=(16,12))\n    pctchange.plot(ax=ax, legend=False if len(stock_index) 30 else True, alpha=0.7)\n    plt.ylabel('pct_change [%]', fontsize=16)\n    plt.xlabel('')\n    plt.title(u \u6caa\u6df1300\u80a1\u7968\u6da8\u8dcc\u5e45(%) , fontsize=20, fontproperties=font)  std   20\u7684\u80a1\u7968  large_index = stock_std_cut[stock_std_cut   2].index.tolist()\nstock_indicator_plot(st_pv_, large_index)\nstock_pctchange_plot(st_pv_, large_index)    10   std   20 \u7684\u80a1\u7968  middle_index = stock_std_cut[stock_std_cut == 2].index.tolist()\nstock_indicator_plot(st_pv_, middle_index)\nstock_pctchange_plot(st_pv_, middle_index)    5   std   10 \u7684\u80a1\u7968  minor_index = stock_std_cut[stock_std_cut == 1].index.tolist()\nstock_indicator_plot(st_pv_, minor_index)\nstock_pctchange_plot(st_pv_, minor_index)    0   std   5 \u7684\u80a1\u7968  poor_index = stock_std_cut[stock_std_cut == 0].index.tolist()\nstock_indicator_plot(st_pv_, poor_index)\nstock_pctchange_plot(st_pv_, poor_index)", 
            "title": "\u6caa\u6df1300\u80a1\u79682012-2017\u6536\u5e02\u4ef7\u683c\u7684\u6ce2\u52a8\u60c5\u51b5\u7edf\u8ba1"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_4", 
            "text": "\u9996\u5148\uff0c\u9009\u62e9\u80a1\u7968\u4ef7\u683c(\u5747\u4ef7\uff09\u572810-30\u5143\u4e4b\u95f4\u7684\u80a1\u7968\u4e3a\u6700\u7ec8\u7814\u7a76\u5bf9\u8c61\uff0c\u5171114\u652f\u80a1\u7968\uff0c\u4ee5\u5f53\u65e5\u6536\u5e02\u80a1\u7968\u6da8\u8dcc\u5e45(pct_change)\u5927\u4e8e0\u7684\u4e3a\u6da8\uff0c\u5c0f\u4e8e0\u7684\u4e3a\u8dcc\u4e3a\u8bc4\u5224\u6807\u51c6\uff0c\u6839\u636e\u524d1\u65e5\u30015\u65e5\u300130\u65e5\u300190\u65e5\u7684\u80a1\u7968\u4fe1\u606f\u4e3a\u4f9d\u636e\u9884\u6d4b\u4eca\u65e5\u80a1\u7968\u7684\u6da8\u8dcc\u60c5\u51b5\u3002  \u5176\u6b21\uff0c\u9009\u62e9\u80a1\u7968\u6536\u5e02\u4ef7\u683c\u3001\u6210\u4ea4\u91cf\u3001\u65e5\u6700\u9ad8\u548c\u6700\u4f4e\u4ef7\u683c\u548c\u5176\u4ed6\u7684tech_features\u59825\u65e5\u5747\u503c\u7b49\u5176\u4ed6\u6839\u636e\u80a1\u7968\u4ef7\u683c\u6210\u4ea4\u91cf\u4fe1\u606f\u8ba1\u7b97\u51fa\u7684\u6307\u6807\uff0c\u5e76\u4e14\u6dfb\u52a0\u4e86\u80a1\u7968\u7684\u57fa\u672c\u9762\u6570\u636e\u3001\u4e2d\u56fd\u80a1\u5e02\u7684\u80a1\u6307\u6570\u636e\u3001\u4e00\u4e9b\u7ecf\u6d4e\u6570\u636e\u7b49\u4fe1\u606f\u6784\u6210\u7279\u5f81\u96c6\u5408\u3002\u7136\u540e\u4f7f\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664\u6cd5\u7b49\u7279\u5f81\u9009\u53d6\u65b9\u6cd5\u8fdb\u884c\u7279\u5f81\u62bd\u53d6\uff0c\u9009\u62e9\u51fa\u7528\u4e8e\u6784\u5efa\u5206\u7c7b\u6a21\u578b\u7684\u7279\u5f81\u96c6\u3002  \u968f\u4e4b\u662f\u6784\u5efa\u5206\u7c7b\u6a21\u578b\uff0c\u91c7\u7528sklearn\u63d0\u4f9b\u7684\u968f\u673a\u68ee\u6797\u3001LogisticRegression\u3001\u51b3\u7b56\u6811\u3001Adaboost\u5206\u7c7b\u7b97\u6cd5\u5206\u522b\u6784\u5efa\u5bf9\u5e94\u7684\u5206\u7c7b\u5668\uff0c\u7136\u540e\u91c7\u7528softVoting\u8fdb\u884c\u6a21\u578b\u878d\u5408\u5f97\u5230\u6700\u7ec8\u7684\u5206\u7c7b\u5668\u3002  \u6839\u636e\u7b2c\u4e00\u6b21\u6784\u5efa\u7684\u5206\u7c7b\u6a21\u578b\uff0c\u5bf9\u90a3\u4e9b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u80a1\u7968\u7528\u7279\u5b9a\u7684\u7279\u5f81\u91cd\u65b0\u5efa\u6a21\u8fdb\u884c\u8bc4\u4f30\u3002", 
            "title": "\u5206\u7c7b\u6a21\u578b\u5efa\u7acb"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_5", 
            "text": "# \u9009\u62e9\u80a1\u7968\u4ef7\u683c(12-17\u5e74\u5747\u503c\uff09\u572810-30\u5143\u4e4b\u95f4\u7684\u80a1\u7968\nstocks_ = st_pv.copy()\nstocks_.columns = st_pv.columns.reorder_levels([1,0])\nst_mean_price = st_pv[ close ].mean()\nstt = st_mean_price[st_mean_price   10.0]\nlarge = set(stt.index)\nsmall = set(stt[stt   30.0].index)\nstockid_list = list(large   small)\n# len(stockid)  # 114\nstocks= stocks_[stockid_list]\nstocks.shape  # (1409, 570)\nstocks.head(2)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       code \n       000002 \n       600066 \n       ... \n       000826 \n       000728 \n     \n     \n       \n       close \n       high \n       low \n       open \n       volume \n       close \n       high \n       low \n       open \n       volume \n       ... \n       close \n       high \n       low \n       open \n       volume \n       close \n       high \n       low \n       open \n       volume \n     \n     \n       date \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       2012-01-04 \n       6.052 \n       6.316 \n       6.044 \n       6.168 \n       474329.0 \n       6.282 \n       6.501 \n       6.179 \n       6.487 \n       39311.0 \n       ... \n       13.505 \n       14.387 \n       13.505 \n       14.269 \n       27417.0 \n       5.249 \n       5.354 \n       5.249 \n       5.354 \n       51205.0 \n     \n     \n       2012-01-05 \n       5.986 \n       6.126 \n       5.937 \n       6.036 \n       528117.0 \n       6.228 \n       6.406 \n       6.193 \n       6.217 \n       54086.0 \n       ... \n       12.622 \n       13.634 \n       12.510 \n       13.375 \n       65717.0 \n       5.174 \n       5.305 \n       5.155 \n       5.230 \n       61228.0 \n     \n     2 rows \u00d7 570 columns   \u5904\u7406\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e  def stock_economy_tackle():\n    stock_en_list = []\n    # \u901a\u8fc7pandas\u5c06csv\u6587\u4ef6\u5185\u5bb9append\u5230\u5217\u8868\u91cc\u7136\u540e\u751f\u6210\u5b57\u5178\u4fbf\u4e8e\u540e\u7eed\u6570\u636e\u5904\u7406\n    for stcok_en in os.listdir( ./datas/stock_economy/ ):\n        st_en_path = os.path.join( ./datas/stock_economy , stcok_en) \n        stock_en_list.append(pd.read_csv(st_en_path, encoding= utf-8 )) \n    stock_en_dict = dict(zip([i[:-9] for i in os.listdir( ./datas/stock_economy/ )], stock_en_list))\n    # \u4e0d\u540c\u6587\u4ef6\u5185\u5bb9\u5206\u522b\u5904\u7406\n    for stock_en in [i[:-9] for i in os.listdir( ./datas/stock_economy/ )]:\n        if stock_en ==  shibor :\n            stock_en_dict[stock_en].set_index(pd.to_datetime(stock_en_dict[stock_en][ date ]), inplace=True)\n            shibor = stock_en_dict[stock_en].drop([ 6M ,  9M ,  1Y ,  date ], axis=1)\n            shibor.columns = shibor.columns.map(lambda x:  shibor_  + x)\n        elif stock_en ==  money :\n            stock_en_dict[stock_en].sort_index(ascending=False, inplace=True)\n            num = len(stock_en_dict[stock_en].columns) - 1\n            stock_en_dict[stock_en] = stock_en_dict[stock_en].append(pd.Series([ 2017.11 ]+[np.nan]*num, index=stock_en_dict[stock_en].columns.values), ignore_index=True)\n            stock_en_dict[stock_en][ month ] = stock_en_dict[stock_en][ month ].astype(str)\n            stock_en_dict[stock_en][ month ] = stock_en_dict[stock_en][ month ].str.replace(r \\. ,  - )\n            stock_en_dict[stock_en].set_index(pd.to_datetime(stock_en_dict[stock_en][ month ]), inplace=True)\n            stock_en_dict[stock_en].drop( month , axis=1, inplace=True)\n            cols = stock_en_dict[stock_en].columns.map(lambda x: x if len(x)   6 else  ).values\n            cols = [i for i in cols if len(i)   1]\n            money = stock_en_dict[stock_en][cols]\n            money = money[ 2013-01-01 :]\n            money = money.astype(np.float)\n            # \u4ece\u6708\u4efd\u6570\u636e\u5347\u91c7\u6837\u5230\u5929\n            money = money .resample( 1D ).mean()\n            money.fillna(method= ffill , inplace=True)\n            money.columns = money.columns.map(lambda x:  money_  + x)\n        elif stock_en ==  lpr :\n            stock_en_dict[stock_en][ date ] = pd.to_datetime(stock_en_dict[stock_en][ date ])\n            stock_en_dict[stock_en].set_index(stock_en_dict[stock_en][ date ], inplace=True)\n            stock_en_dict[stock_en].drop( date , axis=1, inplace=True)\n            stock_en_dict[stock_en].sort_index(ascending=False, inplace=True)\n            stock_en_dict[stock_en].columns = stock_en_dict[stock_en].columns.map(lambda x:  lpr_  + x)\n            ts_a = pd.Series([None]*297, index=pd.date_range(start= 2013-01-01 , end= 2013-10-24 , freq= D ))\n            ts_a.sort_index(ascending=False, inplace=True)\n            lpr = pd.concat([stock_en_dict[stock_en], ts_a], axis=0)\n            lpr.drop(0, axis=1, inplace=True)\n            lpr.fillna(method= ffill , inplace=True)\n        elif stock_en ==  cpi :\n            stock_en_dict[stock_en].sort_index(ascending=False, inplace=True)\n            cpi = stock_en_dict[stock_en].append(pd.Series([2017.11, None], index=stock_en_dict[stock_en].columns), ignore_index=True)\n            cpi[ month ] = cpi[ month ].astype(str)\n            cpi[ month ] = cpi[ month ].str.replace(r \\. ,  - )\n            cpi[ date ] = pd.to_datetime(cpi[ month ])\n            cpi.set_index(cpi[ date ], inplace=True)\n            cpi.drop([ month ,  date ], inplace=True, axis=1)\n            # \u4ece\u6708\u4efd\u6570\u636e\u5347\u91c7\u6837\u5230\u5929\n            cpi = cpi.resample( 1D ).mean()\n            cpi.fillna(method= ffill , inplace=True)\n            cpi = cpi[ 2013-01-01 :]\n    return pd.concat([shibor, money, lpr, cpi], axis=1, join= inner )  \u5904\u7406\u80a1\u7968\u7684\u57fa\u672c\u9762\u6570\u636e  def stock_basics_tackle(stockid, stock_basicd, stock_basic_file_name):\n    stock_basics_df = pd.DataFrame()\n    for skind in stock_basic_file_name:\n        df = stock_basicd[skind]\n        onestock = df[df[u code ] == stockid]        \n        # \u8fd9\u51e0\u4e2a\u6587\u4ef6\u4e2d\u53ea\u6709debt\u6587\u4ef6\u6709\u7279\u6b8a\u7684\u7f3a\u5931\u503c\u201c--\u201d\u6545\u8981\u7279\u6b8a\u5904\u7406\n        if skind == u debt :\n            debt_col = onestock.columns.tolist()        \n            for col in debt_col:\n                onestock[col] = onestock[col].replace( -- , np.nan)\n            debt_col.remove(u code )\n            debt_col.remove(u name )\n            debt_col.remove(u time_q )\n            # \u66f4\u6539DataFrame\u7684\u5217\u7c7b\u578b\n            debt = onestock[debt_col].astype(np.float)\n            debt[u time_q ] = onestock[u time_q ]\n            onestock = debt\n        if skind == u'report':\n            report_col = onestock.columns.tolist() \n            report_col.remove(u code )\n            report_col.remove(u name )\n            report_col.remove(u time_q )\n            report_col.remove(u distrib )\n            report_col.remove(u report_date )            \n            # \u66f4\u6539DataFrame\u7684\u5217\u7c7b\u578b\n            report = onestock[report_col].astype(np.float)\n            report[ time_q ] = onestock[ time_q ]\n            onestock = report           \n        temp = onestock[ time_q ]\n        col_type = onestock.dtypes\n        onestock.drop(col_type[col_type == object].index.values, axis=1, inplace=True)\n        onestock = onestock.astype(np.float)        \n        onestock[ time_q ] = temp\n        num = len(onestock.columns)\n        onestock[ date ] = pd.to_datetime(onestock[ time_q ])\n        onestock = onestock.append(pd.Series([None]*num+[ 2017-11-01 ], index=onestock.columns), ignore_index=True)\n        onestock[ date ] = pd.to_datetime(onestock[ date ])\n        onestock.set_index(onestock[ date ], inplace=True, drop=True)\n        onestock.drop([ date ,  time_q ], axis=1, inplace=True)        \n        # \u4ece\u6708\u4efd\u6570\u636e\u5347\u91c7\u6837\u5230\u5929\n        onestock_dropna = onestock.dropna()\n        if len(onestock_dropna)   1:  # \u53bb\u9664\u4e00\u4e9b\u5168\u4e3a\u7a7a\u7684\u7279\u5f81\uff0c\u8fd9\u6837\u4f1a\u5bfc\u81f4\u4e0d\u540c\u7684\u80a1\u7968\u7684\u7279\u5f81\u6570\u91cf\u4e0d\u4e00\u6837\n            continue\n        onestock.columns = onestock.columns.map(lambda x: skind +  _  + x)\n        onestock = onestock.resample( 1D ).mean()\n        onestock.fillna(method= ffill , inplace=True)\n        temp_df = onestock[ 2013-01-01 :]\n        onestock_ = temp_df.dropna()\n        if onestock_.shape[0]  = 1:\n            if onestock_.iloc[0, :].name   pd.Timestamp( 2013-01-01 ):\n                temp_df.fillna(method= bfill , inplace=True)\n        if stock_basics_df.empty:\n            stock_basics_df = temp_df\n        else:\n            stock_basics_df = stock_basics_df.join(temp_df)            \n    return stock_basics_df  \u5904\u7406\u80a1\u6307\u6570\u636e  def stock_index_tackle():\n    si = pd.read_csv( ./datas/stockindex_2012_2017.csv , parse_dates=True, index_col= date , encoding= utf-8 )    \n    stock_indexes = pd.DataFrame()    \n    for i in si[ code ].unique()[:3]:\n        index_single = si[si[ code ] == i]\n        index_single.drop([ open ,  code ], axis=1, inplace=True)\n        index_single.columns = index_single.columns.map(lambda x: str(i) +  _  + x)\n        if stock_indexes.empty:        \n            stock_indexes = index_single\n        else:\n            stock_indexes = stock_indexes.join(index_single)\n    return stock_indexes  \u8bfb\u53d6\u80a1\u7968\u57fa\u672c\u9762\u6570\u636e  def read_stock_basics():\n    file_cont = []\n    for j in os.listdir( ./datas/stock_basic/ ):\n        file_path = os.path.join( ./datas/stock_basic/ , j)\n        file_cont.append(pd.read_csv(file_path, encoding= utf-8 , dtype={ code : str}))\n    stock_basics = dict(zip([j[:-9] for j in os.listdir( ./datas/stock_basic/ )], file_cont))\n    return stock_basics  \u80a1\u7968\u6da8\u8dcc\u5e45\u5212\u5206\u533a\u95f4  def num_cut(x):\n    if x  0:\n        x = 1\n    elif x  = 0:\n        x = 0\n    return x  \u8ba1\u7b97\u79fb\u52a8\u5e73\u5747  def stock_roll_mean(df):\n    df_temp = pd.DataFrame()\n    for k in [1,5,30,90]:\n        rolling_window = k\n        if  pct_change  in df.columns:\n            df.drop([ pct_change ], axis=1, inplace=True)\n        min_per = int(np.ceil(rolling_window-rolling_window*0.6)) if rolling_window   1 else rolling_window\n        stock_roll = df.rolling(rolling_window, min_periods=min_per).mean()\n        stock_roll.columns = stock_roll.columns.map(lambda x: x +  mean{} .format(rolling_window))\n        if df_temp.empty:\n            df_temp = stock_roll\n        else:\n            df_temp = df_temp.join(stock_roll)            \n    return df_temp", 
            "title": "\u80a1\u7968\u7279\u5f81\u6570\u636e\u5904\u7406"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_6", 
            "text": "# \u80a1\u7968\u7279\u5f81\u9009\u62e9\ndef feature_select(stock_):\n    if  pct_change  in stock_.columns:\n        stock_.drop( pct_change , inplace=True, axis=1)\n    if  close  in stock_.columns:\n        stock_.drop( close , inplace=True, axis=1)\n    y = stock_[ direction ]\n    stock_.drop( direction , axis=1, inplace=True)\n    X = stock_\n    sc = StandardScaler()\n    X_std = sc.fit_transform(X)  \n    feature_name = X.columns.values \n    # \u4f7f\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664(RFE)\u8fdb\u884c\u7279\u5f81\u9009\u62e9\n    estimator = LogisticRegression()\n    selector = RFE(estimator, n_features_to_select=1, step=1)  \n    selector = selector.fit(X_std, y) \n    bag = sorted(zip(feature_name, selector.ranking_, selector.support_),\n                 key=lambda x: x[1])\n    fea_importance = pd.DataFrame(bag)\n    fea_importance.set_index(0,inplace=True)\n    fea_importance.drop(2, axis=1, inplace=True)\n    fea_importance.rename(index=str, columns={1:  RFE_Logistic }, inplace=True)\n    # \u4f7f\u7528\u7ec4\u5408\u51b3\u7b56\u6811(ExtraTrees)\u548c\u7a33\u5b9a\u6027\u9009\u62e9(RandomizedLogisticRegression )\u8fdb\u884c\u7279\u5f81\u9009\u62e9    \n    model_dict = dict(zip([ RandomLR ,  ExtraTree ], [RandomizedLogisticRegression(),\n                                                      ExtraTreesClassifier(n_estimators=1000, random_state=1)]))\n    for i in [ RandomLR ,  ExtraTree ]:\n        model = model_dict[i]\n        model.fit(X if i ==  ExtraTree  else X_std, y)\n        df_fea = pd.DataFrame(sorted(zip(feature_name, \n                model.feature_importances_ if i ==  ExtraTree  else model.scores_),\n                 key=lambda x: x[1], reverse=True))\n        df_fea.set_index(0, inplace=True)\n        df_fea.rename(index=str, columns={1: i}, inplace=True)\n        fea_importance = fea_importance.join(df_fea)\n    RandomLR_list = fea_importance[fea_importance[ RandomLR ]   0].index.tolist()\n    RFELR_list = fea_importance[fea_importance[ RFE_Logistic ]   150].index.tolist()\n    ExtraTree_list = fea_importance[fea_importance[ ExtraTree ]   0.003].index.tolist()\n    # \u4e09\u79cdfeature\u9009\u62e9\u7684\u4ea4\u96c6\n    fea_two = set(RandomLR_list)   set(RFELR_list)\n    fea_thr = fea_two   set(ExtraTree_list)\n    feature_selected = list(fea_thr)\n    return feature_selected", 
            "title": "\u5206\u7c7b\u6a21\u578b\u7279\u5f81\u9009\u62e9"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_7", 
            "text": "\u5206\u7c7b\u6a21\u578b\u7684\u5206\u7c7b\u6548\u679c\u7684\u6df7\u6dc6\u77e9\u9635\u53ef\u89c6\u5316  # \u6df7\u6dc6\u77e9\u9635\u56fe\ndef confusion_group_plot(randomforest_result, logisticR_result, \n                         merge_result,tree_result,ada_result,close_price,pct_change,stockid):\n    # \u8ba1\u7b97\u5404\u4e2a\u5206\u7c7b\u7b97\u6cd5\u6240\u5f97\u7ed3\u679c\u7684\u6df7\u6dc6\u77e9\u9635\n    con_rf = confusion_matrix(randomforest_result[0], randomforest_result[1], labels=[1, 0])    \n    con_lr = confusion_matrix(logisticR_result[0], logisticR_result[1], labels=[1, 0])    \n    con_merge = confusion_matrix(merge_result[0], merge_result[1], labels=[1, 0])    \n    con_tree = confusion_matrix(tree_result[0], tree_result[1], labels=[1, 0])    \n    con_ada = confusion_matrix(ada_result[0], ada_result[1], labels=[1, 0])    \n    # \u6df7\u6dc6\u77e9\u9635\u53ef\u89c6\u5316\n    tick_labels = [u \u6da8 , u \u8dcc ]    \n    fig, axes = plt.subplots(3,2, figsize=(8,12))        \n    ax1 = axes[0][0]\n    ax2 = axes[0][1]\n    ax3 = axes[1][0]        \n    ax4 = axes[1][1]\n    ax5 = axes[2][0]\n    ax6 = axes[2][1]\n    # g1-g5\u662f\u7528seaborn\u7ed8\u5236\u5404\u5206\u7c7b\u7b97\u6cd5\u7684\u6df7\u6dc6\u77e9\u9635\n    g1 = sns.heatmap(con_rf, ax=ax1, cbar=True, annot=True, square=True, fmt= .2f , \n                annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    g2 = sns.heatmap(con_lr, ax=ax2, cbar=True, annot=True, square=True, fmt= .2f , \n                annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    g4 = sns.heatmap(con_ada, ax=ax4, cbar=True, annot=True, square=True, fmt= .2f , \n                annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    g3 = sns.heatmap(con_tree, ax=ax3, cbar=True, annot=True, square=True, \n                     fmt= .2f , annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    g5 = sns.heatmap(con_merge, ax=ax5, cbar=True, annot=True, square=True, \n                     fmt= .2f , annot_kws={'size': 12}, yticklabels=tick_labels,xticklabels=tick_labels)\n    # ax6\u548cax7\u662f\u53ccy\u8f74\u56fe\uff0c\u7528\u4e8e\u80a1\u7968\u7684\u6da8\u8dcc\u5e45\u548c\u4ef7\u683c\u7684\u53ef\u89c6\u5316\u8f93\u51fa\n    pct_change.plot(ax=ax6, legend=False, alpha=0.8)\n    ax7 = ax6.twinx()\n    close_price.plot(ax=ax7, legend=True, color= r ,alpha=0.6)\n    # \u4ee5\u4e0b\u4e3atitle\u3001x_axis\u3001x_label\u3001y_axis\u3001y_label\u7684\u8bbe\u7f6e\n    ax7.set_ylabel(u \u80a1\u7968\u4ef7\u683c \uffe5 , fontsize=14, fontproperties=font)\n    ax6.set_ylabel( pct_change , fontsize=17, fontproperties=font)\n    ax6.set_xlabel( )    \n    ax6.set_title( {} pct_chage   close_price .format(stockid),fontsize=14)\n    ax5.set_title(u Merge-Softvote , fontsize=15, fontproperties=font)    \n    ax1.set_title(u RandomForest , fontsize=15, fontproperties=font)\n    ax2.set_title(u LogisticRegression , fontsize=15, fontproperties=font)    \n    ax3.set_title(u Tree , fontsize=15, fontproperties=font)    \n    ax4.set_title(u Adaboosgt , fontsize=15, fontproperties=font) \n    ax5.set_title(u Merge-Softvote , fontsize=15, fontproperties=font)    \n    # \u6587\u672c\u6807\u6ce8\n    ax1.text(0.3,-0.23,s=randomforest_result[2],fontsize=12,va= bottom ,ha= left ,fontproperties=font,color='green')\n    ax2.text(0.3,-0.23,s=logisticR_result[2],fontsize=12,va= bottom ,ha= left ,fontproperties=font,color='red')\n    ax4.text(0.3,-0.23,s=ada_result[2],fontsize=12,va= bottom ,ha= left ,fontproperties=font,color='blue')\n    ax3.text(0.3,-0.23,s=tree_result[2],fontsize=12,va= bottom ,ha= left ,fontproperties=font,color='purple')\n    ax5.text(0.3,-0.23,s=merge_result[2],fontsize=12,va= bottom ,ha= left ,fontproperties=font,color='k')\n    # x\u3001y\u8f74\u8bbe\u7f6e\n    ax1.set_yticklabels(g1.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax1.set_xticklabels(g1.get_xticklabels(), fontproperties=font, fontsize=12)\n    ax2.set_yticklabels(g2.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax2.set_xticklabels(g2.get_xticklabels(), fontproperties=font, fontsize=12)\n    ax3.set_yticklabels(g3.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax3.set_xticklabels(g3.get_xticklabels(), fontproperties=font, fontsize=12)\n    ax4.set_yticklabels(g4.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax4.set_xticklabels(g4.get_xticklabels(), fontproperties=font, fontsize=12)        \n    ax5.set_yticklabels(g5.get_yticklabels(), fontproperties=font, fontsize=12)\n    ax5.set_xticklabels(g5.get_xticklabels(), fontproperties=font, fontsize=12)        \n    #\u8f74\u6807\u7b7e\u8bbe\u7f6e\n    ax1.set_ylabel(u \u5b9e\u9645 , fontsize=15, fontproperties=font)\n    ax1.set_xlabel(u \u9884\u6d4b , fontsize=15, fontproperties=font)\n    ax2.set_ylabel(u \u5b9e\u9645 , fontsize=15, fontproperties=font)\n    ax2.set_xlabel(u \u9884\u6d4b , fontsize=15, fontproperties=font)\n    ax3.set_ylabel(u \u5b9e\u9645 , fontsize=15, fontproperties=font)\n    ax3.set_xlabel(u \u9884\u6d4b , fontsize=15, fontproperties=font)\n    ax4.set_ylabel(u \u5b9e\u9645 , fontsize=15, fontproperties=font)\n    ax4.set_xlabel(u \u9884\u6d4b , fontsize=15, fontproperties=font)\n    ax5.set_ylabel(u \u5b9e\u9645 , fontsize=15, fontproperties=font)\n    ax5.set_xlabel(u \u9884\u6d4b , fontsize=15, fontproperties=font)\n    plt.tight_layout() \n    plt.show()  \n    # \u4fdd\u5b58\u56fe\u7247\n    fig.savefig( ./classificationResult/reasses/{}_classification_result.png .format(stockid))  \u5206\u7c7b\u5668\u8bad\u7ec3  # \u968f\u673a\u68ee\u6797\u5206\u7c7b\u5668\ndef random_forest(stock_, stock_y, feature_selected):\n    train_num = int(stock_.shape[0] * 0.85)\n    if  pct_change  in stock_.columns:\n        stock_.drop( pct_change , inplace=True, axis=1)\n    if  close  in stock_.columns:\n        stock_.drop( close , inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    random_forest = RandomForestClassifier(max_features= auto ,n_estimators=3000, class_weight= balanced ,random_state=24)\n    parameters = {'max_depth':[6,7,8]}\n    gs = GridSearchCV(estimator=random_forest, param_grid=parameters, \n                        scoring= accuracy , cv=3, n_jobs=3)\n    gs.fit(X_train, y_train)\n    rf = gs.best_estimator_\n    rf.fit(X_train, y_train)\n    rf_prediction_train = rf.predict(X_train)\n    rf_prediction_test = rf.predict(X_test)\n    rf_evaluate_result = classification_report(y_test, rf_prediction_test)\n    train_accuracy = np.round(accuracy_score(y_train, rf_prediction_train),4)\n    test_accuracy = np.round(accuracy_score(y_test, rf_prediction_test),4) \n    train_f = np.round(f1_score(y_train, rf_prediction_train),4)\n    test_f = np.round(f1_score(y_test, rf_prediction_test),4)\n    cls_accuracy =  train:{0},test:{1} .format(train_accuracy, test_accuracy)\n    cls_f =  train:{0},test:{1} .format(train_f, test_f)  \n    cls_report =  classifationReport:{} .format(rf_evaluate_result)    \n    print( rf,{} .format(cls_report))\n    return [y_test, rf_prediction_test,cls_accuracy,cls_f,rf]      # Logistic \u5206\u7c7b\u5668\ndef logistic(stock_, stock_y, feature_selected):\n    # \u4f7f\u7528\u9009\u62e9\u7684\u7279\u5f81\u8bad\u7ec3LogisticRegression\u5206\u7c7b\u5668\n    train_num = int(stock_.shape[0] * 0.85)\n    if  pct_change  in stock_.columns:\n        stock_.drop( pct_change , inplace=True, axis=1)\n    if  close  in stock_.columns:\n        stock_.drop( close , inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    sc = StandardScaler()\n    sc.fit(X_train)  # \u8ba1\u7b97\u5747\u503c\u548c\u65b9\u5dee\n    X_train_std = sc.transform(X_train)  # \u8fdb\u884c\u6807\u51c6\u53d8\u6362\uff0c\u53d8\u6210\u6807\u51c6\u6b63\u6001\u5206\u5e03\n    X_test_std = sc.transform(X_test)\n    parameters = {'C':[0.04, 0.05, 0.06]}\n    logistic = LogisticRegression(penalty= l2 , random_state=24, tol=1e-6)\n    gs = GridSearchCV(estimator=logistic, param_grid=parameters, \n                        scoring= accuracy , cv=3, n_jobs=3)\n    gs.fit(X_train_std, y_train)\n    lr = gs.best_estimator_\n    lr.fit(X_train_std, y_train)\n    y_pred_test = lr.predict(X_test_std)\n    y_pred_train = lr.predict(X_train_std)    \n    lr_evaluate_result = classification_report(y_test, y_pred_test)\n    train_accuracy = np.round(accuracy_score(y_train, y_pred_train),4)\n    test_accuracy = np.round(accuracy_score(y_test, y_pred_test),4) \n    train_f = np.round(f1_score(y_train, y_pred_train),4)\n    test_f = np.round(f1_score(y_test, y_pred_test),4)\n    lr_accuracy =  train:{0},test:{1} .format(train_accuracy, test_accuracy) \n    lr_f =  train:{0},test:{1} .format(train_f, test_f) \n    lr_report =  classifationReport:{} .format(lr_evaluate_result)    \n    print( lr,{} .format(lr_report))\n    return [y_test, y_pred_test, lr_accuracy, lr_f, lr]  # \u6a21\u578b\u878d\u5408\u2014\u2014softVoting\ndef merge(stock_, stock_y, feature_selected, models):\n    train_num = int(stock_.shape[0] * 0.85)\n    if  pct_change  in stock_.columns:\n        stock_.drop( pct_change , inplace=True, axis=1)\n    if  close  in stock_.columns:\n        stock_.drop( close , inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    sc = StandardScaler()\n    sc.fit(X_train)  \n    X_train_std = sc.transform(X_train)  \n    X_test_std = sc.transform(X_test)\n    lr = models.get( lr )\n    rf = models.get( rf )\n    tree = models.get( tree )\n    ada = models.get( ada )    \n    eclf = VotingClassifier(estimators=[( lr , lr),('rf', rf),('ada', ada),('tree', tree),], voting='soft',weights=[1.2,1.2,1.1,0.8]) \n    eclf.fit(X_train_std, y_train)\n    eclf_pred_test = eclf.predict(X_test_std)\n    eclf_pred_train = eclf.predict(X_train_std)\n    eclf_train_accu = np.round(accuracy_score(y_train, eclf_pred_train),4)\n    eclf_test_accu = np.round(accuracy_score(y_test, eclf_pred_test),4)\n    eclf_train_f = np.round(f1_score(y_train, eclf_pred_train),4)\n    eclf_test_f = np.round(f1_score(y_test, eclf_pred_test),4)\n    eclf_evaluate_result = classification_report(y_test, eclf_pred_test)\n    merge_result =  train:{0}, test:{1} .format(eclf_train_accu, eclf_test_accu)\n    merge_result_f =  train:{0}, test:{1} .format(eclf_train_f, eclf_test_f)\n    print( merge,{} .format(eclf_evaluate_result))\n    return [y_test, eclf_pred_test, merge_result, merge_result_f]  # \u51b3\u7b56\u6811\u5206\u7c7b\u5668\ndef tree(stock_, stock_y, feature_selected):\n    train_num = int(stock_.shape[0] * 0.85)\n    if  pct_change  in stock_.columns:\n        stock_.drop( pct_change , inplace=True, axis=1)\n    if  close  in stock_.columns:\n        stock_.drop( close , inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    decision_tree = DecisionTreeClassifier(random_state=24)\n    parameters = {'max_depth':[9,10,11]}\n    gs = GridSearchCV(estimator=decision_tree, param_grid=parameters, \n                        scoring= accuracy , cv=3, n_jobs=3)\n    gs.fit(X_train, y_train)\n    tree = gs.best_estimator_\n    tree.fit(X_train, y_train)\n    tree_pred_test = tree.predict(X_test)\n    tree_evaluate_result = classification_report(y_test, tree_pred_test)\n    tree_pred_train = tree.predict(X_train)    \n    train_accuracy = np.round(accuracy_score(y_train, tree_pred_train),4)\n    test_accuracy = np.round(accuracy_score(y_test, tree_pred_test),4) \n    train_f = np.round(f1_score(y_train, tree_pred_train),4)\n    test_f = np.round(f1_score(y_test, tree_pred_test),4)\n    tree_accuracy =  train:{0},test:{1} .format(train_accuracy, test_accuracy) \n    tree_f =  train:{0},test:{1} .format(train_f, test_f)  \n    tree_report =  classifationReport:{} .format(tree_evaluate_result)    \n    print( tree,{} .format(tree_report))\n    return [y_test, tree_pred_test, tree_accuracy,tree_f,tree]  # Boosting\u5206\u7c7b\u5668\ndef adaboost(stock_, stock_y, feature_selected):\n    train_num = int(stock_.shape[0] * 0.85)\n    if  pct_change  in stock_.columns:\n        stock_.drop( pct_change , inplace=True, axis=1)\n    if  close  in stock_.columns:\n        stock_.drop( close , inplace=True, axis=1)\n    X = stock_[feature_selected]\n    X_train = X[:train_num]\n    X_test = X[train_num:]\n    y_train = stock_y[:train_num]\n    y_test = stock_y[train_num:]\n    sc = StandardScaler()\n    sc.fit(X_train)  \n    X_train_std = sc.transform(X_train)  \n    X_test_std = sc.transform(X_test)\n    tree = DecisionTreeClassifier(max_depth=5, random_state=24)    \n    adaboost = AdaBoostClassifier(base_estimator=tree, random_state=24)\n    parameters = [{'n_estimators':[1000,2000]}, { learning_rate :[0.05,0.08,0.11]}]\n    gs = GridSearchCV(estimator=adaboost, param_grid=parameters, \n                        scoring= accuracy , cv=3, n_jobs=3)\n    gs.fit(X_train_std, y_train)\n    ada = gs.best_estimator_\n    ada = ada.fit(X_train_std, y_train)\n    ada_test_pred = ada.predict(X_test_std)\n    ada_train_pred = ada.predict(X_train_std)    \n    ada_evaluate_result = classification_report(y_test, ada_test_pred)\n    test_f = np.round(f1_score(y_test, ada_test_pred),4)    \n    train_f = np.round(f1_score(y_train, ada_train_pred),4)\n    train_accuracy = np.round(accuracy_score(y_train, ada_train_pred),4)\n    test_accuracy = np.round(accuracy_score(y_test, ada_test_pred),4)    \n    ada_accuracy =  train:{0},test:{1} .format(train_accuracy, test_accuracy)\n    ada_f =  train:{0},test:{1} .format(train_f, test_f)  \n    ada_report =  classifationReport:{} .format(ada_evaluate_result) \n    print( ada,{} .format(ada_report))\n    return [y_test, ada_test_pred, ada_accuracy, ada_f, ada]  def stock_tackle(stockid_list, stocks, features=None, feature_select=1):\n    sf = StockFeature()  \n    clf_result =  ./classificationResult/reasses/ClassificationResultAccuracy.csv \n    clf_result_ =  ./classificationResult/reasses/ClassificationResultReport.csv \n    feature_result =  ./classificationResult/reasses/FeatureResult.csv     \n    stock_basic_file_name = [i[:-9] for i in os.listdir( ./datas/stock_basic/ )]    \n    stock_basics = read_stock_basics()\n    stock_index = stock_index_tackle()\n    stock_eco = stock_economy_tackle()    \n    # \u53d6\u51fa\u6bcf\u4e00\u652f\u80a1\u7968\u8fdb\u884c\u7279\u5f81\u62bd\u53d6\u548c\u6a21\u578b\u8bad\u7ec3\u7684\u5904\u7406\n    for i, stid in enumerate(stockid_list):        \n        models = {}  # \u4fdd\u5b58\u6a21\u578b\u53c2\u6570\u7528\u4e8e\u6700\u540e\u7684\u6a21\u578b\u878d\u5408        \n        tar_st = stocks[stid]\n        tar_st[ pct_change ] = tar_st[ close ].pct_change() * 100\n        tar_st.drop(tar_st[tar_st[ pct_change ]   11.0].index, inplace=True)\n        tar_st.drop(tar_st[tar_st[ pct_change ]   -11.0].index, inplace=True)\n        tar_st.drop([ pct_change ,  open ], inplace=True, axis=1)\n        # \u63d0\u53d6\u80a1\u7968\u7684tech_features\n        stock_tech_fea = sf.extract_stock_fea(tar_st)\n        stock_roll = stock_roll_mean(stock_tech_fea)       \n        # \u589e\u52a0\u80a1\u6307\u6570\u636e\n        stock_roll = stock_roll.join(stock_index)\n        # \u589e\u52a0\u5b8f\u89c2\u7ecf\u6d4e\u6570\u636e\n        stock_roll = stock_roll.join(stock_eco)\n        # \u589e\u52a0\u80a1\u7968\u57fa\u672c\u9762\u6570\u636e\n        stock_basic_one = stock_basics_tackle(stid, stock_basics, stock_basic_file_name)\n        stock_roll = stock_roll.join(stock_basic_one)\n        stock_roll = stock_roll.shift(1)\n        # \u589e\u52a0\u5206\u7c7b\u6807\u7b7e\n        tar_close = pd.DataFrame(index=tar_st.index)\n        tar_close[ close ] = tar_st[ close ]         \n        tar_close[ pct_change ] = tar_st[ close ].pct_change() * 100 \n        tar_close[ direction ] = tar_close[ pct_change ].apply(num_cut)\n        close_price = tar_close[ close ]\n        pct_change = tar_close[ pct_change ]        \n        tar_close.drop([ pct_change ], axis=1, inplace=True)\n        tar_close.drop([ close ], axis=1, inplace=True)\n        stock_roll = stock_roll.join(tar_close)\n        stock_roll.dropna(inplace=True)\n        Y = stock_roll[ direction ]\n        # \u6a21\u578b\u7279\u5f81\u9009\u62e9\n        if feature_select == 1:\n            feature_selected = feature_select(stock_roll)\n        else:\n            feature_selected = features\n        # \u6a21\u578b\u8bad\u7ec3\n        if  direction  in stock_roll.columns:\n            stock_roll.drop( direction , axis=1, inplace=True)\n        randomforest_result = random_forest(stock_roll, Y, feature_selected)\n        logisticR_result = logistic(stock_roll, Y, feature_selected)\n        tree_result = tree(stock_roll, Y, feature_selected)\n        ada_result = adaboost(stock_roll, Y, feature_selected)\n        models[ rf ] = randomforest_result[4]\n        models[ lr ] = logisticR_result[4]\n        models[ tree ] = tree_result[4]\n        models[ ada ] = ada_result[4]\n        merge_result = merge(stock_roll, Y, feature_selected, models)        \n        # \u6df7\u6dc6\u77e9\u9635\u53ef\u89c6\u5316\n        confusion_group_plot(randomforest_result, logisticR_result,\n                             merge_result,tree_result,ada_result,\n                             close_price, pct_change,stid)\n        # \u5206\u7c7b\u7279\u5f81\u4fdd\u5b58\n        if feature_select == 1:\n            feature_selected.insert(0, stid)\n            feature_str =  , .join(feature_selected)\n            with open(feature_result,  a ) as f:\n                f.write( feature_str +  \\n )\n        # \u5206\u7c7b\u7ed3\u679c\u4fdd\u5b58\n        classification_accuracy =  , .join([stid,randomforest_result[2],logisticR_result[2],tree_result[2],ada_result[2],merge_result[2]]) +  \\n  \n        classification_reportf1 =  , .join([stid,randomforest_result[3],logisticR_result[3],tree_result[3],ada_result[3],merge_result[3]]) + str(stock_roll.shape) +  \\n  \n        with open(clf_result,  a ) as f:\n            f.write(classification_accuracy)\n        with open(clf_result_,  a ) as f:\n            f.write(classification_reportf1)  \u5206\u7c7b\u6a21\u578b\u7ed3\u679c\u8f93\u51fa  # \u5206\u7c7b\u7ed3\u679c\u8f93\u51fa\uff0c\u7ed3\u679c\u592a\u957f,\u7565...\nstock_tackle(stockid_list, stocks)", 
            "title": "\u6a21\u578b\u8bad\u7ec3"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_8", 
            "text": "# \u5206\u7c7b\u51c6\u786e\u7387\naccuracy = pd.read_csv( ./classification_result_accuracy.csv ,encoding= utf-8 , dtype=str)\naccuracy.set_index( stockid , inplace=True)\naccuracy.head(2)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       rf_train_accuracy \n       rf_test_accuracy \n       lr_train_accuracy \n       lr_test_accuracy \n       tree_train_accuracy \n       tree_test_accuracy \n       ada_train_accuracy \n       ada_test_accuracy \n       merge_train_accuracy \n       merge_test_accuracy \n     \n     \n       stockid \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       002450 \n       0.9032 \n       0.5833 \n       0.5874 \n       0.5476 \n       0.9179 \n       0.5595 \n       0.9979 \n       0.5952 \n       0.9874 \n       0.5357 \n     \n     \n       600999 \n       0.8713 \n       0.5038 \n       0.5528 \n       0.458 \n       0.8496 \n       0.4733 \n       1.0 \n       0.5191 \n       1.0 \n       0.4733 \n     \n      # \u5206\u7c7bf1scrore\nfscore = pd.read_csv( ./classification_result_fscore.csv ,encoding= utf-8 , dtype=str)\nfscore.set_index( stockid , inplace=True)\nfscore.head(2)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       rf_train_fscore \n       rf_test_fscore \n       lr_train_fscore \n       lr_test_fscore \n       tree_train_fscore \n       tree_test_fscore \n       ada_train_fscore \n       ada_test_fscore \n       merge_train_fscore \n       merge_test_fscore \n     \n     \n       stockid \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       002450 \n       0.9112 \n       0.6535 \n       0.6423 \n       0.4242 \n       0.9234 \n       0.5934 \n       0.998 \n       0.66 \n       0.9882 \n       0.5979 \n     \n     \n       600999 \n       0.8633 \n       0.4037 \n       0.5352 \n       0.4409 \n       0.8326 \n       0.3429 \n       1.0 \n       0.496 \n       1.0 \n       0.3784 \n     \n      # \u5404\u80a1\u7968\u5206\u7c7b\u6a21\u578b\u6784\u5efa\u4f7f\u7528\u7684\u7279\u5f81\nstock_feature_selected_file =  ./feature_selected.csv \nfeature_selected = pd.read_csv(stock_feature_selected_file,header=None,encoding= utf-8 , dtype=str)\nfeature_selected.set_index(0, inplace=True)\nfeature_selected.index.rename( stockid , inplace=True)\nfeature_selected.columns = [ fea_num ,  fea_name ]\nfeature_selected.head(2)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       fea_num \n       fea_name \n     \n     \n       stockid \n       \n       \n     \n   \n   \n     \n       002450 \n       14 \n       volume_roll_20_maxmean90::volume_roll_5_ppmean... \n     \n     \n       600999 \n       9 \n       Lag60mean30::macd_deamean30::volume_roll_20_pp... \n     \n      # \u5408\u5e76\u6587\u4ef6\nresult = pd.concat([feature_selected, accuracy, fscore], axis=1)\nresult.head(2)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       fea_num \n       fea_name \n       rf_train_accuracy \n       rf_test_accuracy \n       lr_train_accuracy \n       lr_test_accuracy \n       tree_train_accuracy \n       tree_test_accuracy \n       ada_train_accuracy \n       ada_test_accuracy \n       ... \n       rf_train_fscore \n       rf_test_fscore \n       lr_train_fscore \n       lr_test_fscore \n       tree_train_fscore \n       tree_test_fscore \n       ada_train_fscore \n       ada_test_fscore \n       merge_train_fscore \n       merge_test_fscore \n     \n     \n       stockid \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       002450 \n       14 \n       volume_roll_20_maxmean90::volume_roll_5_ppmean... \n       0.9032 \n       0.5833 \n       0.5874 \n       0.5476 \n       0.9179 \n       0.5595 \n       0.9979 \n       0.5952 \n       ... \n       0.9112 \n       0.6535 \n       0.6423 \n       0.4242 \n       0.9234 \n       0.5934 \n       0.998 \n       0.66 \n       0.9882 \n       0.5979 \n     \n     \n       600999 \n       9 \n       Lag60mean30::macd_deamean30::volume_roll_20_pp... \n       0.8713 \n       0.5038 \n       0.5528 \n       0.458 \n       0.8496 \n       0.4733 \n       1.0 \n       0.5191 \n       ... \n       0.8633 \n       0.4037 \n       0.5352 \n       0.4409 \n       0.8326 \n       0.3429 \n       1.0 \n       0.496 \n       1.0 \n       0.3784 \n     \n     2 rows \u00d7 22 columns   fea_name = result[ fea_name ]\nresult.drop( fea_name , axis=1, inplace=True)\nresult = result.astype(np.float)\nresult[ fea_name ] = fea_name\nresult.describe()   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       fea_num \n       rf_train_accuracy \n       rf_test_accuracy \n       lr_train_accuracy \n       lr_test_accuracy \n       tree_train_accuracy \n       tree_test_accuracy \n       ada_train_accuracy \n       ada_test_accuracy \n       merge_train_accuracy \n       ... \n       rf_train_fscore \n       rf_test_fscore \n       lr_train_fscore \n       lr_test_fscore \n       tree_train_fscore \n       tree_test_fscore \n       ada_train_fscore \n       ada_test_fscore \n       merge_train_fscore \n       merge_test_fscore \n     \n   \n   \n     \n       count \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       ... \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n       114.000000 \n     \n     \n       mean \n       14.736842 \n       0.931375 \n       0.535332 \n       0.576775 \n       0.539644 \n       0.848904 \n       0.518705 \n       0.997176 \n       0.513425 \n       0.987729 \n       ... \n       0.931418 \n       0.505799 \n       0.591576 \n       0.516610 \n       0.848570 \n       0.504644 \n       0.997196 \n       0.508587 \n       0.987868 \n       0.509133 \n     \n     \n       std \n       5.507923 \n       0.047039 \n       0.044155 \n       0.020905 \n       0.044296 \n       0.076324 \n       0.046297 \n       0.008231 \n       0.044125 \n       0.016967 \n       ... \n       0.048054 \n       0.117307 \n       0.062980 \n       0.144329 \n       0.085231 \n       0.102104 \n       0.008179 \n       0.085687 \n       0.016824 \n       0.098467 \n     \n     \n       min \n       2.000000 \n       0.780500 \n       0.429600 \n       0.521500 \n       0.451100 \n       0.644100 \n       0.373200 \n       0.952500 \n       0.392400 \n       0.923600 \n       ... \n       0.779500 \n       0.038500 \n       0.165300 \n       0.000000 \n       0.400000 \n       0.140400 \n       0.952200 \n       0.228600 \n       0.918200 \n       0.140400 \n     \n     \n       25% \n       11.250000 \n       0.897700 \n       0.508825 \n       0.563525 \n       0.508925 \n       0.797925 \n       0.493250 \n       0.999250 \n       0.486125 \n       0.982825 \n       ... \n       0.896425 \n       0.447150 \n       0.564025 \n       0.473550 \n       0.799850 \n       0.449125 \n       0.999250 \n       0.474700 \n       0.983400 \n       0.471225 \n     \n     \n       50% \n       14.000000 \n       0.937250 \n       0.536100 \n       0.575250 \n       0.537850 \n       0.851200 \n       0.520500 \n       1.000000 \n       0.517500 \n       0.995250 \n       ... \n       0.938100 \n       0.518300 \n       0.600450 \n       0.541600 \n       0.855050 \n       0.522850 \n       1.000000 \n       0.515050 \n       0.995550 \n       0.525050 \n     \n     \n       75% \n       18.750000 \n       0.971250 \n       0.564900 \n       0.590150 \n       0.569000 \n       0.913475 \n       0.543225 \n       1.000000 \n       0.534675 \n       1.000000 \n       ... \n       0.971650 \n       0.591875 \n       0.625400 \n       0.616650 \n       0.914700 \n       0.571400 \n       1.000000 \n       0.571025 \n       1.000000 \n       0.577725 \n     \n     \n       max \n       30.000000 \n       1.000000 \n       0.695700 \n       0.640100 \n       0.658500 \n       0.992800 \n       0.634900 \n       1.000000 \n       0.615400 \n       1.000000 \n       ... \n       1.000000 \n       0.704200 \n       0.704700 \n       0.708700 \n       0.992900 \n       0.691900 \n       1.000000 \n       0.700600 \n       1.000000 \n       0.695700 \n     \n     8 rows \u00d7 21 columns   result.head(3)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       fea_num \n       rf_train_accuracy \n       rf_test_accuracy \n       lr_train_accuracy \n       lr_test_accuracy \n       tree_train_accuracy \n       tree_test_accuracy \n       ada_train_accuracy \n       ada_test_accuracy \n       merge_train_accuracy \n       ... \n       rf_test_fscore \n       lr_train_fscore \n       lr_test_fscore \n       tree_train_fscore \n       tree_test_fscore \n       ada_train_fscore \n       ada_test_fscore \n       merge_train_fscore \n       merge_test_fscore \n       fea_name \n     \n     \n       stockid \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       002450 \n       14.0 \n       0.9032 \n       0.5833 \n       0.5874 \n       0.5476 \n       0.9179 \n       0.5595 \n       0.9979 \n       0.5952 \n       0.9874 \n       ... \n       0.6535 \n       0.6423 \n       0.4242 \n       0.9234 \n       0.5934 \n       0.998 \n       0.6600 \n       0.9882 \n       0.5979 \n       volume_roll_20_maxmean90::volume_roll_5_ppmean... \n     \n     \n       600999 \n       9.0 \n       0.8713 \n       0.5038 \n       0.5528 \n       0.4580 \n       0.8496 \n       0.4733 \n       1.0000 \n       0.5191 \n       1.0000 \n       ... \n       0.4037 \n       0.5352 \n       0.4409 \n       0.8326 \n       0.3429 \n       1.000 \n       0.4960 \n       1.0000 \n       0.3784 \n       Lag60mean30::macd_deamean30::volume_roll_20_pp... \n     \n     \n       601633 \n       28.0 \n       0.9153 \n       0.5435 \n       0.6072 \n       0.5145 \n       0.9037 \n       0.5435 \n       1.0000 \n       0.5507 \n       0.9884 \n       ... \n       0.2588 \n       0.5854 \n       0.1299 \n       0.9007 \n       0.5828 \n       1.000 \n       0.3111 \n       0.9880 \n       0.2444 \n       Lag60mean30::sz_low::volume_roll_10_minmean5::... \n     \n     3 rows \u00d7 22 columns   5\u79cd\u4e0d\u540c\u5206\u7c7b\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u7684\u8868\u73b0  def test_score_plot(df, regex, score_type):\n    score = result.filter(regex=regex)\n    score.columns = score.columns.map(lambda x: re.match(r (.*?)_.* , x).group(1))\n    score.sort_values( merge , ascending=False, inplace=True)\n    score.columns = [ randomForest ,  LogisiticRegression ,  decisionTree ,  Adaboost ,  merge-softvoting ]\n    merge_ = score[ merge-softvoting ]\n    score.drop( merge-softvoting , axis=1, inplace=True)\n    fig, ax = plt.subplots(figsize=(12,9))\n    score.plot(legend=True, ax=ax, grid=False, alpha=0.9)\n    merge_.plot(ax=ax, lw=4, legend=True, grid=False)\n    plt.gca().yaxis.grid(True, linestyle =  -. )\n    plt.xlabel( )\n    plt.ylabel(u {} .format(score_type), fontsize=16, fontproperties=font)\n    plt.title(u \u4e94\u79cd\u5206\u7c7b\u6a21\u578b\u6d4b\u8bd5\u96c6{} .format(score_type), fontsize=20, fontproperties=font)  accuracy_regex= .*?_test_accuracy \ntest_score_plot(result, accuracy_regex, u \u51c6\u786e\u7387 )   fscore_regex= .*?_test_fscore \ntest_score_plot(result, fscore_regex,  f1_score )   # \u5206\u7c7bf1 score\u4e0d\u9ad8\u4e8e50%\u7684\u6bd4\u4f8b\nmerge_test = result[[ merge_test_accuracy ,  merge_test_fscore ]]\nfscore_low_num = merge_test.loc[merge_test[ merge_test_fscore ]  = 0.501, :].shape[0]  # (46,2)\nnp.float(fscore_low_num) / merge_test.shape[0] * 100  37.719298245614034  # \u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u6bd4\u4f8b\naccuracy_low_num = merge_test.loc[merge_test[ merge_test_accuracy ]  = 0.501, :].shape[0]  # (46,2)\nnp.float(accuracy_low_num) / merge_test.shape[0] * 100  30.701754385964914  # \u627e\u51fa\u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u80a1\u7968\naccuracy_low_index = merge_test.loc[merge_test[ merge_test_accuracy ]  = 0.501, :].index.tolist()\nlen(result.loc[accuracy_low_index,  merge_test_accuracy ])  # 35\naccuracy_low_index[:2]  [u'600999', u'002352']  \u6240\u6709\u80a1\u7968\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u4e8e50%\u548c\u4e0d\u9ad8\u4e8e50%\u7684\u6570\u91cf  def test_score_count(df, index_name, score_name):\n    group_name = [u \u51c6\u786e\u7387 0.50 , u \u51c6\u786e\u7387 =0.50 ]\n    bins = [0.1, 0.5, 0.7]\n    score_bins = pd.cut(df, bins,labels=index_name, retbins=True)\n    score_bin_kind = pd.DataFrame(score_bins[0].value_counts())\n    score_bin_kind[ index_name ] = index_name\n    score_bin_kind.columns = [ score ,  index_name ]\n    plt.figure(figsize=(4,3)) \n    g = sns.barplot(x= index_name , y= score , data=score_bin_kind)\n    plt.xticks(g.get_xticks(), fontproperties=font, fontsize=16)\n    plt.ylabel(u \u6570\u91cf , fontsize=16, fontproperties=font)\n    plt.xlabel( )\n    plt.title(u \u80a1\u7968\u6570\u91cf\u5bf9\u6bd4\u2014{} .format(score_name), fontproperties=font, fontsize=18)\n    plt.gca().yaxis.grid(True, linestyle =  -. ,)\n    text_loc = zip(g.get_xticks(), score_bin_kind[ score ].values)    \n    plt.text(text_loc[0][0],text_loc[0][1],s=str(score_bin_kind[ score ].values[0]), fontsize=16,va= bottom ,ha= center ,fontproperties=font)\n    plt.text(text_loc[1][0],text_loc[1][1],s=str(score_bin_kind[ score ].values[1]), fontsize=16,va= bottom ,ha= center ,fontproperties=font)    \n    if  ress  not in score_name:\n        plt.ylim(0,90)\n    else:\n        plt.ylim(0,25)  test_score_count(merge_test[ merge_test_accuracy ], [u \u51c6\u786e\u7387 0.50 ,u \u51c6\u786e\u7387 =0.50 ],u \u51c6\u786e\u7387 )   test_score_count(merge_test[ merge_test_fscore ], [u f1_score 0.50 ,u f1_score =0.50 ],u f1_score )   \u65e0\u8bba\u662f\u51c6\u786e\u7387\u8fd8\u662ff1\uff0c\u5927\u4e8e50%\u7684\u80a1\u7968\u6570\u91cf\u8d85\u8fc760%  # accuracy\u4e0ef1_score\u5bf9\u6bd4\nmerge_test_sorted = merge_test.sort_index()\nmerge_test_sorted.columns = [ accuracy ,  f1_score ]\nmerge_test_sorted.plot(figsize=(8,6), grid=False)\nplt.gca().yaxis.grid(True, linestyle =  -. )\nplt.xlabel( )\nplt.ylabel(u accuracy   f1_score , fontsize=16)\nplt.title(u \u5404\u80a1\u7968\u5728\u6d4b\u8bd5\u96c6\u7684accuracy\u4e0ef1_score\u5bf9\u6bd4 , fontsize=20, fontproperties=font)  matplotlib.text.Text at 0x7f8509327990    fscore_low_index = merge_test.loc[merge_test[ merge_test_fscore ]  = 0.501, :].index.tolist()\nfscore_low_index  fscore_low = result.loc[merge_test[ merge_test_fscore ]  = 0.501, :]\nfscore_low[ fea_num ].describe()  count    43.000000\nmean     14.558140\nstd       5.607403\nmin       2.000000\n25%      11.500000\n50%      14.000000\n75%      19.000000\nmax      28.000000\nName: fea_num, dtype: float64  fscore_large = result.loc[merge_test[ merge_test_fscore ]   0.501, :]\nfscore_large[ fea_num ].describe()  count    71.000000\nmean     14.845070\nstd       5.484127\nmin       2.000000\n25%      11.500000\n50%      14.000000\n75%      18.000000\nmax      30.000000\nName: fea_num, dtype: float64  accuracy_large = result.loc[merge_test[ merge_test_accuracy ]   0.501, :]\naccuracy_large[ fea_num ].describe()  count    79.000000\nmean     15.518987\nstd       5.322571\nmin       2.000000\n25%      12.000000\n50%      15.000000\n75%      19.500000\nmax      28.000000\nName: fea_num, dtype: float64  accuracy_low = result.loc[merge_test[ merge_test_accuracy ]  = 0.501, :]\naccuracy_low[ fea_num ].describe()  count    35.000000\nmean     12.971429\nstd       5.586147\nmin       2.000000\n25%       9.500000\n50%      13.000000\n75%      15.000000\nmax      30.000000\nName: fea_num, dtype: float64  \u5206\u522b\u5bf9\u6bd4\u51c6\u786e\u7387\u548cf1 score\u7684\u7edf\u8ba1\u7ed3\u679c\uff0c\u5373\u9ad8\u4e8e50%\u548c\u4f4e\u4e8e50%\u7684\u4e24\u7c7b\u5bf9\u6bd4\u7ed3\u679c\uff0c\u611f\u811a\u51c6\u786e\u7387\u9ad8\u7684\u7279\u5f81\u6570\u4e5f\u591a\uff01  def score_lowandhigh(df, accu_kind):\n    first_test = df.filter(regex= fea_num|merge_test.* )\n    first_test.sort_values( fea_num , inplace=True)\n    first_test.columns = [ fea_num ,  accuracy ,  f1_score ]\n    feature_num = first_test[ fea_num ]\n    first_test.drop( fea_num , axis=1, inplace=True)\n    fig, ax1 = plt.subplots(figsize=(8,6))\n    first_test.plot(ax=ax1, grid=False)\n    ax2 = ax1.twinx()\n    feature_num.plot(ax=ax2, grid=False, label= feature_number(right_axis) , legend=True, color= purple , alpha=0.7)\n    ax1.set_ylabel( accuracy   f1_score , fontsize=16, fontproperties=font)\n    ax2.set_ylabel( feature_number , fontsize=16, fontproperties=font)\n    ax2.legend(loc=1, fontsize=12)\n    ax1.legend(loc=2, fontsize=12)\n    # merge_test_sorted.plot(figsize=(8,6), grid=False)\n    ax1.yaxis.grid(True, linestyle =  -. )\n    ax1.set_xlabel( )\n    plt.title(u \u51c6\u786e\u7387{}\u7684\u80a1\u7968\u7684accuracy\u3001f1_score\u4e0efeature_num .format(accu_kind), fontsize=17, fontproperties=font)  # \u770b\u770b\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u4e8e0.50\u7684\u90a3\u4e9bstocks\u7684\u51c6\u786e\u7387\u548cf1 score\nscore_lowandhigh(accuracy_large, u \u9ad8\u4e8e0.50 )   # \u770b\u770b\u5206\u7c7b\u51c6\u786e\u7387\u4f4e\u4e8e0.50\u7684\u90a3\u4e9bstocks\u7684\u51c6\u786e\u7387\u548cf1 score\nscore_lowandhigh(accuracy_low, u \u4f4e\u4e8e0.50 )   accuracy_top = result.loc[merge_test[ merge_test_accuracy ]   0.55, :]\n# \u770b\u770b\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u4e8e0.55\u7684\u90a3\u4e9bstocks\u7684\u51c6\u786e\u7387\u548cf1 score\nscore_lowandhigh(accuracy_top, u \u9ad8\u4e8e0.55 )   \u4e0d\u540c\u7684\u51c6\u786e\u7387\u4e0b\u80a1\u7968\u7279\u5f81\u4e0eaccuracy\u548cf1_score\u7684\u5173\u7cfb\u53ef\u770b\u51fa\uff0c\u8f83\u9ad8\u7684\u51c6\u786e\u7387\u5bf9\u5e94\u7740\u8f83\u9ad8\u7684f1_score\uff0c\u540c\u65f6\uff0c\u7279\u5f81\u4e5f\u8f83\u591a\u3002  \u770b\u770b\u5206\u7c7b\u51c6\u786e\u7387\u9ad8\u4e8e55%\u7684\u90a3\u4e9bstocks\u7684\u7279\u5f81\u90fd\u662f\u5565  accuracy_top_list = result.loc[merge_test[ merge_test_accuracy ]   0.55, :].index.tolist()\nfscore_top_list = result.loc[result[ merge_test_fscore ]   0.55, :].index.tolist()\ntarget_index = list(set(accuracy_top_list)   set(fscore_top_list))\n# len(target_index)  # 20\ntarget_stock = result.loc[target_index, :]\ntarget_stock.head(2)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       fea_num \n       rf_train_accuracy \n       rf_test_accuracy \n       lr_train_accuracy \n       lr_test_accuracy \n       tree_train_accuracy \n       tree_test_accuracy \n       ada_train_accuracy \n       ada_test_accuracy \n       merge_train_accuracy \n       ... \n       rf_test_fscore \n       lr_train_fscore \n       lr_test_fscore \n       tree_train_fscore \n       tree_test_fscore \n       ada_train_fscore \n       ada_test_fscore \n       merge_train_fscore \n       merge_test_fscore \n       fea_name \n     \n     \n       stockid \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       601877 \n       14.0 \n       0.8831 \n       0.5556 \n       0.5831 \n       0.5556 \n       0.8085 \n       0.6349 \n       1.0 \n       0.5476 \n       1.0000 \n       ... \n       0.6585 \n       0.5647 \n       0.6818 \n       0.7994 \n       0.6714 \n       1.0 \n       0.6275 \n       1.000 \n       0.6667 \n       sz_volume::rocmean1::fimean5::Lag5mean5::hs300... \n     \n     \n       600332 \n       19.0 \n       0.9942 \n       0.5435 \n       0.5792 \n       0.5870 \n       0.8533 \n       0.5652 \n       1.0 \n       0.4783 \n       0.9981 \n       ... \n       0.5962 \n       0.5381 \n       0.5000 \n       0.8538 \n       0.6078 \n       1.0 \n       0.5000 \n       0.998 \n       0.5859 \n       close_roll_20_ppmean90::fimean5::high_pctchang... \n     \n     2 rows \u00d7 22 columns   target_stock.describe()   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       fea_num \n       rf_train_accuracy \n       rf_test_accuracy \n       lr_train_accuracy \n       lr_test_accuracy \n       tree_train_accuracy \n       tree_test_accuracy \n       ada_train_accuracy \n       ada_test_accuracy \n       merge_train_accuracy \n       ... \n       rf_train_fscore \n       rf_test_fscore \n       lr_train_fscore \n       lr_test_fscore \n       tree_train_fscore \n       tree_test_fscore \n       ada_train_fscore \n       ada_test_fscore \n       merge_train_fscore \n       merge_test_fscore \n     \n   \n   \n     \n       count \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       ... \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n       20.000000 \n     \n     \n       mean \n       15.950000 \n       0.940980 \n       0.559530 \n       0.583380 \n       0.553630 \n       0.856590 \n       0.565900 \n       0.999245 \n       0.527110 \n       0.989585 \n       ... \n       0.941895 \n       0.584980 \n       0.599625 \n       0.573735 \n       0.868400 \n       0.614970 \n       0.999255 \n       0.553925 \n       0.989940 \n       0.615905 \n     \n     \n       std \n       3.872644 \n       0.045878 \n       0.038063 \n       0.016712 \n       0.049804 \n       0.080882 \n       0.038997 \n       0.001889 \n       0.045610 \n       0.017169 \n       ... \n       0.045279 \n       0.085217 \n       0.044295 \n       0.093469 \n       0.067407 \n       0.051002 \n       0.001867 \n       0.077192 \n       0.016303 \n       0.036228 \n     \n     \n       min \n       10.000000 \n       0.838000 \n       0.493400 \n       0.555800 \n       0.457400 \n       0.709500 \n       0.503600 \n       0.992200 \n       0.428600 \n       0.933300 \n       ... \n       0.842600 \n       0.384000 \n       0.510100 \n       0.333300 \n       0.768900 \n       0.527500 \n       0.992300 \n       0.371400 \n       0.938100 \n       0.552200 \n     \n     \n       25% \n       13.000000 \n       0.924775 \n       0.537600 \n       0.567525 \n       0.511600 \n       0.795325 \n       0.527800 \n       1.000000 \n       0.481425 \n       0.987825 \n       ... \n       0.923500 \n       0.557475 \n       0.579100 \n       0.510925 \n       0.810450 \n       0.571400 \n       1.000000 \n       0.497575 \n       0.988250 \n       0.589375 \n     \n     \n       50% \n       14.500000 \n       0.948400 \n       0.562050 \n       0.584250 \n       0.555600 \n       0.859800 \n       0.565450 \n       1.000000 \n       0.528300 \n       0.997700 \n       ... \n       0.948750 \n       0.601850 \n       0.601500 \n       0.570900 \n       0.861700 \n       0.610650 \n       1.000000 \n       0.566200 \n       0.997700 \n       0.610000 \n     \n     \n       75% \n       19.000000 \n       0.983525 \n       0.578025 \n       0.593950 \n       0.586400 \n       0.933800 \n       0.596350 \n       1.000000 \n       0.563975 \n       1.000000 \n       ... \n       0.983925 \n       0.654000 \n       0.621475 \n       0.666700 \n       0.933250 \n       0.664450 \n       1.000000 \n       0.604250 \n       1.000000 \n       0.639975 \n     \n     \n       max \n       23.000000 \n       0.995500 \n       0.641000 \n       0.627600 \n       0.642900 \n       0.992800 \n       0.634900 \n       1.000000 \n       0.594800 \n       1.000000 \n       ... \n       0.995500 \n       0.681800 \n       0.677200 \n       0.681800 \n       0.992900 \n       0.691900 \n       1.000000 \n       0.700600 \n       1.000000 \n       0.695700 \n     \n     8 rows \u00d7 21 columns   target_stock\u7684\u7279\u5f81\u6570\u76ee\u6700\u5c11\u768410\u4e2a\uff0c\u6700\u591a\u768423\u4e2a\uff0c\u5e73\u574715\u4e2a\u5de6\u53f3\uff0c\u5373\u5206\u7c7b\u6548\u679c\u8f83\u597d\u7684stocks\u7684\u7279\u5f81\u6570\u76ee\u65e2\u4e0d\u592a\u5c11\u4e5f\u4e0d\u592a\u591a\uff0c\u90a3\u8fd9\u4e9b\u80a1\u7968\u90fd\u4f7f\u7528\u4e86\u54ea\u4e9b\u7279\u5f81\u5462\uff0c\u53ef\u5426\u7528\u8fd9\u4e9b\u7279\u5f81\u4f5c\u4e3a\u6240\u6709\u80a1\u7968\u7684\u6700\u7ec8\u7684\u5206\u7c7b\u7279\u5f81\u5462\uff1f  target_stock[ fea_name ].head(2)  stockid\n002241    volume_roll_5_ppmean90::rocmean1::close_roll_3...\n600703    Lag20mean90::rocmean1::ccimean1::rsv9mean1::vo...\nName: fea_name, dtype: object  top_fea_name = target_stock[ fea_name ].str.split( :: )\ntop_fea_name.head(2)  stockid\n601877    [sz_volume, rocmean1, fimean5, Lag5mean5, hs30...\n600332    [close_roll_20_ppmean90, fimean5, high_pctchan...\nName: fea_name, dtype: object  \u53d6\u572820\u652f\u80a1\u7968\u4e2d\u516c\u5171\u7279\u5f81\u6b21\u6570\u8d85\u8fc73\u6b21\u7684\u90a3\u4e9b\u7279\u5f81  tip_fea_list = []\nfor i in range(len(top_fea_name)):\n    tip_fea_list.extend(top_fea_name[i])\nfname, fcount = np.unique(tip_fea_list, return_counts=True)\nfea_sorted = sorted(zip(fname, fcount), key=lambda x: x[1], reverse=True)\nfea_sorted = filter(lambda x: x[1] 3, fea_sorted)\n# len(fea_sorted)  # 25\nfeature_final = [i[0] for i in fea_sorted]\nfeature_final[:3]  [u'rsimean1', u'rocmean1', u'obvmean5']", 
            "title": "\u5206\u7c7b\u7ed3\u679c\u5206\u6790"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_9", 
            "text": "\u4f7f\u7528\u9009\u62e9\u768425\u4e2a\u7279\u5f81\u5bf9\u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684stocks\u91cd\u65b0\u8fdb\u884c\u5206\u7c7b\u8bad\u7ec3  stock_tackle(accuracy_low_index, stocks, feature_final, 0)\n# \u5206\u7c7b\u7ed3\u679c\u5728\u6b64\u7565\u8fc7...  \u4f7f\u7528\u9009\u5b9a\u768425\u4e2a\u7279\u5f81\u5bf9\u7b2c\u4e00\u6b21\u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u80a1\u7968\u91cd\u65b0\u8fdb\u884c\u5206\u7c7b\u8bc4\u4f30\uff0c\u7ed3\u679c\u5982\u4e0b\uff1a  # \u8bfb\u5165\u6587\u4ef6\naccuracy_ress = pd.read_csv( ./classification_result_ress_accuracy.csv ,encoding= utf-8 , dtype=str)\naccuracy_ress.set_index( stockid , inplace=True)\nfscore_ress = pd.read_csv( ./classification_result_ress_fscore.csv ,encoding= utf-8 , dtype=str)\nfscore_ress.set_index( stockid , inplace=True)\nresult_ress = pd.concat([accuracy_ress, fscore_ress], axis=1)\nresult_ress.drop( data_shape , axis=1, inplace=True)\nresult_ress = result_ress.astype(np.float)\nresult_ress.head(2)   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       rf_train_accuracy \n       rf_test_accuracy \n       lr_train_accuracy \n       lr_test_accuracy \n       tree_train_accuracy \n       tree_test_accuracy \n       ada_train_accuracy \n       ada_test_accuracy \n       merge_train_accuracy \n       merge_test_accuracy \n       rf_train_fscore \n       rf_test_fscore \n       lr_train_fscore \n       lr_test_fscore \n       tree_train_fscore \n       tree_test_fscore \n       ada_train_fscore \n       ada_test_fscore \n       merge_train_fscore \n       merge_test_fscore \n     \n     \n       stockid \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       600999 \n       0.9892 \n       0.5573 \n       0.5732 \n       0.4351 \n       0.8889 \n       0.5496 \n       1.0 \n       0.5038 \n       1.0000 \n       0.5191 \n       0.9888 \n       0.4314 \n       0.5428 \n       0.1778 \n       0.8898 \n       0.5124 \n       1.0 \n       0.3299 \n       1.0000 \n       0.3762 \n     \n     \n       002352 \n       0.9925 \n       0.5141 \n       0.5593 \n       0.5634 \n       0.7878 \n       0.4366 \n       1.0 \n       0.4789 \n       0.9925 \n       0.4859 \n       0.9931 \n       0.6057 \n       0.6728 \n       0.6265 \n       0.8265 \n       0.4872 \n       1.0 \n       0.5432 \n       0.9932 \n       0.5576 \n     \n      result_ress.describe()   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       rf_train_accuracy \n       rf_test_accuracy \n       lr_train_accuracy \n       lr_test_accuracy \n       tree_train_accuracy \n       tree_test_accuracy \n       ada_train_accuracy \n       ada_test_accuracy \n       merge_train_accuracy \n       merge_test_accuracy \n       rf_train_fscore \n       rf_test_fscore \n       lr_train_fscore \n       lr_test_fscore \n       tree_train_fscore \n       tree_test_fscore \n       ada_train_fscore \n       ada_test_fscore \n       merge_train_fscore \n       merge_test_fscore \n     \n   \n   \n     \n       count \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n       35.000000 \n     \n     \n       mean \n       0.966860 \n       0.505991 \n       0.574640 \n       0.502557 \n       0.845254 \n       0.507454 \n       0.997851 \n       0.498680 \n       0.991723 \n       0.506531 \n       0.967537 \n       0.484546 \n       0.588957 \n       0.504066 \n       0.841951 \n       0.490154 \n       0.997880 \n       0.495414 \n       0.991934 \n       0.502054 \n     \n     \n       std \n       0.030945 \n       0.049303 \n       0.024525 \n       0.039650 \n       0.081260 \n       0.054788 \n       0.006110 \n       0.043482 \n       0.013401 \n       0.038681 \n       0.029980 \n       0.107487 \n       0.061700 \n       0.125887 \n       0.087532 \n       0.092912 \n       0.006022 \n       0.078563 \n       0.012882 \n       0.084782 \n     \n     \n       min \n       0.890700 \n       0.417500 \n       0.541000 \n       0.435100 \n       0.661800 \n       0.418900 \n       0.967500 \n       0.421100 \n       0.939400 \n       0.426400 \n       0.896300 \n       0.256400 \n       0.349100 \n       0.177800 \n       0.586700 \n       0.335900 \n       0.968000 \n       0.329900 \n       0.942100 \n       0.273500 \n     \n     \n       25% \n       0.948100 \n       0.467400 \n       0.558850 \n       0.472950 \n       0.793450 \n       0.459600 \n       1.000000 \n       0.466000 \n       0.991750 \n       0.474700 \n       0.950150 \n       0.406200 \n       0.553900 \n       0.425550 \n       0.795500 \n       0.408250 \n       1.000000 \n       0.451400 \n       0.992150 \n       0.449500 \n     \n     \n       50% \n       0.976000 \n       0.506200 \n       0.572800 \n       0.503100 \n       0.860200 \n       0.500000 \n       1.000000 \n       0.500000 \n       0.997000 \n       0.506300 \n       0.976100 \n       0.493500 \n       0.602300 \n       0.528700 \n       0.858100 \n       0.493000 \n       1.000000 \n       0.500000 \n       0.997100 \n       0.490300 \n     \n     \n       75% \n       0.991400 \n       0.548750 \n       0.583850 \n       0.531150 \n       0.892400 \n       0.538950 \n       1.000000 \n       0.524000 \n       1.000000 \n       0.523550 \n       0.991400 \n       0.565150 \n       0.633400 \n       0.604150 \n       0.891800 \n       0.565350 \n       1.000000 \n       0.551500 \n       1.000000 \n       0.578650 \n     \n     \n       max \n       1.000000 \n       0.611100 \n       0.665100 \n       0.610000 \n       0.954200 \n       0.638900 \n       1.000000 \n       0.638900 \n       1.000000 \n       0.629600 \n       1.000000 \n       0.679200 \n       0.684800 \n       0.678000 \n       0.955100 \n       0.681600 \n       1.000000 \n       0.682900 \n       1.000000 \n       0.661000 \n     \n      # \u5206\u7c7b\u51c6\u786e\u7387\u4f4e\u4e8e50%\u7684\u6bd4\u4f8b\naccuracy_low_num_ress = merge_test_ress.loc[merge_test_ress[ merge_test_accuracy ]  = 0.501, :].shape[0]\nnp.float(accuracy_low_num_ress) / merge_test_ress.shape[0] * 100  40.0  # \u5206\u7c7bf1_score\u4f4e\u4e8e50%\u7684\u6bd4\u4f8b\nmerge_test_ress = result_ress[[ merge_test_accuracy ,  merge_test_fscore ]]\nfscore_low_num_ress = merge_test_ress.loc[merge_test_ress[ merge_test_fscore ]  = 0.501, :].shape[0]\nnp.float(fscore_low_num_ress) / merge_test_ress.shape[0] * 100  57.14285714285714  test_score_count(merge_test_ress[ merge_test_accuracy ], [u \u51c6\u786e\u7387 0.50 ,u \u51c6\u786e\u7387 =0.50 ],u \u51c6\u786e\u7387_ress )   test_score_count(merge_test_ress[ merge_test_fscore ], [u f1_score =0.50 ,u f1_score 0.50 ],u f1_score_ress )   # \u4f7f\u7528\u7279\u5b9a\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u8bc4\u4f30\u4e0e\u4e4b\u524d\u7684\u5206\u7c7b\u51c6\u786e\u7387\u5bf9\u6bd4\nfig, ax = plt.subplots(figsize=(8,6))\nmerge_test_ress_sorted = merge_test_ress.sort_index()\nmerge_test_ress_sorted.columns = [ accuracy ,  f1_score ]\nmerge_test_ress_sorted[ accuracy ].plot(ax=ax, grid=False, linewidth=2, label= accuracy_ress , legend=True, color= red , style= -. ,alpha=0.7)\n# merge_test_ress_sorted[ f1_score ].plot(ax=ax, grid=False, label= f1_score_ress , legend=True,linewidth=4, color= purple ,style= -. ,alpha=0.8)\nmerge_low_sorted = merge_test_sorted.loc[merge_test_sorted[ accuracy ]   0.501, :]\nmerge_low_sorted  = merge_low_sorted .sort_index()\nmerge_low_sorted[ accuracy ].plot(ax=ax,grid=False,linewidth=2,alpha=0.9,legend=True, label= accuracy )\n# merge_low_sorted[ f1_score ].plot(ax=ax,grid=False,linewidth=2,alpha=0.9,legend=True, label= fscore )\nplt.gca().yaxis.grid(True, linestyle =  -. )\nplt.xlabel( )\nplt.ylabel(u accuracy , fontsize=16)\nplt.title(u \u4f7f\u7528\u7279\u5b9a\u7279\u5f81\u8fdb\u884c\u5206\u7c7b\u8bc4\u4f30\u4e0e\u4e4b\u524d\u7684\u5206\u7c7b\u5bf9\u6bd4 , fontsize=20, fontproperties=font)  matplotlib.text.Text at 0x7f8502d89ed0    \u5404\u79cd\u5206\u7c7b\u5668\u5728\u4f7f\u7528\u7279\u5b9a\u7279\u5f81\u91cd\u65b0\u5206\u7c7b\u7684\u7684\u8868\u73b0  test_score_plot(result_ress, accuracy_regex, u \u51c6\u786e\u7387_ress )   test_score_plot(result_ress, fscore_regex, u f1_score_ress )   \u5728\u4f7f\u7528\u9009\u5b9a\u768425\u4e2a\u7279\u5f81\u5bf9\u7b2c\u4e00\u6b21\u5206\u7c7b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\u7684\u90a3\u4e9b\u80a1\u7968\u8fdb\u884c\u91cd\u5206\u7c7b\u6a21\u578b\u6784\u5efa\uff0c\u6574\u4f53\u51c6\u786e\u7387\u6709\u63d0\u9ad8\uff0c\u8bf4\u660e\u7279\u5f81\u9009\u62e9\u5f88\u91cd\u8981\uff01\uff01\uff01  \u5bf9114\u652f\u80a1\u7968\u5206\u522b\u5efa\u7acb\u5206\u7c7b\u6a21\u578b\u9884\u6d4b\u80a1\u4ef7\u6da8\u8dcc\uff0c\u5206\u7c7b\u7ed3\u679c\u8be6\u60c5\u5c31\u4e0d\u5217\u51fa\u4e86\uff0c\u5728\u8fd9\u4e3e\u4e00\u4e2a\u5b9e\u4f8b\uff0c\u5c31\u62ff\u5728\u7b2c\u4e8c\u6b21\u91cd\u65b0\u5206\u7c7b\u51c6\u786e\u7387\u6700\u9ad8\u7684000063\u8fd9\u652f\u80a1\u7968\u4e3a\u4f8b\uff1a  result_ress_sorted_ = result_ress.sort_values( merge_test_accuracy , ascending=False)\nresult_ress_sorted_.head()   \n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }  \n   \n     \n       \n       rf_train_accuracy \n       rf_test_accuracy \n       lr_train_accuracy \n       lr_test_accuracy \n       tree_train_accuracy \n       tree_test_accuracy \n       ada_train_accuracy \n       ada_test_accuracy \n       merge_train_accuracy \n       merge_test_accuracy \n       rf_train_fscore \n       rf_test_fscore \n       lr_train_fscore \n       lr_test_fscore \n       tree_train_fscore \n       tree_test_fscore \n       ada_train_fscore \n       ada_test_fscore \n       merge_train_fscore \n       merge_test_fscore \n     \n     \n       stockid \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n       \n     \n   \n   \n     \n       000063 \n       0.9984 \n       0.6111 \n       0.5698 \n       0.5370 \n       0.9524 \n       0.6389 \n       1.0000 \n       0.6389 \n       1.0000 \n       0.6296 \n       0.9984 \n       0.6719 \n       0.6147 \n       0.6377 \n       0.9532 \n       0.6422 \n       1.0000 \n       0.6829 \n       1.0000 \n       0.6610 \n     \n     \n       300070 \n       0.9728 \n       0.4898 \n       0.5725 \n       0.5204 \n       0.8297 \n       0.5000 \n       0.9982 \n       0.5714 \n       0.9783 \n       0.5816 \n       0.9731 \n       0.3902 \n       0.5986 \n       0.3896 \n       0.8058 \n       0.3951 \n       0.9982 \n       0.6182 \n       0.9783 \n       0.6019 \n     \n     \n       600741 \n       0.8914 \n       0.5414 \n       0.5837 \n       0.5541 \n       0.7862 \n       0.4904 \n       0.9966 \n       0.5350 \n       0.9593 \n       0.5478 \n       0.8963 \n       0.5862 \n       0.6175 \n       0.6196 \n       0.8000 \n       0.5699 \n       0.9967 \n       0.5922 \n       0.9605 \n       0.6162 \n     \n     \n       601601 \n       0.9414 \n       0.4914 \n       0.5566 \n       0.5143 \n       0.8879 \n       0.5257 \n       1.0000 \n       0.5429 \n       0.9970 \n       0.5429 \n       0.9428 \n       0.5389 \n       0.6049 \n       0.6222 \n       0.8917 \n       0.5608 \n       1.0000 \n       0.5876 \n       0.9971 \n       0.5876 \n     \n     \n       300133 \n       0.9936 \n       0.5904 \n       0.5906 \n       0.5422 \n       0.9424 \n       0.6024 \n       1.0000 \n       0.4578 \n       1.0000 \n       0.5422 \n       0.9937 \n       0.6792 \n       0.6082 \n       0.6780 \n       0.9434 \n       0.6118 \n       1.0000 \n       0.5455 \n       1.0000 \n       0.6275 \n     \n      result_ress_sorted_.loc[ 000063 ,  merge_test_accuracy ]  0.62960000000000005  result.loc[ 000063 ,  merge_test_accuracy ]  0.46300000000000002  000063\u80a1\u7968\u5728\u7b2c\u4e00\u6b21\u6784\u5efa\u5206\u7c7b\u6a21\u578b\u7684\u6d4b\u8bd5\u96c6\u7684\u51c6\u786e\u7387\u4e3a0.463\uff0c\u800c\u5728\u7b2c\u4e8c\u6b21\u4f7f\u7528\u9009\u5b9a\u7684\u7279\u5f81\u8fdb\u884c\u7684\u5206\u7c7b\u6a21\u578b\u6784\u5efa\u7684\u51c6\u786e\u7387\u4e3a0.629\uff0c\u7cbe\u786e\u7387\uff0c\u53ec\u56de\u7387\u53caf1_score\u5c31\u4e0d\u4e00\u4e00\u5217\u51fa\u6765\u4e86\uff0c\u4e0d\u540c\u5206\u7c7b\u5668\u7684\u5206\u7c7b\u6548\u679c\u53ef\u53c2\u8003\u89c1\u4e0b\u9762\u7684\u6df7\u6dc6\u77e9\u9635\u56fe\uff0c\u5176\u4e2d\uff0c\u524d5\u526f\u56fe\u4e3a\u6df7\u6dc6\u77e9\u9635\uff0c\u540e\u4e00\u5f20\u4e3a\u8be5\u80a1\u7968\u7684close_price\u548cpct_change\u3002  000063\u6df7\u6dc6\u77e9\u9635\u56fe", 
            "title": "\u4f7f\u7528\u9009\u5b9a\u7279\u5f81\u91cd\u65b0\u5efa\u6a21"
        }, 
        {
            "location": "/machine_learning/hs300_classification/hs300_classificatio/#_10", 
            "text": "\u672c\u9879\u76ee\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5206\u7c7b\u7b97\u6cd5\u9884\u6d4b\u90e8\u5206\u6caa\u6df1300\u80a1\u7968\u7684\u6da8\u8dcc\u60c5\u51b5\u3002\u6570\u636e\u662f\u4f7f\u7528tushare\u63d0\u4f9b\u7684API\u91c7\u96c62012-2017\u5e74\u6caa\u6df1300\u80a1\u7968\u7684\u4fe1\u606f\uff0c\u540c\u65f6\uff0c\u4e5f\u6536\u96c6\u4e86\u540c\u65f6\u671f\u7684\u5404\u80a1\u6307\u3001\u80a1\u7968\u57fa\u672c\u9762\u3001\u7ecf\u6d4e\u6570\u636e\u7b49\u76f8\u5173\u4fe1\u606f\uff0c\u91c7\u7528sklearn\u7684\u5206\u7c7b\u6a21\u578b\uff0c\u5982\u968f\u673a\u68ee\u6797\u3001LogisticRegression\u7b49\u5206\u7c7b\u5668\u5bf9\u90e8\u5206\u6caa\u6df1300\u80a1\u7968\u7684\u6da8\u8dcc\u60c5\u51b5\u8fdb\u884c\u9884\u6d4b\u3002  \u5206\u7c7b\u5efa\u6a21\u4f7f\u7528\u7684\u80a1\u7968\u6570\u636e\u662f\u6e90\u81ea\u662f\u6caa\u6df1300\u4e2d\u5747\u4ef7\u572810-30\u5143\u4e4b\u95f4\u5e76\u4e14\u7f3a\u5931\u6570\u636e\u5c11\u4e8e20%\u7684114\u652f\u80a1\u7968\u4fe1\u606f\uff0c\u7279\u5f81\u5de5\u7a0b\u9009\u62e9\u7684\u7279\u5f81\u5305\u62ec\u4e86\u80a1\u7968\u4ef7\u683c\u3001\u6210\u4ea4\u91cf\u4fe1\u606f\uff0c\u57fa\u4e8e\u80a1\u7968\u4ef7\u683c\u548c\u6210\u4ea4\u91cf\u8ba1\u7b97\u7684\u5176\u4ed6\u80a1\u7968\u6307\u6807\uff0c\u56fd\u5185\u540c\u65f6\u671f\u80a1\u6307\u3001\u7ecf\u6d4e\u4ee5\u53ca\u80a1\u7968\u7684\u57fa\u672c\u9762\u4fe1\u606f\u7b49\u3002\u4f7f\u7528\u9012\u5f52\u7279\u5f81\u6d88\u9664(RFE)\u7b49\u4e09\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u9009\u51fa\u91cd\u8981\u7684\u7279\u5f81\uff0c\u7136\u540e\u7b80\u5355\u7c97\u66b4\u5730\u7528\u4e09\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u9009\u62e9\u7684\u7279\u5f81\u7684\u4ea4\u96c6\u4e3a\u5206\u7c7b\u6a21\u578b\u7684\u8bad\u7ec3\u7279\u5f81\u3002\u4f7f\u7528sklearn\u8fdb\u884c\u5206\u7c7b\u6a21\u578b\u7684\u6784\u5efa\uff0c\u5177\u4f53\u800c\u8a00\u662f\u91c7\u7528\u4e86\u968f\u673a\u68ee\u6797\u3001LogisticRegression\u3001\u51b3\u7b56\u6811\u3001Adaboost\u56db\u79cd\u5206\u7c7b\u5668\u5206\u522b\u6784\u5efa\u76f8\u5e94\u7684\u5206\u7c7b\u6a21\u578b\uff0c\u6700\u540e\u4f7f\u7528softVoting\u5bf9\u4e0a\u8ff0\u56db\u7c7b\u5206\u7c7b\u5668\u8fdb\u884c\u6a21\u578b\u878d\u5408\uff0c\u4ece\u800c\u5b8c\u6210\u5206\u7c7b\u6a21\u578b\u7684\u6784\u5efa\u3002  \u5206\u7c7b\u6a21\u578b\u5728\u6d4b\u8bd5\u96c6\u7684\u8868\u73b0\u4e3a\uff0c\u670940%\u5de6\u53f3\u7684\u80a1\u7968\u7684\u5206\u7c7b\u9884\u6d4b\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\uff0c\u5206\u6790\u5206\u7c7b\u7ed3\u679c\u80fd\u53d1\u73b0\uff0c\u5206\u7c7b\u51c6\u786e\u7387\u8f83\u9ad8\u7684stocks\u7684\u7279\u5f81\u6570\u91cf\u8f83\u591a\uff0c\u4e3a\u6b64\uff0c\u4f7f\u7528\u5206\u7c7b\u7ed3\u679c\u4e2d\u51c6\u786e\u7387\u9ad8\u4e8e55%\u7684\u80a1\u7968\u7684\u7279\u5f81\u4e3a\u7279\u5b9a\u7684\u7279\u5f81\u5bf9\u90a340%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u4f4e\u7684\u80a1\u7968\u91cd\u65b0\u8fdb\u884c\u5206\u7c7b\u8bad\u7ec3\uff0c\u7ed3\u679c\u4e3a\u670940%\u7684\u80a1\u7968\u7684\u5206\u7c7b\u51c6\u786e\u7387\u4ecd\u65e7\u4e0d\u9ad8\u4e8e50%\uff0c\u670960%\u7684\u5728\u7b2c\u4e00\u6b21\u5206\u7c7b\u4e2d\u7684\u51c6\u786e\u7387\u4e0d\u9ad8\u4e8e50%\uff0c\u5728\u7b2c\u4e8c\u6b21\u4f7f\u7528\u9009\u5b9a\u7684\u7279\u5f81\u8bad\u7ec3\u540e\u5176\u51c6\u786e\u7387\u8d85\u8fc750%\uff0c\u8bf4\u660e\u9009\u5b9a\u7684\u7279\u5f81\u5bf9\u5206\u7c7b\u6a21\u578b\u6784\u5efa\u662f\u6709\u6548\u7684\u3002  \u76ee\u524d\uff0c\u5728\u91cf\u5316\u6295\u8d44\u9886\u57df\u6709\u5f88\u591a\u4eba\u5728\u7528\u4e00\u4e9b\u673a\u5668\u5b66\u4e60\u7684\u7b97\u6cd5\u8fdb\u884cresearch\uff0c\u5982\u7528\u81ea\u7136\u8bed\u8a00\u5904\u7406\u6765\u9009\u80a1\uff0c\u7ebf\u6027\u56de\u5f52\u7684\u03b2\u7cfb\u6570\u3001\u5206\u7c7b\u9884\u6d4b\u7b49\u7b49\uff0c\u672c\u9879\u76ee\u5c31\u662f\u5229\u7528sklearn\u5c01\u88c5\u7684\u5206\u7c7b\u7b97\u6cd5\u5bf9\u80a1\u7968\u6da8\u8dcc\u8fdb\u884c\u9884\u6d4b\uff0c\u672c\u8d28\u662f\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u5206\u7c7b\u95ee\u9898\u3002\u4e3a\u4e86\u7b80\u5316\u6d41\u7a0b\uff0c\u5728\u6784\u5efa\u7684\u5206\u7c7b\u6a21\u578b\u7684\u65f6\u5019\u91c7\u7528\u7684\u662f\u4e8c\u5206\u7c7b\uff0c\u540c\u65f6\u7531\u4e8e\u6700\u7ec8\u5206\u7c7b\u6548\u679c\u8f83\u5dee\uff0c\u56e0\u6b64\u4e0d\u5177\u5907\u5b9e\u9645\u610f\u4e49\u3002\u540e\u7eed\uff0c\u53ef\u8fdb\u884c\u591a\u5206\u7c7b\u6a21\u578b\u6784\u5efa\uff0c\u540c\u65f6\u5e94\u91c7\u7528\u66f4\u591a\u6709\u6548\u7684\u7279\u5f81\uff0c\u7ed3\u5408\u5176\u4ed6\u65b9\u6cd5\u6bd4\u5982\u52a0\u5165\u81ea\u7136\u8bed\u8a00\u5904\u7406\u7684\u624b\u6bb5\u5bf9\u80a1\u7968\u7684\u65b0\u95fb\u7c7b\u4fe1\u606f\u8fdb\u884c\u91c7\u96c6\u548c\u5206\u6790\u5e76\u52a0\u5165\u5230\u6a21\u578b\u4e2d\uff0c\u4ee5\u63d0\u9ad8\u6a21\u578b\u7684\u9884\u6d4b\u7cbe\u51c6\u6027\u3002", 
            "title": "\u603b\u7ed3"
        }
    ]
}